{
  "schema": "1.0.1", "pid": 18802, "time": "2024-02-29 22:27:00", "start_ts": 11018678,
  "nodes": [
    {
      "name": "[pytorch|profiler|execution_trace|thread]", "id": 2, "rf_id": 0, "parent": 1, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3, "rf_id": 1, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],0,"<None>","cuda","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","None","None"],
      "outputs": [[4,5,0,1,1,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(unsigned char)"]
    },
    {
      "name": "aten::empty", "id": 8, "rf_id": 4, "parent": 7, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],0,"<None>","cuda","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","None","None"],
      "outputs": [[9,10,0,1,1,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(unsigned char)"]
    },
    {
      "name": "nccl:all_reduce", "id": 12, "rf_id": 6, "parent": 11, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[9,10,0,1,1,"cuda:1"]], "input_shapes": [[1]], "input_types": ["Tensor(unsigned char)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 11, "rf_id": 5, "parent": 7, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[9,10,0,1,1,"cuda:1"]],40,94716834063120,1,"allreduce",[],[],4], "input_shapes": [[[1]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(unsigned char)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[9,10,0,1,1,"cuda:1"]]], "output_shapes": [[[1]]], "output_types": ["GenericList[Tensor(unsigned char)]"]
    },
    {
      "name": "record_param_comms", "id": 7, "rf_id": 3, "parent": 6, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [40,94716834063120,1,"barrier",[],[],4], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "c10d::barrier", "id": 6, "rf_id": 2, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::barrier(Tensor tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, int[] device_ids, int timeout) -> __torch__.torch.classes.c10d.Work",
      "inputs": [[4,5,0,1,1,"cuda:1"],"<Object>",[],-1], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(unsigned char)","Object","GenericList[]","Int"],
      "outputs": ["<Object>"], "output_shapes": [[]], "output_types": ["Object"]
    },
    {
      "name": "record_param_comms", "id": 13, "rf_id": 7, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [40,0,1,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::lift_fresh", "id": 17, "rf_id": 9, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[15,16,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[15,16,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 18, "rf_id": 10, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[15,16,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[15,16,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 21, "rf_id": 11, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[19,20,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[19,20,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 22, "rf_id": 12, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[19,20,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[19,20,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 25, "rf_id": 13, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[23,24,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[23,24,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 26, "rf_id": 14, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[23,24,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[23,24,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 29, "rf_id": 15, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[27,28,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[27,28,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 30, "rf_id": 16, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[27,28,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[27,28,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 33, "rf_id": 17, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[31,32,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[31,32,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 34, "rf_id": 18, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[31,32,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[31,32,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 37, "rf_id": 19, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[35,36,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[35,36,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 38, "rf_id": 20, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[35,36,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[35,36,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 41, "rf_id": 21, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[39,40,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[39,40,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 42, "rf_id": 22, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[39,40,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[39,40,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 45, "rf_id": 23, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[43,44,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[43,44,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 46, "rf_id": 24, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[43,44,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[43,44,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::cat", "id": 48, "rf_id": 26, "parent": 47, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[15,16,0,21,8,"cpu"],[19,20,0,21,8,"cpu"],[23,24,0,21,8,"cpu"],[27,28,0,21,8,"cpu"],[31,32,0,21,8,"cpu"],[35,36,0,21,8,"cpu"],[39,40,0,21,8,"cpu"],[43,44,0,21,8,"cpu"]],0], "input_shapes": [[[21],[21],[21],[21],[21],[21],[21],[21]],[]], "input_types": ["GenericList[Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int)]","Int"],
      "outputs": [[49,50,0,168,8,"cpu"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 51, "rf_id": 27, "parent": 47, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[49,50,0,168,8,"cpu"],[8,21]], "input_shapes": [[168],[[],[]]], "input_types": ["Tensor(long int)","GenericList[Int,Int]"],
      "outputs": [[52,50,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::stack", "id": 47, "rf_id": 25, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::stack(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[15,16,0,21,8,"cpu"],[19,20,0,21,8,"cpu"],[23,24,0,21,8,"cpu"],[27,28,0,21,8,"cpu"],[31,32,0,21,8,"cpu"],[35,36,0,21,8,"cpu"],[39,40,0,21,8,"cpu"],[43,44,0,21,8,"cpu"]],0], "input_shapes": [[[21],[21],[21],[21],[21],[21],[21],[21]],[]], "input_types": ["GenericList[Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int)]","Int"],
      "outputs": [[52,50,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::is_pinned", "id": 54, "rf_id": 29, "parent": 53, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::is_pinned(Tensor self, Device? device=None) -> bool",
      "inputs": [[52,50,0,168,8,"cpu"],"<None>"], "input_shapes": [[8,21],[]], "input_types": ["Tensor(long int)","None"],
      "outputs": [false], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::set_", "id": 58, "rf_id": 31, "parent": 55, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::set_.source_Storage_storage_offset(Tensor(a!) self, Storage source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -> Tensor(a!)",
      "inputs": [[56,57,0,0,8,"cpu"],"<Storage>",0,[8,21],[21,1]], "input_shapes": [[0],[],[],[[],[]],[[],[]]], "input_types": ["Tensor(long int)","Storage","Int","GenericList[Int,Int]","GenericList[Int,Int]"],
      "outputs": [[56,59,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 60, "rf_id": 32, "parent": 55, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[56,59,0,168,8,"cpu"],[52,50,0,168,8,"cpu"],false], "input_shapes": [[8,21],[8,21],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[56,59,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_pin_memory", "id": 55, "rf_id": 30, "parent": 53, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_pin_memory(Tensor self, Device? device=None) -> Tensor",
      "inputs": [[52,50,0,168,8,"cpu"],"<None>"], "input_shapes": [[8,21],[]], "input_types": ["Tensor(long int)","None"],
      "outputs": [[56,59,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::pin_memory", "id": 53, "rf_id": 28, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pin_memory(Tensor(a) self, Device? device=None) -> Tensor(a)",
      "inputs": [[52,50,0,168,8,"cpu"],"<None>"], "input_shapes": [[8,21],[]], "input_types": ["Tensor(long int)","None"],
      "outputs": [[56,59,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "enumerate(DataLoader)#_SingleProcessDataLoaderIter.__next__", "id": 14, "rf_id": 8, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 61, "rf_id": 33, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[5],4,0,"cpu",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","Bool","None"],
      "outputs": [[62,50,0,5,8,"cpu"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_strided", "id": 65, "rf_id": 36, "parent": 64, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[5],[1],4,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[66,10,0,5,8,"cuda:1"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 67, "rf_id": 37, "parent": 64, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[66,10,0,5,8,"cuda:1"],[62,50,0,5,8,"cpu"],false], "input_shapes": [[5],[5],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[66,10,0,5,8,"cuda:1"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_to_copy", "id": 64, "rf_id": 35, "parent": 63, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[62,50,0,5,8,"cpu"],4,"<None>","cuda:1","<None>",false,"<None>"], "input_shapes": [[5],[],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","None","Device","None","Bool","None"],
      "outputs": [[66,10,0,5,8,"cuda:1"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 63, "rf_id": 34, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[62,50,0,5,8,"cpu"],"cuda",4,false,false,"<None>"], "input_shapes": [[5],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[66,10,0,5,8,"cuda:1"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 68, "rf_id": 38, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[66,10,0,5,8,"cuda:1"]], "input_shapes": [[5]], "input_types": ["Tensor(long int)"],
      "outputs": [[66,10,0,5,8,"cuda:1"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "nccl:broadcast", "id": 71, "rf_id": 41, "parent": 70, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[66,10,0,5,8,"cuda:1"]], "input_shapes": [[5]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 70, "rf_id": 40, "parent": 69, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[66,10,0,5,8,"cuda:1"]],17,94716841683536,0,"broadcast",[],[],1], "input_shapes": [[[5]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(long int)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[66,10,0,5,8,"cuda:1"]]], "output_shapes": [[[5]]], "output_types": ["GenericList[Tensor(long int)]"]
    },
    {
      "name": "c10d::broadcast_", "id": 69, "rf_id": 39, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::broadcast_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, int root_rank, int root_tensor, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[66,10,0,5,8,"cuda:1"]],"<Object>",0,0,-1], "input_shapes": [[[5]],[],[],[],[]], "input_types": ["GenericList[Tensor(long int)]","Object","Int","Int","Int"],
      "outputs": [[[66,10,0,5,8,"cuda:1"]],"<Object>"], "output_shapes": [[[5]],[]], "output_types": ["GenericList[Tensor(long int)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 72, "rf_id": 42, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [17,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 75, "rf_id": 45, "parent": 74, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[5],[1],4,0,"cpu",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[76,77,0,5,8,"cpu"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 78, "rf_id": 46, "parent": 74, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[76,77,0,5,8,"cpu"],[66,10,0,5,8,"cuda:1"],false], "input_shapes": [[5],[5],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[76,77,0,5,8,"cpu"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_to_copy", "id": 74, "rf_id": 44, "parent": 73, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[66,10,0,5,8,"cuda:1"],4,0,"cpu","<None>",false,"<None>"], "input_shapes": [[5],[],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Bool","None"],
      "outputs": [[76,77,0,5,8,"cpu"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 73, "rf_id": 43, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[66,10,0,5,8,"cuda:1"],4,0,"cpu","<None>",false,false,"<None>"], "input_shapes": [[5],[],[],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[76,77,0,5,8,"cpu"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 80, "rf_id": 48, "parent": 79, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],[],[],0], "input_shapes": [[5],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[81,77,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 79, "rf_id": 47, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],0,0], "input_shapes": [[5],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[81,77,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::gt", "id": 82, "rf_id": 49, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::gt.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[81,77,0,1,8,"cpu"],0], "input_shapes": [[],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[83,84,0,1,1,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 87, "rf_id": 52, "parent": 86, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[83,84,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::item", "id": 86, "rf_id": 51, "parent": 85, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[83,84,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::is_nonzero", "id": 85, "rf_id": 50, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::is_nonzero(Tensor self) -> bool",
      "inputs": [[83,84,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 89, "rf_id": 54, "parent": 88, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],[],[],0], "input_shapes": [[5],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[90,77,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 88, "rf_id": 53, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],0,0], "input_shapes": [[5],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[90,77,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::mul", "id": 93, "rf_id": 55, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[90,77,0,1,8,"cpu"],[91,92,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(long int)","Tensor(long int)"],
      "outputs": [[94,95,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 97, "rf_id": 57, "parent": 96, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],[],[],1], "input_shapes": [[5],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[98,77,1,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 96, "rf_id": 56, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],0,1], "input_shapes": [[5],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[98,77,1,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::gt", "id": 99, "rf_id": 58, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::gt.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[98,77,1,1,8,"cpu"],0], "input_shapes": [[],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[100,101,0,1,1,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 104, "rf_id": 61, "parent": 103, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[100,101,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::item", "id": 103, "rf_id": 60, "parent": 102, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[100,101,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::is_nonzero", "id": 102, "rf_id": 59, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::is_nonzero(Tensor self) -> bool",
      "inputs": [[100,101,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 106, "rf_id": 63, "parent": 105, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],[],[],1], "input_shapes": [[5],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[107,77,1,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 105, "rf_id": 62, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],0,1], "input_shapes": [[5],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[107,77,1,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::mul_", "id": 108, "rf_id": 64, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[94,95,0,1,8,"cpu"],[107,77,1,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(long int)","Tensor(long int)"],
      "outputs": [[94,95,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 110, "rf_id": 66, "parent": 109, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],[],[],2], "input_shapes": [[5],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[111,77,2,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 109, "rf_id": 65, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],0,2], "input_shapes": [[5],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[111,77,2,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::gt", "id": 112, "rf_id": 67, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::gt.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[111,77,2,1,8,"cpu"],0], "input_shapes": [[],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[113,114,0,1,1,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 117, "rf_id": 70, "parent": 116, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[113,114,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [false], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::item", "id": 116, "rf_id": 69, "parent": 115, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[113,114,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [false], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::is_nonzero", "id": 115, "rf_id": 68, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::is_nonzero(Tensor self) -> bool",
      "inputs": [[113,114,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [false], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::add", "id": 120, "rf_id": 71, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[94,95,0,1,8,"cpu"],[118,119,0,1,8,"cpu"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Int"],
      "outputs": [[121,122,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 123, "rf_id": 72, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[56,59,0,168,8,"cpu"],[-1]], "input_shapes": [[8,21],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[124,59,0,168,8,"cpu"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::cat", "id": 125, "rf_id": 73, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[124,59,0,168,8,"cpu"]],0], "input_shapes": [[[168]],[]], "input_types": ["GenericList[Tensor(long int)]","Int"],
      "outputs": [[126,127,0,168,8,"cpu"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_strided", "id": 130, "rf_id": 76, "parent": 129, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[168],[1],4,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[131,132,0,168,8,"cuda:1"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 133, "rf_id": 77, "parent": 129, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[131,132,0,168,8,"cuda:1"],[126,127,0,168,8,"cpu"],false], "input_shapes": [[168],[168],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[131,132,0,168,8,"cuda:1"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_to_copy", "id": 129, "rf_id": 75, "parent": 128, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[126,127,0,168,8,"cpu"],4,0,"cuda:1","<None>",false,"<None>"], "input_shapes": [[168],[],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Bool","None"],
      "outputs": [[131,132,0,168,8,"cuda:1"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 128, "rf_id": 74, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[126,127,0,168,8,"cpu"],4,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[168],[],[],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[131,132,0,168,8,"cuda:1"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "nccl:broadcast", "id": 136, "rf_id": 80, "parent": 135, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[131,132,0,168,8,"cuda:1"]], "input_shapes": [[168]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 135, "rf_id": 79, "parent": 134, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[131,132,0,168,8,"cuda:1"]],18,94716841683536,0,"broadcast",[],[],1], "input_shapes": [[[168]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(long int)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[131,132,0,168,8,"cuda:1"]]], "output_shapes": [[[168]]], "output_types": ["GenericList[Tensor(long int)]"]
    },
    {
      "name": "c10d::broadcast_", "id": 134, "rf_id": 78, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::broadcast_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, int root_rank, int root_tensor, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[131,132,0,168,8,"cuda:1"]],"<Object>",0,0,-1], "input_shapes": [[[168]],[],[],[],[]], "input_types": ["GenericList[Tensor(long int)]","Object","Int","Int","Int"],
      "outputs": [[[131,132,0,168,8,"cuda:1"]],"<Object>"], "output_shapes": [[[168]],[]], "output_types": ["GenericList[Tensor(long int)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 137, "rf_id": 81, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [18,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_local_scalar_dense", "id": 139, "rf_id": 83, "parent": 138, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 138, "rf_id": 82, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 141, "rf_id": 85, "parent": 140, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 140, "rf_id": 84, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 143, "rf_id": 87, "parent": 142, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 142, "rf_id": 86, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::as_strided", "id": 146, "rf_id": 90, "parent": 145, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[131,132,0,168,8,"cuda:1"],[168],[1],0], "input_shapes": [[168],[[]],[[]],[]], "input_types": ["Tensor(long int)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[147,132,0,168,8,"cuda:1"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 145, "rf_id": 89, "parent": 144, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[131,132,0,168,8,"cuda:1"],0,0,168,1], "input_shapes": [[168],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[147,132,0,168,8,"cuda:1"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::narrow", "id": 144, "rf_id": 88, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[131,132,0,168,8,"cuda:1"],0,0,168], "input_shapes": [[168],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int"],
      "outputs": [[147,132,0,168,8,"cuda:1"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 149, "rf_id": 92, "parent": 148, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[90,77,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [8], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 148, "rf_id": 91, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[90,77,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [8], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 151, "rf_id": 94, "parent": 150, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[90,77,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [8], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 150, "rf_id": 93, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[90,77,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [8], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 153, "rf_id": 96, "parent": 152, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[107,77,1,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [21], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 152, "rf_id": 95, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[107,77,1,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [21], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::view", "id": 154, "rf_id": 97, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[147,132,0,168,8,"cuda:1"],[8,21]], "input_shapes": [[168],[[],[]]], "input_types": ["Tensor(long int)","GenericList[Int,Int]"],
      "outputs": [[155,132,0,168,8,"cuda:1"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::add", "id": 158, "rf_id": 98, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[94,95,0,1,8,"cpu"],[156,157,0,1,8,"cpu"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Int"],
      "outputs": [[159,160,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 161, "rf_id": 99, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[155,132,0,168,8,"cuda:1"],4,false,false,"<None>"], "input_shapes": [[8,21],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Bool","Bool","None"],
      "outputs": [[155,132,0,168,8,"cuda:1"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 163, "rf_id": 101, "parent": 162, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[155,132,0,168,8,"cuda:1"],[8,21],[21,1],0], "input_shapes": [[8,21],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[159,132,0,168,8,"cuda:1"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 162, "rf_id": 100, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[155,132,0,168,8,"cuda:1"],0,0,9223372036854775807,1], "input_shapes": [[8,21],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[159,132,0,168,8,"cuda:1"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 165, "rf_id": 103, "parent": 164, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[159,132,0,168,8,"cuda:1"],[8,20],[21,1],1], "input_shapes": [[8,21],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[121,132,1,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 164, "rf_id": 102, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[159,132,0,168,8,"cuda:1"],1,1,9223372036854775807,1], "input_shapes": [[8,21],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[121,132,1,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 169, "rf_id": 107, "parent": 168, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],4,0,"cuda:1","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[170,171,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_like", "id": 168, "rf_id": 106, "parent": 167, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[121,132,1,160,8,"cuda:1"],4,0,"cuda:1","<None>",0], "input_shapes": [[8,20],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Int"],
      "outputs": [[170,171,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 172, "rf_id": 108, "parent": 167, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[170,171,0,160,8,"cuda:1"],[121,132,1,160,8,"cuda:1"],false], "input_shapes": [[8,20],[8,20],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[170,171,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 167, "rf_id": 105, "parent": 166, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[121,132,1,160,8,"cuda:1"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[170,171,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::contiguous", "id": 166, "rf_id": 104, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[121,132,1,160,8,"cuda:1"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[170,171,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 174, "rf_id": 110, "parent": 173, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[155,132,0,168,8,"cuda:1"],[8,21],[21,1],0], "input_shapes": [[8,21],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[175,132,0,168,8,"cuda:1"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 173, "rf_id": 109, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[155,132,0,168,8,"cuda:1"],0,0,9223372036854775807,1], "input_shapes": [[8,21],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[175,132,0,168,8,"cuda:1"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 177, "rf_id": 112, "parent": 176, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[175,132,0,168,8,"cuda:1"],[8,20],[21,1],0], "input_shapes": [[8,21],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[178,132,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 176, "rf_id": 111, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[175,132,0,168,8,"cuda:1"],1,0,-1,1], "input_shapes": [[8,21],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[178,132,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 182, "rf_id": 116, "parent": 181, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],4,0,"cuda:1","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[183,184,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_like", "id": 181, "rf_id": 115, "parent": 180, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[178,132,0,160,8,"cuda:1"],4,0,"cuda:1","<None>",0], "input_shapes": [[8,20],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Int"],
      "outputs": [[183,184,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 185, "rf_id": 117, "parent": 180, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[183,184,0,160,8,"cuda:1"],[178,132,0,160,8,"cuda:1"],false], "input_shapes": [[8,20],[8,20],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[183,184,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 180, "rf_id": 114, "parent": 179, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[178,132,0,160,8,"cuda:1"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[183,184,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::contiguous", "id": 179, "rf_id": 113, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[178,132,0,160,8,"cuda:1"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[183,184,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 187, "rf_id": 119, "parent": 186, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1,20,20],6,"<None>","cpu",false,"<None>"], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","None","Device","Bool","None"],
      "outputs": [[188,189,0,400,4,"cpu"]], "output_shapes": [[1,20,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::fill_", "id": 190, "rf_id": 120, "parent": 186, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[188,189,0,400,4,"cpu"],1.000000], "input_shapes": [[1,20,20],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [[188,189,0,400,4,"cpu"]], "output_shapes": [[1,20,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::ones", "id": 186, "rf_id": 118, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ones(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1,20,20],"<None>","<None>","cpu",false], "input_shapes": [[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","None","None","Device","Bool"],
      "outputs": [[188,189,0,400,4,"cpu"]], "output_shapes": [[1,20,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::tril", "id": 191, "rf_id": 121, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::tril(Tensor self, int diagonal=0) -> Tensor",
      "inputs": [[188,189,0,400,4,"cpu"],0], "input_shapes": [[1,20,20],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[192,193,0,400,4,"cpu"]], "output_shapes": [[1,20,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 194, "rf_id": 122, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[192,193,0,400,4,"cpu"],[1,1,20,20]], "input_shapes": [[1,20,20],[[],[],[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[189,193,0,400,4,"cpu"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 196, "rf_id": 124, "parent": 195, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],6,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","None","Device","Bool","None"],
      "outputs": [[197,198,0,160,4,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::fill_", "id": 199, "rf_id": 125, "parent": 195, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[197,198,0,160,4,"cuda:1"],1.000000], "input_shapes": [[8,20],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [[197,198,0,160,4,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::ones", "id": 195, "rf_id": 123, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ones(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[8,20],6,"<None>","cuda:1",false], "input_shapes": [[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","None","Device","Bool"],
      "outputs": [[197,198,0,160,4,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 201, "rf_id": 127, "parent": 200, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],4,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[202,57,0,0,8,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::resize_", "id": 204, "rf_id": 129, "parent": 203, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[202,57,0,0,8,"cuda:1"],[20],"<None>"], "input_shapes": [[0],[[]],[]], "input_types": ["Tensor(long int)","GenericList[Int]","None"],
      "outputs": [[202,10,0,20,8,"cuda:1"]], "output_shapes": [[20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 203, "rf_id": 128, "parent": 200, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::arange.start_out(Scalar start, Scalar end, Scalar step=1, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [0,20,1,[202,57,0,0,8,"cuda:1"]], "input_shapes": [[],[],[],[0]], "input_types": ["Int","Int","Int","Tensor(long int)"],
      "outputs": [[202,10,0,20,8,"cuda:1"]], "output_shapes": [[20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 200, "rf_id": 126, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::arange(Scalar end, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [20,4,"<None>","cuda:1",false], "input_shapes": [[],[],[],[],[]], "input_types": ["Int","Int","None","Device","Bool"],
      "outputs": [[202,10,0,20,8,"cuda:1"]], "output_shapes": [[20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 206, "rf_id": 131, "parent": 205, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[202,10,0,20,8,"cuda:1"],[1,20],[20,1],"<None>"], "input_shapes": [[20],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[207,10,0,20,8,"cuda:1"]], "output_shapes": [[1,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::unsqueeze", "id": 205, "rf_id": 130, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[202,10,0,20,8,"cuda:1"],0], "input_shapes": [[20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[207,10,0,20,8,"cuda:1"]], "output_shapes": [[1,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 210, "rf_id": 134, "parent": 209, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[207,10,0,20,8,"cuda:1"],[8,20],[0,1],"<None>"], "input_shapes": [[1,20],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[211,10,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::expand", "id": 209, "rf_id": 133, "parent": 208, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)",
      "inputs": [[207,10,0,20,8,"cuda:1"],[8,20],false], "input_shapes": [[1,20],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","Bool"],
      "outputs": [[211,10,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::expand_as", "id": 208, "rf_id": 132, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[207,10,0,20,8,"cuda:1"],[183,184,0,160,8,"cuda:1"]], "input_shapes": [[1,20],[8,20]], "input_types": ["Tensor(long int)","Tensor(long int)"],
      "outputs": [[211,10,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_strided", "id": 217, "rf_id": 138, "parent": 216, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],6,0,"cpu",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[218,219,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 220, "rf_id": 139, "parent": 216, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[218,219,0,1,4,"cpu"],[213,214,0,1,8,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(double)","Bool"],
      "outputs": [[218,219,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 216, "rf_id": 137, "parent": 215, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[213,214,0,1,8,"cpu"],6,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","None","None","Bool","None"],
      "outputs": [[218,219,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 215, "rf_id": 136, "parent": 212, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[213,214,0,1,8,"cpu"],6,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[218,219,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::lt", "id": 212, "rf_id": 135, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[189,193,0,400,4,"cpu"],0.500000], "input_shapes": [[1,1,20,20],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [[221,222,0,400,1,"cpu"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 225, "rf_id": 142, "parent": 224, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1,1,20,20],[400,400,20,1],11,0,"cuda:1",false], "input_shapes": [[[],[],[],[]],[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int","Int","Device","Bool"],
      "outputs": [[226,227,0,400,1,"cuda:1"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::copy_", "id": 228, "rf_id": 143, "parent": 224, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[226,227,0,400,1,"cuda:1"],[221,222,0,400,1,"cpu"],false], "input_shapes": [[1,1,20,20],[1,1,20,20],[]], "input_types": ["Tensor(bool)","Tensor(bool)","Bool"],
      "outputs": [[226,227,0,400,1,"cuda:1"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::_to_copy", "id": 224, "rf_id": 141, "parent": 223, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[221,222,0,400,1,"cpu"],11,0,"cuda:1","<None>",false,"<None>"], "input_shapes": [[1,1,20,20],[],[],[],[],[],[]], "input_types": ["Tensor(bool)","Int","Int","Device","None","Bool","None"],
      "outputs": [[226,227,0,400,1,"cuda:1"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::to", "id": 223, "rf_id": 140, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[221,222,0,400,1,"cpu"],11,0,"cuda:1","<None>",false,false,"<None>"], "input_shapes": [[1,1,20,20],[],[],[],[],[],[],[]], "input_types": ["Tensor(bool)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[226,227,0,400,1,"cuda:1"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::as_strided", "id": 230, "rf_id": 145, "parent": 229, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[183,184,0,160,8,"cuda:1"],[8,20],[20,1],0], "input_shapes": [[8,20],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[231,184,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 229, "rf_id": 144, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[183,184,0,160,8,"cuda:1"],0,0,9223372036854775807,1], "input_shapes": [[8,20],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[231,184,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 233, "rf_id": 147, "parent": 232, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[211,10,0,160,8,"cuda:1"],[8,20],[0,1],0], "input_shapes": [[8,20],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[234,10,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 232, "rf_id": 146, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[211,10,0,160,8,"cuda:1"],0,0,9223372036854775807,1], "input_shapes": [[8,20],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[234,10,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 235, "rf_id": 148, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[51511296],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[236,237,0,51511296,2,"cuda:1"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 240, "rf_id": 149, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[238,239,0,12877824,2,"cuda:1"],15,0,"cuda:1","<None>",false,false,"<None>"], "input_shapes": [[12877824],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[238,239,0,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 243, "rf_id": 152, "parent": 242, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[238,239,0,12877824,2,"cuda:1"]], "input_shapes": [[12877824]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 242, "rf_id": 151, "parent": 241, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[238,239,0,12877824,2,"cuda:1"],125,94716817711568,1,"_allgather_base",[],[],4], "input_shapes": [[12877824],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[236,237,0,51511296,2,"cuda:1"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 241, "rf_id": 150, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[236,237,0,51511296,2,"cuda:1"],[238,239,0,12877824,2,"cuda:1"],"<Object>",true,-1], "input_shapes": [[51511296],[12877824],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[236,237,0,51511296,2,"cuda:1"],"<Object>"], "output_shapes": [[51511296],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::as_strided", "id": 246, "rf_id": 155, "parent": 245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[236,237,0,51511296,2,"cuda:1"],[51511296],[1],0], "input_shapes": [[51511296],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[247,237,0,51511296,2,"cuda:1"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 245, "rf_id": 154, "parent": 244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[236,237,0,51511296,2,"cuda:1"],0,0,51511296,1], "input_shapes": [[51511296],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[247,237,0,51511296,2,"cuda:1"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 244, "rf_id": 153, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[236,237,0,51511296,2,"cuda:1"],0,0,51511296], "input_shapes": [[51511296],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[247,237,0,51511296,2,"cuda:1"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 248, "rf_id": 156, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[247,237,0,51511296,2,"cuda:1"],[50304,1024]], "input_shapes": [[51511296],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[249,237,0,51511296,2,"cuda:1"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 250, "rf_id": 157, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[249,237,0,51511296,2,"cuda:1"],15,0,"cuda:1","<None>",false,false,"<None>"], "input_shapes": [[50304,1024],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[249,237,0,51511296,2,"cuda:1"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 252, "rf_id": 158, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[251,57,0,0,2,"cuda:1"],[249,237,0,51511296,2,"cuda:1"]], "input_shapes": [[0],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "record_param_comms", "id": 253, "rf_id": 159, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [125,0,1,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 254, "rf_id": 160, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[12582912],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[255,256,0,12582912,2,"cuda:1"]], "output_shapes": [[12582912]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 259, "rf_id": 163, "parent": 258, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:1"],[3145728],[1],0], "input_shapes": [[12582912],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[260,256,0,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 258, "rf_id": 162, "parent": 257, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:1"],0,0,3145728,1], "input_shapes": [[12582912],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[260,256,0,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 257, "rf_id": 161, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:1"],0,0,3145728], "input_shapes": [[12582912],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[260,256,0,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 263, "rf_id": 166, "parent": 262, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:1"],[3145728],[1],3145728], "input_shapes": [[12582912],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[264,256,3145728,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 262, "rf_id": 165, "parent": 261, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:1"],0,3145728,6291456,1], "input_shapes": [[12582912],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[264,256,3145728,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 261, "rf_id": 164, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:1"],0,3145728,3145728], "input_shapes": [[12582912],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[264,256,3145728,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 267, "rf_id": 169, "parent": 266, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:1"],[3145728],[1],6291456], "input_shapes": [[12582912],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[268,256,6291456,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 266, "rf_id": 168, "parent": 265, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:1"],0,6291456,9437184,1], "input_shapes": [[12582912],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[268,256,6291456,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 265, "rf_id": 167, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:1"],0,6291456,3145728], "input_shapes": [[12582912],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[268,256,6291456,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 271, "rf_id": 172, "parent": 270, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:1"],[3145728],[1],9437184], "input_shapes": [[12582912],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[272,256,9437184,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 270, "rf_id": 171, "parent": 269, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:1"],0,9437184,12582912,1], "input_shapes": [[12582912],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[272,256,9437184,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 269, "rf_id": 170, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:1"],0,9437184,3145728], "input_shapes": [[12582912],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[272,256,9437184,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 274, "rf_id": 173, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[273,239,12882944,786432,2,"cuda:1"],15,0,"cuda:1","<None>",false,false,"<None>"], "input_shapes": [[786432],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[273,239,12882944,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 276, "rf_id": 174, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[275,239,13669376,262144,2,"cuda:1"],15,0,"cuda:1","<None>",false,false,"<None>"], "input_shapes": [[262144],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[275,239,13669376,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 278, "rf_id": 175, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[277,239,13931520,1048576,2,"cuda:1"],15,0,"cuda:1","<None>",false,false,"<None>"], "input_shapes": [[1048576],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[277,239,13931520,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 280, "rf_id": 176, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[279,239,14980096,1048576,2,"cuda:1"],15,0,"cuda:1","<None>",false,false,"<None>"], "input_shapes": [[1048576],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[279,239,14980096,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 281, "rf_id": 177, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat.out(Tensor[] tensors, int dim=0, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[[273,239,12882944,786432,2,"cuda:1"],[275,239,13669376,262144,2,"cuda:1"],[277,239,13931520,1048576,2,"cuda:1"],[279,239,14980096,1048576,2,"cuda:1"]],0,[264,256,3145728,3145728,2,"cuda:1"]], "input_shapes": [[[786432],[262144],[1048576],[1048576]],[],[3145728]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int","Tensor(c10::BFloat16)"],
      "outputs": [[264,256,3145728,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 284, "rf_id": 180, "parent": 283, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[264,256,3145728,3145728,2,"cuda:1"]], "input_shapes": [[3145728]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 283, "rf_id": 179, "parent": 282, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[264,256,3145728,3145728,2,"cuda:1"],126,94716817711568,1,"_allgather_base",[],[],4], "input_shapes": [[3145728],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[255,256,0,12582912,2,"cuda:1"]], "output_shapes": [[12582912]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 282, "rf_id": 178, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[255,256,0,12582912,2,"cuda:1"],[264,256,3145728,3145728,2,"cuda:1"],"<Object>",true,-1], "input_shapes": [[12582912],[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[255,256,0,12582912,2,"cuda:1"],"<Object>"], "output_shapes": [[12582912],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "detach", "id": 287, "rf_id": 183, "parent": 286, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[231,184,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 286, "rf_id": 182, "parent": 285, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[231,184,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [[288,184,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 285, "rf_id": 181, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[231,184,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 291, "rf_id": 186, "parent": 290, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[234,10,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 290, "rf_id": 185, "parent": 289, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[234,10,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [[292,10,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 289, "rf_id": 184, "parent": 2, "fw_parent": 0, "seq_id": 383, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[234,10,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 295, "rf_id": 189, "parent": 294, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[226,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 294, "rf_id": 188, "parent": 293, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[226,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[296,227,0,400,1,"cuda:1"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 293, "rf_id": 187, "parent": 2, "fw_parent": 0, "seq_id": 384, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[226,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 299, "rf_id": 192, "parent": 298, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[288,184,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 298, "rf_id": 191, "parent": 297, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[288,184,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [[300,184,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 297, "rf_id": 190, "parent": 2, "fw_parent": 0, "seq_id": 385, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[288,184,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 303, "rf_id": 195, "parent": 302, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[292,10,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 302, "rf_id": 194, "parent": 301, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[292,10,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [[304,10,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 301, "rf_id": 193, "parent": 2, "fw_parent": 0, "seq_id": 386, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[292,10,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 307, "rf_id": 198, "parent": 306, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[296,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 306, "rf_id": 197, "parent": 305, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[296,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[308,227,0,400,1,"cuda:1"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 305, "rf_id": 196, "parent": 2, "fw_parent": 0, "seq_id": 387, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[296,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 311, "rf_id": 201, "parent": 310, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[300,184,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 310, "rf_id": 200, "parent": 309, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[300,184,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [[312,184,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 309, "rf_id": 199, "parent": 2, "fw_parent": 0, "seq_id": 388, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[300,184,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 315, "rf_id": 204, "parent": 314, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[304,10,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 314, "rf_id": 203, "parent": 313, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[304,10,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [[316,10,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 313, "rf_id": 202, "parent": 2, "fw_parent": 0, "seq_id": 389, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[304,10,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 319, "rf_id": 207, "parent": 318, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[312,184,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 318, "rf_id": 206, "parent": 317, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[312,184,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [[320,184,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 317, "rf_id": 205, "parent": 2, "fw_parent": 0, "seq_id": 390, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[312,184,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 323, "rf_id": 210, "parent": 322, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[320,184,0,160,8,"cuda:1"],[-1]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[324,184,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 322, "rf_id": 209, "parent": 321, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[320,184,0,160,8,"cuda:1"],[-1]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[324,184,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 326, "rf_id": 212, "parent": 325, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[327,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::resize_", "id": 328, "rf_id": 213, "parent": 325, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[327,57,0,0,2,"cuda:1"],[160,1024],"<None>"], "input_shapes": [[0],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","None"],
      "outputs": [[327,329,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::index_select", "id": 325, "rf_id": 211, "parent": 321, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::index_select(Tensor self, int dim, Tensor index) -> Tensor",
      "inputs": [[251,237,0,51511296,2,"cuda:1"],0,[324,184,0,160,8,"cuda:1"]], "input_shapes": [[50304,1024],[],[160]], "input_types": ["Tensor(c10::BFloat16)","Int","Tensor(long int)"],
      "outputs": [[327,329,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 330, "rf_id": 214, "parent": 321, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[327,329,0,163840,2,"cuda:1"],[8,20,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[331,329,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding", "id": 321, "rf_id": 208, "parent": 2, "fw_parent": 0, "seq_id": 391, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::embedding(Tensor weight, Tensor indices, SymInt padding_idx=-1, bool scale_grad_by_freq=False, bool sparse=False) -> Tensor",
      "inputs": [[251,237,0,51511296,2,"cuda:1"],[320,184,0,160,8,"cuda:1"],-1,false,false], "input_shapes": [[50304,1024],[8,20],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Bool","Bool"],
      "outputs": [[331,329,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 334, "rf_id": 217, "parent": 333, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[331,329,0,163840,2,"cuda:1"],[8,20,1024]], "input_shapes": [[8,20,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[335,329,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 333, "rf_id": 216, "parent": 332, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[331,329,0,163840,2,"cuda:1"],[331,329,0,163840,2,"cuda:1"]], "input_shapes": [[8,20,1024],[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[335,329,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_ReduceFromModelParallelRegion", "id": 332, "rf_id": 215, "parent": 2, "fw_parent": 0, "seq_id": 392, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[331,329,0,163840,2,"cuda:1"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 338, "rf_id": 220, "parent": 337, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[335,329,0,163840,2,"cuda:1"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 337, "rf_id": 219, "parent": 336, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[335,329,0,163840,2,"cuda:1"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[339,329,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 336, "rf_id": 218, "parent": 2, "fw_parent": 0, "seq_id": 393, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[335,329,0,163840,2,"cuda:1"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 342, "rf_id": 223, "parent": 341, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[316,10,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 341, "rf_id": 222, "parent": 340, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[316,10,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [[343,10,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 340, "rf_id": 221, "parent": 2, "fw_parent": 0, "seq_id": 394, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[316,10,0,160,8,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 350, "rf_id": 228, "parent": 349, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],4,0,"cuda:1","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[351,132,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_like", "id": 349, "rf_id": 227, "parent": 348, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[343,10,0,160,8,"cuda:1"],4,0,"cuda:1","<None>",0], "input_shapes": [[8,20],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Int"],
      "outputs": [[351,132,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 352, "rf_id": 229, "parent": 348, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[351,132,0,160,8,"cuda:1"],[343,10,0,160,8,"cuda:1"],false], "input_shapes": [[8,20],[8,20],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[351,132,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 348, "rf_id": 226, "parent": 347, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[343,10,0,160,8,"cuda:1"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[351,132,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 353, "rf_id": 230, "parent": 347, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[351,132,0,160,8,"cuda:1"],[160]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[354,132,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 347, "rf_id": 225, "parent": 346, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[343,10,0,160,8,"cuda:1"],[-1]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[354,132,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 356, "rf_id": 232, "parent": 355, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[357,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::resize_", "id": 358, "rf_id": 233, "parent": 355, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[357,57,0,0,2,"cuda:1"],[160,1024],"<None>"], "input_shapes": [[0],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","None"],
      "outputs": [[357,359,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::index_select", "id": 355, "rf_id": 231, "parent": 346, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::index_select(Tensor self, int dim, Tensor index) -> Tensor",
      "inputs": [[344,345,0,20480,2,"cuda:1"],0,[354,132,0,160,8,"cuda:1"]], "input_shapes": [[20,1024],[],[160]], "input_types": ["Tensor(c10::BFloat16)","Int","Tensor(long int)"],
      "outputs": [[357,359,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 360, "rf_id": 234, "parent": 346, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[357,359,0,163840,2,"cuda:1"],[8,20,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[361,359,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding", "id": 346, "rf_id": 224, "parent": 2, "fw_parent": 0, "seq_id": 395, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::embedding(Tensor weight, Tensor indices, SymInt padding_idx=-1, bool scale_grad_by_freq=False, bool sparse=False) -> Tensor",
      "inputs": [[344,345,0,20480,2,"cuda:1"],[343,10,0,160,8,"cuda:1"],-1,false,false], "input_shapes": [[20,1024],[8,20],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Bool","Bool"],
      "outputs": [[361,359,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 364, "rf_id": 237, "parent": 363, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[361,359,0,163840,2,"cuda:1"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 363, "rf_id": 236, "parent": 362, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[361,359,0,163840,2,"cuda:1"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[365,359,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 362, "rf_id": 235, "parent": 2, "fw_parent": 0, "seq_id": 396, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[361,359,0,163840,2,"cuda:1"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 366, "rf_id": 238, "parent": 2, "fw_parent": 0, "seq_id": 397, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[339,329,0,163840,2,"cuda:1"],[365,359,0,163840,2,"cuda:1"],1], "input_shapes": [[8,20,1024],[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[367,368,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 370, "rf_id": 240, "parent": 369, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[367,368,0,163840,2,"cuda:1"],[20,8,1024],[1024,20480,1],"<None>"], "input_shapes": [[8,20,1024],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[371,368,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 369, "rf_id": 239, "parent": 2, "fw_parent": 0, "seq_id": 398, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[367,368,0,163840,2,"cuda:1"],0,1], "input_shapes": [[8,20,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[371,368,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 375, "rf_id": 244, "parent": 374, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,1024],15,0,"cuda:1","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[376,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 374, "rf_id": 243, "parent": 373, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[371,368,0,163840,2,"cuda:1"],15,0,"cuda:1","<None>",0], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Int"],
      "outputs": [[376,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 378, "rf_id": 245, "parent": 373, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[376,377,0,163840,2,"cuda:1"],[371,368,0,163840,2,"cuda:1"],false], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[376,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::clone", "id": 373, "rf_id": 242, "parent": 372, "fw_parent": 0, "seq_id": 399, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[371,368,0,163840,2,"cuda:1"],0], "input_shapes": [[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[376,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::contiguous", "id": 372, "rf_id": 241, "parent": 2, "fw_parent": 0, "seq_id": 399, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[371,368,0,163840,2,"cuda:1"],0], "input_shapes": [[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[376,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 381, "rf_id": 248, "parent": 380, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[376,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 380, "rf_id": 247, "parent": 379, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[376,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[382,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 379, "rf_id": 246, "parent": 2, "fw_parent": 0, "seq_id": 400, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[376,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 386, "rf_id": 252, "parent": 385, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],11,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[387,388,0,163840,1,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 385, "rf_id": 251, "parent": 384, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[382,377,0,163840,2,"cuda:1"],11,0,"cuda:1","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[387,388,0,163840,1,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 390, "rf_id": 254, "parent": 389, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[391,368,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 389, "rf_id": 253, "parent": 384, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[382,377,0,163840,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[391,368,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 384, "rf_id": 250, "parent": 383, "fw_parent": 0, "seq_id": 401, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[382,377,0,163840,2,"cuda:1"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[391,368,0,163840,2,"cuda:1"],[387,388,0,163840,1,"cuda:1"]], "output_shapes": [[20,8,1024],[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::dropout", "id": 383, "rf_id": 249, "parent": 2, "fw_parent": 0, "seq_id": 401, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::dropout(Tensor input, float p, bool train) -> Tensor",
      "inputs": [[382,377,0,163840,2,"cuda:1"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[391,368,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 394, "rf_id": 257, "parent": 393, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[391,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 393, "rf_id": 256, "parent": 392, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[391,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[395,368,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 392, "rf_id": 255, "parent": 2, "fw_parent": 0, "seq_id": 402, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[391,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 398, "rf_id": 260, "parent": 397, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[395,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 397, "rf_id": 259, "parent": 396, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[395,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[399,368,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 396, "rf_id": 258, "parent": 2, "fw_parent": 0, "seq_id": 403, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[395,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 402, "rf_id": 263, "parent": 401, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[399,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 401, "rf_id": 262, "parent": 400, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[399,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[403,368,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 400, "rf_id": 261, "parent": 2, "fw_parent": 0, "seq_id": 404, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[399,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 406, "rf_id": 266, "parent": 405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[308,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 405, "rf_id": 265, "parent": 404, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[308,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[407,227,0,400,1,"cuda:1"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 404, "rf_id": 264, "parent": 2, "fw_parent": 0, "seq_id": 405, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[308,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::to", "id": 409, "rf_id": 268, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[403,368,0,163840,2,"cuda:1"],15,0,"cuda:1","<None>",false,false,"<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[403,368,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 412, "rf_id": 271, "parent": 411, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[403,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 411, "rf_id": 270, "parent": 410, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[403,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[413,368,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 410, "rf_id": 269, "parent": 408, "fw_parent": 0, "seq_id": 407, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[403,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 416, "rf_id": 274, "parent": 415, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[407,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 415, "rf_id": 273, "parent": 414, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[407,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[417,227,0,400,1,"cuda:1"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 414, "rf_id": 272, "parent": 408, "fw_parent": 0, "seq_id": 408, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[407,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 420, "rf_id": 277, "parent": 419, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[413,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 419, "rf_id": 276, "parent": 418, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[413,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[421,368,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 418, "rf_id": 275, "parent": 408, "fw_parent": 0, "seq_id": 409, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[413,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 428, "rf_id": 280, "parent": 427, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[429,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 427, "rf_id": 279, "parent": 426, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[421,368,0,163840,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[429,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 430, "rf_id": 281, "parent": 426, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[160],6,0,"cuda:1","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[431,132,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 433, "rf_id": 283, "parent": 432, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:1","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[434,435,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 432, "rf_id": 282, "parent": 426, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[431,132,0,160,4,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[160],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[434,435,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunction", "id": 426, "rf_id": 278, "parent": 408, "fw_parent": 0, "seq_id": 410, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[421,368,0,163840,2,"cuda:1"],[422,423,0,1024,2,"cuda:1"],[424,425,0,1024,2,"cuda:1"]], "input_shapes": [[20,8,1024],[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 438, "rf_id": 286, "parent": 437, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[429,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 437, "rf_id": 285, "parent": 436, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[429,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[439,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 436, "rf_id": 284, "parent": 408, "fw_parent": 0, "seq_id": 411, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[429,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 442, "rf_id": 289, "parent": 441, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[439,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 441, "rf_id": 288, "parent": 440, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[439,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[443,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 440, "rf_id": 287, "parent": 408, "fw_parent": 0, "seq_id": 412, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[439,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 446, "rf_id": 292, "parent": 445, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[417,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 445, "rf_id": 291, "parent": 444, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[417,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[447,227,0,400,1,"cuda:1"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 444, "rf_id": 290, "parent": 408, "fw_parent": 0, "seq_id": 413, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[417,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 448, "rf_id": 293, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [126,0,1,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 451, "rf_id": 296, "parent": 450, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:1"],[786432],[1],0], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[452,256,0,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 450, "rf_id": 295, "parent": 449, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:1"],0,0,786432,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[452,256,0,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 449, "rf_id": 294, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:1"],0,0,786432], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[452,256,0,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 455, "rf_id": 299, "parent": 454, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:1"],[786432],[1],3145728], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[434,256,3145728,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 454, "rf_id": 298, "parent": 453, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:1"],0,0,786432,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[434,256,3145728,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 453, "rf_id": 297, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:1"],0,0,786432], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[434,256,3145728,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 458, "rf_id": 302, "parent": 457, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:1"],[786432],[1],6291456], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[459,256,6291456,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 457, "rf_id": 301, "parent": 456, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:1"],0,0,786432,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[459,256,6291456,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 456, "rf_id": 300, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:1"],0,0,786432], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[459,256,6291456,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 462, "rf_id": 305, "parent": 461, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:1"],[786432],[1],9437184], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[463,256,9437184,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 461, "rf_id": 304, "parent": 460, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:1"],0,0,786432,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[463,256,9437184,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 460, "rf_id": 303, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:1"],0,0,786432], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[463,256,9437184,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 464, "rf_id": 306, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[452,256,0,786432,2,"cuda:1"],[434,256,3145728,786432,2,"cuda:1"],[459,256,6291456,786432,2,"cuda:1"],[463,256,9437184,786432,2,"cuda:1"]],0], "input_shapes": [[[786432],[786432],[786432],[786432]],[]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int"],
      "outputs": [[465,466,0,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 467, "rf_id": 307, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[465,466,0,3145728,2,"cuda:1"],[3072,1024]], "input_shapes": [[3145728],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[468,466,0,3145728,2,"cuda:1"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 470, "rf_id": 308, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[469,57,0,0,2,"cuda:1"],[468,466,0,3145728,2,"cuda:1"]], "input_shapes": [[0],[3072,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 471, "rf_id": 309, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[452,256,0,786432,2,"cuda:1"],"<Stream>"], "input_shapes": [[786432],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 472, "rf_id": 310, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[434,256,3145728,786432,2,"cuda:1"],"<Stream>"], "input_shapes": [[786432],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 473, "rf_id": 311, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[459,256,6291456,786432,2,"cuda:1"],"<Stream>"], "input_shapes": [[786432],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 474, "rf_id": 312, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[463,256,9437184,786432,2,"cuda:1"],"<Stream>"], "input_shapes": [[786432],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 477, "rf_id": 315, "parent": 476, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:1"],[262144],[1],786432], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[478,256,786432,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 476, "rf_id": 314, "parent": 475, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:1"],0,786432,1048576,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[478,256,786432,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 475, "rf_id": 313, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:1"],0,786432,262144], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[478,256,786432,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 481, "rf_id": 318, "parent": 480, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:1"],[262144],[1],3932160], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[482,256,3932160,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 480, "rf_id": 317, "parent": 479, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:1"],0,786432,1048576,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[482,256,3932160,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 479, "rf_id": 316, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:1"],0,786432,262144], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[482,256,3932160,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 485, "rf_id": 321, "parent": 484, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:1"],[262144],[1],7077888], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[486,256,7077888,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 484, "rf_id": 320, "parent": 483, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:1"],0,786432,1048576,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[486,256,7077888,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 483, "rf_id": 319, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:1"],0,786432,262144], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[486,256,7077888,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 489, "rf_id": 324, "parent": 488, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:1"],[262144],[1],10223616], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[490,256,10223616,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 488, "rf_id": 323, "parent": 487, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:1"],0,786432,1048576,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[490,256,10223616,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 487, "rf_id": 322, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:1"],0,786432,262144], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[490,256,10223616,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 491, "rf_id": 325, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[478,256,786432,262144,2,"cuda:1"],[482,256,3932160,262144,2,"cuda:1"],[486,256,7077888,262144,2,"cuda:1"],[490,256,10223616,262144,2,"cuda:1"]],0], "input_shapes": [[[262144],[262144],[262144],[262144]],[]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int"],
      "outputs": [[492,493,0,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 494, "rf_id": 326, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[492,493,0,1048576,2,"cuda:1"],[1024,1024]], "input_shapes": [[1048576],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[495,493,0,1048576,2,"cuda:1"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 497, "rf_id": 327, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[496,57,0,0,2,"cuda:1"],[495,493,0,1048576,2,"cuda:1"]], "input_shapes": [[0],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 498, "rf_id": 328, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[478,256,786432,262144,2,"cuda:1"],"<Stream>"], "input_shapes": [[262144],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 499, "rf_id": 329, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[482,256,3932160,262144,2,"cuda:1"],"<Stream>"], "input_shapes": [[262144],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 500, "rf_id": 330, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[486,256,7077888,262144,2,"cuda:1"],"<Stream>"], "input_shapes": [[262144],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 501, "rf_id": 331, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[490,256,10223616,262144,2,"cuda:1"],"<Stream>"], "input_shapes": [[262144],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 504, "rf_id": 334, "parent": 503, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:1"],[1048576],[1],1048576], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[505,256,1048576,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 503, "rf_id": 333, "parent": 502, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:1"],0,1048576,2097152,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[505,256,1048576,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 502, "rf_id": 332, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:1"],0,1048576,1048576], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[505,256,1048576,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 508, "rf_id": 337, "parent": 507, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:1"],[1048576],[1],4194304], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[509,256,4194304,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 507, "rf_id": 336, "parent": 506, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:1"],0,1048576,2097152,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[509,256,4194304,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 506, "rf_id": 335, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:1"],0,1048576,1048576], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[509,256,4194304,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 512, "rf_id": 340, "parent": 511, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:1"],[1048576],[1],7340032], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[513,256,7340032,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 511, "rf_id": 339, "parent": 510, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:1"],0,1048576,2097152,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[513,256,7340032,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 510, "rf_id": 338, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:1"],0,1048576,1048576], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[513,256,7340032,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 516, "rf_id": 343, "parent": 515, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:1"],[1048576],[1],10485760], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[517,256,10485760,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 515, "rf_id": 342, "parent": 514, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:1"],0,1048576,2097152,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[517,256,10485760,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 514, "rf_id": 341, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:1"],0,1048576,1048576], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[517,256,10485760,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 518, "rf_id": 344, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[505,256,1048576,1048576,2,"cuda:1"],[509,256,4194304,1048576,2,"cuda:1"],[513,256,7340032,1048576,2,"cuda:1"],[517,256,10485760,1048576,2,"cuda:1"]],0], "input_shapes": [[[1048576],[1048576],[1048576],[1048576]],[]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int"],
      "outputs": [[519,520,0,4194304,2,"cuda:1"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 521, "rf_id": 345, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[519,520,0,4194304,2,"cuda:1"],[4096,1024]], "input_shapes": [[4194304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[522,520,0,4194304,2,"cuda:1"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 524, "rf_id": 346, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[523,57,0,0,2,"cuda:1"],[522,520,0,4194304,2,"cuda:1"]], "input_shapes": [[0],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 525, "rf_id": 347, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[505,256,1048576,1048576,2,"cuda:1"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 526, "rf_id": 348, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[509,256,4194304,1048576,2,"cuda:1"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 527, "rf_id": 349, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[513,256,7340032,1048576,2,"cuda:1"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 528, "rf_id": 350, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[517,256,10485760,1048576,2,"cuda:1"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 531, "rf_id": 353, "parent": 530, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:1"],[1048576],[1],2097152], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[532,256,2097152,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 530, "rf_id": 352, "parent": 529, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:1"],0,2097152,3145728,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[532,256,2097152,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 529, "rf_id": 351, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:1"],0,2097152,1048576], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[532,256,2097152,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 535, "rf_id": 356, "parent": 534, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:1"],[1048576],[1],5242880], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[536,256,5242880,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 534, "rf_id": 355, "parent": 533, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:1"],0,2097152,3145728,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[536,256,5242880,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 533, "rf_id": 354, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:1"],0,2097152,1048576], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[536,256,5242880,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 539, "rf_id": 359, "parent": 538, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:1"],[1048576],[1],8388608], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[540,256,8388608,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 538, "rf_id": 358, "parent": 537, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:1"],0,2097152,3145728,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[540,256,8388608,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 537, "rf_id": 357, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:1"],0,2097152,1048576], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[540,256,8388608,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 543, "rf_id": 362, "parent": 542, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:1"],[1048576],[1],11534336], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[544,256,11534336,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 542, "rf_id": 361, "parent": 541, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:1"],0,2097152,3145728,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[544,256,11534336,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 541, "rf_id": 360, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:1"],0,2097152,1048576], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[544,256,11534336,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 545, "rf_id": 363, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[532,256,2097152,1048576,2,"cuda:1"],[536,256,5242880,1048576,2,"cuda:1"],[540,256,8388608,1048576,2,"cuda:1"],[544,256,11534336,1048576,2,"cuda:1"]],0], "input_shapes": [[[1048576],[1048576],[1048576],[1048576]],[]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int"],
      "outputs": [[546,547,0,4194304,2,"cuda:1"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 548, "rf_id": 364, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[546,547,0,4194304,2,"cuda:1"],[1024,4096]], "input_shapes": [[4194304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[549,547,0,4194304,2,"cuda:1"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 551, "rf_id": 365, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[550,57,0,0,2,"cuda:1"],[549,547,0,4194304,2,"cuda:1"]], "input_shapes": [[0],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 552, "rf_id": 366, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[532,256,2097152,1048576,2,"cuda:1"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 553, "rf_id": 367, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[536,256,5242880,1048576,2,"cuda:1"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 554, "rf_id": 368, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[540,256,8388608,1048576,2,"cuda:1"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 555, "rf_id": 369, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[544,256,11534336,1048576,2,"cuda:1"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 558, "rf_id": 372, "parent": 557, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[443,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 557, "rf_id": 371, "parent": 556, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[443,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[559,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 556, "rf_id": 370, "parent": 408, "fw_parent": 0, "seq_id": 414, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[443,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 562, "rf_id": 375, "parent": 561, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[559,329,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[563,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 561, "rf_id": 374, "parent": 560, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[559,329,0,163840,2,"cuda:1"],[559,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[563,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_CopyToModelParallelRegion", "id": 560, "rf_id": 373, "parent": 408, "fw_parent": 0, "seq_id": 415, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[559,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 569, "rf_id": 379, "parent": 568, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[469,466,0,3145728,2,"cuda:1"],[1024,3072],[1,1024],"<None>"], "input_shapes": [[3072,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[570,466,0,3145728,2,"cuda:1"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 568, "rf_id": 378, "parent": 567, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[469,466,0,3145728,2,"cuda:1"],0,1], "input_shapes": [[3072,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[570,466,0,3145728,2,"cuda:1"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 567, "rf_id": 377, "parent": 566, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[469,466,0,3145728,2,"cuda:1"]], "input_shapes": [[3072,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[570,466,0,3145728,2,"cuda:1"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 573, "rf_id": 382, "parent": 572, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[563,329,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[574,329,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 572, "rf_id": 381, "parent": 571, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[563,329,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[574,329,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 575, "rf_id": 383, "parent": 571, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[574,329,0,163840,2,"cuda:1"],[570,466,0,3145728,2,"cuda:1"]], "input_shapes": [[160,1024],[1024,3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[576,577,0,491520,2,"cuda:1"]], "output_shapes": [[160,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 578, "rf_id": 384, "parent": 571, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[576,577,0,491520,2,"cuda:1"],[20,8,3072]], "input_shapes": [[160,3072],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[579,577,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 571, "rf_id": 380, "parent": 566, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[563,329,0,163840,2,"cuda:1"],[570,466,0,3145728,2,"cuda:1"]], "input_shapes": [[20,8,1024],[1024,3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[579,577,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 580, "rf_id": 385, "parent": 566, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[579,577,0,491520,2,"cuda:1"],[564,565,0,3072,2,"cuda:1"],1], "input_shapes": [[20,8,3072],[3072],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[581,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 566, "rf_id": 376, "parent": 408, "fw_parent": 0, "seq_id": 416, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[563,329,0,163840,2,"cuda:1"],[469,466,0,3145728,2,"cuda:1"],[564,565,0,3072,2,"cuda:1"]], "input_shapes": [[20,8,1024],[3072,1024],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 585, "rf_id": 388, "parent": 584, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[581,582,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 584, "rf_id": 387, "parent": 583, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[581,582,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[586,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 583, "rf_id": 386, "parent": 408, "fw_parent": 0, "seq_id": 417, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[581,582,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 587, "rf_id": 389, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[586,582,0,491520,2,"cuda:1"],[20,8,-1,3,64]], "input_shapes": [[20,8,3072],[[],[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]"],
      "outputs": [[588,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 590, "rf_id": 391, "parent": 589, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[588,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[591,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 589, "rf_id": 390, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[588,582,0,491520,2,"cuda:1"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[591,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 593, "rf_id": 393, "parent": 592, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[591,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[594,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 592, "rf_id": 392, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[591,582,0,491520,2,"cuda:1"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[594,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 596, "rf_id": 395, "parent": 595, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[594,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[597,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 595, "rf_id": 394, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[594,582,0,491520,2,"cuda:1"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[597,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 599, "rf_id": 397, "parent": 598, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[597,582,0,491520,2,"cuda:1"],[20,8,16,1,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[600,582,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 598, "rf_id": 396, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[597,582,0,491520,2,"cuda:1"],3,0,-2,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[600,582,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 602, "rf_id": 399, "parent": 601, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[600,582,0,163840,2,"cuda:1"],[20,8,16,1,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,1,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[603,582,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 601, "rf_id": 398, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[600,582,0,163840,2,"cuda:1"],4,0,9223372036854775807,1], "input_shapes": [[20,8,16,1,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[603,582,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_reshape_alias", "id": 605, "rf_id": 401, "parent": 604, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[603,582,0,163840,2,"cuda:1"],[20,8,16,64],[24576,3072,192,1]], "input_shapes": [[20,8,16,1,64],[[],[],[],[]],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]"],
      "outputs": [[606,582,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 604, "rf_id": 400, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[603,582,0,163840,2,"cuda:1"],[20,8,-1,64]], "input_shapes": [[20,8,16,1,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[606,582,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 608, "rf_id": 403, "parent": 607, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[588,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[609,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 607, "rf_id": 402, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[588,582,0,491520,2,"cuda:1"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[609,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 611, "rf_id": 405, "parent": 610, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[609,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[612,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 610, "rf_id": 404, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[609,582,0,491520,2,"cuda:1"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[612,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 614, "rf_id": 407, "parent": 613, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[612,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[615,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 613, "rf_id": 406, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[612,582,0,491520,2,"cuda:1"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[615,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 617, "rf_id": 409, "parent": 616, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[615,582,0,491520,2,"cuda:1"],[20,8,16,64],[24576,3072,192,1],64], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[618,582,64,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 616, "rf_id": 408, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[615,582,0,491520,2,"cuda:1"],3,-2], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[618,582,64,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 620, "rf_id": 411, "parent": 619, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[618,582,64,163840,2,"cuda:1"],[20,8,16,64],[24576,3072,192,1],64], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[621,582,64,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 619, "rf_id": 410, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[618,582,64,163840,2,"cuda:1"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[621,582,64,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 623, "rf_id": 413, "parent": 622, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[588,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[624,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 622, "rf_id": 412, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[588,582,0,491520,2,"cuda:1"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[624,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 626, "rf_id": 415, "parent": 625, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[624,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[627,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 625, "rf_id": 414, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[624,582,0,491520,2,"cuda:1"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[627,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 629, "rf_id": 417, "parent": 628, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[627,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[630,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 628, "rf_id": 416, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[627,582,0,491520,2,"cuda:1"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[630,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 632, "rf_id": 419, "parent": 631, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[630,582,0,491520,2,"cuda:1"],[20,8,16,64],[24576,3072,192,1],128], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[633,582,128,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 631, "rf_id": 418, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[630,582,0,491520,2,"cuda:1"],3,-1], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[633,582,128,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 635, "rf_id": 421, "parent": 634, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[633,582,128,163840,2,"cuda:1"],[20,8,16,64],[24576,3072,192,1],128], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[636,582,128,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 634, "rf_id": 420, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[633,582,128,163840,2,"cuda:1"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[636,582,128,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 639, "rf_id": 424, "parent": 638, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[606,582,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 638, "rf_id": 423, "parent": 637, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[606,582,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[640,582,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 637, "rf_id": 422, "parent": 408, "fw_parent": 0, "seq_id": 418, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[606,582,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 643, "rf_id": 427, "parent": 642, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[621,582,64,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 642, "rf_id": 426, "parent": 641, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[621,582,64,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[644,582,64,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 641, "rf_id": 425, "parent": 408, "fw_parent": 0, "seq_id": 419, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[621,582,64,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 647, "rf_id": 430, "parent": 646, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[636,582,128,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 646, "rf_id": 429, "parent": 645, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[636,582,128,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[648,582,128,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 645, "rf_id": 428, "parent": 408, "fw_parent": 0, "seq_id": 420, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[636,582,128,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 651, "rf_id": 433, "parent": 650, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[447,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 650, "rf_id": 432, "parent": 649, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[447,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[652,227,0,400,1,"cuda:1"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 649, "rf_id": 431, "parent": 408, "fw_parent": 0, "seq_id": 421, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[447,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 653, "rf_id": 434, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[640,582,0,163840,2,"cuda:1"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[654,582,0,163840,2,"cuda:1"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 655, "rf_id": 435, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[644,582,64,163840,2,"cuda:1"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[656,582,64,163840,2,"cuda:1"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 660, "rf_id": 437, "parent": 659, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[657,658,0,51200,2,"cuda:1"],[51200],[1],0], "input_shapes": [[51200],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[661,658,0,51200,2,"cuda:1"]], "output_shapes": [[51200]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 659, "rf_id": 436, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[657,658,0,51200,2,"cuda:1"],0,0,51200,1], "input_shapes": [[51200],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[661,658,0,51200,2,"cuda:1"]], "output_shapes": [[51200]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 662, "rf_id": 438, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[661,658,0,51200,2,"cuda:1"],[128,20,20]], "input_shapes": [[51200],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[663,658,0,51200,2,"cuda:1"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 665, "rf_id": 440, "parent": 664, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[654,582,0,163840,2,"cuda:1"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[666,582,0,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 664, "rf_id": 439, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[654,582,0,163840,2,"cuda:1"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[666,582,0,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 668, "rf_id": 442, "parent": 667, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[656,582,64,163840,2,"cuda:1"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[669,582,64,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 667, "rf_id": 441, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[656,582,64,163840,2,"cuda:1"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[669,582,64,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 671, "rf_id": 444, "parent": 670, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[669,582,64,163840,2,"cuda:1"],[128,64,20],[192,1,24576],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[672,582,64,163840,2,"cuda:1"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 670, "rf_id": 443, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[669,582,64,163840,2,"cuda:1"],1,2], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[672,582,64,163840,2,"cuda:1"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::baddbmm", "id": 673, "rf_id": 445, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor",
      "inputs": [[663,658,0,51200,2,"cuda:1"],[666,582,0,163840,2,"cuda:1"],[672,582,64,163840,2,"cuda:1"],0.000000,0.125000], "input_shapes": [[128,20,20],[128,20,64],[128,64,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Double","Double"],
      "outputs": [[674,359,0,51200,2,"cuda:1"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 675, "rf_id": 446, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[674,359,0,51200,2,"cuda:1"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[676,359,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 679, "rf_id": 449, "parent": 678, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[676,359,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 678, "rf_id": 448, "parent": 677, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[676,359,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[680,359,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 677, "rf_id": 447, "parent": 408, "fw_parent": 0, "seq_id": 422, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[676,359,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 683, "rf_id": 452, "parent": 682, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[652,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 682, "rf_id": 451, "parent": 681, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[652,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[684,227,0,400,1,"cuda:1"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 681, "rf_id": 450, "parent": 408, "fw_parent": 0, "seq_id": 423, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[652,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 685, "rf_id": 453, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[680,359,0,51200,2,"cuda:1"],[-1,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[686,359,0,51200,2,"cuda:1"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 688, "rf_id": 455, "parent": 687, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],4,0,"cpu",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","Bool","None"],
      "outputs": [[689,690,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 691, "rf_id": 456, "parent": 687, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[689,690,0,1,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[1],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[689,690,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 692, "rf_id": 457, "parent": 687, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[689,690,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [[689,690,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "detach_", "id": 694, "rf_id": 459, "parent": 693, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[689,690,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 693, "rf_id": 458, "parent": 687, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[689,690,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [[689,690,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 696, "rf_id": 461, "parent": 695, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[689,690,0,1,8,"cpu"],[],[],0], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[697,690,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 695, "rf_id": 460, "parent": 687, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[689,690,0,1,8,"cpu"],0,0], "input_shapes": [[1],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[697,690,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 699, "rf_id": 463, "parent": 698, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[697,690,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 698, "rf_id": 462, "parent": 687, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[697,690,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::empty", "id": 700, "rf_id": 464, "parent": 687, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[128,20,20],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[701,702,0,51200,2,"cuda:1"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ScaledUpperTriangMaskedSoftmax", "id": 687, "rf_id": 454, "parent": 408, "fw_parent": 0, "seq_id": 424, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[686,359,0,51200,2,"cuda:1"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 703, "rf_id": 465, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[701,702,0,51200,2,"cuda:1"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[704,702,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 707, "rf_id": 468, "parent": 706, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[704,702,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 706, "rf_id": 467, "parent": 705, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[704,702,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[708,702,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 705, "rf_id": 466, "parent": 408, "fw_parent": 0, "seq_id": 425, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[704,702,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 711, "rf_id": 471, "parent": 710, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[708,702,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 710, "rf_id": 470, "parent": 709, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[708,702,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[712,702,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 709, "rf_id": 469, "parent": 408, "fw_parent": 0, "seq_id": 426, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[708,702,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 716, "rf_id": 475, "parent": 715, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[8,16,20,20],[6400,400,20,1],11,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[]],[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[717,718,0,51200,1,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 715, "rf_id": 474, "parent": 714, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[712,702,0,51200,2,"cuda:1"],11,0,"cuda:1","<None>","<None>"], "input_shapes": [[8,16,20,20],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[717,718,0,51200,1,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 720, "rf_id": 477, "parent": 719, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[8,16,20,20],[6400,400,20,1],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[]],[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[721,377,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 719, "rf_id": 476, "parent": 714, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[712,702,0,51200,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[8,16,20,20],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[721,377,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 714, "rf_id": 473, "parent": 713, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[712,702,0,51200,2,"cuda:1"],0.100000,true], "input_shapes": [[8,16,20,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[721,377,0,51200,2,"cuda:1"],[717,718,0,51200,1,"cuda:1"]], "output_shapes": [[8,16,20,20],[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::dropout", "id": 713, "rf_id": 472, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::dropout(Tensor input, float p, bool train) -> Tensor",
      "inputs": [[712,702,0,51200,2,"cuda:1"],0.100000,true], "input_shapes": [[8,16,20,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[721,377,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 724, "rf_id": 480, "parent": 723, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[721,377,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 723, "rf_id": 479, "parent": 722, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[721,377,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[725,377,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 722, "rf_id": 478, "parent": 408, "fw_parent": 0, "seq_id": 427, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[721,377,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 726, "rf_id": 481, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[648,582,128,163840,2,"cuda:1"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[684,582,128,163840,2,"cuda:1"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 727, "rf_id": 482, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[725,377,0,51200,2,"cuda:1"],[128,20,-1]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[728,377,0,51200,2,"cuda:1"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 730, "rf_id": 484, "parent": 729, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[684,582,128,163840,2,"cuda:1"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[731,582,128,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 729, "rf_id": 483, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[684,582,128,163840,2,"cuda:1"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[731,582,128,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 732, "rf_id": 485, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[728,377,0,51200,2,"cuda:1"],[731,582,128,163840,2,"cuda:1"]], "input_shapes": [[128,20,20],[128,20,64]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[733,734,0,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 735, "rf_id": 486, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[733,734,0,163840,2,"cuda:1"],[8,16,20,64]], "input_shapes": [[128,20,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[736,734,0,163840,2,"cuda:1"]], "output_shapes": [[8,16,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 738, "rf_id": 488, "parent": 737, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[736,734,0,163840,2,"cuda:1"],[20,8,16,64],[64,20480,1280,1],"<None>"], "input_shapes": [[8,16,20,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","None"],
      "outputs": [[739,734,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::permute", "id": 737, "rf_id": 487, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)",
      "inputs": [[736,734,0,163840,2,"cuda:1"],[2,0,1,3]], "input_shapes": [[8,16,20,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[739,734,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 743, "rf_id": 492, "parent": 742, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:1","<None>",0], "input_shapes": [[[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[744,745,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 742, "rf_id": 491, "parent": 741, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[739,734,0,163840,2,"cuda:1"],15,0,"cuda:1","<None>",0], "input_shapes": [[20,8,16,64],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Int"],
      "outputs": [[744,745,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 746, "rf_id": 493, "parent": 741, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[744,745,0,163840,2,"cuda:1"],[739,734,0,163840,2,"cuda:1"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[744,745,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::clone", "id": 741, "rf_id": 490, "parent": 740, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[739,734,0,163840,2,"cuda:1"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[744,745,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::contiguous", "id": 740, "rf_id": 489, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[739,734,0,163840,2,"cuda:1"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[744,745,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 747, "rf_id": 494, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[744,745,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[748,745,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 751, "rf_id": 497, "parent": 750, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[748,745,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 750, "rf_id": 496, "parent": 749, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[748,745,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[752,745,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 749, "rf_id": 495, "parent": 408, "fw_parent": 0, "seq_id": 428, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[748,745,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 755, "rf_id": 500, "parent": 754, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[752,745,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 754, "rf_id": 499, "parent": 753, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[752,745,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[756,745,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 753, "rf_id": 498, "parent": 408, "fw_parent": 0, "seq_id": 429, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[752,745,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 760, "rf_id": 504, "parent": 759, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[496,493,0,1048576,2,"cuda:1"],[1024,1024],[1,1024],"<None>"], "input_shapes": [[1024,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[761,493,0,1048576,2,"cuda:1"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 759, "rf_id": 503, "parent": 758, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[496,493,0,1048576,2,"cuda:1"],0,1], "input_shapes": [[1024,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[761,493,0,1048576,2,"cuda:1"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 758, "rf_id": 502, "parent": 757, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[496,493,0,1048576,2,"cuda:1"]], "input_shapes": [[1024,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[761,493,0,1048576,2,"cuda:1"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 764, "rf_id": 507, "parent": 763, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[756,745,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[765,745,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 763, "rf_id": 506, "parent": 762, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[756,745,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[765,745,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 766, "rf_id": 508, "parent": 762, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[765,745,0,163840,2,"cuda:1"],[761,493,0,1048576,2,"cuda:1"]], "input_shapes": [[160,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[767,359,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 768, "rf_id": 509, "parent": 762, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[767,359,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[769,359,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 762, "rf_id": 505, "parent": 757, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[756,745,0,163840,2,"cuda:1"],[761,493,0,1048576,2,"cuda:1"]], "input_shapes": [[20,8,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[769,359,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 757, "rf_id": 501, "parent": 408, "fw_parent": 0, "seq_id": 430, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[756,745,0,163840,2,"cuda:1"],[496,493,0,1048576,2,"cuda:1"]], "input_shapes": [[20,8,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 772, "rf_id": 512, "parent": 771, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[769,359,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[773,359,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 771, "rf_id": 511, "parent": 770, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[769,359,0,163840,2,"cuda:1"],[769,359,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[773,359,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_ReduceFromModelParallelRegion", "id": 770, "rf_id": 510, "parent": 408, "fw_parent": 0, "seq_id": 431, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[769,359,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 776, "rf_id": 515, "parent": 775, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[773,359,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 775, "rf_id": 514, "parent": 774, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[773,359,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[777,359,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 774, "rf_id": 513, "parent": 408, "fw_parent": 0, "seq_id": 432, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[773,359,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 782, "rf_id": 518, "parent": 781, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[778,779,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 781, "rf_id": 517, "parent": 780, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[778,779,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[783,779,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 780, "rf_id": 516, "parent": 408, "fw_parent": 0, "seq_id": 433, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[778,779,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 786, "rf_id": 521, "parent": 785, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[777,359,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 785, "rf_id": 520, "parent": 784, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[777,359,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[787,359,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 784, "rf_id": 519, "parent": 408, "fw_parent": 0, "seq_id": 434, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[777,359,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 790, "rf_id": 524, "parent": 789, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[783,779,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 789, "rf_id": 523, "parent": 788, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[783,779,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[791,779,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 788, "rf_id": 522, "parent": 408, "fw_parent": 0, "seq_id": 435, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[783,779,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 794, "rf_id": 527, "parent": 793, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[791,779,0,1024,2,"cuda:1"],[20,8,1024],[0,0,1],"<None>"], "input_shapes": [[1024],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[795,779,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::expand", "id": 793, "rf_id": 526, "parent": 792, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)",
      "inputs": [[791,779,0,1024,2,"cuda:1"],[20,8,1024],false], "input_shapes": [[1024],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","Bool"],
      "outputs": [[795,779,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::expand_as", "id": 792, "rf_id": 525, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[791,779,0,1024,2,"cuda:1"],[413,368,0,163840,2,"cuda:1"]], "input_shapes": [[1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[795,779,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 799, "rf_id": 531, "parent": 798, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[787,359,0,163840,2,"cuda:1"],[795,779,0,163840,2,"cuda:1"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[800,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "fallback_function", "id": 798, "rf_id": 530, "parent": 797, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[795,779,0,163840,2,"cuda:1"],[787,359,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "fallback_function", "id": 797, "rf_id": 529, "parent": 796, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[795,779,0,163840,2,"cuda:1"],[787,359,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 805, "rf_id": 536, "parent": 804, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],11,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[806,807,0,163840,1,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 804, "rf_id": 535, "parent": 803, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[800,377,0,163840,2,"cuda:1"],11,0,"cuda:1","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[806,807,0,163840,1,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 809, "rf_id": 538, "parent": 808, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[810,811,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 808, "rf_id": 537, "parent": 803, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[800,377,0,163840,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[810,811,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 803, "rf_id": 534, "parent": 802, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[800,377,0,163840,2,"cuda:1"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[810,811,0,163840,2,"cuda:1"],[806,807,0,163840,1,"cuda:1"]], "output_shapes": [[20,8,1024],[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::dropout", "id": 802, "rf_id": 533, "parent": 801, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::dropout(Tensor input, float p, bool train) -> Tensor",
      "inputs": [[800,377,0,163840,2,"cuda:1"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[810,811,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 812, "rf_id": 539, "parent": 801, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[413,368,0,163840,2,"cuda:1"],[810,811,0,163840,2,"cuda:1"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[806,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "fallback_function", "id": 801, "rf_id": 532, "parent": 796, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[413,368,0,163840,2,"cuda:1"],0.100000,[800,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_dropout_add_fused_train", "id": 796, "rf_id": 528, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[787,359,0,163840,2,"cuda:1"],[795,779,0,163840,2,"cuda:1"],[413,368,0,163840,2,"cuda:1"],0.100000], "input_shapes": [[20,8,1024],[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Double"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 815, "rf_id": 542, "parent": 814, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[806,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 814, "rf_id": 541, "parent": 813, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[806,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[816,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 813, "rf_id": 540, "parent": 408, "fw_parent": 0, "seq_id": 436, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[806,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 823, "rf_id": 545, "parent": 822, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[824,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 822, "rf_id": 544, "parent": 821, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[816,577,0,163840,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[824,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 825, "rf_id": 546, "parent": 821, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[160],6,0,"cuda:1","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[826,132,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 828, "rf_id": 548, "parent": 827, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:1","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[829,435,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 827, "rf_id": 547, "parent": 821, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[826,132,0,160,4,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[160],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[829,435,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunction", "id": 821, "rf_id": 543, "parent": 408, "fw_parent": 0, "seq_id": 437, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[816,577,0,163840,2,"cuda:1"],[817,818,0,1024,2,"cuda:1"],[819,820,0,1024,2,"cuda:1"]], "input_shapes": [[20,8,1024],[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 832, "rf_id": 551, "parent": 831, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[824,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 831, "rf_id": 550, "parent": 830, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[824,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[833,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 830, "rf_id": 549, "parent": 408, "fw_parent": 0, "seq_id": 438, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[824,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 834, "rf_id": 552, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],15,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[829,835,0,1,2,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 838, "rf_id": 555, "parent": 837, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],15,0,"cuda:1",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[839,132,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 840, "rf_id": 556, "parent": 837, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[839,132,0,1,2,"cuda:1"],[829,835,0,1,2,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[839,132,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_to_copy", "id": 837, "rf_id": 554, "parent": 836, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[829,835,0,1,2,"cpu"],15,"<None>","cuda:1","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","Device","None","Bool","None"],
      "outputs": [[839,132,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 836, "rf_id": 553, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[829,835,0,1,2,"cpu"],"cuda:1",15,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Device","Int","Bool","Bool","None"],
      "outputs": [[839,132,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::lift_fresh", "id": 841, "rf_id": 557, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[839,132,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[839,132,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach_", "id": 843, "rf_id": 559, "parent": 842, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[839,132,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 842, "rf_id": 558, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[839,132,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[839,132,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 844, "rf_id": 560, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],15,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[845,846,0,1,2,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 849, "rf_id": 563, "parent": 848, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],15,0,"cuda:1",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[850,851,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 852, "rf_id": 564, "parent": 848, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[850,851,0,1,2,"cuda:1"],[845,846,0,1,2,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[850,851,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_to_copy", "id": 848, "rf_id": 562, "parent": 847, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[845,846,0,1,2,"cpu"],15,"<None>","cuda:1","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","Device","None","Bool","None"],
      "outputs": [[850,851,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 847, "rf_id": 561, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[845,846,0,1,2,"cpu"],"cuda:1",15,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Device","Int","Bool","Bool","None"],
      "outputs": [[850,851,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::lift_fresh", "id": 853, "rf_id": 565, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[850,851,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[850,851,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach_", "id": 855, "rf_id": 567, "parent": 854, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[850,851,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 854, "rf_id": 566, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[850,851,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[850,851,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 858, "rf_id": 570, "parent": 857, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[833,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 857, "rf_id": 569, "parent": 856, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[833,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[859,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 856, "rf_id": 568, "parent": 408, "fw_parent": 0, "seq_id": 439, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[833,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 862, "rf_id": 573, "parent": 861, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[859,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 861, "rf_id": 572, "parent": 860, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[859,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[863,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 860, "rf_id": 571, "parent": 408, "fw_parent": 0, "seq_id": 440, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[859,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 866, "rf_id": 576, "parent": 865, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[863,377,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[867,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 865, "rf_id": 575, "parent": 864, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[863,377,0,163840,2,"cuda:1"],[863,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[867,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_CopyToModelParallelRegion", "id": 864, "rf_id": 574, "parent": 408, "fw_parent": 0, "seq_id": 441, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[863,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 871, "rf_id": 580, "parent": 870, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[523,520,0,4194304,2,"cuda:1"],[1024,4096],[1,1024],"<None>"], "input_shapes": [[4096,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[872,520,0,4194304,2,"cuda:1"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 870, "rf_id": 579, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[523,520,0,4194304,2,"cuda:1"],0,1], "input_shapes": [[4096,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[872,520,0,4194304,2,"cuda:1"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 869, "rf_id": 578, "parent": 868, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[523,520,0,4194304,2,"cuda:1"]], "input_shapes": [[4096,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[872,520,0,4194304,2,"cuda:1"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 875, "rf_id": 583, "parent": 874, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[867,377,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[876,377,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 874, "rf_id": 582, "parent": 873, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[867,377,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[876,377,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 877, "rf_id": 584, "parent": 873, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[876,377,0,163840,2,"cuda:1"],[872,520,0,4194304,2,"cuda:1"]], "input_shapes": [[160,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[878,879,0,655360,2,"cuda:1"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 880, "rf_id": 585, "parent": 873, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[878,879,0,655360,2,"cuda:1"],[20,8,4096]], "input_shapes": [[160,4096],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[881,879,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 873, "rf_id": 581, "parent": 868, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[867,377,0,163840,2,"cuda:1"],[872,520,0,4194304,2,"cuda:1"]], "input_shapes": [[20,8,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[881,879,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 868, "rf_id": 577, "parent": 408, "fw_parent": 0, "seq_id": 442, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[867,377,0,163840,2,"cuda:1"],[523,520,0,4194304,2,"cuda:1"]], "input_shapes": [[20,8,1024],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 884, "rf_id": 588, "parent": 883, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[881,879,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 883, "rf_id": 587, "parent": 882, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[881,879,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[885,879,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 882, "rf_id": 586, "parent": 408, "fw_parent": 0, "seq_id": 443, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[881,879,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 890, "rf_id": 591, "parent": 889, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[886,887,0,4096,2,"cuda:1"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 889, "rf_id": 590, "parent": 888, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[886,887,0,4096,2,"cuda:1"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[891,887,0,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 888, "rf_id": 589, "parent": 408, "fw_parent": 0, "seq_id": 444, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[886,887,0,4096,2,"cuda:1"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 896, "rf_id": 596, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[891,887,0,4096,2,"cuda:1"],[885,879,0,655360,2,"cuda:1"],1], "input_shapes": [[4096],[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[897,898,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 902, "rf_id": 598, "parent": 899, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[897,898,0,655360,2,"cuda:1"],[900,901,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[903,904,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 899, "rf_id": 597, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[897,898,0,655360,2,"cuda:1"],0.500000], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[903,904,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 908, "rf_id": 600, "parent": 905, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[897,898,0,655360,2,"cuda:1"],[906,907,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[909,910,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 905, "rf_id": 599, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[897,898,0,655360,2,"cuda:1"],0.797885], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[909,910,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 914, "rf_id": 602, "parent": 911, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[897,898,0,655360,2,"cuda:1"],[912,913,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[915,916,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 911, "rf_id": 601, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[897,898,0,655360,2,"cuda:1"],0.044715], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[915,916,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 917, "rf_id": 603, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[915,916,0,655360,2,"cuda:1"],[897,898,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[918,919,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 923, "rf_id": 605, "parent": 920, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[918,919,0,655360,2,"cuda:1"],[921,922,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[924,916,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 920, "rf_id": 604, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[918,919,0,655360,2,"cuda:1"],1,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[924,916,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 925, "rf_id": 606, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[909,910,0,655360,2,"cuda:1"],[924,916,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[926,898,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::tanh", "id": 927, "rf_id": 607, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::tanh(Tensor self) -> Tensor",
      "inputs": [[926,898,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[928,910,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 932, "rf_id": 609, "parent": 929, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[928,910,0,655360,2,"cuda:1"],[930,931,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)","Int"],
      "outputs": [[933,898,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 929, "rf_id": 608, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[928,910,0,655360,2,"cuda:1"],1.000000,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Int"],
      "outputs": [[933,898,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 934, "rf_id": 610, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[903,904,0,655360,2,"cuda:1"],[933,898,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[935,910,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "fallback_function", "id": 895, "rf_id": 595, "parent": 894, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[885,879,0,655360,2,"cuda:1"],[891,887,0,4096,2,"cuda:1"]], "input_shapes": [[20,8,4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "fallback_function", "id": 894, "rf_id": 594, "parent": 893, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[885,879,0,655360,2,"cuda:1"],[891,887,0,4096,2,"cuda:1"]], "input_shapes": [[20,8,4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_gelu", "id": 893, "rf_id": 593, "parent": 892, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[891,887,0,4096,2,"cuda:1"],[885,879,0,655360,2,"cuda:1"]], "input_shapes": [[4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "GeLUFunction", "id": 892, "rf_id": 592, "parent": 408, "fw_parent": 0, "seq_id": 445, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[885,879,0,655360,2,"cuda:1"],[891,887,0,4096,2,"cuda:1"]], "input_shapes": [[20,8,4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 938, "rf_id": 613, "parent": 937, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[935,910,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 937, "rf_id": 612, "parent": 936, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[935,910,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[939,910,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 936, "rf_id": 611, "parent": 408, "fw_parent": 0, "seq_id": 446, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[935,910,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 943, "rf_id": 617, "parent": 942, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[550,547,0,4194304,2,"cuda:1"],[4096,1024],[1,4096],"<None>"], "input_shapes": [[1024,4096],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[944,547,0,4194304,2,"cuda:1"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 942, "rf_id": 616, "parent": 941, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[550,547,0,4194304,2,"cuda:1"],0,1], "input_shapes": [[1024,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[944,547,0,4194304,2,"cuda:1"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 941, "rf_id": 615, "parent": 940, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[550,547,0,4194304,2,"cuda:1"]], "input_shapes": [[1024,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[944,547,0,4194304,2,"cuda:1"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 947, "rf_id": 620, "parent": 946, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[939,910,0,655360,2,"cuda:1"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[948,910,0,655360,2,"cuda:1"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 946, "rf_id": 619, "parent": 945, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[939,910,0,655360,2,"cuda:1"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[948,910,0,655360,2,"cuda:1"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 949, "rf_id": 621, "parent": 945, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[948,910,0,655360,2,"cuda:1"],[944,547,0,4194304,2,"cuda:1"]], "input_shapes": [[160,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[950,329,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 951, "rf_id": 622, "parent": 945, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[950,329,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[952,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 945, "rf_id": 618, "parent": 940, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[939,910,0,655360,2,"cuda:1"],[944,547,0,4194304,2,"cuda:1"]], "input_shapes": [[20,8,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[952,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 940, "rf_id": 614, "parent": 408, "fw_parent": 0, "seq_id": 447, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[939,910,0,655360,2,"cuda:1"],[550,547,0,4194304,2,"cuda:1"]], "input_shapes": [[20,8,4096],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 955, "rf_id": 625, "parent": 954, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[952,329,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[956,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 954, "rf_id": 624, "parent": 953, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[952,329,0,163840,2,"cuda:1"],[952,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[956,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_ReduceFromModelParallelRegion", "id": 953, "rf_id": 623, "parent": 408, "fw_parent": 0, "seq_id": 448, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[952,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 959, "rf_id": 626, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[956,329,0,163840,2,"cuda:1"],[957,958,0,1024,2,"cuda:1"],1], "input_shapes": [[20,8,1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[960,807,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 963, "rf_id": 629, "parent": 962, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[960,807,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 962, "rf_id": 628, "parent": 961, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[960,807,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[964,807,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 961, "rf_id": 627, "parent": 408, "fw_parent": 0, "seq_id": 449, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[960,807,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 967, "rf_id": 632, "parent": 966, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[964,807,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 966, "rf_id": 631, "parent": 965, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[964,807,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[968,807,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 965, "rf_id": 630, "parent": 408, "fw_parent": 0, "seq_id": 450, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[964,807,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 974, "rf_id": 638, "parent": 973, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],11,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[975,976,0,163840,1,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 973, "rf_id": 637, "parent": 972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[968,807,0,163840,2,"cuda:1"],11,0,"cuda:1","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[975,976,0,163840,1,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 978, "rf_id": 640, "parent": 977, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[979,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 977, "rf_id": 639, "parent": 972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[968,807,0,163840,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[979,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 972, "rf_id": 636, "parent": 971, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[968,807,0,163840,2,"cuda:1"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[979,329,0,163840,2,"cuda:1"],[975,976,0,163840,1,"cuda:1"]], "output_shapes": [[20,8,1024],[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::dropout", "id": 971, "rf_id": 635, "parent": 970, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::dropout(Tensor input, float p, bool train) -> Tensor",
      "inputs": [[968,807,0,163840,2,"cuda:1"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[979,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 980, "rf_id": 641, "parent": 970, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[806,577,0,163840,2,"cuda:1"],[979,329,0,163840,2,"cuda:1"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[975,981,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "fallback_function", "id": 970, "rf_id": 634, "parent": 969, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[806,577,0,163840,2,"cuda:1"],0.100000,[968,807,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_dropout_add_fused_train", "id": 969, "rf_id": 633, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[968,807,0,163840,2,"cuda:1"],"<None>",[806,577,0,163840,2,"cuda:1"],0.100000], "input_shapes": [[20,8,1024],[],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","None","Tensor(c10::BFloat16)","Double"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 984, "rf_id": 644, "parent": 983, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[975,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 983, "rf_id": 643, "parent": 982, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[975,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[985,981,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 982, "rf_id": 642, "parent": 408, "fw_parent": 0, "seq_id": 451, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[975,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 988, "rf_id": 647, "parent": 987, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[839,132,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 987, "rf_id": 646, "parent": 986, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[839,132,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[989,132,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 986, "rf_id": 645, "parent": 408, "fw_parent": 0, "seq_id": 452, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[839,132,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "CheckpointFunction", "id": 408, "rf_id": 267, "parent": 2, "fw_parent": 0, "seq_id": 406, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[403,368,0,163840,2,"cuda:1"],[407,227,0,400,1,"cuda:1"]], "input_shapes": [[20,8,1024],[1,1,20,20]], "input_types": ["Tensor(c10::BFloat16)","Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 992, "rf_id": 650, "parent": 991, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[985,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 991, "rf_id": 649, "parent": 990, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[985,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[993,981,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 990, "rf_id": 648, "parent": 2, "fw_parent": 0, "seq_id": 453, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[985,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 1000, "rf_id": 653, "parent": 999, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1001,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 999, "rf_id": 652, "parent": 998, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[993,981,0,163840,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1001,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1002, "rf_id": 654, "parent": 998, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[160],6,0,"cuda:1","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[1003,851,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 1005, "rf_id": 656, "parent": 1004, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:1","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[1006,435,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 1004, "rf_id": 655, "parent": 998, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1003,851,0,160,4,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[160],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[1006,435,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunction", "id": 998, "rf_id": 651, "parent": 2, "fw_parent": 0, "seq_id": 454, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[993,981,0,163840,2,"cuda:1"],[994,995,0,1024,2,"cuda:1"],[996,997,0,1024,2,"cuda:1"]], "input_shapes": [[20,8,1024],[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1009, "rf_id": 659, "parent": 1008, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1001,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1008, "rf_id": 658, "parent": 1007, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1001,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1010,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1007, "rf_id": 657, "parent": 2, "fw_parent": 0, "seq_id": 455, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1001,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1013, "rf_id": 662, "parent": 1012, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1010,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1012, "rf_id": 661, "parent": 1011, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1010,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1014,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1011, "rf_id": 660, "parent": 2, "fw_parent": 0, "seq_id": 456, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1010,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1017, "rf_id": 665, "parent": 1016, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[989,132,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1016, "rf_id": 664, "parent": 1015, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[989,132,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1018,132,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1015, "rf_id": 663, "parent": 2, "fw_parent": 0, "seq_id": 457, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[989,132,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1021, "rf_id": 668, "parent": 1020, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1014,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1020, "rf_id": 667, "parent": 1019, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1014,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1022,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1019, "rf_id": 666, "parent": 2, "fw_parent": 0, "seq_id": 458, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1014,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1025, "rf_id": 671, "parent": 1024, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1018,132,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1024, "rf_id": 670, "parent": 1023, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1018,132,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1026,132,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1023, "rf_id": 669, "parent": 2, "fw_parent": 0, "seq_id": 459, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1018,132,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1029, "rf_id": 674, "parent": 1028, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1022,577,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1030,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1028, "rf_id": 673, "parent": 1027, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1022,577,0,163840,2,"cuda:1"],[1022,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1030,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_CopyToModelParallelRegion", "id": 1027, "rf_id": 672, "parent": 2, "fw_parent": 0, "seq_id": 460, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1022,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1034, "rf_id": 678, "parent": 1033, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[251,237,0,51511296,2,"cuda:1"],[1024,50304],[1,1024],"<None>"], "input_shapes": [[50304,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1035,237,0,51511296,2,"cuda:1"]], "output_shapes": [[1024,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1033, "rf_id": 677, "parent": 1032, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[251,237,0,51511296,2,"cuda:1"],0,1], "input_shapes": [[50304,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1035,237,0,51511296,2,"cuda:1"]], "output_shapes": [[1024,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1032, "rf_id": 676, "parent": 1031, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[251,237,0,51511296,2,"cuda:1"]], "input_shapes": [[50304,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1035,237,0,51511296,2,"cuda:1"]], "output_shapes": [[1024,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1038, "rf_id": 681, "parent": 1037, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1030,577,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1039,577,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1037, "rf_id": 680, "parent": 1036, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1030,577,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1039,577,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1040, "rf_id": 682, "parent": 1036, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1039,577,0,163840,2,"cuda:1"],[1035,237,0,51511296,2,"cuda:1"]], "input_shapes": [[160,1024],[1024,50304]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1041,904,0,8048640,2,"cuda:1"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1042, "rf_id": 683, "parent": 1036, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1041,904,0,8048640,2,"cuda:1"],[20,8,50304]], "input_shapes": [[160,50304],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1043,904,0,8048640,2,"cuda:1"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1036, "rf_id": 679, "parent": 1031, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1030,577,0,163840,2,"cuda:1"],[1035,237,0,51511296,2,"cuda:1"]], "input_shapes": [[20,8,1024],[1024,50304]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1043,904,0,8048640,2,"cuda:1"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 1031, "rf_id": 675, "parent": 2, "fw_parent": 0, "seq_id": 461, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1030,577,0,163840,2,"cuda:1"],[251,237,0,51511296,2,"cuda:1"]], "input_shapes": [[20,8,1024],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1045, "rf_id": 685, "parent": 1044, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[170,171,0,160,8,"cuda:1"],[20,8],[1,20],"<None>"], "input_shapes": [[8,20],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1046,171,0,160,8,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::transpose", "id": 1044, "rf_id": 684, "parent": 2, "fw_parent": 0, "seq_id": 462, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[170,171,0,160,8,"cuda:1"],0,1], "input_shapes": [[8,20],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[1046,171,0,160,8,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 1050, "rf_id": 689, "parent": 1049, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8],4,0,"cuda:1","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[1051,1052,0,160,8,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_like", "id": 1049, "rf_id": 688, "parent": 1048, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1046,171,0,160,8,"cuda:1"],4,0,"cuda:1","<None>",0], "input_shapes": [[20,8],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Int"],
      "outputs": [[1051,1052,0,160,8,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 1053, "rf_id": 690, "parent": 1048, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1051,1052,0,160,8,"cuda:1"],[1046,171,0,160,8,"cuda:1"],false], "input_shapes": [[20,8],[20,8],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[1051,1052,0,160,8,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 1048, "rf_id": 687, "parent": 1047, "fw_parent": 0, "seq_id": 462, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1046,171,0,160,8,"cuda:1"],0], "input_shapes": [[20,8],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[1051,1052,0,160,8,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::contiguous", "id": 1047, "rf_id": 686, "parent": 2, "fw_parent": 0, "seq_id": 462, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[1046,171,0,160,8,"cuda:1"],0], "input_shapes": [[20,8],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[1051,1052,0,160,8,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_strided", "id": 1056, "rf_id": 693, "parent": 1055, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,50304],[402432,50304,1],6,0,"cuda:1",false], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","Bool"],
      "outputs": [[1057,1058,0,8048640,4,"cuda:1"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 1059, "rf_id": 694, "parent": 1055, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1057,1058,0,8048640,4,"cuda:1"],[1043,904,0,8048640,2,"cuda:1"],false], "input_shapes": [[20,8,50304],[20,8,50304],[]], "input_types": ["Tensor(float)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1057,1058,0,8048640,4,"cuda:1"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 1055, "rf_id": 692, "parent": 1054, "fw_parent": 0, "seq_id": 462, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1043,904,0,8048640,2,"cuda:1"],6,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[20,8,50304],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[1057,1058,0,8048640,4,"cuda:1"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 1054, "rf_id": 691, "parent": 2, "fw_parent": 0, "seq_id": 462, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1043,904,0,8048640,2,"cuda:1"],6,false,false,"<None>"], "input_shapes": [[20,8,50304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[1057,1058,0,8048640,4,"cuda:1"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1063, "rf_id": 697, "parent": 1061, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1062,851,0,160,4,"cuda:1"],[20,8,1],[8,1,0],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1064,851,0,160,4,"cuda:1"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1067, "rf_id": 698, "parent": 1061, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1065,1066,0,160,8,"cuda:1"],[20,8,1],[8,1,0],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1068,1066,0,160,8,"cuda:1"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::max", "id": 1061, "rf_id": 696, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::max.dim(Tensor self, int dim, bool keepdim=False) -> (Tensor values, Tensor indices)",
      "inputs": [[1057,1058,0,8048640,4,"cuda:1"],-1,false], "input_shapes": [[20,8,50304],[],[]], "input_types": ["Tensor(float)","Int","Bool"],
      "outputs": [[1062,851,0,160,4,"cuda:1"],[1065,1066,0,160,8,"cuda:1"]], "output_shapes": [[20,8],[20,8]], "output_types": ["Tensor(float)","Tensor(long int)"]
    },
    {
      "name": "nccl:all_reduce", "id": 1071, "rf_id": 701, "parent": 1070, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1062,851,0,160,4,"cuda:1"]], "input_shapes": [[20,8]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 1070, "rf_id": 700, "parent": 1069, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[1062,851,0,160,4,"cuda:1"]],19,94716841683536,0,"allreduce",[],[],1], "input_shapes": [[[20,8]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[1062,851,0,160,4,"cuda:1"]]], "output_shapes": [[[20,8]]], "output_types": ["GenericList[Tensor(float)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 1069, "rf_id": 699, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[1062,851,0,160,4,"cuda:1"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[20,8]],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Object","Object","None","Int"],
      "outputs": [[[1062,851,0,160,4,"cuda:1"]],"<Object>"], "output_shapes": [[[20,8]],[]], "output_types": ["GenericList[Tensor(float)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 1072, "rf_id": 702, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [19,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1074, "rf_id": 704, "parent": 1073, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1062,851,0,160,4,"cuda:1"],[20,8,1],[8,1,1],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1075,851,0,160,4,"cuda:1"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::unsqueeze", "id": 1073, "rf_id": 703, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[1062,851,0,160,4,"cuda:1"],-1], "input_shapes": [[20,8],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[1075,851,0,160,4,"cuda:1"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sub", "id": 1076, "rf_id": 705, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1057,1058,0,8048640,4,"cuda:1"],[1075,851,0,160,4,"cuda:1"],1], "input_shapes": [[20,8,50304],[20,8,1],[]], "input_types": ["Tensor(float)","Tensor(float)","Int"],
      "outputs": [[1077,1078,0,8048640,4,"cuda:1"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::lt", "id": 1079, "rf_id": 706, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1051,1052,0,160,8,"cuda:1"],0], "input_shapes": [[20,8],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[1080,1066,0,160,1,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::ge", "id": 1081, "rf_id": 707, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ge.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1051,1052,0,160,8,"cuda:1"],50304], "input_shapes": [[20,8],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[1082,1083,0,160,1,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::bitwise_or", "id": 1085, "rf_id": 709, "parent": 1084, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::bitwise_or.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1080,1066,0,160,1,"cuda:1"],[1082,1083,0,160,1,"cuda:1"]], "input_shapes": [[20,8],[20,8]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[1086,1087,0,160,1,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::__or__", "id": 1084, "rf_id": 708, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::__or__.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1080,1066,0,160,1,"cuda:1"],[1082,1083,0,160,1,"cuda:1"]], "input_shapes": [[20,8],[20,8]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[1086,1087,0,160,1,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 1089, "rf_id": 711, "parent": 1088, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8],[8,1],4,0,"cuda:1","<None>"], "input_shapes": [[[],[]],[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[1090,1091,0,160,8,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 1092, "rf_id": 712, "parent": 1088, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1090,1091,0,160,8,"cuda:1"],[1051,1052,0,160,8,"cuda:1"],false], "input_shapes": [[20,8],[20,8],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[1090,1091,0,160,8,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 1088, "rf_id": 710, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1051,1052,0,160,8,"cuda:1"],"<None>"], "input_shapes": [[20,8],[]], "input_types": ["Tensor(long int)","None"],
      "outputs": [[1090,1091,0,160,8,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::sub", "id": 1095, "rf_id": 713, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1090,1091,0,160,8,"cuda:1"],[1093,1094,0,1,8,"cpu"],1], "input_shapes": [[20,8],[],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Int"],
      "outputs": [[1096,1097,0,160,8,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 1100, "rf_id": 714, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1098,1099,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [[1098,1099,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 1104, "rf_id": 718, "parent": 1103, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[1098,1099,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [0], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 1103, "rf_id": 717, "parent": 1102, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[1098,1099,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [0], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::masked_fill_", "id": 1105, "rf_id": 719, "parent": 1102, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -> Tensor(a!)",
      "inputs": [[1096,1097,0,160,8,"cuda:1"],[1086,1087,0,160,1,"cuda:1"],0], "input_shapes": [[20,8],[20,8],[]], "input_types": ["Tensor(long int)","Tensor(bool)","Int"],
      "outputs": [[1096,1097,0,160,8,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_index_put_impl_", "id": 1102, "rf_id": 716, "parent": 1101, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_index_put_impl_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False, bool unsafe=False) -> Tensor(a!)",
      "inputs": [[1096,1097,0,160,8,"cuda:1"],[[1086,1087,0,160,1,"cuda:1"]],[1098,1099,0,1,8,"cpu"],false,false], "input_shapes": [[20,8],[[20,8]],[],[],[]], "input_types": ["Tensor(long int)","GenericList[Tensor(bool)]","Tensor(long int)","Bool","Bool"],
      "outputs": [[1096,1097,0,160,8,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::index_put_", "id": 1101, "rf_id": 715, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -> Tensor(a!)",
      "inputs": [[1096,1097,0,160,8,"cuda:1"],[[1086,1087,0,160,1,"cuda:1"]],[1098,1099,0,1,8,"cpu"],false], "input_shapes": [[20,8],[[20,8]],[],[]], "input_types": ["Tensor(long int)","GenericList[Tensor(bool)]","Tensor(long int)","Bool"],
      "outputs": [[1096,1097,0,160,8,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 1106, "rf_id": 720, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1077,1078,0,8048640,4,"cuda:1"],[-1,50304]], "input_shapes": [[20,8,50304],[[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int]"],
      "outputs": [[1107,1078,0,8048640,4,"cuda:1"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 1108, "rf_id": 721, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1096,1097,0,160,8,"cuda:1"],[-1]], "input_shapes": [[20,8],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1109,1097,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 1111, "rf_id": 723, "parent": 1110, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],4,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[1112,57,0,0,8,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::resize_", "id": 1114, "rf_id": 725, "parent": 1113, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[1112,57,0,0,8,"cuda:1"],[160],"<None>"], "input_shapes": [[0],[[]],[]], "input_types": ["Tensor(long int)","GenericList[Int]","None"],
      "outputs": [[1112,1091,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 1113, "rf_id": 724, "parent": 1110, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::arange.start_out(Scalar start, Scalar end, Scalar step=1, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [0,160,1,[1112,57,0,0,8,"cuda:1"]], "input_shapes": [[],[],[],[0]], "input_types": ["Int","Int","Int","Tensor(long int)"],
      "outputs": [[1112,1091,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 1110, "rf_id": 722, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::arange.start(Scalar start, Scalar end, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [0,160,"<None>","<None>","cuda:1",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Int","Int","None","None","Device","Bool"],
      "outputs": [[1112,1091,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 1116, "rf_id": 727, "parent": 1115, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1107,1078,0,8048640,4,"cuda:1"],[160],[0],"<None>"], "input_shapes": [[160,50304],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[1117,1078,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 1119, "rf_id": 729, "parent": 1118, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1112,1091,0,160,8,"cuda:1"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1120,1091,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 1118, "rf_id": 728, "parent": 1115, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1112,1091,0,160,8,"cuda:1"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1120,1091,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 1122, "rf_id": 731, "parent": 1121, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1109,1097,0,160,8,"cuda:1"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1123,1097,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 1121, "rf_id": 730, "parent": 1115, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1109,1097,0,160,8,"cuda:1"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1123,1097,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::index", "id": 1115, "rf_id": 726, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::index.Tensor(Tensor self, Tensor?[] indices) -> Tensor",
      "inputs": [[1107,1078,0,8048640,4,"cuda:1"],[[1112,1091,0,160,8,"cuda:1"],[1109,1097,0,160,8,"cuda:1"]]], "input_shapes": [[160,50304],[[160],[160]]], "input_types": ["Tensor(float)","GenericList[Tensor(long int),Tensor(long int)]"],
      "outputs": [[1124,1066,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 1126, "rf_id": 733, "parent": 1125, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:1","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[1117,1127,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 1128, "rf_id": 734, "parent": 1125, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1117,1127,0,160,4,"cuda:1"],[1124,1066,0,160,4,"cuda:1"],false], "input_shapes": [[160],[160],[]], "input_types": ["Tensor(float)","Tensor(float)","Bool"],
      "outputs": [[1117,1127,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::clone", "id": 1125, "rf_id": 732, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1124,1066,0,160,4,"cuda:1"],"<None>"], "input_shapes": [[160],[]], "input_types": ["Tensor(float)","None"],
      "outputs": [[1117,1127,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 1130, "rf_id": 736, "parent": 1129, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1117,1127,0,160,4,"cuda:1"],[20,8]], "input_shapes": [[160],[[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int]"],
      "outputs": [[1120,1127,0,160,4,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view_as", "id": 1129, "rf_id": 735, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1117,1127,0,160,4,"cuda:1"],[1051,1052,0,160,8,"cuda:1"]], "input_shapes": [[160],[20,8]], "input_types": ["Tensor(float)","Tensor(long int)"],
      "outputs": [[1120,1127,0,160,4,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::lift_fresh", "id": 1132, "rf_id": 737, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1123,1131,0,1,4,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[1123,1131,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 1136, "rf_id": 741, "parent": 1135, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[1123,1131,0,1,4,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [0.000000], "output_shapes": [[]], "output_types": ["Double"]
    },
    {
      "name": "aten::item", "id": 1135, "rf_id": 740, "parent": 1134, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[1123,1131,0,1,4,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [0.000000], "output_shapes": [[]], "output_types": ["Double"]
    },
    {
      "name": "aten::masked_fill_", "id": 1137, "rf_id": 742, "parent": 1134, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -> Tensor(a!)",
      "inputs": [[1120,1127,0,160,4,"cuda:1"],[1086,1087,0,160,1,"cuda:1"],0.000000], "input_shapes": [[20,8],[20,8],[]], "input_types": ["Tensor(float)","Tensor(bool)","Double"],
      "outputs": [[1120,1127,0,160,4,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_index_put_impl_", "id": 1134, "rf_id": 739, "parent": 1133, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_index_put_impl_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False, bool unsafe=False) -> Tensor(a!)",
      "inputs": [[1120,1127,0,160,4,"cuda:1"],[[1086,1087,0,160,1,"cuda:1"]],[1123,1131,0,1,4,"cpu"],false,false], "input_shapes": [[20,8],[[20,8]],[],[],[]], "input_types": ["Tensor(float)","GenericList[Tensor(bool)]","Tensor(float)","Bool","Bool"],
      "outputs": [[1120,1127,0,160,4,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::index_put_", "id": 1133, "rf_id": 738, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -> Tensor(a!)",
      "inputs": [[1120,1127,0,160,4,"cuda:1"],[[1086,1087,0,160,1,"cuda:1"]],[1123,1131,0,1,4,"cpu"],false], "input_shapes": [[20,8],[[20,8]],[],[]], "input_types": ["Tensor(float)","GenericList[Tensor(bool)]","Tensor(float)","Bool"],
      "outputs": [[1120,1127,0,160,4,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "nccl:all_reduce", "id": 1140, "rf_id": 745, "parent": 1139, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1120,1127,0,160,4,"cuda:1"]], "input_shapes": [[20,8]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 1139, "rf_id": 744, "parent": 1138, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[1120,1127,0,160,4,"cuda:1"]],20,94716841683536,0,"allreduce",[],[],1], "input_shapes": [[[20,8]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[1120,1127,0,160,4,"cuda:1"]]], "output_shapes": [[[20,8]]], "output_types": ["GenericList[Tensor(float)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 1138, "rf_id": 743, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[1120,1127,0,160,4,"cuda:1"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[20,8]],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Object","Object","None","Int"],
      "outputs": [[[1120,1127,0,160,4,"cuda:1"]],"<Object>"], "output_shapes": [[[20,8]],[]], "output_types": ["GenericList[Tensor(float)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 1141, "rf_id": 746, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [20,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::exp", "id": 1142, "rf_id": 747, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::exp.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[1077,1078,0,8048640,4,"cuda:1"],[1077,1078,0,8048640,4,"cuda:1"]], "input_shapes": [[20,8,50304],[20,8,50304]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[1077,1078,0,8048640,4,"cuda:1"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1145, "rf_id": 749, "parent": 1143, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1144,1066,0,160,4,"cuda:1"],[20,8,1],[8,1,0],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1146,1066,0,160,4,"cuda:1"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sum", "id": 1143, "rf_id": 748, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1077,1078,0,8048640,4,"cuda:1"],[-1],false,"<None>"], "input_shapes": [[20,8,50304],[[]],[],[]], "input_types": ["Tensor(float)","GenericList[Int]","Bool","None"],
      "outputs": [[1144,1066,0,160,4,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "nccl:all_reduce", "id": 1149, "rf_id": 752, "parent": 1148, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1144,1066,0,160,4,"cuda:1"]], "input_shapes": [[20,8]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 1148, "rf_id": 751, "parent": 1147, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[1144,1066,0,160,4,"cuda:1"]],21,94716841683536,0,"allreduce",[],[],1], "input_shapes": [[[20,8]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[1144,1066,0,160,4,"cuda:1"]]], "output_shapes": [[[20,8]]], "output_types": ["GenericList[Tensor(float)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 1147, "rf_id": 750, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[1144,1066,0,160,4,"cuda:1"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[20,8]],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Object","Object","None","Int"],
      "outputs": [[[1144,1066,0,160,4,"cuda:1"]],"<Object>"], "output_shapes": [[[20,8]],[]], "output_types": ["GenericList[Tensor(float)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 1150, "rf_id": 753, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [21,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::log", "id": 1151, "rf_id": 754, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::log(Tensor self) -> Tensor",
      "inputs": [[1144,1066,0,160,4,"cuda:1"]], "input_shapes": [[20,8]], "input_types": ["Tensor(float)"],
      "outputs": [[1152,1153,0,160,4,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sub", "id": 1154, "rf_id": 755, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1152,1153,0,160,4,"cuda:1"],[1120,1127,0,160,4,"cuda:1"],1], "input_shapes": [[20,8],[20,8],[]], "input_types": ["Tensor(float)","Tensor(float)","Int"],
      "outputs": [[1155,1156,0,160,4,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1158, "rf_id": 757, "parent": 1157, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1144,1066,0,160,4,"cuda:1"],[20,8,1],[8,1,1],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1159,1066,0,160,4,"cuda:1"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::unsqueeze", "id": 1157, "rf_id": 756, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[1144,1066,0,160,4,"cuda:1"],-1], "input_shapes": [[20,8],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[1159,1066,0,160,4,"cuda:1"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::div_", "id": 1160, "rf_id": 758, "parent": 1060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[1077,1078,0,8048640,4,"cuda:1"],[1159,1066,0,160,4,"cuda:1"]], "input_shapes": [[20,8,50304],[20,8,1]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[1077,1078,0,8048640,4,"cuda:1"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "_VocabParallelCrossEntropy", "id": 1060, "rf_id": 695, "parent": 2, "fw_parent": 0, "seq_id": 463, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1057,1058,0,8048640,4,"cuda:1"],[1051,1052,0,160,8,"cuda:1"]], "input_shapes": [[20,8,50304],[20,8]], "input_types": ["Tensor(float)","Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1162, "rf_id": 760, "parent": 1161, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1155,1156,0,160,4,"cuda:1"],[8,20],[1,8],"<None>"], "input_shapes": [[20,8],[[],[]],[[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1163,1156,0,160,4,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::transpose", "id": 1161, "rf_id": 759, "parent": 2, "fw_parent": 0, "seq_id": 464, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1155,1156,0,160,4,"cuda:1"],0,1], "input_shapes": [[20,8],[],[]], "input_types": ["Tensor(float)","Int","Int"],
      "outputs": [[1163,1156,0,160,4,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 1167, "rf_id": 764, "parent": 1166, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],6,0,"cuda:1","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[1168,1066,0,160,4,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 1166, "rf_id": 763, "parent": 1165, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1163,1156,0,160,4,"cuda:1"],6,0,"cuda:1","<None>",0], "input_shapes": [[8,20],[],[],[],[],[]], "input_types": ["Tensor(float)","Int","Int","Device","None","Int"],
      "outputs": [[1168,1066,0,160,4,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 1169, "rf_id": 765, "parent": 1165, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1168,1066,0,160,4,"cuda:1"],[1163,1156,0,160,4,"cuda:1"],false], "input_shapes": [[8,20],[8,20],[]], "input_types": ["Tensor(float)","Tensor(float)","Bool"],
      "outputs": [[1168,1066,0,160,4,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::clone", "id": 1165, "rf_id": 762, "parent": 1164, "fw_parent": 0, "seq_id": 465, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1163,1156,0,160,4,"cuda:1"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[1168,1066,0,160,4,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::contiguous", "id": 1164, "rf_id": 761, "parent": 2, "fw_parent": 0, "seq_id": 465, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[1163,1156,0,160,4,"cuda:1"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[1168,1066,0,160,4,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "detach", "id": 1172, "rf_id": 768, "parent": 1171, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1168,1066,0,160,4,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1171, "rf_id": 767, "parent": 1170, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1168,1066,0,160,4,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(float)"],
      "outputs": [[1146,1066,0,160,4,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1170, "rf_id": 766, "parent": 2, "fw_parent": 0, "seq_id": 466, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1168,1066,0,160,4,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1175, "rf_id": 771, "parent": 1174, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1026,132,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1174, "rf_id": 770, "parent": 1173, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1026,132,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1176,132,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1173, "rf_id": 769, "parent": 2, "fw_parent": 0, "seq_id": 467, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1026,132,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 1178, "rf_id": 772, "parent": 2, "fw_parent": 0, "seq_id": 468, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1176,132,0,1,2,"cuda:1"],[1064,1177,0,1,8,"cpu"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[1179,1127,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1182, "rf_id": 773, "parent": 2, "fw_parent": 0, "seq_id": 469, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1179,1127,0,1,2,"cuda:1"],[1180,1181,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1183,1184,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 1185, "rf_id": 774, "parent": 2, "fw_parent": 0, "seq_id": 470, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1146,1066,0,160,4,"cuda:1"],6,false,false,"<None>"], "input_shapes": [[8,20],[],[],[],[]], "input_types": ["Tensor(float)","Int","Bool","Bool","None"],
      "outputs": [[1146,1066,0,160,4,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 1186, "rf_id": 775, "parent": 2, "fw_parent": 0, "seq_id": 470, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[197,198,0,160,4,"cuda:1"],[-1]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(float)","GenericList[Int]"],
      "outputs": [[1187,198,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 1188, "rf_id": 776, "parent": 2, "fw_parent": 0, "seq_id": 470, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1187,198,0,160,4,"cuda:1"],6,false,false,"<None>"], "input_shapes": [[160],[],[],[],[]], "input_types": ["Tensor(float)","Int","Bool","Bool","None"],
      "outputs": [[1187,198,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 1189, "rf_id": 777, "parent": 2, "fw_parent": 0, "seq_id": 470, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1146,1066,0,160,4,"cuda:1"],[-1]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(float)","GenericList[Int]"],
      "outputs": [[1190,1066,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul", "id": 1191, "rf_id": 778, "parent": 2, "fw_parent": 0, "seq_id": 471, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1190,1066,0,160,4,"cuda:1"],[1187,198,0,160,4,"cuda:1"]], "input_shapes": [[160],[160]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[1192,171,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1197, "rf_id": 781, "parent": 1194, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1195,1196,0,1,4,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[1198,1196,0,1,4,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sum", "id": 1194, "rf_id": 780, "parent": 1193, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1192,171,0,160,4,"cuda:1"],[],false,"<None>"], "input_shapes": [[160],[],[],[]], "input_types": ["Tensor(float)","GenericList[]","Bool","None"],
      "outputs": [[1195,1196,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sum", "id": 1193, "rf_id": 779, "parent": 2, "fw_parent": 0, "seq_id": 472, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum(Tensor self, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1192,171,0,160,4,"cuda:1"],"<None>"], "input_shapes": [[160],[]], "input_types": ["Tensor(float)","None"],
      "outputs": [[1195,1196,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1202, "rf_id": 784, "parent": 1200, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1201,1127,0,1,4,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[1203,1127,0,1,4,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sum", "id": 1200, "rf_id": 783, "parent": 1199, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1187,198,0,160,4,"cuda:1"],[],false,"<None>"], "input_shapes": [[160],[],[],[]], "input_types": ["Tensor(float)","GenericList[]","Bool","None"],
      "outputs": [[1201,1127,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sum", "id": 1199, "rf_id": 782, "parent": 2, "fw_parent": 0, "seq_id": 473, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum(Tensor self, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1187,198,0,160,4,"cuda:1"],"<None>"], "input_shapes": [[160],[]], "input_types": ["Tensor(float)","None"],
      "outputs": [[1201,1127,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::div", "id": 1204, "rf_id": 785, "parent": 2, "fw_parent": 0, "seq_id": 473, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1195,1196,0,1,4,"cuda:1"],[1201,1127,0,1,4,"cuda:1"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[1203,171,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 1206, "rf_id": 787, "parent": 1205, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],6,0,"cuda:1","<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","None"],
      "outputs": [[1198,1207,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 1208, "rf_id": 788, "parent": 1205, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1198,1207,0,1,4,"cuda:1"],[1203,171,0,1,4,"cuda:1"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(float)","Bool"],
      "outputs": [[1198,1207,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::clone", "id": 1205, "rf_id": 786, "parent": 2, "fw_parent": 0, "seq_id": 474, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1203,171,0,1,4,"cuda:1"],"<None>"], "input_shapes": [[],[]], "input_types": ["Tensor(float)","None"],
      "outputs": [[1198,1207,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "detach", "id": 1210, "rf_id": 790, "parent": 1209, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1198,1207,0,1,4,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1209, "rf_id": 789, "parent": 2, "fw_parent": 0, "seq_id": 475, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1198,1207,0,1,4,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[1211,1207,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 1212, "rf_id": 791, "parent": 2, "fw_parent": 0, "seq_id": 475, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1211,1207,0,1,4,"cuda:1"],[1]], "input_shapes": [[],[[]]], "input_types": ["Tensor(float)","GenericList[Int]"],
      "outputs": [[1213,1207,0,1,4,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1218, "rf_id": 795, "parent": 1217, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1215,1196,0,1,4,"cuda:1"],[1],[1],0], "input_shapes": [[1],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1219,1196,0,1,4,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::slice", "id": 1217, "rf_id": 794, "parent": 1216, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1215,1196,0,1,4,"cuda:1"],0,0,1,1], "input_shapes": [[1],[],[],[],[]], "input_types": ["Tensor(float)","Int","Int","Int","Int"],
      "outputs": [[1219,1196,0,1,4,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::narrow", "id": 1216, "rf_id": 793, "parent": 1214, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1215,1196,0,1,4,"cuda:1"],0,0,1], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(float)","Int","Int","Int"],
      "outputs": [[1219,1196,0,1,4,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::cat", "id": 1214, "rf_id": 792, "parent": 2, "fw_parent": 0, "seq_id": 475, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[1213,1207,0,1,4,"cuda:1"]],0], "input_shapes": [[[1]],[]], "input_types": ["GenericList[Tensor(float)]","Int"],
      "outputs": [[1215,1196,0,1,4,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "nccl:all_reduce", "id": 1222, "rf_id": 798, "parent": 1221, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1215,1196,0,1,4,"cuda:1"]], "input_shapes": [[1]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 1221, "rf_id": 797, "parent": 1220, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[1215,1196,0,1,4,"cuda:1"]],127,94716817711568,1,"allreduce",[],[],4], "input_shapes": [[[1]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[1215,1196,0,1,4,"cuda:1"]]], "output_shapes": [[[1]]], "output_types": ["GenericList[Tensor(float)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 1220, "rf_id": 796, "parent": 2, "fw_parent": 0, "seq_id": 475, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[1215,1196,0,1,4,"cuda:1"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[1]],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Object","Object","None","Int"],
      "outputs": [[[1215,1196,0,1,4,"cuda:1"]],"<Object>"], "output_shapes": [[[1]],[]], "output_types": ["GenericList[Tensor(float)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 1223, "rf_id": 799, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [127,0,1,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::div", "id": 1226, "rf_id": 800, "parent": 2, "fw_parent": 0, "seq_id": 475, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1215,1196,0,1,4,"cuda:1"],[1224,1225,0,1,8,"cpu"]], "input_shapes": [[1],[]], "input_types": ["Tensor(float)","Tensor(long int)"],
      "outputs": [[1227,1207,0,1,4,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1229, "rf_id": 802, "parent": 1228, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1227,1207,0,1,4,"cuda:1"],[],[],0], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(float)","GenericList[]","GenericList[]","Int"],
      "outputs": [[1219,1207,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::select", "id": 1228, "rf_id": 801, "parent": 2, "fw_parent": 0, "seq_id": 475, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[1227,1207,0,1,4,"cuda:1"],0,0], "input_shapes": [[1],[],[]], "input_types": ["Tensor(float)","Int","Int"],
      "outputs": [[1219,1207,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1232, "rf_id": 805, "parent": 1231, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1183,1184,0,1,4,"cuda:1"],[],[],"<None>"], "input_shapes": [[],[],[],[]], "input_types": ["Tensor(float)","GenericList[]","GenericList[]","None"],
      "outputs": [[1233,1184,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mean", "id": 1231, "rf_id": 804, "parent": 1230, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mean.dim(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1203,171,0,1,4,"cuda:1"],[],false,"<None>"], "input_shapes": [[],[],[],[]], "input_types": ["Tensor(float)","GenericList[]","Bool","None"],
      "outputs": [[1183,1184,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mean", "id": 1230, "rf_id": 803, "parent": 2, "fw_parent": 0, "seq_id": 475, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mean(Tensor self, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1203,171,0,1,4,"cuda:1"],"<None>"], "input_shapes": [[],[]], "input_types": ["Tensor(float)","None"],
      "outputs": [[1183,1184,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 1235, "rf_id": 807, "parent": 1234, "fw_parent": 0, "seq_id": 476, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[1183,1184,0,1,4,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [10.893984], "output_shapes": [[]], "output_types": ["Double"]
    },
    {
      "name": "aten::item", "id": 1234, "rf_id": 806, "parent": 2, "fw_parent": 0, "seq_id": 476, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[1183,1184,0,1,4,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [10.893984], "output_shapes": [[]], "output_types": ["Double"]
    },
    {
      "name": "aten::to", "id": 1236, "rf_id": 808, "parent": 2, "fw_parent": 0, "seq_id": 476, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1203,171,0,1,4,"cuda:1"],6,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(float)","Int","Bool","Bool","None"],
      "outputs": [[1203,171,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul", "id": 1238, "rf_id": 809, "parent": 2, "fw_parent": 0, "seq_id": 476, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1203,171,0,1,4,"cuda:1"],[1233,1237,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[1239,1196,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 1242, "rf_id": 812, "parent": 1241, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],6,0,"cuda:1",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[1243,1184,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 1241, "rf_id": 811, "parent": 1240, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1239,1196,0,1,4,"cuda:1"],"<None>","<None>","<None>",false,1], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","Bool","Int"],
      "outputs": [[1243,1184,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::fill_", "id": 1244, "rf_id": 813, "parent": 1240, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1243,1184,0,1,4,"cuda:1"],1.000000], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [[1243,1184,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::ones_like", "id": 1240, "rf_id": 810, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ones_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1239,1196,0,1,4,"cuda:1"],"<None>","<None>","<None>",false,1], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","Bool","Int"],
      "outputs": [[1243,1184,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "[pytorch|profiler|execution_trace|thread]", "id": 1245, "rf_id": 0, "parent": 1, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::mul", "id": 1248, "rf_id": 816, "parent": 1247, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1243,1184,0,1,4,"cuda:1"],[1233,1237,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[1249,1091,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "MulBackward0", "id": 1247, "rf_id": 815, "parent": 1246, "fw_parent": 2, "seq_id": 476, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1243,1184,0,1,4,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: MulBackward0", "id": 1246, "rf_id": 814, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::div", "id": 1252, "rf_id": 819, "parent": 1251, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::div.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1249,1091,0,1,4,"cuda:1"],[1201,1127,0,1,4,"cuda:1"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[1253,1254,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "DivBackward0", "id": 1251, "rf_id": 818, "parent": 1250, "fw_parent": 2, "seq_id": 473, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1249,1091,0,1,4,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: DivBackward0", "id": 1250, "rf_id": 817, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1258, "rf_id": 823, "parent": 1257, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1253,1254,0,1,4,"cuda:1"],[160],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[1259,1254,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::expand", "id": 1257, "rf_id": 822, "parent": 1256, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)",
      "inputs": [[1253,1254,0,1,4,"cuda:1"],[160],false], "input_shapes": [[],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","Bool"],
      "outputs": [[1259,1254,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "SumBackward0", "id": 1256, "rf_id": 821, "parent": 1255, "fw_parent": 2, "seq_id": 472, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1253,1254,0,1,4,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SumBackward0", "id": 1255, "rf_id": 820, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::mul", "id": 1262, "rf_id": 826, "parent": 1261, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1259,1254,0,160,4,"cuda:1"],[1187,198,0,160,4,"cuda:1"]], "input_shapes": [[160],[160]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[1263,132,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "MulBackward0", "id": 1261, "rf_id": 825, "parent": 1260, "fw_parent": 2, "seq_id": 471, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1259,1254,0,160,4,"cuda:1"]], "input_shapes": [[160]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: MulBackward0", "id": 1260, "rf_id": 824, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1267, "rf_id": 830, "parent": 1266, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1263,132,0,160,4,"cuda:1"],[8,20]], "input_shapes": [[160],[[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int]"],
      "outputs": [[1268,132,0,160,4,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::reshape", "id": 1266, "rf_id": 829, "parent": 1265, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1263,132,0,160,4,"cuda:1"],[8,20]], "input_shapes": [[160],[[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int]"],
      "outputs": [[1268,132,0,160,4,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "ViewBackward0", "id": 1265, "rf_id": 828, "parent": 1264, "fw_parent": 2, "seq_id": 470, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1263,132,0,160,4,"cuda:1"]], "input_shapes": [[160]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 1264, "rf_id": 827, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 1270, "rf_id": 832, "parent": 1269, "fw_parent": 2, "seq_id": 466, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1268,132,0,160,4,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 1269, "rf_id": 831, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "CloneBackward0", "id": 1272, "rf_id": 834, "parent": 1271, "fw_parent": 2, "seq_id": 465, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1268,132,0,160,4,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: CloneBackward0", "id": 1271, "rf_id": 833, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1276, "rf_id": 838, "parent": 1275, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1268,132,0,160,4,"cuda:1"],[20,8],[1,20],"<None>"], "input_shapes": [[8,20],[[],[]],[[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1277,132,0,160,4,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::transpose", "id": 1275, "rf_id": 837, "parent": 1274, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1268,132,0,160,4,"cuda:1"],0,1], "input_shapes": [[8,20],[],[]], "input_types": ["Tensor(float)","Int","Int"],
      "outputs": [[1277,132,0,160,4,"cuda:1"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "TransposeBackward0", "id": 1274, "rf_id": 836, "parent": 1273, "fw_parent": 2, "seq_id": 464, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1268,132,0,160,4,"cuda:1"]], "input_shapes": [[8,20]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 1273, "rf_id": 835, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1280, "rf_id": 841, "parent": 1279, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1077,1078,0,8048640,4,"cuda:1"],[-1,50304]], "input_shapes": [[20,8,50304],[[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int]"],
      "outputs": [[1281,1078,0,8048640,4,"cuda:1"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 1283, "rf_id": 843, "parent": 1282, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],4,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[1284,57,0,0,8,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::resize_", "id": 1286, "rf_id": 845, "parent": 1285, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[1284,57,0,0,8,"cuda:1"],[160],"<None>"], "input_shapes": [[0],[[]],[]], "input_types": ["Tensor(long int)","GenericList[Int]","None"],
      "outputs": [[1284,1091,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 1285, "rf_id": 844, "parent": 1282, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::arange.start_out(Scalar start, Scalar end, Scalar step=1, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [0,160,1,[1284,57,0,0,8,"cuda:1"]], "input_shapes": [[],[],[],[0]], "input_types": ["Int","Int","Int","Tensor(long int)"],
      "outputs": [[1284,1091,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 1282, "rf_id": 842, "parent": 1279, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::arange.start(Scalar start, Scalar end, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [0,160,"<None>","<None>","cuda:1",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Int","Int","None","None","Device","Bool"],
      "outputs": [[1284,1091,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 1287, "rf_id": 846, "parent": 1279, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1086,1087,0,160,1,"cuda:1"],[-1]], "input_shapes": [[20,8],[[]]], "input_types": ["Tensor(bool)","GenericList[Int]"],
      "outputs": [[1288,1087,0,160,1,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 1291, "rf_id": 849, "parent": 1290, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[1292,198,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 1293, "rf_id": 850, "parent": 1290, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1292,198,0,160,4,"cuda:1"],[1288,1087,0,160,1,"cuda:1"],false], "input_shapes": [[160],[160],[]], "input_types": ["Tensor(float)","Tensor(bool)","Bool"],
      "outputs": [[1292,198,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 1290, "rf_id": 848, "parent": 1289, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1288,1087,0,160,1,"cuda:1"],6,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[160],[],[],[],[],[],[]], "input_types": ["Tensor(bool)","Int","None","None","None","Bool","None"],
      "outputs": [[1292,198,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 1289, "rf_id": 847, "parent": 1279, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1288,1087,0,160,1,"cuda:1"],6,false,false,"<None>"], "input_shapes": [[160],[],[],[],[]], "input_types": ["Tensor(bool)","Int","Bool","Bool","None"],
      "outputs": [[1292,198,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sub", "id": 1297, "rf_id": 852, "parent": 1294, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1295,1296,0,1,8,"cpu"],[1292,198,0,160,4,"cuda:1"],1], "input_shapes": [[],[160],[]], "input_types": ["Tensor(double)","Tensor(float)","Int"],
      "outputs": [[1298,1052,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::rsub", "id": 1294, "rf_id": 851, "parent": 1279, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::rsub.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[1292,198,0,160,4,"cuda:1"],1.000000,1], "input_shapes": [[160],[],[]], "input_types": ["Tensor(float)","Double","Int"],
      "outputs": [[1298,1052,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1300, "rf_id": 854, "parent": 1299, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1281,1078,0,8048640,4,"cuda:1"],[160],[0],"<None>"], "input_shapes": [[160,50304],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[1301,1078,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 1303, "rf_id": 856, "parent": 1302, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1284,1091,0,160,8,"cuda:1"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1304,1091,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 1302, "rf_id": 855, "parent": 1299, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1284,1091,0,160,8,"cuda:1"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1304,1091,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 1306, "rf_id": 858, "parent": 1305, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1109,1097,0,160,8,"cuda:1"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1307,1097,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 1305, "rf_id": 857, "parent": 1299, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1109,1097,0,160,8,"cuda:1"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1307,1097,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::index", "id": 1299, "rf_id": 853, "parent": 1279, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::index.Tensor(Tensor self, Tensor?[] indices) -> Tensor",
      "inputs": [[1281,1078,0,8048640,4,"cuda:1"],[[1284,1091,0,160,8,"cuda:1"],[1109,1097,0,160,8,"cuda:1"]]], "input_shapes": [[160,50304],[[160],[160]]], "input_types": ["Tensor(float)","GenericList[Tensor(long int),Tensor(long int)]"],
      "outputs": [[1308,198,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sub_", "id": 1309, "rf_id": 859, "parent": 1279, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sub_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)",
      "inputs": [[1308,198,0,160,4,"cuda:1"],[1298,1052,0,160,4,"cuda:1"],1], "input_shapes": [[160],[160],[]], "input_types": ["Tensor(float)","Tensor(float)","Int"],
      "outputs": [[1308,198,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1312, "rf_id": 862, "parent": 1311, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1281,1078,0,8048640,4,"cuda:1"],[160],[0],"<None>"], "input_shapes": [[160,50304],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[1301,1078,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 1314, "rf_id": 864, "parent": 1313, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1284,1091,0,160,8,"cuda:1"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1304,1091,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 1313, "rf_id": 863, "parent": 1311, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1284,1091,0,160,8,"cuda:1"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1304,1091,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 1316, "rf_id": 866, "parent": 1315, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1109,1097,0,160,8,"cuda:1"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1307,1097,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 1315, "rf_id": 865, "parent": 1311, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1109,1097,0,160,8,"cuda:1"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1307,1097,0,160,8,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_index_put_impl_", "id": 1311, "rf_id": 861, "parent": 1310, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_index_put_impl_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False, bool unsafe=False) -> Tensor(a!)",
      "inputs": [[1281,1078,0,8048640,4,"cuda:1"],[[1284,1091,0,160,8,"cuda:1"],[1109,1097,0,160,8,"cuda:1"]],[1308,198,0,160,4,"cuda:1"],false,false], "input_shapes": [[160,50304],[[160],[160]],[160],[],[]], "input_types": ["Tensor(float)","GenericList[Tensor(long int),Tensor(long int)]","Tensor(float)","Bool","Bool"],
      "outputs": [[1281,1078,0,8048640,4,"cuda:1"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::index_put_", "id": 1310, "rf_id": 860, "parent": 1279, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -> Tensor(a!)",
      "inputs": [[1281,1078,0,8048640,4,"cuda:1"],[[1284,1091,0,160,8,"cuda:1"],[1109,1097,0,160,8,"cuda:1"]],[1308,198,0,160,4,"cuda:1"],false], "input_shapes": [[160,50304],[[160],[160]],[160],[]], "input_types": ["Tensor(float)","GenericList[Tensor(long int),Tensor(long int)]","Tensor(float)","Bool"],
      "outputs": [[1281,1078,0,8048640,4,"cuda:1"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1318, "rf_id": 868, "parent": 1317, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1277,132,0,160,4,"cuda:1"],[20,8,1],[1,20,1],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1301,132,0,160,4,"cuda:1"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::unsqueeze", "id": 1317, "rf_id": 867, "parent": 1279, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[1277,132,0,160,4,"cuda:1"],-1], "input_shapes": [[20,8],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[1301,132,0,160,4,"cuda:1"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul_", "id": 1319, "rf_id": 869, "parent": 1279, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[1077,1078,0,8048640,4,"cuda:1"],[1301,132,0,160,4,"cuda:1"]], "input_shapes": [[20,8,50304],[20,8,1]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[1077,1078,0,8048640,4,"cuda:1"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "_VocabParallelCrossEntropyBackward", "id": 1279, "rf_id": 840, "parent": 1278, "fw_parent": 2, "seq_id": 463, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1277,132,0,160,4,"cuda:1"]], "input_shapes": [[20,8]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _VocabParallelCrossEntropyBackward", "id": 1278, "rf_id": 839, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 1324, "rf_id": 874, "parent": 1323, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,50304],[402432,50304,1],15,0,"cuda:1",false], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","Bool"],
      "outputs": [[1307,904,0,8048640,2,"cuda:1"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1325, "rf_id": 875, "parent": 1323, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1307,904,0,8048640,2,"cuda:1"],[1077,1078,0,8048640,4,"cuda:1"],false], "input_shapes": [[20,8,50304],[20,8,50304],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(float)","Bool"],
      "outputs": [[1307,904,0,8048640,2,"cuda:1"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_to_copy", "id": 1323, "rf_id": 873, "parent": 1322, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1077,1078,0,8048640,4,"cuda:1"],15,0,"cuda:1","<None>",false,"<None>"], "input_shapes": [[20,8,50304],[],[],[],[],[],[]], "input_types": ["Tensor(float)","Int","Int","Device","None","Bool","None"],
      "outputs": [[1307,904,0,8048640,2,"cuda:1"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 1322, "rf_id": 872, "parent": 1321, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1077,1078,0,8048640,4,"cuda:1"],15,0,"cuda:1","<None>",false,false,"<None>"], "input_shapes": [[20,8,50304],[],[],[],[],[],[],[]], "input_types": ["Tensor(float)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[1307,904,0,8048640,2,"cuda:1"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ToCopyBackward0", "id": 1321, "rf_id": 871, "parent": 1320, "fw_parent": 2, "seq_id": 462, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1077,1078,0,8048640,4,"cuda:1"]], "input_shapes": [[20,8,50304]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ToCopyBackward0", "id": 1320, "rf_id": 870, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1330, "rf_id": 880, "parent": 1329, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1307,904,0,8048640,2,"cuda:1"],[160,50304]], "input_shapes": [[20,8,50304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1331,904,0,8048640,2,"cuda:1"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1329, "rf_id": 879, "parent": 1328, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1307,904,0,8048640,2,"cuda:1"],[160,50304]], "input_shapes": [[20,8,50304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1331,904,0,8048640,2,"cuda:1"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1332, "rf_id": 881, "parent": 1328, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1331,904,0,8048640,2,"cuda:1"],[251,237,0,51511296,2,"cuda:1"]], "input_shapes": [[160,50304],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1333,329,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1334, "rf_id": 882, "parent": 1328, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1333,329,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1335,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1328, "rf_id": 878, "parent": 1327, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1307,904,0,8048640,2,"cuda:1"],[251,237,0,51511296,2,"cuda:1"]], "input_shapes": [[20,8,50304],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1335,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1336, "rf_id": 883, "parent": 1327, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1307,904,0,8048640,2,"cuda:1"],[160,50304]], "input_shapes": [[20,8,50304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1337,904,0,8048640,2,"cuda:1"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1338, "rf_id": 884, "parent": 1327, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1030,577,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1339,577,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1342, "rf_id": 887, "parent": 1341, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1337,904,0,8048640,2,"cuda:1"],[50304,160],[1,50304],"<None>"], "input_shapes": [[160,50304],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1343,904,0,8048640,2,"cuda:1"]], "output_shapes": [[50304,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1341, "rf_id": 886, "parent": 1340, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1337,904,0,8048640,2,"cuda:1"],0,1], "input_shapes": [[160,50304],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1343,904,0,8048640,2,"cuda:1"]], "output_shapes": [[50304,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1340, "rf_id": 885, "parent": 1327, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1337,904,0,8048640,2,"cuda:1"]], "input_shapes": [[160,50304]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1343,904,0,8048640,2,"cuda:1"]], "output_shapes": [[50304,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1345, "rf_id": 889, "parent": 1344, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1343,904,0,8048640,2,"cuda:1"],[1339,577,0,163840,2,"cuda:1"]], "input_shapes": [[50304,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1346,1078,0,51511296,2,"cuda:1"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1344, "rf_id": 888, "parent": 1327, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1343,904,0,8048640,2,"cuda:1"],[1339,577,0,163840,2,"cuda:1"]], "input_shapes": [[50304,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1346,1078,0,51511296,2,"cuda:1"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 1327, "rf_id": 877, "parent": 1326, "fw_parent": 2, "seq_id": 461, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1307,904,0,8048640,2,"cuda:1"]], "input_shapes": [[20,8,50304]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 1326, "rf_id": 876, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_CopyToModelParallelRegionBackward", "id": 1348, "rf_id": 891, "parent": 1347, "fw_parent": 2, "seq_id": 460, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1335,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _CopyToModelParallelRegionBackward", "id": 1347, "rf_id": 890, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 1350, "rf_id": 893, "parent": 1349, "fw_parent": 2, "seq_id": 458, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1335,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 1349, "rf_id": 892, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 1352, "rf_id": 895, "parent": 1351, "fw_parent": 2, "seq_id": 456, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1335,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 1351, "rf_id": 894, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 1354, "rf_id": 897, "parent": 1353, "fw_parent": 2, "seq_id": 455, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1335,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 1353, "rf_id": 896, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 1359, "rf_id": 901, "parent": 1358, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1360,359,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1358, "rf_id": 900, "parent": 1356, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1357,577,0,163840,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1360,359,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1362, "rf_id": 903, "parent": 1361, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:1","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[1304,1052,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1361, "rf_id": 902, "parent": 1356, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[994,995,0,1024,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1304,1052,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1364, "rf_id": 905, "parent": 1363, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:1","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[1365,1083,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1363, "rf_id": 904, "parent": 1356, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[996,997,0,1024,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1365,1083,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1366, "rf_id": 906, "parent": 1356, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[16,1024],6,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1367,377,0,16384,4,"cuda:1"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 1369, "rf_id": 908, "parent": 1368, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[16,1024],[1024,1],6,0,"cuda:1","<None>"], "input_shapes": [[[],[]],[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[1370,1371,0,16384,4,"cuda:1"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 1368, "rf_id": 907, "parent": 1356, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1367,377,0,16384,4,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[16,1024],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[1370,1371,0,16384,4,"cuda:1"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunctionBackward", "id": 1356, "rf_id": 899, "parent": 1355, "fw_parent": 2, "seq_id": 454, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1335,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: FusedLayerNormAffineFunctionBackward", "id": 1355, "rf_id": 898, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1375, "rf_id": 912, "parent": 1374, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1304,1052,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1374, "rf_id": 911, "parent": 1373, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1304,1052,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1376,1052,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 1373, "rf_id": 910, "parent": 1372, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1304,1052,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1381, "rf_id": 915, "parent": 1380, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],[1024],[1],0], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1006,1378,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1380, "rf_id": 914, "parent": 1379, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,0,1024,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1006,1378,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 1379, "rf_id": 913, "parent": 1372, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,0,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1006,1378,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1383, "rf_id": 917, "parent": 1382, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1006,1378,0,1024,2,"cuda:1"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1384,1378,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1382, "rf_id": 916, "parent": 1372, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1006,1378,0,1024,2,"cuda:1"],[1376,1052,0,1024,2,"cuda:1"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1384,1378,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1385, "rf_id": 918, "parent": 1372, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1384,1378,0,1024,2,"cuda:1"],[1376,1052,0,1024,2,"cuda:1"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1384,1378,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 1386, "rf_id": 919, "parent": 1372, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1376,1052,0,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1387, "rf_id": 920, "parent": 1372, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[1376,1052,0,1024,2,"cuda:1"],[1384,1378,0,1024,2,"cuda:1"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 1372, "rf_id": 909, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1391, "rf_id": 924, "parent": 1390, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1365,1083,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1390, "rf_id": 923, "parent": 1389, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1365,1083,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1392,1083,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 1389, "rf_id": 922, "parent": 1388, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1365,1083,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1395, "rf_id": 927, "parent": 1394, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],[1024],[1],1024], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1370,1378,1024,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1394, "rf_id": 926, "parent": 1393, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,1024,2048,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1370,1378,1024,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 1393, "rf_id": 925, "parent": 1388, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,1024,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1370,1378,1024,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1397, "rf_id": 929, "parent": 1396, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1370,1378,1024,1024,2,"cuda:1"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1398,1378,1024,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1396, "rf_id": 928, "parent": 1388, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1370,1378,1024,1024,2,"cuda:1"],[1392,1083,0,1024,2,"cuda:1"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1398,1378,1024,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1399, "rf_id": 930, "parent": 1388, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1398,1378,1024,1024,2,"cuda:1"],[1392,1083,0,1024,2,"cuda:1"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1398,1378,1024,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 1400, "rf_id": 931, "parent": 1388, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1392,1083,0,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1401, "rf_id": 932, "parent": 1388, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[1392,1083,0,1024,2,"cuda:1"],[1398,1378,1024,1024,2,"cuda:1"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 1388, "rf_id": 921, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 1403, "rf_id": 934, "parent": 1402, "fw_parent": 2, "seq_id": 453, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1360,359,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 1402, "rf_id": 933, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1408, "rf_id": 938, "parent": 1407, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","None","None"],
      "outputs": [[1409,132,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 1411, "rf_id": 940, "parent": 1410, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1409,132,0,1,2,"cuda:1"],0], "input_shapes": [[],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1409,132,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 1410, "rf_id": 939, "parent": 1407, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1409,132,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1409,132,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 1407, "rf_id": 937, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],15,0,"cuda:1","<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","None"],
      "outputs": [[1409,132,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1413, "rf_id": 942, "parent": 1412, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[403,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1412, "rf_id": 941, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[403,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1414,368,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1416, "rf_id": 944, "parent": 1415, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[407,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1415, "rf_id": 943, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[407,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[1417,227,0,400,1,"cuda:1"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "detach", "id": 1420, "rf_id": 947, "parent": 1419, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1414,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1419, "rf_id": 946, "parent": 1418, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1414,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1421,368,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1418, "rf_id": 945, "parent": 1406, "fw_parent": 0, "seq_id": 261, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1414,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1424, "rf_id": 950, "parent": 1423, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1417,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1423, "rf_id": 949, "parent": 1422, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1417,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[1425,227,0,400,1,"cuda:1"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1422, "rf_id": 948, "parent": 1406, "fw_parent": 0, "seq_id": 262, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1417,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1428, "rf_id": 953, "parent": 1427, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1421,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1427, "rf_id": 952, "parent": 1426, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1421,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1429,368,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1426, "rf_id": 951, "parent": 1406, "fw_parent": 0, "seq_id": 263, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1421,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 1432, "rf_id": 956, "parent": 1431, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1433,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1431, "rf_id": 955, "parent": 1430, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1429,368,0,163840,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1433,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1434, "rf_id": 957, "parent": 1430, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[160],6,0,"cuda:1","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[1435,851,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 1437, "rf_id": 959, "parent": 1436, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:1","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[1438,198,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 1436, "rf_id": 958, "parent": 1430, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1435,851,0,160,4,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[160],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[1438,198,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunction", "id": 1430, "rf_id": 954, "parent": 1406, "fw_parent": 0, "seq_id": 264, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1429,368,0,163840,2,"cuda:1"],[422,423,0,1024,2,"cuda:1"],[424,425,0,1024,2,"cuda:1"]], "input_shapes": [[20,8,1024],[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1441, "rf_id": 962, "parent": 1440, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1433,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1440, "rf_id": 961, "parent": 1439, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1433,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1442,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1439, "rf_id": 960, "parent": 1406, "fw_parent": 0, "seq_id": 265, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1433,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1445, "rf_id": 965, "parent": 1444, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1442,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1444, "rf_id": 964, "parent": 1443, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1442,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1446,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1443, "rf_id": 963, "parent": 1406, "fw_parent": 0, "seq_id": 266, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1442,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1449, "rf_id": 968, "parent": 1448, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1425,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1448, "rf_id": 967, "parent": 1447, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1425,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[1450,227,0,400,1,"cuda:1"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1447, "rf_id": 966, "parent": 1406, "fw_parent": 0, "seq_id": 267, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1425,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1453, "rf_id": 971, "parent": 1452, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1446,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1452, "rf_id": 970, "parent": 1451, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1446,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1454,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1451, "rf_id": 969, "parent": 1406, "fw_parent": 0, "seq_id": 268, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1446,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1457, "rf_id": 974, "parent": 1456, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1454,329,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1458,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1456, "rf_id": 973, "parent": 1455, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1454,329,0,163840,2,"cuda:1"],[1454,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1458,329,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_CopyToModelParallelRegion", "id": 1455, "rf_id": 972, "parent": 1406, "fw_parent": 0, "seq_id": 269, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1454,329,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1462, "rf_id": 978, "parent": 1461, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[469,466,0,3145728,2,"cuda:1"],[1024,3072],[1,1024],"<None>"], "input_shapes": [[3072,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1463,466,0,3145728,2,"cuda:1"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1461, "rf_id": 977, "parent": 1460, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[469,466,0,3145728,2,"cuda:1"],0,1], "input_shapes": [[3072,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1463,466,0,3145728,2,"cuda:1"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1460, "rf_id": 976, "parent": 1459, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[469,466,0,3145728,2,"cuda:1"]], "input_shapes": [[3072,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1463,466,0,3145728,2,"cuda:1"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1466, "rf_id": 981, "parent": 1465, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1458,329,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1467,329,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1465, "rf_id": 980, "parent": 1464, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1458,329,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1467,329,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1468, "rf_id": 982, "parent": 1464, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1467,329,0,163840,2,"cuda:1"],[1463,466,0,3145728,2,"cuda:1"]], "input_shapes": [[160,1024],[1024,3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1469,577,0,491520,2,"cuda:1"]], "output_shapes": [[160,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1470, "rf_id": 983, "parent": 1464, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1469,577,0,491520,2,"cuda:1"],[20,8,3072]], "input_shapes": [[160,3072],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1471,577,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1464, "rf_id": 979, "parent": 1459, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1458,329,0,163840,2,"cuda:1"],[1463,466,0,3145728,2,"cuda:1"]], "input_shapes": [[20,8,1024],[1024,3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1471,577,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1472, "rf_id": 984, "parent": 1459, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1471,577,0,491520,2,"cuda:1"],[564,565,0,3072,2,"cuda:1"],1], "input_shapes": [[20,8,3072],[3072],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1473,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 1459, "rf_id": 975, "parent": 1406, "fw_parent": 0, "seq_id": 270, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1458,329,0,163840,2,"cuda:1"],[469,466,0,3145728,2,"cuda:1"],[564,565,0,3072,2,"cuda:1"]], "input_shapes": [[20,8,1024],[3072,1024],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1476, "rf_id": 987, "parent": 1475, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1473,582,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1475, "rf_id": 986, "parent": 1474, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1473,582,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1477,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1474, "rf_id": 985, "parent": 1406, "fw_parent": 0, "seq_id": 271, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1473,582,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1478, "rf_id": 988, "parent": 1406, "fw_parent": 0, "seq_id": 272, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1477,582,0,491520,2,"cuda:1"],[20,8,-1,3,64]], "input_shapes": [[20,8,3072],[[],[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]"],
      "outputs": [[1479,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1481, "rf_id": 990, "parent": 1480, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1479,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1482,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1480, "rf_id": 989, "parent": 1406, "fw_parent": 0, "seq_id": 273, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1479,582,0,491520,2,"cuda:1"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1482,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1484, "rf_id": 992, "parent": 1483, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1482,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1485,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1483, "rf_id": 991, "parent": 1406, "fw_parent": 0, "seq_id": 274, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1482,582,0,491520,2,"cuda:1"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1485,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1487, "rf_id": 994, "parent": 1486, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1485,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1488,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1486, "rf_id": 993, "parent": 1406, "fw_parent": 0, "seq_id": 275, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1485,582,0,491520,2,"cuda:1"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1488,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1490, "rf_id": 996, "parent": 1489, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1488,582,0,491520,2,"cuda:1"],[20,8,16,1,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1491,582,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1489, "rf_id": 995, "parent": 1406, "fw_parent": 0, "seq_id": 276, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1488,582,0,491520,2,"cuda:1"],3,0,-2,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1491,582,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1493, "rf_id": 998, "parent": 1492, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1491,582,0,163840,2,"cuda:1"],[20,8,16,1,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,1,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1494,582,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1492, "rf_id": 997, "parent": 1406, "fw_parent": 0, "seq_id": 277, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1491,582,0,163840,2,"cuda:1"],4,0,9223372036854775807,1], "input_shapes": [[20,8,16,1,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1494,582,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_reshape_alias", "id": 1496, "rf_id": 1000, "parent": 1495, "fw_parent": 0, "seq_id": 278, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[1494,582,0,163840,2,"cuda:1"],[20,8,16,64],[24576,3072,192,1]], "input_shapes": [[20,8,16,1,64],[[],[],[],[]],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1497,582,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1495, "rf_id": 999, "parent": 1406, "fw_parent": 0, "seq_id": 278, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1494,582,0,163840,2,"cuda:1"],[20,8,-1,64]], "input_shapes": [[20,8,16,1,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1497,582,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1499, "rf_id": 1002, "parent": 1498, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1479,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1500,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1498, "rf_id": 1001, "parent": 1406, "fw_parent": 0, "seq_id": 279, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1479,582,0,491520,2,"cuda:1"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1500,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1502, "rf_id": 1004, "parent": 1501, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1500,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1503,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1501, "rf_id": 1003, "parent": 1406, "fw_parent": 0, "seq_id": 280, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1500,582,0,491520,2,"cuda:1"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1503,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1505, "rf_id": 1006, "parent": 1504, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1503,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1506,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1504, "rf_id": 1005, "parent": 1406, "fw_parent": 0, "seq_id": 281, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1503,582,0,491520,2,"cuda:1"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1506,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1508, "rf_id": 1008, "parent": 1507, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1506,582,0,491520,2,"cuda:1"],[20,8,16,64],[24576,3072,192,1],64], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[1509,582,64,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 1507, "rf_id": 1007, "parent": 1406, "fw_parent": 0, "seq_id": 282, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[1506,582,0,491520,2,"cuda:1"],3,-2], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1509,582,64,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1511, "rf_id": 1010, "parent": 1510, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1509,582,64,163840,2,"cuda:1"],[20,8,16,64],[24576,3072,192,1],64], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[1512,582,64,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1510, "rf_id": 1009, "parent": 1406, "fw_parent": 0, "seq_id": 283, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1509,582,64,163840,2,"cuda:1"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1512,582,64,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1514, "rf_id": 1012, "parent": 1513, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1479,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1515,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1513, "rf_id": 1011, "parent": 1406, "fw_parent": 0, "seq_id": 284, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1479,582,0,491520,2,"cuda:1"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1515,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1517, "rf_id": 1014, "parent": 1516, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1515,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1518,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1516, "rf_id": 1013, "parent": 1406, "fw_parent": 0, "seq_id": 285, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1515,582,0,491520,2,"cuda:1"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1518,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1520, "rf_id": 1016, "parent": 1519, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1518,582,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1521,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1519, "rf_id": 1015, "parent": 1406, "fw_parent": 0, "seq_id": 286, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1518,582,0,491520,2,"cuda:1"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1521,582,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1523, "rf_id": 1018, "parent": 1522, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1521,582,0,491520,2,"cuda:1"],[20,8,16,64],[24576,3072,192,1],128], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[1524,582,128,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 1522, "rf_id": 1017, "parent": 1406, "fw_parent": 0, "seq_id": 287, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[1521,582,0,491520,2,"cuda:1"],3,-1], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1524,582,128,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1526, "rf_id": 1020, "parent": 1525, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1524,582,128,163840,2,"cuda:1"],[20,8,16,64],[24576,3072,192,1],128], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[1527,582,128,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1525, "rf_id": 1019, "parent": 1406, "fw_parent": 0, "seq_id": 288, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1524,582,128,163840,2,"cuda:1"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1527,582,128,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1530, "rf_id": 1023, "parent": 1529, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1497,582,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1529, "rf_id": 1022, "parent": 1528, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1497,582,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1531,582,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1528, "rf_id": 1021, "parent": 1406, "fw_parent": 0, "seq_id": 289, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1497,582,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1534, "rf_id": 1026, "parent": 1533, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1512,582,64,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1533, "rf_id": 1025, "parent": 1532, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1512,582,64,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1535,582,64,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1532, "rf_id": 1024, "parent": 1406, "fw_parent": 0, "seq_id": 290, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1512,582,64,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1538, "rf_id": 1029, "parent": 1537, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1527,582,128,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1537, "rf_id": 1028, "parent": 1536, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1527,582,128,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1539,582,128,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1536, "rf_id": 1027, "parent": 1406, "fw_parent": 0, "seq_id": 291, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1527,582,128,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1542, "rf_id": 1032, "parent": 1541, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1450,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1541, "rf_id": 1031, "parent": 1540, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1450,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[1543,227,0,400,1,"cuda:1"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1540, "rf_id": 1030, "parent": 1406, "fw_parent": 0, "seq_id": 292, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1450,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1544, "rf_id": 1033, "parent": 1406, "fw_parent": 0, "seq_id": 293, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1531,582,0,163840,2,"cuda:1"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1545,582,0,163840,2,"cuda:1"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1546, "rf_id": 1034, "parent": 1406, "fw_parent": 0, "seq_id": 294, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1535,582,64,163840,2,"cuda:1"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1547,582,64,163840,2,"cuda:1"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1549, "rf_id": 1036, "parent": 1548, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[657,658,0,51200,2,"cuda:1"],[51200],[1],0], "input_shapes": [[51200],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1550,658,0,51200,2,"cuda:1"]], "output_shapes": [[51200]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1548, "rf_id": 1035, "parent": 1406, "fw_parent": 0, "seq_id": 295, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[657,658,0,51200,2,"cuda:1"],0,0,51200,1], "input_shapes": [[51200],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1550,658,0,51200,2,"cuda:1"]], "output_shapes": [[51200]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1551, "rf_id": 1037, "parent": 1406, "fw_parent": 0, "seq_id": 295, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1550,658,0,51200,2,"cuda:1"],[128,20,20]], "input_shapes": [[51200],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1552,658,0,51200,2,"cuda:1"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1554, "rf_id": 1039, "parent": 1553, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1545,582,0,163840,2,"cuda:1"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1555,582,0,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1553, "rf_id": 1038, "parent": 1406, "fw_parent": 0, "seq_id": 295, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1545,582,0,163840,2,"cuda:1"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1555,582,0,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1557, "rf_id": 1041, "parent": 1556, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1547,582,64,163840,2,"cuda:1"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1558,582,64,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1556, "rf_id": 1040, "parent": 1406, "fw_parent": 0, "seq_id": 296, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1547,582,64,163840,2,"cuda:1"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1558,582,64,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1560, "rf_id": 1043, "parent": 1559, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1558,582,64,163840,2,"cuda:1"],[128,64,20],[192,1,24576],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1561,582,64,163840,2,"cuda:1"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1559, "rf_id": 1042, "parent": 1406, "fw_parent": 0, "seq_id": 297, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1558,582,64,163840,2,"cuda:1"],1,2], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1561,582,64,163840,2,"cuda:1"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::baddbmm", "id": 1562, "rf_id": 1044, "parent": 1406, "fw_parent": 0, "seq_id": 298, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor",
      "inputs": [[1552,658,0,51200,2,"cuda:1"],[1555,582,0,163840,2,"cuda:1"],[1561,582,64,163840,2,"cuda:1"],0.000000,0.125000], "input_shapes": [[128,20,20],[128,20,64],[128,64,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Double","Double"],
      "outputs": [[1563,377,0,51200,2,"cuda:1"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1564, "rf_id": 1045, "parent": 1406, "fw_parent": 0, "seq_id": 299, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1563,377,0,51200,2,"cuda:1"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1565,377,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1568, "rf_id": 1048, "parent": 1567, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1565,377,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1567, "rf_id": 1047, "parent": 1566, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1565,377,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1569,377,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1566, "rf_id": 1046, "parent": 1406, "fw_parent": 0, "seq_id": 300, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1565,377,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1572, "rf_id": 1051, "parent": 1571, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1543,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1571, "rf_id": 1050, "parent": 1570, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1543,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[1573,227,0,400,1,"cuda:1"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1570, "rf_id": 1049, "parent": 1406, "fw_parent": 0, "seq_id": 301, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1543,227,0,400,1,"cuda:1"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1574, "rf_id": 1052, "parent": 1406, "fw_parent": 0, "seq_id": 302, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1569,377,0,51200,2,"cuda:1"],[-1,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1575,377,0,51200,2,"cuda:1"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1577, "rf_id": 1054, "parent": 1576, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],4,0,"cpu",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","Bool","None"],
      "outputs": [[1578,1579,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 1580, "rf_id": 1055, "parent": 1576, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1578,1579,0,1,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[1],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[1578,1579,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 1581, "rf_id": 1056, "parent": 1576, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1578,1579,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [[1578,1579,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "detach_", "id": 1583, "rf_id": 1058, "parent": 1582, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1578,1579,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 1582, "rf_id": 1057, "parent": 1576, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1578,1579,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [[1578,1579,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 1585, "rf_id": 1060, "parent": 1584, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1578,1579,0,1,8,"cpu"],[],[],0], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[1586,1579,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 1584, "rf_id": 1059, "parent": 1576, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[1578,1579,0,1,8,"cpu"],0,0], "input_shapes": [[1],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[1586,1579,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 1588, "rf_id": 1062, "parent": 1587, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[1586,1579,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 1587, "rf_id": 1061, "parent": 1576, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[1586,1579,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::empty", "id": 1589, "rf_id": 1063, "parent": 1576, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[128,20,20],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1590,734,0,51200,2,"cuda:1"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ScaledUpperTriangMaskedSoftmax", "id": 1576, "rf_id": 1053, "parent": 1406, "fw_parent": 0, "seq_id": 303, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1575,377,0,51200,2,"cuda:1"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1591, "rf_id": 1064, "parent": 1406, "fw_parent": 0, "seq_id": 304, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1590,734,0,51200,2,"cuda:1"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1592,734,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1595, "rf_id": 1067, "parent": 1594, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1592,734,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1594, "rf_id": 1066, "parent": 1593, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1592,734,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1596,734,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1593, "rf_id": 1065, "parent": 1406, "fw_parent": 0, "seq_id": 305, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1592,734,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1599, "rf_id": 1070, "parent": 1598, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1596,734,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1598, "rf_id": 1069, "parent": 1597, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1596,734,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1600,734,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1597, "rf_id": 1068, "parent": 1406, "fw_parent": 0, "seq_id": 306, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1596,734,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 1604, "rf_id": 1074, "parent": 1603, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[8,16,20,20],[6400,400,20,1],11,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[]],[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1605,1606,0,51200,1,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 1603, "rf_id": 1073, "parent": 1602, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1600,734,0,51200,2,"cuda:1"],11,0,"cuda:1","<None>","<None>"], "input_shapes": [[8,16,20,20],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[1605,1606,0,51200,1,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 1608, "rf_id": 1076, "parent": 1607, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[8,16,20,20],[6400,400,20,1],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[]],[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1609,1610,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1607, "rf_id": 1075, "parent": 1602, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1600,734,0,51200,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[8,16,20,20],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1609,1610,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 1602, "rf_id": 1072, "parent": 1601, "fw_parent": 0, "seq_id": 307, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[1600,734,0,51200,2,"cuda:1"],0.100000,true], "input_shapes": [[8,16,20,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[1609,1610,0,51200,2,"cuda:1"],[1605,1606,0,51200,1,"cuda:1"]], "output_shapes": [[8,16,20,20],[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::dropout", "id": 1601, "rf_id": 1071, "parent": 1406, "fw_parent": 0, "seq_id": 307, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::dropout(Tensor input, float p, bool train) -> Tensor",
      "inputs": [[1600,734,0,51200,2,"cuda:1"],0.100000,true], "input_shapes": [[8,16,20,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[1609,1610,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1613, "rf_id": 1079, "parent": 1612, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1609,1610,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1612, "rf_id": 1078, "parent": 1611, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1609,1610,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1614,1610,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1611, "rf_id": 1077, "parent": 1406, "fw_parent": 0, "seq_id": 308, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1609,1610,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1615, "rf_id": 1080, "parent": 1406, "fw_parent": 0, "seq_id": 309, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1539,582,128,163840,2,"cuda:1"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1616,582,128,163840,2,"cuda:1"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1617, "rf_id": 1081, "parent": 1406, "fw_parent": 0, "seq_id": 310, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1614,1610,0,51200,2,"cuda:1"],[128,20,-1]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1618,1610,0,51200,2,"cuda:1"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1620, "rf_id": 1083, "parent": 1619, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1616,582,128,163840,2,"cuda:1"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1573,582,128,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1619, "rf_id": 1082, "parent": 1406, "fw_parent": 0, "seq_id": 311, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1616,582,128,163840,2,"cuda:1"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1573,582,128,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 1621, "rf_id": 1084, "parent": 1406, "fw_parent": 0, "seq_id": 312, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1618,1610,0,51200,2,"cuda:1"],[1573,582,128,163840,2,"cuda:1"]], "input_shapes": [[128,20,20],[128,20,64]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1622,1623,0,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1624, "rf_id": 1085, "parent": 1406, "fw_parent": 0, "seq_id": 313, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1622,1623,0,163840,2,"cuda:1"],[8,16,20,64]], "input_shapes": [[128,20,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1625,1623,0,163840,2,"cuda:1"]], "output_shapes": [[8,16,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1627, "rf_id": 1087, "parent": 1626, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1625,1623,0,163840,2,"cuda:1"],[20,8,16,64],[64,20480,1280,1],"<None>"], "input_shapes": [[8,16,20,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","None"],
      "outputs": [[1628,1623,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::permute", "id": 1626, "rf_id": 1086, "parent": 1406, "fw_parent": 0, "seq_id": 314, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)",
      "inputs": [[1625,1623,0,163840,2,"cuda:1"],[2,0,1,3]], "input_shapes": [[8,16,20,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1628,1623,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1632, "rf_id": 1091, "parent": 1631, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:1","<None>",0], "input_shapes": [[[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[1633,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1631, "rf_id": 1090, "parent": 1630, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1628,1623,0,163840,2,"cuda:1"],15,0,"cuda:1","<None>",0], "input_shapes": [[20,8,16,64],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Int"],
      "outputs": [[1633,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1634, "rf_id": 1092, "parent": 1630, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1633,577,0,163840,2,"cuda:1"],[1628,1623,0,163840,2,"cuda:1"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1633,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::clone", "id": 1630, "rf_id": 1089, "parent": 1629, "fw_parent": 0, "seq_id": 315, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1628,1623,0,163840,2,"cuda:1"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1633,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::contiguous", "id": 1629, "rf_id": 1088, "parent": 1406, "fw_parent": 0, "seq_id": 315, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[1628,1623,0,163840,2,"cuda:1"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1633,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1635, "rf_id": 1093, "parent": 1406, "fw_parent": 0, "seq_id": 316, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1633,577,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1636,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1639, "rf_id": 1096, "parent": 1638, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1636,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1638, "rf_id": 1095, "parent": 1637, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1636,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1640,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1637, "rf_id": 1094, "parent": 1406, "fw_parent": 0, "seq_id": 317, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1636,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1643, "rf_id": 1099, "parent": 1642, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1640,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1642, "rf_id": 1098, "parent": 1641, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1640,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1644,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1641, "rf_id": 1097, "parent": 1406, "fw_parent": 0, "seq_id": 318, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1640,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1648, "rf_id": 1103, "parent": 1647, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[496,493,0,1048576,2,"cuda:1"],[1024,1024],[1,1024],"<None>"], "input_shapes": [[1024,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1649,493,0,1048576,2,"cuda:1"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1647, "rf_id": 1102, "parent": 1646, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[496,493,0,1048576,2,"cuda:1"],0,1], "input_shapes": [[1024,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1649,493,0,1048576,2,"cuda:1"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1646, "rf_id": 1101, "parent": 1645, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[496,493,0,1048576,2,"cuda:1"]], "input_shapes": [[1024,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1649,493,0,1048576,2,"cuda:1"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1652, "rf_id": 1106, "parent": 1651, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1644,577,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1653,577,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1651, "rf_id": 1105, "parent": 1650, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1644,577,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1653,577,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1654, "rf_id": 1107, "parent": 1650, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1653,577,0,163840,2,"cuda:1"],[1649,493,0,1048576,2,"cuda:1"]], "input_shapes": [[160,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1655,1623,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1656, "rf_id": 1108, "parent": 1650, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1655,1623,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1657,1623,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1650, "rf_id": 1104, "parent": 1645, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1644,577,0,163840,2,"cuda:1"],[1649,493,0,1048576,2,"cuda:1"]], "input_shapes": [[20,8,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1657,1623,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 1645, "rf_id": 1100, "parent": 1406, "fw_parent": 0, "seq_id": 319, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1644,577,0,163840,2,"cuda:1"],[496,493,0,1048576,2,"cuda:1"]], "input_shapes": [[20,8,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1660, "rf_id": 1111, "parent": 1659, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1657,1623,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1661,1623,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1659, "rf_id": 1110, "parent": 1658, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1657,1623,0,163840,2,"cuda:1"],[1657,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1661,1623,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_ReduceFromModelParallelRegion", "id": 1658, "rf_id": 1109, "parent": 1406, "fw_parent": 0, "seq_id": 320, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1657,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1664, "rf_id": 1114, "parent": 1663, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1661,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1663, "rf_id": 1113, "parent": 1662, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1661,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1665,1623,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1662, "rf_id": 1112, "parent": 1406, "fw_parent": 0, "seq_id": 321, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1661,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1668, "rf_id": 1117, "parent": 1667, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[778,779,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1667, "rf_id": 1116, "parent": 1666, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[778,779,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1669,779,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1666, "rf_id": 1115, "parent": 1406, "fw_parent": 0, "seq_id": 322, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[778,779,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1672, "rf_id": 1120, "parent": 1671, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1665,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1671, "rf_id": 1119, "parent": 1670, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1665,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1673,1623,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1670, "rf_id": 1118, "parent": 1406, "fw_parent": 0, "seq_id": 323, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1665,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1676, "rf_id": 1123, "parent": 1675, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1669,779,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1675, "rf_id": 1122, "parent": 1674, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1669,779,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1677,779,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1674, "rf_id": 1121, "parent": 1406, "fw_parent": 0, "seq_id": 324, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1669,779,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1680, "rf_id": 1126, "parent": 1679, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1677,779,0,1024,2,"cuda:1"],[20,8,1024],[0,0,1],"<None>"], "input_shapes": [[1024],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1681,779,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::expand", "id": 1679, "rf_id": 1125, "parent": 1678, "fw_parent": 0, "seq_id": 325, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)",
      "inputs": [[1677,779,0,1024,2,"cuda:1"],[20,8,1024],false], "input_shapes": [[1024],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","Bool"],
      "outputs": [[1681,779,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::expand_as", "id": 1678, "rf_id": 1124, "parent": 1406, "fw_parent": 0, "seq_id": 325, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1677,779,0,1024,2,"cuda:1"],[1421,368,0,163840,2,"cuda:1"]], "input_shapes": [[1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1681,779,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1685, "rf_id": 1130, "parent": 1684, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1681,779,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1684, "rf_id": 1129, "parent": 1683, "fw_parent": 0, "seq_id": 327, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1681,779,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1686,779,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1688, "rf_id": 1132, "parent": 1687, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1673,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1687, "rf_id": 1131, "parent": 1683, "fw_parent": 0, "seq_id": 327, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1673,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1689,1623,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1691, "rf_id": 1134, "parent": 1690, "fw_parent": 0, "seq_id": 327, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1689,1623,0,163840,2,"cuda:1"],[1686,779,0,163840,2,"cuda:1"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1692,981,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<forward op>", "id": 1690, "rf_id": 1133, "parent": 1683, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1686,779,0,163840,2,"cuda:1"],[1689,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "fallback_function", "id": 1683, "rf_id": 1128, "parent": 1682, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1681,779,0,163840,2,"cuda:1"],[1673,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1694, "rf_id": 1136, "parent": 1693, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1421,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1693, "rf_id": 1135, "parent": 1682, "fw_parent": 0, "seq_id": 328, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1421,368,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1695,368,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1697, "rf_id": 1138, "parent": 1696, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1692,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1696, "rf_id": 1137, "parent": 1682, "fw_parent": 0, "seq_id": 328, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1692,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1698,981,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1702, "rf_id": 1142, "parent": 1701, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],11,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1703,1704,0,163840,1,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 1701, "rf_id": 1141, "parent": 1700, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1698,981,0,163840,2,"cuda:1"],11,0,"cuda:1","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[1703,1704,0,163840,1,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 1706, "rf_id": 1144, "parent": 1705, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1707,1708,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1705, "rf_id": 1143, "parent": 1700, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1698,981,0,163840,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1707,1708,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 1700, "rf_id": 1140, "parent": 1699, "fw_parent": 0, "seq_id": 328, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[1698,981,0,163840,2,"cuda:1"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[1707,1708,0,163840,2,"cuda:1"],[1703,1704,0,163840,1,"cuda:1"]], "output_shapes": [[20,8,1024],[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::add", "id": 1709, "rf_id": 1145, "parent": 1699, "fw_parent": 0, "seq_id": 328, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1695,368,0,163840,2,"cuda:1"],[1707,1708,0,163840,2,"cuda:1"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1710,1711,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<forward op>", "id": 1699, "rf_id": 1139, "parent": 1682, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1695,368,0,163840,2,"cuda:1"],0.100000,[1698,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_dropout_add_fused_train", "id": 1682, "rf_id": 1127, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1673,1623,0,163840,2,"cuda:1"],[1681,779,0,163840,2,"cuda:1"],[1421,368,0,163840,2,"cuda:1"],0.100000], "input_shapes": [[20,8,1024],[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Double"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1714, "rf_id": 1148, "parent": 1713, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1710,1711,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1713, "rf_id": 1147, "parent": 1712, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1710,1711,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1715,1711,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1712, "rf_id": 1146, "parent": 1406, "fw_parent": 0, "seq_id": 328, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1710,1711,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 1718, "rf_id": 1151, "parent": 1717, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1719,981,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1717, "rf_id": 1150, "parent": 1716, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1715,1711,0,163840,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1719,981,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1720, "rf_id": 1152, "parent": 1716, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[160],6,0,"cuda:1","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[1721,851,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 1723, "rf_id": 1154, "parent": 1722, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:1","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[1724,435,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 1722, "rf_id": 1153, "parent": 1716, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1721,851,0,160,4,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[160],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[1724,435,0,160,4,"cuda:1"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunction", "id": 1716, "rf_id": 1149, "parent": 1406, "fw_parent": 0, "seq_id": 329, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1715,1711,0,163840,2,"cuda:1"],[817,818,0,1024,2,"cuda:1"],[819,820,0,1024,2,"cuda:1"]], "input_shapes": [[20,8,1024],[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1727, "rf_id": 1157, "parent": 1726, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1719,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1726, "rf_id": 1156, "parent": 1725, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1719,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1728,981,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1725, "rf_id": 1155, "parent": 1406, "fw_parent": 0, "seq_id": 330, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1719,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1729, "rf_id": 1158, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],15,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[1730,1731,0,1,2,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1734, "rf_id": 1161, "parent": 1733, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],15,0,"cuda:1",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[1735,851,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1736, "rf_id": 1162, "parent": 1733, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1735,851,0,1,2,"cuda:1"],[1730,1731,0,1,2,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1735,851,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_to_copy", "id": 1733, "rf_id": 1160, "parent": 1732, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1730,1731,0,1,2,"cpu"],15,"<None>","cuda:1","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","Device","None","Bool","None"],
      "outputs": [[1735,851,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 1732, "rf_id": 1159, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1730,1731,0,1,2,"cpu"],"cuda:1",15,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Device","Int","Bool","Bool","None"],
      "outputs": [[1735,851,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::lift_fresh", "id": 1737, "rf_id": 1163, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1735,851,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1735,851,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach_", "id": 1739, "rf_id": 1165, "parent": 1738, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1735,851,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 1738, "rf_id": 1164, "parent": 1406, "fw_parent": 0, "seq_id": 331, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1735,851,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1735,851,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1740, "rf_id": 1166, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],15,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[1741,1742,0,1,2,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1745, "rf_id": 1169, "parent": 1744, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],15,0,"cuda:1",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[1746,1747,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1748, "rf_id": 1170, "parent": 1744, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1746,1747,0,1,2,"cuda:1"],[1741,1742,0,1,2,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1746,1747,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_to_copy", "id": 1744, "rf_id": 1168, "parent": 1743, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1741,1742,0,1,2,"cpu"],15,"<None>","cuda:1","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","Device","None","Bool","None"],
      "outputs": [[1746,1747,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 1743, "rf_id": 1167, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1741,1742,0,1,2,"cpu"],"cuda:1",15,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Device","Int","Bool","Bool","None"],
      "outputs": [[1746,1747,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::lift_fresh", "id": 1749, "rf_id": 1171, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1746,1747,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1746,1747,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach_", "id": 1751, "rf_id": 1173, "parent": 1750, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1746,1747,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 1750, "rf_id": 1172, "parent": 1406, "fw_parent": 0, "seq_id": 331, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1746,1747,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1746,1747,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1754, "rf_id": 1176, "parent": 1753, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1728,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1753, "rf_id": 1175, "parent": 1752, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1728,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1755,981,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1752, "rf_id": 1174, "parent": 1406, "fw_parent": 0, "seq_id": 331, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1728,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1758, "rf_id": 1179, "parent": 1757, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1755,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1757, "rf_id": 1178, "parent": 1756, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1755,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1759,981,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1756, "rf_id": 1177, "parent": 1406, "fw_parent": 0, "seq_id": 332, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1755,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1762, "rf_id": 1182, "parent": 1761, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1759,981,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1763,981,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1761, "rf_id": 1181, "parent": 1760, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1759,981,0,163840,2,"cuda:1"],[1759,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1763,981,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_CopyToModelParallelRegion", "id": 1760, "rf_id": 1180, "parent": 1406, "fw_parent": 0, "seq_id": 333, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1759,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1767, "rf_id": 1186, "parent": 1766, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[523,520,0,4194304,2,"cuda:1"],[1024,4096],[1,1024],"<None>"], "input_shapes": [[4096,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1768,520,0,4194304,2,"cuda:1"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1766, "rf_id": 1185, "parent": 1765, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[523,520,0,4194304,2,"cuda:1"],0,1], "input_shapes": [[4096,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1768,520,0,4194304,2,"cuda:1"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1765, "rf_id": 1184, "parent": 1764, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[523,520,0,4194304,2,"cuda:1"]], "input_shapes": [[4096,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1768,520,0,4194304,2,"cuda:1"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1771, "rf_id": 1189, "parent": 1770, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1763,981,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1772,981,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1770, "rf_id": 1188, "parent": 1769, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1763,981,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1772,981,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1773, "rf_id": 1190, "parent": 1769, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1772,981,0,163840,2,"cuda:1"],[1768,520,0,4194304,2,"cuda:1"]], "input_shapes": [[160,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1774,879,0,655360,2,"cuda:1"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1775, "rf_id": 1191, "parent": 1769, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1774,879,0,655360,2,"cuda:1"],[20,8,4096]], "input_shapes": [[160,4096],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1776,879,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1769, "rf_id": 1187, "parent": 1764, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1763,981,0,163840,2,"cuda:1"],[1768,520,0,4194304,2,"cuda:1"]], "input_shapes": [[20,8,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1776,879,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 1764, "rf_id": 1183, "parent": 1406, "fw_parent": 0, "seq_id": 334, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1763,981,0,163840,2,"cuda:1"],[523,520,0,4194304,2,"cuda:1"]], "input_shapes": [[20,8,1024],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1779, "rf_id": 1194, "parent": 1778, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1776,879,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1778, "rf_id": 1193, "parent": 1777, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1776,879,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1780,879,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1777, "rf_id": 1192, "parent": 1406, "fw_parent": 0, "seq_id": 335, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1776,879,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1783, "rf_id": 1197, "parent": 1782, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[886,887,0,4096,2,"cuda:1"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1782, "rf_id": 1196, "parent": 1781, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[886,887,0,4096,2,"cuda:1"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1784,887,0,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1781, "rf_id": 1195, "parent": 1406, "fw_parent": 0, "seq_id": 336, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[886,887,0,4096,2,"cuda:1"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1789, "rf_id": 1202, "parent": 1788, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1780,879,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1788, "rf_id": 1201, "parent": 1787, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1780,879,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1790,879,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1792, "rf_id": 1204, "parent": 1791, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1784,887,0,4096,2,"cuda:1"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1791, "rf_id": 1203, "parent": 1787, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1784,887,0,4096,2,"cuda:1"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1793,887,0,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1795, "rf_id": 1206, "parent": 1794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1793,887,0,4096,2,"cuda:1"],[1790,879,0,655360,2,"cuda:1"],1], "input_shapes": [[4096],[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1796,898,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1800, "rf_id": 1208, "parent": 1797, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1796,898,0,655360,2,"cuda:1"],[1798,1799,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1801,1802,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1797, "rf_id": 1207, "parent": 1794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1796,898,0,655360,2,"cuda:1"],0.500000], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1801,1802,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1806, "rf_id": 1210, "parent": 1803, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1796,898,0,655360,2,"cuda:1"],[1804,1805,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1807,904,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1803, "rf_id": 1209, "parent": 1794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1796,898,0,655360,2,"cuda:1"],0.797885], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1807,904,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1811, "rf_id": 1212, "parent": 1808, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1796,898,0,655360,2,"cuda:1"],[1809,1810,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1812,910,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1808, "rf_id": 1211, "parent": 1794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1796,898,0,655360,2,"cuda:1"],0.044715], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1812,910,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1813, "rf_id": 1213, "parent": 1794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1812,910,0,655360,2,"cuda:1"],[1796,898,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1814,916,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1818, "rf_id": 1215, "parent": 1815, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1814,916,0,655360,2,"cuda:1"],[1816,1817,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[1819,919,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1815, "rf_id": 1214, "parent": 1794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[1814,916,0,655360,2,"cuda:1"],1,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1819,919,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1820, "rf_id": 1216, "parent": 1794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1807,904,0,655360,2,"cuda:1"],[1819,919,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1821,916,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::tanh", "id": 1822, "rf_id": 1217, "parent": 1794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::tanh(Tensor self) -> Tensor",
      "inputs": [[1821,916,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1823,1824,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1828, "rf_id": 1219, "parent": 1825, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1823,1824,0,655360,2,"cuda:1"],[1826,1827,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)","Int"],
      "outputs": [[1829,916,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1825, "rf_id": 1218, "parent": 1794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[1823,1824,0,655360,2,"cuda:1"],1.000000,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Int"],
      "outputs": [[1829,916,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1830, "rf_id": 1220, "parent": 1794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1801,1802,0,655360,2,"cuda:1"],[1829,916,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1831,1832,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<forward op>", "id": 1794, "rf_id": 1205, "parent": 1787, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1790,879,0,655360,2,"cuda:1"],[1793,887,0,4096,2,"cuda:1"]], "input_shapes": [[20,8,4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "fallback_function", "id": 1787, "rf_id": 1200, "parent": 1786, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1780,879,0,655360,2,"cuda:1"],[1784,887,0,4096,2,"cuda:1"]], "input_shapes": [[20,8,4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_gelu", "id": 1786, "rf_id": 1199, "parent": 1785, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1784,887,0,4096,2,"cuda:1"],[1780,879,0,655360,2,"cuda:1"]], "input_shapes": [[4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "GeLUFunction", "id": 1785, "rf_id": 1198, "parent": 1406, "fw_parent": 0, "seq_id": 337, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1780,879,0,655360,2,"cuda:1"],[1784,887,0,4096,2,"cuda:1"]], "input_shapes": [[20,8,4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1835, "rf_id": 1223, "parent": 1834, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1831,1832,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1834, "rf_id": 1222, "parent": 1833, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1831,1832,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1836,1832,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1833, "rf_id": 1221, "parent": 1406, "fw_parent": 0, "seq_id": 339, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1831,1832,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1840, "rf_id": 1227, "parent": 1839, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[550,547,0,4194304,2,"cuda:1"],[4096,1024],[1,4096],"<None>"], "input_shapes": [[1024,4096],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1841,547,0,4194304,2,"cuda:1"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1839, "rf_id": 1226, "parent": 1838, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[550,547,0,4194304,2,"cuda:1"],0,1], "input_shapes": [[1024,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1841,547,0,4194304,2,"cuda:1"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1838, "rf_id": 1225, "parent": 1837, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[550,547,0,4194304,2,"cuda:1"]], "input_shapes": [[1024,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1841,547,0,4194304,2,"cuda:1"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1844, "rf_id": 1230, "parent": 1843, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1836,1832,0,655360,2,"cuda:1"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1845,1832,0,655360,2,"cuda:1"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1843, "rf_id": 1229, "parent": 1842, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1836,1832,0,655360,2,"cuda:1"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1845,1832,0,655360,2,"cuda:1"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1846, "rf_id": 1231, "parent": 1842, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1845,1832,0,655360,2,"cuda:1"],[1841,547,0,4194304,2,"cuda:1"]], "input_shapes": [[160,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1847,1708,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1848, "rf_id": 1232, "parent": 1842, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1847,1708,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1849,1708,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1842, "rf_id": 1228, "parent": 1837, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1836,1832,0,655360,2,"cuda:1"],[1841,547,0,4194304,2,"cuda:1"]], "input_shapes": [[20,8,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1849,1708,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 1837, "rf_id": 1224, "parent": 1406, "fw_parent": 0, "seq_id": 340, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1836,1832,0,655360,2,"cuda:1"],[550,547,0,4194304,2,"cuda:1"]], "input_shapes": [[20,8,4096],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1852, "rf_id": 1235, "parent": 1851, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1849,1708,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1853,1708,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1851, "rf_id": 1234, "parent": 1850, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1849,1708,0,163840,2,"cuda:1"],[1849,1708,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1853,1708,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_ReduceFromModelParallelRegion", "id": 1850, "rf_id": 1233, "parent": 1406, "fw_parent": 0, "seq_id": 341, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1849,1708,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 1854, "rf_id": 1236, "parent": 1406, "fw_parent": 0, "seq_id": 342, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1853,1708,0,163840,2,"cuda:1"],[957,958,0,1024,2,"cuda:1"],1], "input_shapes": [[20,8,1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1855,1856,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1859, "rf_id": 1239, "parent": 1858, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1855,1856,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1858, "rf_id": 1238, "parent": 1857, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1855,1856,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1860,1856,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1857, "rf_id": 1237, "parent": 1406, "fw_parent": 0, "seq_id": 343, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1855,1856,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1863, "rf_id": 1242, "parent": 1862, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1860,1856,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1862, "rf_id": 1241, "parent": 1861, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1860,1856,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1864,1856,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1861, "rf_id": 1240, "parent": 1406, "fw_parent": 0, "seq_id": 344, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1860,1856,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1867, "rf_id": 1245, "parent": 1866, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1710,1711,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1866, "rf_id": 1244, "parent": 1865, "fw_parent": 0, "seq_id": 346, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1710,1711,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1868,1711,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1870, "rf_id": 1247, "parent": 1869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1864,1856,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1869, "rf_id": 1246, "parent": 1865, "fw_parent": 0, "seq_id": 346, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1864,1856,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1871,1856,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1875, "rf_id": 1251, "parent": 1874, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],11,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1876,1877,0,163840,1,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 1874, "rf_id": 1250, "parent": 1873, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1871,1856,0,163840,2,"cuda:1"],11,0,"cuda:1","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[1876,1877,0,163840,1,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 1879, "rf_id": 1253, "parent": 1878, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1880,1708,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1878, "rf_id": 1252, "parent": 1873, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1871,1856,0,163840,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1880,1708,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 1873, "rf_id": 1249, "parent": 1872, "fw_parent": 0, "seq_id": 346, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[1871,1856,0,163840,2,"cuda:1"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[1880,1708,0,163840,2,"cuda:1"],[1876,1877,0,163840,1,"cuda:1"]], "output_shapes": [[20,8,1024],[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::add", "id": 1881, "rf_id": 1254, "parent": 1872, "fw_parent": 0, "seq_id": 346, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1868,1711,0,163840,2,"cuda:1"],[1880,1708,0,163840,2,"cuda:1"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1882,1883,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<forward op>", "id": 1872, "rf_id": 1248, "parent": 1865, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1868,1711,0,163840,2,"cuda:1"],0.100000,[1871,1856,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_dropout_add_fused_train", "id": 1865, "rf_id": 1243, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1864,1856,0,163840,2,"cuda:1"],"<None>",[1710,1711,0,163840,2,"cuda:1"],0.100000], "input_shapes": [[20,8,1024],[],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","None","Tensor(c10::BFloat16)","Double"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1886, "rf_id": 1257, "parent": 1885, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1882,1883,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1885, "rf_id": 1256, "parent": 1884, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1882,1883,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1887,1883,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1884, "rf_id": 1255, "parent": 1406, "fw_parent": 0, "seq_id": 346, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1882,1883,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1890, "rf_id": 1260, "parent": 1889, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1735,851,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1889, "rf_id": 1259, "parent": 1888, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1735,851,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1891,851,0,1,2,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1888, "rf_id": 1258, "parent": 1406, "fw_parent": 0, "seq_id": 347, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1735,851,0,1,2,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::is_same_size", "id": 1892, "rf_id": 1261, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::is_same_size(Tensor self, Tensor other) -> bool",
      "inputs": [[1887,1883,0,163840,2,"cuda:1"],[1360,359,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 1894, "rf_id": 1263, "parent": 1893, "fw_parent": 1893, "seq_id": 346, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1360,359,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 1893, "rf_id": 1262, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1900, "rf_id": 1269, "parent": 1899, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,1024],15,0,"cuda:1","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[1901,1623,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1899, "rf_id": 1268, "parent": 1898, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1360,359,0,163840,2,"cuda:1"],"<None>","<None>","<None>","<None>",0], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","Int"],
      "outputs": [[1901,1623,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout_backward", "id": 1898, "rf_id": 1267, "parent": 1897, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout_backward(Tensor grad_output, Tensor mask, float scale) -> Tensor",
      "inputs": [[1360,359,0,163840,2,"cuda:1"],[1876,1877,0,163840,1,"cuda:1"],1.111111], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(bool)","Double"],
      "outputs": [[1901,1623,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<backward op>", "id": 1897, "rf_id": 1266, "parent": 1896, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1360,359,0,163840,2,"cuda:1"],1.111111,[1876,1877,0,163840,1,"cuda:1"],"<None>","<None>"], "input_shapes": [[20,8,1024],[],[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(bool)","None","None"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 1896, "rf_id": 1265, "parent": 1895, "fw_parent": 1895, "seq_id": 345, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1360,359,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 1895, "rf_id": 1264, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 1903, "rf_id": 1271, "parent": 1902, "fw_parent": 1902, "seq_id": 344, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1901,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 1902, "rf_id": 1270, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 1905, "rf_id": 1273, "parent": 1904, "fw_parent": 1904, "seq_id": 343, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1901,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 1904, "rf_id": 1272, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "AddBackward0", "id": 1907, "rf_id": 1275, "parent": 1906, "fw_parent": 1906, "seq_id": 342, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1901,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::sum", "id": 1908, "rf_id": 1276, "parent": 1906, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1901,1623,0,163840,2,"cuda:1"],[0,1],true,"<None>"], "input_shapes": [[20,8,1024],[[],[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","Bool","None"],
      "outputs": [[1909,1052,0,1024,2,"cuda:1"]], "output_shapes": [[1,1,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1910, "rf_id": 1277, "parent": 1906, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1909,1052,0,1024,2,"cuda:1"],[1024]], "input_shapes": [[1,1,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1911,1052,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: AddBackward0", "id": 1906, "rf_id": 1274, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1915, "rf_id": 1281, "parent": 1914, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1911,1052,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1914, "rf_id": 1280, "parent": 1913, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1911,1052,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1916,1052,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 1913, "rf_id": 1279, "parent": 1912, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1911,1052,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1919, "rf_id": 1284, "parent": 1918, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],[1024],[1],2048], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1920,1378,2048,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1918, "rf_id": 1283, "parent": 1917, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,2048,3072,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1920,1378,2048,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 1917, "rf_id": 1282, "parent": 1912, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,2048,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1920,1378,2048,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1922, "rf_id": 1286, "parent": 1921, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1920,1378,2048,1024,2,"cuda:1"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1923,1378,2048,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1921, "rf_id": 1285, "parent": 1912, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1920,1378,2048,1024,2,"cuda:1"],[1916,1052,0,1024,2,"cuda:1"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1923,1378,2048,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1924, "rf_id": 1287, "parent": 1912, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1923,1378,2048,1024,2,"cuda:1"],[1916,1052,0,1024,2,"cuda:1"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1923,1378,2048,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 1925, "rf_id": 1288, "parent": 1912, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1916,1052,0,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1926, "rf_id": 1289, "parent": 1912, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[1916,1052,0,1024,2,"cuda:1"],[1923,1378,2048,1024,2,"cuda:1"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 1912, "rf_id": 1278, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_ReduceFromModelParallelRegionBackward", "id": 1928, "rf_id": 1291, "parent": 1927, "fw_parent": 1927, "seq_id": 341, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1901,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _ReduceFromModelParallelRegionBackward", "id": 1927, "rf_id": 1290, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1933, "rf_id": 1296, "parent": 1932, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1901,1623,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1934,1623,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1932, "rf_id": 1295, "parent": 1931, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1901,1623,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1934,1623,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1935, "rf_id": 1297, "parent": 1931, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1934,1623,0,163840,2,"cuda:1"],[550,547,0,4194304,2,"cuda:1"]], "input_shapes": [[160,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1936,898,0,655360,2,"cuda:1"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1937, "rf_id": 1298, "parent": 1931, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1936,898,0,655360,2,"cuda:1"],[20,8,4096]], "input_shapes": [[160,4096],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1938,898,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1931, "rf_id": 1294, "parent": 1930, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1901,1623,0,163840,2,"cuda:1"],[550,547,0,4194304,2,"cuda:1"]], "input_shapes": [[20,8,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1938,898,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1939, "rf_id": 1299, "parent": 1930, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1901,1623,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1940,1623,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1941, "rf_id": 1300, "parent": 1930, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1836,1832,0,655360,2,"cuda:1"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1942,1832,0,655360,2,"cuda:1"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1945, "rf_id": 1303, "parent": 1944, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1940,1623,0,163840,2,"cuda:1"],[1024,160],[1,1024],"<None>"], "input_shapes": [[160,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1946,1623,0,163840,2,"cuda:1"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1944, "rf_id": 1302, "parent": 1943, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1940,1623,0,163840,2,"cuda:1"],0,1], "input_shapes": [[160,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1946,1623,0,163840,2,"cuda:1"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1943, "rf_id": 1301, "parent": 1930, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1940,1623,0,163840,2,"cuda:1"]], "input_shapes": [[160,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1946,1623,0,163840,2,"cuda:1"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1948, "rf_id": 1305, "parent": 1947, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1946,1623,0,163840,2,"cuda:1"],[1942,1832,0,655360,2,"cuda:1"]], "input_shapes": [[1024,160],[160,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1949,1950,0,4194304,2,"cuda:1"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1947, "rf_id": 1304, "parent": 1930, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1946,1623,0,163840,2,"cuda:1"],[1942,1832,0,655360,2,"cuda:1"]], "input_shapes": [[1024,160],[160,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1949,1950,0,4194304,2,"cuda:1"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 1930, "rf_id": 1293, "parent": 1929, "fw_parent": 1929, "seq_id": 340, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1901,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 1929, "rf_id": 1292, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1954, "rf_id": 1309, "parent": 1953, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1949,1950,0,4194304,2,"cuda:1"]], "input_shapes": [[1024,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1953, "rf_id": 1308, "parent": 1952, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1949,1950,0,4194304,2,"cuda:1"]], "input_shapes": [[1024,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1955,1950,0,4194304,2,"cuda:1"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 1952, "rf_id": 1307, "parent": 1951, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1949,1950,0,4194304,2,"cuda:1"]], "input_shapes": [[1024,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1958, "rf_id": 1312, "parent": 1957, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],[4194304],[1],3072], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1959,1378,3072,4194304,2,"cuda:1"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1957, "rf_id": 1311, "parent": 1956, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,3072,4197376,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1959,1378,3072,4194304,2,"cuda:1"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 1956, "rf_id": 1310, "parent": 1951, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,3072,4194304], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1959,1378,3072,4194304,2,"cuda:1"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1961, "rf_id": 1314, "parent": 1960, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1959,1378,3072,4194304,2,"cuda:1"],[1024,4096]], "input_shapes": [[4194304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1962,1378,3072,4194304,2,"cuda:1"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1960, "rf_id": 1313, "parent": 1951, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1959,1378,3072,4194304,2,"cuda:1"],[1955,1950,0,4194304,2,"cuda:1"]], "input_shapes": [[4194304],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1962,1378,3072,4194304,2,"cuda:1"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1963, "rf_id": 1315, "parent": 1951, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1962,1378,3072,4194304,2,"cuda:1"],[1955,1950,0,4194304,2,"cuda:1"],true], "input_shapes": [[1024,4096],[1024,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1962,1378,3072,4194304,2,"cuda:1"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 1964, "rf_id": 1316, "parent": 1951, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1955,1950,0,4194304,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1965, "rf_id": 1317, "parent": 1951, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[1955,1950,0,4194304,2,"cuda:1"],[1962,1378,3072,4194304,2,"cuda:1"]], "input_shapes": [[1024,4096],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 1951, "rf_id": 1306, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 1969, "rf_id": 1320, "parent": 1967, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1968,547,0,4194304,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1970, "rf_id": 1321, "parent": 1967, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[1971,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1972, "rf_id": 1322, "parent": 1967, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[550,547,0,4194304,2,"cuda:1"],[1971,57,0,0,2,"cuda:1"]], "input_shapes": [[1024,4096],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 1967, "rf_id": 1319, "parent": 1966, "fw_parent": 1966, "seq_id": 339, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1938,898,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 1966, "rf_id": 1318, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 1976, "rf_id": 1326, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1784,887,0,4096,2,"cuda:1"],[1780,879,0,655360,2,"cuda:1"],1], "input_shapes": [[4096],[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1977,1802,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1981, "rf_id": 1328, "parent": 1978, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1977,1802,0,655360,2,"cuda:1"],[1979,1980,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1982,904,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1978, "rf_id": 1327, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1977,1802,0,655360,2,"cuda:1"],0.797885], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1982,904,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1986, "rf_id": 1330, "parent": 1983, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1977,1802,0,655360,2,"cuda:1"],[1984,1985,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1987,910,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1983, "rf_id": 1329, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1977,1802,0,655360,2,"cuda:1"],0.044715], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1987,910,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1988, "rf_id": 1331, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1987,910,0,655360,2,"cuda:1"],[1977,1802,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1989,916,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1993, "rf_id": 1333, "parent": 1990, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1989,916,0,655360,2,"cuda:1"],[1991,1992,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[1994,910,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1990, "rf_id": 1332, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[1989,916,0,655360,2,"cuda:1"],1,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1994,910,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1995, "rf_id": 1334, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1982,904,0,655360,2,"cuda:1"],[1994,910,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1996,916,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::tanh", "id": 1997, "rf_id": 1335, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::tanh(Tensor self) -> Tensor",
      "inputs": [[1996,916,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1998,904,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2002, "rf_id": 1337, "parent": 1999, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1977,1802,0,655360,2,"cuda:1"],[2000,2001,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[2003,910,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1999, "rf_id": 1336, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1977,1802,0,655360,2,"cuda:1"],0.500000], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[2003,910,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2004, "rf_id": 1338, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1998,904,0,655360,2,"cuda:1"],[1998,904,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2005,916,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::neg", "id": 2006, "rf_id": 1339, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::neg(Tensor self) -> Tensor",
      "inputs": [[2005,916,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2007,919,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 2011, "rf_id": 1341, "parent": 2008, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[2007,919,0,655360,2,"cuda:1"],[2009,2010,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[2012,916,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 2008, "rf_id": 1340, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[2007,919,0,655360,2,"cuda:1"],1,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2012,916,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2016, "rf_id": 1343, "parent": 2013, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1977,1802,0,655360,2,"cuda:1"],[2014,2015,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[2017,919,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2013, "rf_id": 1342, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1977,1802,0,655360,2,"cuda:1"],0.107032], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[2017,919,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2018, "rf_id": 1344, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2017,919,0,655360,2,"cuda:1"],[1977,1802,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2019,1824,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 2023, "rf_id": 1346, "parent": 2020, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[2019,1824,0,655360,2,"cuda:1"],[2021,2022,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)","Int"],
      "outputs": [[2024,919,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 2020, "rf_id": 1345, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[2019,1824,0,655360,2,"cuda:1"],0.797885,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Int"],
      "outputs": [[2024,919,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2025, "rf_id": 1347, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2012,916,0,655360,2,"cuda:1"],[2024,919,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2026,1802,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2027, "rf_id": 1348, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2003,910,0,655360,2,"cuda:1"],[2026,1802,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2028,916,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 2032, "rf_id": 1350, "parent": 2029, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1998,904,0,655360,2,"cuda:1"],[2030,2031,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[2033,910,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 2029, "rf_id": 1349, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[1998,904,0,655360,2,"cuda:1"],1,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2033,910,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2037, "rf_id": 1352, "parent": 2034, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2033,910,0,655360,2,"cuda:1"],[2035,2036,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[2038,904,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2034, "rf_id": 1351, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[2033,910,0,655360,2,"cuda:1"],0.500000], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[2038,904,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 2039, "rf_id": 1353, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[2028,916,0,655360,2,"cuda:1"],[2038,904,0,655360,2,"cuda:1"],1], "input_shapes": [[20,8,4096],[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[2040,910,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2041, "rf_id": 1354, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2040,910,0,655360,2,"cuda:1"],[1938,898,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2042,904,0,655360,2,"cuda:1"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "bias_gelu_back", "id": 1975, "rf_id": 1325, "parent": 1974, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1938,898,0,655360,2,"cuda:1"],[1784,887,0,4096,2,"cuda:1"],[1780,879,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096],[4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "GeLUFunctionBackward", "id": 1974, "rf_id": 1324, "parent": 1973, "fw_parent": 1973, "seq_id": 337, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1938,898,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::sum", "id": 2043, "rf_id": 1355, "parent": 1973, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[2042,904,0,655360,2,"cuda:1"],[0,1],true,"<None>"], "input_shapes": [[20,8,4096],[[],[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","Bool","None"],
      "outputs": [[2044,1153,0,4096,2,"cuda:1"]], "output_shapes": [[1,1,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2045, "rf_id": 1356, "parent": 1973, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2044,1153,0,4096,2,"cuda:1"],[4096]], "input_shapes": [[1,1,4096],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2046,1153,0,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: GeLUFunctionBackward", "id": 1973, "rf_id": 1323, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2048, "rf_id": 1358, "parent": 2047, "fw_parent": 2047, "seq_id": 336, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2046,1153,0,4096,2,"cuda:1"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2047, "rf_id": 1357, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2052, "rf_id": 1362, "parent": 2051, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2046,1153,0,4096,2,"cuda:1"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2051, "rf_id": 1361, "parent": 2050, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2046,1153,0,4096,2,"cuda:1"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2053,1153,0,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2050, "rf_id": 1360, "parent": 2049, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2046,1153,0,4096,2,"cuda:1"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2056, "rf_id": 1365, "parent": 2055, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],[4096],[1],4197376], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2057,1378,4197376,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2055, "rf_id": 1364, "parent": 2054, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,4197376,4201472,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2057,1378,4197376,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2054, "rf_id": 1363, "parent": 2049, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,4197376,4096], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2057,1378,4197376,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2059, "rf_id": 1367, "parent": 2058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2057,1378,4197376,4096,2,"cuda:1"],[4096]], "input_shapes": [[4096],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2060,1378,4197376,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2058, "rf_id": 1366, "parent": 2049, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2057,1378,4197376,4096,2,"cuda:1"],[2053,1153,0,4096,2,"cuda:1"]], "input_shapes": [[4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2060,1378,4197376,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2061, "rf_id": 1368, "parent": 2049, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2060,1378,4197376,4096,2,"cuda:1"],[2053,1153,0,4096,2,"cuda:1"],true], "input_shapes": [[4096],[4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2060,1378,4197376,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2062, "rf_id": 1369, "parent": 2049, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2053,1153,0,4096,2,"cuda:1"],"<Stream>"], "input_shapes": [[4096],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2063, "rf_id": 1370, "parent": 2049, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2053,1153,0,4096,2,"cuda:1"],[2060,1378,4197376,4096,2,"cuda:1"]], "input_shapes": [[4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2049, "rf_id": 1359, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2065, "rf_id": 1372, "parent": 2064, "fw_parent": 2064, "seq_id": 335, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2042,904,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2064, "rf_id": 1371, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2070, "rf_id": 1377, "parent": 2069, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2042,904,0,655360,2,"cuda:1"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2071,904,0,655360,2,"cuda:1"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2069, "rf_id": 1376, "parent": 2068, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2042,904,0,655360,2,"cuda:1"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2071,904,0,655360,2,"cuda:1"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 2072, "rf_id": 1378, "parent": 2068, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2071,904,0,655360,2,"cuda:1"],[523,520,0,4194304,2,"cuda:1"]], "input_shapes": [[160,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2073,1623,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 2074, "rf_id": 1379, "parent": 2068, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[2073,1623,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2075,1623,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 2068, "rf_id": 1375, "parent": 2067, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2042,904,0,655360,2,"cuda:1"],[523,520,0,4194304,2,"cuda:1"]], "input_shapes": [[20,8,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2075,1623,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2076, "rf_id": 1380, "parent": 2067, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2042,904,0,655360,2,"cuda:1"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2077,904,0,655360,2,"cuda:1"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2078, "rf_id": 1381, "parent": 2067, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1763,981,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2079,981,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2082, "rf_id": 1384, "parent": 2081, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2077,904,0,655360,2,"cuda:1"],[4096,160],[1,4096],"<None>"], "input_shapes": [[160,4096],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[2083,904,0,655360,2,"cuda:1"]], "output_shapes": [[4096,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2081, "rf_id": 1383, "parent": 2080, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[2077,904,0,655360,2,"cuda:1"],0,1], "input_shapes": [[160,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2083,904,0,655360,2,"cuda:1"]], "output_shapes": [[4096,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 2080, "rf_id": 1382, "parent": 2067, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2077,904,0,655360,2,"cuda:1"]], "input_shapes": [[160,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2083,904,0,655360,2,"cuda:1"]], "output_shapes": [[4096,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 2085, "rf_id": 1386, "parent": 2084, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2083,904,0,655360,2,"cuda:1"],[2079,981,0,163840,2,"cuda:1"]], "input_shapes": [[4096,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2086,910,0,4194304,2,"cuda:1"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 2084, "rf_id": 1385, "parent": 2067, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2083,904,0,655360,2,"cuda:1"],[2079,981,0,163840,2,"cuda:1"]], "input_shapes": [[4096,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2086,910,0,4194304,2,"cuda:1"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 2067, "rf_id": 1374, "parent": 2066, "fw_parent": 2066, "seq_id": 334, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2042,904,0,655360,2,"cuda:1"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 2066, "rf_id": 1373, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2090, "rf_id": 1390, "parent": 2089, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2086,910,0,4194304,2,"cuda:1"]], "input_shapes": [[4096,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2089, "rf_id": 1389, "parent": 2088, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2086,910,0,4194304,2,"cuda:1"]], "input_shapes": [[4096,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2091,910,0,4194304,2,"cuda:1"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2088, "rf_id": 1388, "parent": 2087, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2086,910,0,4194304,2,"cuda:1"]], "input_shapes": [[4096,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2094, "rf_id": 1393, "parent": 2093, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],[4194304],[1],4201472], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2095,1378,4201472,4194304,2,"cuda:1"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2093, "rf_id": 1392, "parent": 2092, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,4201472,8395776,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2095,1378,4201472,4194304,2,"cuda:1"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2092, "rf_id": 1391, "parent": 2087, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,4201472,4194304], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2095,1378,4201472,4194304,2,"cuda:1"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2097, "rf_id": 1395, "parent": 2096, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2095,1378,4201472,4194304,2,"cuda:1"],[4096,1024]], "input_shapes": [[4194304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2098,1378,4201472,4194304,2,"cuda:1"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2096, "rf_id": 1394, "parent": 2087, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2095,1378,4201472,4194304,2,"cuda:1"],[2091,910,0,4194304,2,"cuda:1"]], "input_shapes": [[4194304],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2098,1378,4201472,4194304,2,"cuda:1"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2099, "rf_id": 1396, "parent": 2087, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2098,1378,4201472,4194304,2,"cuda:1"],[2091,910,0,4194304,2,"cuda:1"],true], "input_shapes": [[4096,1024],[4096,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2098,1378,4201472,4194304,2,"cuda:1"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2100, "rf_id": 1397, "parent": 2087, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2091,910,0,4194304,2,"cuda:1"],"<Stream>"], "input_shapes": [[4096,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2101, "rf_id": 1398, "parent": 2087, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2091,910,0,4194304,2,"cuda:1"],[2098,1378,4201472,4194304,2,"cuda:1"]], "input_shapes": [[4096,1024],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2087, "rf_id": 1387, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_CopyToModelParallelRegionBackward", "id": 2103, "rf_id": 1400, "parent": 2102, "fw_parent": 2102, "seq_id": 333, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2075,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _CopyToModelParallelRegionBackward", "id": 2102, "rf_id": 1399, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 2107, "rf_id": 1403, "parent": 2105, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2106,520,0,4194304,2,"cuda:1"],"<Stream>"], "input_shapes": [[4096,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2108, "rf_id": 1404, "parent": 2105, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[2109,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2110, "rf_id": 1405, "parent": 2105, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[523,520,0,4194304,2,"cuda:1"],[2109,57,0,0,2,"cuda:1"]], "input_shapes": [[4096,1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2105, "rf_id": 1402, "parent": 2104, "fw_parent": 2104, "seq_id": 332, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2075,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2104, "rf_id": 1401, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2112, "rf_id": 1407, "parent": 2111, "fw_parent": 2111, "seq_id": 331, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2075,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2111, "rf_id": 1406, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2114, "rf_id": 1409, "parent": 2113, "fw_parent": 2113, "seq_id": 330, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2075,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2113, "rf_id": 1408, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 2119, "rf_id": 1413, "parent": 2118, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2120,2121,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2118, "rf_id": 1412, "parent": 2116, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2117,981,0,163840,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[2120,2121,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 2123, "rf_id": 1415, "parent": 2122, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:1","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[2124,1052,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2122, "rf_id": 1414, "parent": 2116, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[817,818,0,1024,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[2124,1052,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 2126, "rf_id": 1417, "parent": 2125, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:1","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[2127,1083,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2125, "rf_id": 1416, "parent": 2116, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[819,820,0,1024,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[2127,1083,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 2128, "rf_id": 1418, "parent": 2116, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[16,1024],6,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2129,377,0,16384,4,"cuda:1"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 2131, "rf_id": 1420, "parent": 2130, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[16,1024],[1024,1],6,0,"cuda:1","<None>"], "input_shapes": [[[],[]],[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[2132,2133,0,16384,4,"cuda:1"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 2130, "rf_id": 1419, "parent": 2116, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2129,377,0,16384,4,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[16,1024],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[2132,2133,0,16384,4,"cuda:1"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunctionBackward", "id": 2116, "rf_id": 1411, "parent": 2115, "fw_parent": 2115, "seq_id": 329, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2075,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: FusedLayerNormAffineFunctionBackward", "id": 2115, "rf_id": 1410, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2137, "rf_id": 1424, "parent": 2136, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2124,1052,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2136, "rf_id": 1423, "parent": 2135, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2124,1052,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2138,1052,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2135, "rf_id": 1422, "parent": 2134, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2124,1052,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2141, "rf_id": 1427, "parent": 2140, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],[1024],[1],8395776], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1724,1378,8395776,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2140, "rf_id": 1426, "parent": 2139, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,8395776,8396800,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1724,1378,8395776,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2139, "rf_id": 1425, "parent": 2134, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,8395776,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1724,1378,8395776,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2143, "rf_id": 1429, "parent": 2142, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1724,1378,8395776,1024,2,"cuda:1"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2144,1378,8395776,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2142, "rf_id": 1428, "parent": 2134, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1724,1378,8395776,1024,2,"cuda:1"],[2138,1052,0,1024,2,"cuda:1"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2144,1378,8395776,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2145, "rf_id": 1430, "parent": 2134, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2144,1378,8395776,1024,2,"cuda:1"],[2138,1052,0,1024,2,"cuda:1"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2144,1378,8395776,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2146, "rf_id": 1431, "parent": 2134, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2138,1052,0,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2147, "rf_id": 1432, "parent": 2134, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2138,1052,0,1024,2,"cuda:1"],[2144,1378,8395776,1024,2,"cuda:1"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2134, "rf_id": 1421, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2151, "rf_id": 1436, "parent": 2150, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2127,1083,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2150, "rf_id": 1435, "parent": 2149, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2127,1083,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2152,1083,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2149, "rf_id": 1434, "parent": 2148, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2127,1083,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2155, "rf_id": 1439, "parent": 2154, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],[1024],[1],8396800], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2132,1378,8396800,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2154, "rf_id": 1438, "parent": 2153, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,8396800,8397824,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2132,1378,8396800,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2153, "rf_id": 1437, "parent": 2148, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,8396800,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2132,1378,8396800,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2157, "rf_id": 1441, "parent": 2156, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2132,1378,8396800,1024,2,"cuda:1"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2158,1378,8396800,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2156, "rf_id": 1440, "parent": 2148, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2132,1378,8396800,1024,2,"cuda:1"],[2152,1083,0,1024,2,"cuda:1"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2158,1378,8396800,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2159, "rf_id": 1442, "parent": 2148, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2158,1378,8396800,1024,2,"cuda:1"],[2152,1083,0,1024,2,"cuda:1"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2158,1378,8396800,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2160, "rf_id": 1443, "parent": 2148, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2152,1083,0,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2161, "rf_id": 1444, "parent": 2148, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2152,1083,0,1024,2,"cuda:1"],[2158,1378,8396800,1024,2,"cuda:1"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2148, "rf_id": 1433, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2163, "rf_id": 1446, "parent": 2162, "fw_parent": 2162, "seq_id": 328, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2120,2121,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 2164, "rf_id": 1447, "parent": 2162, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1360,359,0,163840,2,"cuda:1"],[2120,2121,0,163840,2,"cuda:1"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[2165,981,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2162, "rf_id": 1445, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2171, "rf_id": 1453, "parent": 2170, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,1024],15,0,"cuda:1","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[2172,1623,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2170, "rf_id": 1452, "parent": 2169, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2165,981,0,163840,2,"cuda:1"],"<None>","<None>","<None>","<None>",0], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","Int"],
      "outputs": [[2172,1623,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout_backward", "id": 2169, "rf_id": 1451, "parent": 2168, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout_backward(Tensor grad_output, Tensor mask, float scale) -> Tensor",
      "inputs": [[2165,981,0,163840,2,"cuda:1"],[1703,1704,0,163840,1,"cuda:1"],1.111111], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(bool)","Double"],
      "outputs": [[2172,1623,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<backward op>", "id": 2168, "rf_id": 1450, "parent": 2167, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2165,981,0,163840,2,"cuda:1"],1.111111,[1703,1704,0,163840,1,"cuda:1"],"<None>","<None>"], "input_shapes": [[20,8,1024],[],[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(bool)","None","None"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 2167, "rf_id": 1449, "parent": 2166, "fw_parent": 2166, "seq_id": 327, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2165,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 2166, "rf_id": 1448, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::mul", "id": 2179, "rf_id": 1458, "parent": 2176, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2172,1623,0,163840,2,"cuda:1"],[2177,2178,0,1,8,"cpu"]], "input_shapes": [[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)"],
      "outputs": [[2180,1704,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2176, "rf_id": 1457, "parent": 2175, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[2172,1623,0,163840,2,"cuda:1"],1], "input_shapes": [[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2180,1704,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<backward op>", "id": 2175, "rf_id": 1456, "parent": 2174, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2172,1623,0,163840,2,"cuda:1"],"<None>","<None>"], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 2174, "rf_id": 1455, "parent": 2173, "fw_parent": 2173, "seq_id": 326, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2172,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 2173, "rf_id": 1454, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::sum", "id": 2183, "rf_id": 1461, "parent": 2182, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[2180,1704,0,163840,2,"cuda:1"],[0,1],true,"<None>"], "input_shapes": [[20,8,1024],[[],[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","Bool","None"],
      "outputs": [[2184,435,0,1024,2,"cuda:1"]], "output_shapes": [[1,1,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2185, "rf_id": 1462, "parent": 2182, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2184,435,0,1024,2,"cuda:1"],[1024]], "input_shapes": [[1,1,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2186,435,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ExpandBackward0", "id": 2182, "rf_id": 1460, "parent": 2181, "fw_parent": 2181, "seq_id": 325, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2180,1704,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ExpandBackward0", "id": 2181, "rf_id": 1459, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2188, "rf_id": 1464, "parent": 2187, "fw_parent": 2187, "seq_id": 324, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2186,435,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2187, "rf_id": 1463, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2190, "rf_id": 1466, "parent": 2189, "fw_parent": 2189, "seq_id": 323, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2172,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2189, "rf_id": 1465, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2192, "rf_id": 1468, "parent": 2191, "fw_parent": 2191, "seq_id": 322, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2186,435,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2191, "rf_id": 1467, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2196, "rf_id": 1472, "parent": 2195, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2186,435,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2195, "rf_id": 1471, "parent": 2194, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2186,435,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2197,435,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2194, "rf_id": 1470, "parent": 2193, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2186,435,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2200, "rf_id": 1475, "parent": 2199, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],[1024],[1],8397824], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2201,1378,8397824,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2199, "rf_id": 1474, "parent": 2198, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,8397824,8398848,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2201,1378,8397824,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2198, "rf_id": 1473, "parent": 2193, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,8397824,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2201,1378,8397824,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2203, "rf_id": 1477, "parent": 2202, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2201,1378,8397824,1024,2,"cuda:1"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2204,1378,8397824,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2202, "rf_id": 1476, "parent": 2193, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2201,1378,8397824,1024,2,"cuda:1"],[2197,435,0,1024,2,"cuda:1"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2204,1378,8397824,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2205, "rf_id": 1478, "parent": 2193, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2204,1378,8397824,1024,2,"cuda:1"],[2197,435,0,1024,2,"cuda:1"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2204,1378,8397824,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2206, "rf_id": 1479, "parent": 2193, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2197,435,0,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2207, "rf_id": 1480, "parent": 2193, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2197,435,0,1024,2,"cuda:1"],[2204,1378,8397824,1024,2,"cuda:1"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2193, "rf_id": 1469, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2209, "rf_id": 1482, "parent": 2208, "fw_parent": 2208, "seq_id": 321, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2172,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2208, "rf_id": 1481, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_ReduceFromModelParallelRegionBackward", "id": 2211, "rf_id": 1484, "parent": 2210, "fw_parent": 2210, "seq_id": 320, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2172,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _ReduceFromModelParallelRegionBackward", "id": 2210, "rf_id": 1483, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2216, "rf_id": 1489, "parent": 2215, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2172,1623,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2217,1623,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2215, "rf_id": 1488, "parent": 2214, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2172,1623,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2217,1623,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 2218, "rf_id": 1490, "parent": 2214, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2217,1623,0,163840,2,"cuda:1"],[496,493,0,1048576,2,"cuda:1"]], "input_shapes": [[160,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2219,1704,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 2220, "rf_id": 1491, "parent": 2214, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[2219,1704,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2221,1704,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 2214, "rf_id": 1487, "parent": 2213, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2172,1623,0,163840,2,"cuda:1"],[496,493,0,1048576,2,"cuda:1"]], "input_shapes": [[20,8,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2221,1704,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2222, "rf_id": 1492, "parent": 2213, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2172,1623,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2223,1623,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2224, "rf_id": 1493, "parent": 2213, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1644,577,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2225,577,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2228, "rf_id": 1496, "parent": 2227, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2223,1623,0,163840,2,"cuda:1"],[1024,160],[1,1024],"<None>"], "input_shapes": [[160,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[2229,1623,0,163840,2,"cuda:1"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2227, "rf_id": 1495, "parent": 2226, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[2223,1623,0,163840,2,"cuda:1"],0,1], "input_shapes": [[160,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2229,1623,0,163840,2,"cuda:1"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 2226, "rf_id": 1494, "parent": 2213, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2223,1623,0,163840,2,"cuda:1"]], "input_shapes": [[160,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2229,1623,0,163840,2,"cuda:1"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 2231, "rf_id": 1498, "parent": 2230, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2229,1623,0,163840,2,"cuda:1"],[2225,577,0,163840,2,"cuda:1"]], "input_shapes": [[1024,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2232,904,0,1048576,2,"cuda:1"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 2230, "rf_id": 1497, "parent": 2213, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2229,1623,0,163840,2,"cuda:1"],[2225,577,0,163840,2,"cuda:1"]], "input_shapes": [[1024,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2232,904,0,1048576,2,"cuda:1"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 2213, "rf_id": 1486, "parent": 2212, "fw_parent": 2212, "seq_id": 319, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2172,1623,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 2212, "rf_id": 1485, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2236, "rf_id": 1502, "parent": 2235, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2232,904,0,1048576,2,"cuda:1"]], "input_shapes": [[1024,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2235, "rf_id": 1501, "parent": 2234, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2232,904,0,1048576,2,"cuda:1"]], "input_shapes": [[1024,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2237,904,0,1048576,2,"cuda:1"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2234, "rf_id": 1500, "parent": 2233, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2232,904,0,1048576,2,"cuda:1"]], "input_shapes": [[1024,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2240, "rf_id": 1505, "parent": 2239, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],[1048576],[1],8398848], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2241,1378,8398848,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2239, "rf_id": 1504, "parent": 2238, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,8398848,9447424,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2241,1378,8398848,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2238, "rf_id": 1503, "parent": 2233, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,8398848,1048576], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2241,1378,8398848,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2243, "rf_id": 1507, "parent": 2242, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2241,1378,8398848,1048576,2,"cuda:1"],[1024,1024]], "input_shapes": [[1048576],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2244,1378,8398848,1048576,2,"cuda:1"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2242, "rf_id": 1506, "parent": 2233, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2241,1378,8398848,1048576,2,"cuda:1"],[2237,904,0,1048576,2,"cuda:1"]], "input_shapes": [[1048576],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2244,1378,8398848,1048576,2,"cuda:1"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2245, "rf_id": 1508, "parent": 2233, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2244,1378,8398848,1048576,2,"cuda:1"],[2237,904,0,1048576,2,"cuda:1"],true], "input_shapes": [[1024,1024],[1024,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2244,1378,8398848,1048576,2,"cuda:1"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2246, "rf_id": 1509, "parent": 2233, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2237,904,0,1048576,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2247, "rf_id": 1510, "parent": 2233, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2237,904,0,1048576,2,"cuda:1"],[2244,1378,8398848,1048576,2,"cuda:1"]], "input_shapes": [[1024,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2233, "rf_id": 1499, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 2251, "rf_id": 1513, "parent": 2249, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2250,493,0,1048576,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2252, "rf_id": 1514, "parent": 2249, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[2253,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2254, "rf_id": 1515, "parent": 2249, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[496,493,0,1048576,2,"cuda:1"],[2253,57,0,0,2,"cuda:1"]], "input_shapes": [[1024,1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2249, "rf_id": 1512, "parent": 2248, "fw_parent": 2248, "seq_id": 318, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2221,1704,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2248, "rf_id": 1511, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2256, "rf_id": 1517, "parent": 2255, "fw_parent": 2255, "seq_id": 317, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2221,1704,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2255, "rf_id": 1516, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2260, "rf_id": 1521, "parent": 2259, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2221,1704,0,163840,2,"cuda:1"],[20,8,16,64]], "input_shapes": [[20,8,1024],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2261,1704,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2259, "rf_id": 1520, "parent": 2258, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2221,1704,0,163840,2,"cuda:1"],[20,8,16,64]], "input_shapes": [[20,8,1024],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2261,1704,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2258, "rf_id": 1519, "parent": 2257, "fw_parent": 2257, "seq_id": 316, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2221,1704,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2257, "rf_id": 1518, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "CloneBackward0", "id": 2263, "rf_id": 1523, "parent": 2262, "fw_parent": 2262, "seq_id": 315, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2261,1704,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: CloneBackward0", "id": 2262, "rf_id": 1522, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2267, "rf_id": 1527, "parent": 2266, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2261,1704,0,163840,2,"cuda:1"],[8,16,20,64],[1024,64,8192,1],"<None>"], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","None"],
      "outputs": [[2268,1704,0,163840,2,"cuda:1"]], "output_shapes": [[8,16,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::permute", "id": 2266, "rf_id": 1526, "parent": 2265, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)",
      "inputs": [[2261,1704,0,163840,2,"cuda:1"],[1,2,0,3]], "input_shapes": [[20,8,16,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2268,1704,0,163840,2,"cuda:1"]], "output_shapes": [[8,16,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PermuteBackward0", "id": 2265, "rf_id": 1525, "parent": 2264, "fw_parent": 2264, "seq_id": 314, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2261,1704,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PermuteBackward0", "id": 2264, "rf_id": 1524, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_reshape_alias", "id": 2272, "rf_id": 1531, "parent": 2271, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[2268,1704,0,163840,2,"cuda:1"],[128,20,64],[64,8192,1]], "input_shapes": [[8,16,20,64],[[],[],[]],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]"],
      "outputs": [[2273,1704,0,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2271, "rf_id": 1530, "parent": 2270, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2268,1704,0,163840,2,"cuda:1"],[128,20,64]], "input_shapes": [[8,16,20,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2273,1704,0,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2270, "rf_id": 1529, "parent": 2269, "fw_parent": 2269, "seq_id": 313, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2268,1704,0,163840,2,"cuda:1"]], "input_shapes": [[8,16,20,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2269, "rf_id": 1528, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2277, "rf_id": 1535, "parent": 2276, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1618,1610,0,51200,2,"cuda:1"],[128,20,20],[400,1,20],"<None>"], "input_shapes": [[128,20,20],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2278,1610,0,51200,2,"cuda:1"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2276, "rf_id": 1534, "parent": 2275, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1618,1610,0,51200,2,"cuda:1"],1,2], "input_shapes": [[128,20,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2278,1610,0,51200,2,"cuda:1"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 2279, "rf_id": 1536, "parent": 2275, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2278,1610,0,51200,2,"cuda:1"],[2273,1704,0,163840,2,"cuda:1"]], "input_shapes": [[128,20,20],[128,20,64]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2280,577,0,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2282, "rf_id": 1538, "parent": 2281, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1573,582,128,163840,2,"cuda:1"],[128,64,20],[192,1,24576],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2283,582,128,163840,2,"cuda:1"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2281, "rf_id": 1537, "parent": 2275, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1573,582,128,163840,2,"cuda:1"],1,2], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2283,582,128,163840,2,"cuda:1"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 2284, "rf_id": 1539, "parent": 2275, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2273,1704,0,163840,2,"cuda:1"],[2283,582,128,163840,2,"cuda:1"]], "input_shapes": [[128,20,64],[128,64,20]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2285,377,0,51200,2,"cuda:1"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "BmmBackward0", "id": 2275, "rf_id": 1533, "parent": 2274, "fw_parent": 2274, "seq_id": 312, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2273,1704,0,163840,2,"cuda:1"]], "input_shapes": [[128,20,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: BmmBackward0", "id": 2274, "rf_id": 1532, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2289, "rf_id": 1543, "parent": 2288, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2280,577,0,163840,2,"cuda:1"],[20,128,64],[64,1280,1],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2290,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2288, "rf_id": 1542, "parent": 2287, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[2280,577,0,163840,2,"cuda:1"],0,1], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2290,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "TransposeBackward0", "id": 2287, "rf_id": 1541, "parent": 2286, "fw_parent": 2286, "seq_id": 311, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2280,577,0,163840,2,"cuda:1"]], "input_shapes": [[128,20,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 2286, "rf_id": 1540, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2294, "rf_id": 1547, "parent": 2293, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2285,377,0,51200,2,"cuda:1"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2295,377,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2293, "rf_id": 1546, "parent": 2292, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2285,377,0,51200,2,"cuda:1"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2295,377,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2292, "rf_id": 1545, "parent": 2291, "fw_parent": 2291, "seq_id": 310, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2285,377,0,51200,2,"cuda:1"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2291, "rf_id": 1544, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_reshape_alias", "id": 2299, "rf_id": 1551, "parent": 2298, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[2290,577,0,163840,2,"cuda:1"],[20,8,16,64],[64,20480,1280,1]], "input_shapes": [[20,128,64],[[],[],[],[]],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2300,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2298, "rf_id": 1550, "parent": 2297, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2290,577,0,163840,2,"cuda:1"],[20,8,16,64]], "input_shapes": [[20,128,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2300,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2297, "rf_id": 1549, "parent": 2296, "fw_parent": 2296, "seq_id": 309, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2290,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,128,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2296, "rf_id": 1548, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2302, "rf_id": 1553, "parent": 2301, "fw_parent": 2301, "seq_id": 308, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2295,377,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2301, "rf_id": 1552, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2307, "rf_id": 1558, "parent": 2306, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,16,20,20],15,0,"cuda:1","<None>",0], "input_shapes": [[[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[2308,1704,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2306, "rf_id": 1557, "parent": 2305, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2295,377,0,51200,2,"cuda:1"],"<None>","<None>","<None>","<None>",0], "input_shapes": [[8,16,20,20],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","Int"],
      "outputs": [[2308,1704,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout_backward", "id": 2305, "rf_id": 1556, "parent": 2304, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout_backward(Tensor grad_output, Tensor mask, float scale) -> Tensor",
      "inputs": [[2295,377,0,51200,2,"cuda:1"],[1605,1606,0,51200,1,"cuda:1"],1.111111], "input_shapes": [[8,16,20,20],[8,16,20,20],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(bool)","Double"],
      "outputs": [[2308,1704,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "NativeDropoutBackward0", "id": 2304, "rf_id": 1555, "parent": 2303, "fw_parent": 2303, "seq_id": 307, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2295,377,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: NativeDropoutBackward0", "id": 2303, "rf_id": 1554, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2310, "rf_id": 1560, "parent": 2309, "fw_parent": 2309, "seq_id": 306, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2308,1704,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2309, "rf_id": 1559, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2312, "rf_id": 1562, "parent": 2311, "fw_parent": 2311, "seq_id": 305, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2308,1704,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2311, "rf_id": 1561, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2316, "rf_id": 1566, "parent": 2315, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2308,1704,0,51200,2,"cuda:1"],[128,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2317,1704,0,51200,2,"cuda:1"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2315, "rf_id": 1565, "parent": 2314, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2308,1704,0,51200,2,"cuda:1"],[128,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2317,1704,0,51200,2,"cuda:1"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2314, "rf_id": 1564, "parent": 2313, "fw_parent": 2313, "seq_id": 304, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2308,1704,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2313, "rf_id": 1563, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2321, "rf_id": 1570, "parent": 2320, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1578,1579,0,1,8,"cpu"],[],[],0], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[2322,1579,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 2320, "rf_id": 1569, "parent": 2319, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[1578,1579,0,1,8,"cpu"],0,0], "input_shapes": [[1],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[2322,1579,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 2324, "rf_id": 1572, "parent": 2323, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[2322,1579,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 2323, "rf_id": 1571, "parent": 2319, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[2322,1579,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "ScaledUpperTriangMaskedSoftmaxBackward", "id": 2319, "rf_id": 1568, "parent": 2318, "fw_parent": 2318, "seq_id": 303, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2317,1704,0,51200,2,"cuda:1"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ScaledUpperTriangMaskedSoftmaxBackward", "id": 2318, "rf_id": 1567, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2328, "rf_id": 1576, "parent": 2327, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2317,1704,0,51200,2,"cuda:1"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2329,1704,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2327, "rf_id": 1575, "parent": 2326, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2317,1704,0,51200,2,"cuda:1"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2329,1704,0,51200,2,"cuda:1"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2326, "rf_id": 1574, "parent": 2325, "fw_parent": 2325, "seq_id": 302, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2317,1704,0,51200,2,"cuda:1"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2325, "rf_id": 1573, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2331, "rf_id": 1578, "parent": 2330, "fw_parent": 2330, "seq_id": 300, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2329,1704,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2330, "rf_id": 1577, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2335, "rf_id": 1582, "parent": 2334, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2329,1704,0,51200,2,"cuda:1"],[128,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2336,1704,0,51200,2,"cuda:1"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2334, "rf_id": 1581, "parent": 2333, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2329,1704,0,51200,2,"cuda:1"],[128,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2336,1704,0,51200,2,"cuda:1"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2333, "rf_id": 1580, "parent": 2332, "fw_parent": 2332, "seq_id": 299, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2329,1704,0,51200,2,"cuda:1"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2332, "rf_id": 1579, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2340, "rf_id": 1586, "parent": 2339, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1561,582,64,163840,2,"cuda:1"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[128,64,20],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2341,582,64,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2339, "rf_id": 1585, "parent": 2338, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1561,582,64,163840,2,"cuda:1"],1,2], "input_shapes": [[128,64,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2341,582,64,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 2342, "rf_id": 1587, "parent": 2338, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2336,1704,0,51200,2,"cuda:1"],[2341,582,64,163840,2,"cuda:1"]], "input_shapes": [[128,20,20],[128,20,64]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2343,2121,0,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2347, "rf_id": 1589, "parent": 2344, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2343,2121,0,163840,2,"cuda:1"],[2345,2346,0,1,8,"cpu"]], "input_shapes": [[128,20,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[2348,2349,0,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2344, "rf_id": 1588, "parent": 2338, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[2343,2121,0,163840,2,"cuda:1"],0.125000], "input_shapes": [[128,20,64],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[2348,2349,0,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2351, "rf_id": 1591, "parent": 2350, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1555,582,0,163840,2,"cuda:1"],[128,64,20],[192,1,24576],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2352,582,0,163840,2,"cuda:1"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2350, "rf_id": 1590, "parent": 2338, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1555,582,0,163840,2,"cuda:1"],1,2], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2352,582,0,163840,2,"cuda:1"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 2353, "rf_id": 1592, "parent": 2338, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2352,582,0,163840,2,"cuda:1"],[2336,1704,0,51200,2,"cuda:1"]], "input_shapes": [[128,64,20],[128,20,20]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2354,2121,0,163840,2,"cuda:1"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2358, "rf_id": 1594, "parent": 2355, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2354,2121,0,163840,2,"cuda:1"],[2356,2357,0,1,8,"cpu"]], "input_shapes": [[128,64,20],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[2359,377,0,163840,2,"cuda:1"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2355, "rf_id": 1593, "parent": 2338, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[2354,2121,0,163840,2,"cuda:1"],0.125000], "input_shapes": [[128,64,20],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[2359,377,0,163840,2,"cuda:1"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "BaddbmmBackward0", "id": 2338, "rf_id": 1584, "parent": 2337, "fw_parent": 2337, "seq_id": 298, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2336,1704,0,51200,2,"cuda:1"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: BaddbmmBackward0", "id": 2337, "rf_id": 1583, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2363, "rf_id": 1598, "parent": 2362, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2359,377,0,163840,2,"cuda:1"],[128,20,64],[1280,1,20],"<None>"], "input_shapes": [[128,64,20],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2364,377,0,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2362, "rf_id": 1597, "parent": 2361, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[2359,377,0,163840,2,"cuda:1"],1,2], "input_shapes": [[128,64,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2364,377,0,163840,2,"cuda:1"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "TransposeBackward0", "id": 2361, "rf_id": 1596, "parent": 2360, "fw_parent": 2360, "seq_id": 297, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2359,377,0,163840,2,"cuda:1"]], "input_shapes": [[128,64,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 2360, "rf_id": 1595, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2368, "rf_id": 1602, "parent": 2367, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2364,377,0,163840,2,"cuda:1"],[20,128,64],[1,1280,20],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2369,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2367, "rf_id": 1601, "parent": 2366, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[2364,377,0,163840,2,"cuda:1"],0,1], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2369,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "TransposeBackward0", "id": 2366, "rf_id": 1600, "parent": 2365, "fw_parent": 2365, "seq_id": 296, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2364,377,0,163840,2,"cuda:1"]], "input_shapes": [[128,20,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 2365, "rf_id": 1599, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2373, "rf_id": 1606, "parent": 2372, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2348,2349,0,163840,2,"cuda:1"],[20,128,64],[64,1280,1],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2374,2349,0,163840,2,"cuda:1"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2372, "rf_id": 1605, "parent": 2371, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[2348,2349,0,163840,2,"cuda:1"],0,1], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2374,2349,0,163840,2,"cuda:1"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "TransposeBackward0", "id": 2371, "rf_id": 1604, "parent": 2370, "fw_parent": 2370, "seq_id": 295, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2348,2349,0,163840,2,"cuda:1"]], "input_shapes": [[128,20,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 2370, "rf_id": 1603, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_reshape_alias", "id": 2378, "rf_id": 1610, "parent": 2377, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[2369,377,0,163840,2,"cuda:1"],[20,8,16,64],[1,20480,1280,20]], "input_shapes": [[20,128,64],[[],[],[],[]],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2379,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2377, "rf_id": 1609, "parent": 2376, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2369,377,0,163840,2,"cuda:1"],[20,8,16,64]], "input_shapes": [[20,128,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2379,377,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2376, "rf_id": 1608, "parent": 2375, "fw_parent": 2375, "seq_id": 294, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2369,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,128,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2375, "rf_id": 1607, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_reshape_alias", "id": 2383, "rf_id": 1614, "parent": 2382, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[2374,2349,0,163840,2,"cuda:1"],[20,8,16,64],[64,20480,1280,1]], "input_shapes": [[20,128,64],[[],[],[],[]],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2384,2349,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2382, "rf_id": 1613, "parent": 2381, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2374,2349,0,163840,2,"cuda:1"],[20,8,16,64]], "input_shapes": [[20,128,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2384,2349,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2381, "rf_id": 1612, "parent": 2380, "fw_parent": 2380, "seq_id": 293, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2374,2349,0,163840,2,"cuda:1"]], "input_shapes": [[20,128,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2380, "rf_id": 1611, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2386, "rf_id": 1616, "parent": 2385, "fw_parent": 2385, "seq_id": 291, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2300,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2385, "rf_id": 1615, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2388, "rf_id": 1618, "parent": 2387, "fw_parent": 2387, "seq_id": 290, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2379,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2387, "rf_id": 1617, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2390, "rf_id": 1620, "parent": 2389, "fw_parent": 2389, "seq_id": 289, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2384,2349,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2389, "rf_id": 1619, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2395, "rf_id": 1625, "parent": 2394, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2396,2121,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2398, "rf_id": 1627, "parent": 2397, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2396,2121,0,163840,2,"cuda:1"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2396,2121,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2397, "rf_id": 1626, "parent": 2394, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2396,2121,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2396,2121,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2394, "rf_id": 1624, "parent": 2393, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2396,2121,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2400, "rf_id": 1629, "parent": 2399, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2396,2121,0,163840,2,"cuda:1"],[20,8,16,64],[8192,1024,64,1],0], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[2401,2121,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2399, "rf_id": 1628, "parent": 2393, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2396,2121,0,163840,2,"cuda:1"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2401,2121,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2402, "rf_id": 1630, "parent": 2393, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2401,2121,0,163840,2,"cuda:1"],[2300,577,0,163840,2,"cuda:1"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2401,2121,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2393, "rf_id": 1623, "parent": 2392, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2300,577,0,163840,2,"cuda:1"],[20,8,16,64],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2396,2121,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2392, "rf_id": 1622, "parent": 2391, "fw_parent": 2391, "seq_id": 288, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2300,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2391, "rf_id": 1621, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2407, "rf_id": 1635, "parent": 2406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2408,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2410, "rf_id": 1637, "parent": 2409, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2408,1708,0,491520,2,"cuda:1"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2408,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2409, "rf_id": 1636, "parent": 2406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2408,1708,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2408,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2406, "rf_id": 1634, "parent": 2405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2408,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2412, "rf_id": 1639, "parent": 2411, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2408,1708,0,491520,2,"cuda:1"],[20,8,16,64],[24576,3072,192,1],128], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[2413,1708,128,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 2411, "rf_id": 1638, "parent": 2405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[2408,1708,0,491520,2,"cuda:1"],3,-1], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2413,1708,128,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2414, "rf_id": 1640, "parent": 2405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2413,1708,128,163840,2,"cuda:1"],[2396,2121,0,163840,2,"cuda:1"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2413,1708,128,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select_backward", "id": 2405, "rf_id": 1633, "parent": 2404, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt index) -> Tensor",
      "inputs": [[2396,2121,0,163840,2,"cuda:1"],[20,8,16,3,64],3,-1], "input_shapes": [[20,8,16,64],[[],[],[],[],[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int"],
      "outputs": [[2408,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SelectBackward0", "id": 2404, "rf_id": 1632, "parent": 2403, "fw_parent": 2403, "seq_id": 287, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2396,2121,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SelectBackward0", "id": 2403, "rf_id": 1631, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2419, "rf_id": 1645, "parent": 2418, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2420,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2422, "rf_id": 1647, "parent": 2421, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2420,1704,0,491520,2,"cuda:1"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2420,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2421, "rf_id": 1646, "parent": 2418, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2420,1704,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2420,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2418, "rf_id": 1644, "parent": 2417, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2420,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2424, "rf_id": 1649, "parent": 2423, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2420,1704,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2425,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2423, "rf_id": 1648, "parent": 2417, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2420,1704,0,491520,2,"cuda:1"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2425,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2426, "rf_id": 1650, "parent": 2417, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2425,1704,0,491520,2,"cuda:1"],[2408,1708,0,491520,2,"cuda:1"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2425,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2417, "rf_id": 1643, "parent": 2416, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2408,1708,0,491520,2,"cuda:1"],[20,8,16,3,64],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2420,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2416, "rf_id": 1642, "parent": 2415, "fw_parent": 2415, "seq_id": 286, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2408,1708,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2415, "rf_id": 1641, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2431, "rf_id": 1655, "parent": 2430, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2432,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2434, "rf_id": 1657, "parent": 2433, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2432,1708,0,491520,2,"cuda:1"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2432,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2433, "rf_id": 1656, "parent": 2430, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2432,1708,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2432,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2430, "rf_id": 1654, "parent": 2429, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2432,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2436, "rf_id": 1659, "parent": 2435, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2432,1708,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2437,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2435, "rf_id": 1658, "parent": 2429, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2432,1708,0,491520,2,"cuda:1"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2437,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2438, "rf_id": 1660, "parent": 2429, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2437,1708,0,491520,2,"cuda:1"],[2420,1704,0,491520,2,"cuda:1"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2437,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2429, "rf_id": 1653, "parent": 2428, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2420,1704,0,491520,2,"cuda:1"],[20,8,16,3,64],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2432,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2428, "rf_id": 1652, "parent": 2427, "fw_parent": 2427, "seq_id": 285, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2420,1704,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2427, "rf_id": 1651, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2443, "rf_id": 1665, "parent": 2442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2444,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2446, "rf_id": 1667, "parent": 2445, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2444,1704,0,491520,2,"cuda:1"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2444,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2445, "rf_id": 1666, "parent": 2442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2444,1704,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2444,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2442, "rf_id": 1664, "parent": 2441, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2444,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2448, "rf_id": 1669, "parent": 2447, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2444,1704,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2449,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2447, "rf_id": 1668, "parent": 2441, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2444,1704,0,491520,2,"cuda:1"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2449,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2450, "rf_id": 1670, "parent": 2441, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2449,1704,0,491520,2,"cuda:1"],[2432,1708,0,491520,2,"cuda:1"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2449,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2441, "rf_id": 1663, "parent": 2440, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2432,1708,0,491520,2,"cuda:1"],[20,8,16,3,64],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2444,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2440, "rf_id": 1662, "parent": 2439, "fw_parent": 2439, "seq_id": 284, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2432,1708,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2439, "rf_id": 1661, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2455, "rf_id": 1675, "parent": 2454, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2456,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2458, "rf_id": 1677, "parent": 2457, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2456,577,0,163840,2,"cuda:1"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2456,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2457, "rf_id": 1676, "parent": 2454, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2456,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2456,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2454, "rf_id": 1674, "parent": 2453, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2456,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2460, "rf_id": 1679, "parent": 2459, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2456,577,0,163840,2,"cuda:1"],[20,8,16,64],[8192,1024,64,1],0], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[2461,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2459, "rf_id": 1678, "parent": 2453, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2456,577,0,163840,2,"cuda:1"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2461,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2462, "rf_id": 1680, "parent": 2453, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2461,577,0,163840,2,"cuda:1"],[2379,377,0,163840,2,"cuda:1"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2461,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2453, "rf_id": 1673, "parent": 2452, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2379,377,0,163840,2,"cuda:1"],[20,8,16,64],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2456,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2452, "rf_id": 1672, "parent": 2451, "fw_parent": 2451, "seq_id": 283, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2379,377,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2451, "rf_id": 1671, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2467, "rf_id": 1685, "parent": 2466, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2468,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2470, "rf_id": 1687, "parent": 2469, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2468,1708,0,491520,2,"cuda:1"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2468,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2469, "rf_id": 1686, "parent": 2466, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2468,1708,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2468,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2466, "rf_id": 1684, "parent": 2465, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2468,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2472, "rf_id": 1689, "parent": 2471, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2468,1708,0,491520,2,"cuda:1"],[20,8,16,64],[24576,3072,192,1],64], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[2473,1708,64,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 2471, "rf_id": 1688, "parent": 2465, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[2468,1708,0,491520,2,"cuda:1"],3,-2], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2473,1708,64,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2474, "rf_id": 1690, "parent": 2465, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2473,1708,64,163840,2,"cuda:1"],[2456,577,0,163840,2,"cuda:1"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2473,1708,64,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select_backward", "id": 2465, "rf_id": 1683, "parent": 2464, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt index) -> Tensor",
      "inputs": [[2456,577,0,163840,2,"cuda:1"],[20,8,16,3,64],3,-2], "input_shapes": [[20,8,16,64],[[],[],[],[],[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int"],
      "outputs": [[2468,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SelectBackward0", "id": 2464, "rf_id": 1682, "parent": 2463, "fw_parent": 2463, "seq_id": 282, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2456,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SelectBackward0", "id": 2463, "rf_id": 1681, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2479, "rf_id": 1695, "parent": 2478, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2480,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2483, "rf_id": 1697, "parent": 2482, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2480,2481,0,491520,2,"cuda:1"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2480,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2482, "rf_id": 1696, "parent": 2478, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2480,2481,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2480,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2478, "rf_id": 1694, "parent": 2477, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2480,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2485, "rf_id": 1699, "parent": 2484, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2480,2481,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2486,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2484, "rf_id": 1698, "parent": 2477, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2480,2481,0,491520,2,"cuda:1"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2486,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2487, "rf_id": 1700, "parent": 2477, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2486,2481,0,491520,2,"cuda:1"],[2468,1708,0,491520,2,"cuda:1"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2486,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2477, "rf_id": 1693, "parent": 2476, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2468,1708,0,491520,2,"cuda:1"],[20,8,16,3,64],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2480,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2476, "rf_id": 1692, "parent": 2475, "fw_parent": 2475, "seq_id": 281, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2468,1708,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2475, "rf_id": 1691, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2492, "rf_id": 1705, "parent": 2491, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2493,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2495, "rf_id": 1707, "parent": 2494, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2493,1708,0,491520,2,"cuda:1"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2493,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2494, "rf_id": 1706, "parent": 2491, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2493,1708,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2493,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2491, "rf_id": 1704, "parent": 2490, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2493,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2497, "rf_id": 1709, "parent": 2496, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2493,1708,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2498,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2496, "rf_id": 1708, "parent": 2490, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2493,1708,0,491520,2,"cuda:1"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2498,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2499, "rf_id": 1710, "parent": 2490, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2498,1708,0,491520,2,"cuda:1"],[2480,2481,0,491520,2,"cuda:1"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2498,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2490, "rf_id": 1703, "parent": 2489, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2480,2481,0,491520,2,"cuda:1"],[20,8,16,3,64],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2493,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2489, "rf_id": 1702, "parent": 2488, "fw_parent": 2488, "seq_id": 280, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2480,2481,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2488, "rf_id": 1701, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2504, "rf_id": 1715, "parent": 2503, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2505,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2507, "rf_id": 1717, "parent": 2506, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2505,2481,0,491520,2,"cuda:1"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2505,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2506, "rf_id": 1716, "parent": 2503, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2505,2481,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2505,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2503, "rf_id": 1714, "parent": 2502, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2505,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2509, "rf_id": 1719, "parent": 2508, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2505,2481,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2510,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2508, "rf_id": 1718, "parent": 2502, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2505,2481,0,491520,2,"cuda:1"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2510,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2511, "rf_id": 1720, "parent": 2502, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2510,2481,0,491520,2,"cuda:1"],[2493,1708,0,491520,2,"cuda:1"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2510,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2502, "rf_id": 1713, "parent": 2501, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2493,1708,0,491520,2,"cuda:1"],[20,8,16,3,64],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2505,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2501, "rf_id": 1712, "parent": 2500, "fw_parent": 2500, "seq_id": 279, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2493,1708,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add_", "id": 2512, "rf_id": 1721, "parent": 2500, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)",
      "inputs": [[2444,1704,0,491520,2,"cuda:1"],[2505,2481,0,491520,2,"cuda:1"],1], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[2444,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2500, "rf_id": 1711, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_reshape_alias", "id": 2516, "rf_id": 1725, "parent": 2515, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[2384,2349,0,163840,2,"cuda:1"],[20,8,16,1,64],[64,20480,1280,64,1]], "input_shapes": [[20,8,16,64],[[],[],[],[],[]],[[],[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]"],
      "outputs": [[2517,2349,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2515, "rf_id": 1724, "parent": 2514, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2384,2349,0,163840,2,"cuda:1"],[20,8,16,1,64]], "input_shapes": [[20,8,16,64],[[],[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]"],
      "outputs": [[2517,2349,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ReshapeAliasBackward0", "id": 2514, "rf_id": 1723, "parent": 2513, "fw_parent": 2513, "seq_id": 278, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2384,2349,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ReshapeAliasBackward0", "id": 2513, "rf_id": 1722, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2522, "rf_id": 1730, "parent": 2521, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,1,64],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2523,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2525, "rf_id": 1732, "parent": 2524, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2523,577,0,163840,2,"cuda:1"],0], "input_shapes": [[20,8,16,1,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2523,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2524, "rf_id": 1731, "parent": 2521, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2523,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,1,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2523,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2521, "rf_id": 1729, "parent": 2520, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,1,64],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2523,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2527, "rf_id": 1734, "parent": 2526, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2523,577,0,163840,2,"cuda:1"],[20,8,16,1,64],[8192,1024,64,64,1],0], "input_shapes": [[20,8,16,1,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2528,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2526, "rf_id": 1733, "parent": 2520, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2523,577,0,163840,2,"cuda:1"],4,0,9223372036854775807,1], "input_shapes": [[20,8,16,1,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2528,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2529, "rf_id": 1735, "parent": 2520, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2528,577,0,163840,2,"cuda:1"],[2517,2349,0,163840,2,"cuda:1"],false], "input_shapes": [[20,8,16,1,64],[20,8,16,1,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2528,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2520, "rf_id": 1728, "parent": 2519, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2517,2349,0,163840,2,"cuda:1"],[20,8,16,1,64],4,0,9223372036854775807,1], "input_shapes": [[20,8,16,1,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2523,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2519, "rf_id": 1727, "parent": 2518, "fw_parent": 2518, "seq_id": 277, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2517,2349,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,1,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2518, "rf_id": 1726, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2534, "rf_id": 1740, "parent": 2533, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2535,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2537, "rf_id": 1742, "parent": 2536, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2535,1708,0,491520,2,"cuda:1"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2535,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2536, "rf_id": 1741, "parent": 2533, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2535,1708,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2535,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2533, "rf_id": 1739, "parent": 2532, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2535,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2539, "rf_id": 1744, "parent": 2538, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2535,1708,0,491520,2,"cuda:1"],[20,8,16,1,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2540,1708,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2538, "rf_id": 1743, "parent": 2532, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2535,1708,0,491520,2,"cuda:1"],3,0,-2,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2540,1708,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2541, "rf_id": 1745, "parent": 2532, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2540,1708,0,163840,2,"cuda:1"],[2523,577,0,163840,2,"cuda:1"],false], "input_shapes": [[20,8,16,1,64],[20,8,16,1,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2540,1708,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2532, "rf_id": 1738, "parent": 2531, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2523,577,0,163840,2,"cuda:1"],[20,8,16,3,64],3,0,-2,1], "input_shapes": [[20,8,16,1,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2535,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2531, "rf_id": 1737, "parent": 2530, "fw_parent": 2530, "seq_id": 276, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2523,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,16,1,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2530, "rf_id": 1736, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2546, "rf_id": 1750, "parent": 2545, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2547,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2549, "rf_id": 1752, "parent": 2548, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2547,2481,0,491520,2,"cuda:1"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2547,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2548, "rf_id": 1751, "parent": 2545, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2547,2481,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2547,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2545, "rf_id": 1749, "parent": 2544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2547,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2551, "rf_id": 1754, "parent": 2550, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2547,2481,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2552,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2550, "rf_id": 1753, "parent": 2544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2547,2481,0,491520,2,"cuda:1"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2552,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2553, "rf_id": 1755, "parent": 2544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2552,2481,0,491520,2,"cuda:1"],[2535,1708,0,491520,2,"cuda:1"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2552,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2544, "rf_id": 1748, "parent": 2543, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2535,1708,0,491520,2,"cuda:1"],[20,8,16,3,64],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2547,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2543, "rf_id": 1747, "parent": 2542, "fw_parent": 2542, "seq_id": 275, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2535,1708,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2542, "rf_id": 1746, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2558, "rf_id": 1760, "parent": 2557, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2559,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2561, "rf_id": 1762, "parent": 2560, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2559,1708,0,491520,2,"cuda:1"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2559,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2560, "rf_id": 1761, "parent": 2557, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2559,1708,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2559,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2557, "rf_id": 1759, "parent": 2556, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2559,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2563, "rf_id": 1764, "parent": 2562, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2559,1708,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2564,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2562, "rf_id": 1763, "parent": 2556, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2559,1708,0,491520,2,"cuda:1"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2564,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2565, "rf_id": 1765, "parent": 2556, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2564,1708,0,491520,2,"cuda:1"],[2547,2481,0,491520,2,"cuda:1"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2564,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2556, "rf_id": 1758, "parent": 2555, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2547,2481,0,491520,2,"cuda:1"],[20,8,16,3,64],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2559,1708,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2555, "rf_id": 1757, "parent": 2554, "fw_parent": 2554, "seq_id": 274, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2547,2481,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2554, "rf_id": 1756, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2570, "rf_id": 1770, "parent": 2569, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2571,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2573, "rf_id": 1772, "parent": 2572, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2571,2481,0,491520,2,"cuda:1"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2571,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2572, "rf_id": 1771, "parent": 2569, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2571,2481,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2571,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2569, "rf_id": 1769, "parent": 2568, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2571,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2575, "rf_id": 1774, "parent": 2574, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2571,2481,0,491520,2,"cuda:1"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2576,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2574, "rf_id": 1773, "parent": 2568, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2571,2481,0,491520,2,"cuda:1"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2576,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2577, "rf_id": 1775, "parent": 2568, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2576,2481,0,491520,2,"cuda:1"],[2559,1708,0,491520,2,"cuda:1"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2576,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2568, "rf_id": 1768, "parent": 2567, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2559,1708,0,491520,2,"cuda:1"],[20,8,16,3,64],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2571,2481,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2567, "rf_id": 1767, "parent": 2566, "fw_parent": 2566, "seq_id": 273, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2559,1708,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add_", "id": 2578, "rf_id": 1776, "parent": 2566, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)",
      "inputs": [[2444,1704,0,491520,2,"cuda:1"],[2571,2481,0,491520,2,"cuda:1"],1], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[2444,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2566, "rf_id": 1766, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2582, "rf_id": 1780, "parent": 2581, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2444,1704,0,491520,2,"cuda:1"],[20,8,3072]], "input_shapes": [[20,8,16,3,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2583,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2581, "rf_id": 1779, "parent": 2580, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2444,1704,0,491520,2,"cuda:1"],[20,8,3072]], "input_shapes": [[20,8,16,3,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2583,1704,0,491520,2,"cuda:1"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2580, "rf_id": 1778, "parent": 2579, "fw_parent": 2579, "seq_id": 272, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2444,1704,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2579, "rf_id": 1777, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2585, "rf_id": 1782, "parent": 2584, "fw_parent": 2584, "seq_id": 271, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2583,1704,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2584, "rf_id": 1781, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2590, "rf_id": 1787, "parent": 2589, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2583,1704,0,491520,2,"cuda:1"],[160,3072]], "input_shapes": [[20,8,3072],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2591,1704,0,491520,2,"cuda:1"]], "output_shapes": [[160,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2589, "rf_id": 1786, "parent": 2588, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2583,1704,0,491520,2,"cuda:1"],[160,3072]], "input_shapes": [[20,8,3072],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2591,1704,0,491520,2,"cuda:1"]], "output_shapes": [[160,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 2592, "rf_id": 1788, "parent": 2588, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2591,1704,0,491520,2,"cuda:1"],[469,466,0,3145728,2,"cuda:1"]], "input_shapes": [[160,3072],[3072,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2593,577,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 2594, "rf_id": 1789, "parent": 2588, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[2593,577,0,163840,2,"cuda:1"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2595,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 2588, "rf_id": 1785, "parent": 2587, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2583,1704,0,491520,2,"cuda:1"],[469,466,0,3145728,2,"cuda:1"]], "input_shapes": [[20,8,3072],[3072,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2595,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2596, "rf_id": 1790, "parent": 2587, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2583,1704,0,491520,2,"cuda:1"],[160,3072]], "input_shapes": [[20,8,3072],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2597,1704,0,491520,2,"cuda:1"]], "output_shapes": [[160,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2598, "rf_id": 1791, "parent": 2587, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1458,329,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2599,329,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2602, "rf_id": 1794, "parent": 2601, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2597,1704,0,491520,2,"cuda:1"],[3072,160],[1,3072],"<None>"], "input_shapes": [[160,3072],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[2603,1704,0,491520,2,"cuda:1"]], "output_shapes": [[3072,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2601, "rf_id": 1793, "parent": 2600, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[2597,1704,0,491520,2,"cuda:1"],0,1], "input_shapes": [[160,3072],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2603,1704,0,491520,2,"cuda:1"]], "output_shapes": [[3072,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 2600, "rf_id": 1792, "parent": 2587, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2597,1704,0,491520,2,"cuda:1"]], "input_shapes": [[160,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2603,1704,0,491520,2,"cuda:1"]], "output_shapes": [[3072,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 2605, "rf_id": 1796, "parent": 2604, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2603,1704,0,491520,2,"cuda:1"],[2599,329,0,163840,2,"cuda:1"]], "input_shapes": [[3072,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2606,904,0,3145728,2,"cuda:1"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 2604, "rf_id": 1795, "parent": 2587, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2603,1704,0,491520,2,"cuda:1"],[2599,329,0,163840,2,"cuda:1"]], "input_shapes": [[3072,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2606,904,0,3145728,2,"cuda:1"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2609, "rf_id": 1798, "parent": 2607, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2608,435,0,3072,2,"cuda:1"],[1,3072],[0,1],"<None>"], "input_shapes": [[3072],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[2610,435,0,3072,2,"cuda:1"]], "output_shapes": [[1,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::sum", "id": 2607, "rf_id": 1797, "parent": 2587, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[2597,1704,0,491520,2,"cuda:1"],[0],false,"<None>"], "input_shapes": [[160,3072],[[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","Bool","None"],
      "outputs": [[2608,435,0,3072,2,"cuda:1"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 2587, "rf_id": 1784, "parent": 2586, "fw_parent": 2586, "seq_id": 270, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2583,1704,0,491520,2,"cuda:1"]], "input_shapes": [[20,8,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 2586, "rf_id": 1783, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2614, "rf_id": 1802, "parent": 2613, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2606,904,0,3145728,2,"cuda:1"]], "input_shapes": [[3072,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2613, "rf_id": 1801, "parent": 2612, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2606,904,0,3145728,2,"cuda:1"]], "input_shapes": [[3072,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2610,904,0,3145728,2,"cuda:1"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2612, "rf_id": 1800, "parent": 2611, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2606,904,0,3145728,2,"cuda:1"]], "input_shapes": [[3072,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2617, "rf_id": 1805, "parent": 2616, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],[3145728],[1],9447424], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2618,1378,9447424,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2616, "rf_id": 1804, "parent": 2615, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,9447424,12593152,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2618,1378,9447424,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2615, "rf_id": 1803, "parent": 2611, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,9447424,3145728], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2618,1378,9447424,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2620, "rf_id": 1807, "parent": 2619, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2618,1378,9447424,3145728,2,"cuda:1"],[3072,1024]], "input_shapes": [[3145728],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2621,1378,9447424,3145728,2,"cuda:1"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2619, "rf_id": 1806, "parent": 2611, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2618,1378,9447424,3145728,2,"cuda:1"],[2610,904,0,3145728,2,"cuda:1"]], "input_shapes": [[3145728],[3072,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2621,1378,9447424,3145728,2,"cuda:1"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2622, "rf_id": 1808, "parent": 2611, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2621,1378,9447424,3145728,2,"cuda:1"],[2610,904,0,3145728,2,"cuda:1"],true], "input_shapes": [[3072,1024],[3072,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2621,1378,9447424,3145728,2,"cuda:1"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2623, "rf_id": 1809, "parent": 2611, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2610,904,0,3145728,2,"cuda:1"],"<Stream>"], "input_shapes": [[3072,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2624, "rf_id": 1810, "parent": 2611, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2610,904,0,3145728,2,"cuda:1"],[2621,1378,9447424,3145728,2,"cuda:1"]], "input_shapes": [[3072,1024],[3072,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2611, "rf_id": 1799, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2628, "rf_id": 1814, "parent": 2627, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2608,435,0,3072,2,"cuda:1"]], "input_shapes": [[3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2627, "rf_id": 1813, "parent": 2626, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2608,435,0,3072,2,"cuda:1"]], "input_shapes": [[3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2629,435,0,3072,2,"cuda:1"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2626, "rf_id": 1812, "parent": 2625, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2608,435,0,3072,2,"cuda:1"]], "input_shapes": [[3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2632, "rf_id": 1817, "parent": 2631, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],[3072],[1],12593152], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2633,1378,12593152,3072,2,"cuda:1"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2631, "rf_id": 1816, "parent": 2630, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,12593152,12596224,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2633,1378,12593152,3072,2,"cuda:1"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2630, "rf_id": 1815, "parent": 2625, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,12593152,3072], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2633,1378,12593152,3072,2,"cuda:1"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2635, "rf_id": 1819, "parent": 2634, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2633,1378,12593152,3072,2,"cuda:1"],[3072]], "input_shapes": [[3072],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2636,1378,12593152,3072,2,"cuda:1"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2634, "rf_id": 1818, "parent": 2625, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2633,1378,12593152,3072,2,"cuda:1"],[2629,435,0,3072,2,"cuda:1"]], "input_shapes": [[3072],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2636,1378,12593152,3072,2,"cuda:1"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2637, "rf_id": 1820, "parent": 2625, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2636,1378,12593152,3072,2,"cuda:1"],[2629,435,0,3072,2,"cuda:1"],true], "input_shapes": [[3072],[3072],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2636,1378,12593152,3072,2,"cuda:1"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2638, "rf_id": 1821, "parent": 2625, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2629,435,0,3072,2,"cuda:1"],"<Stream>"], "input_shapes": [[3072],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2639, "rf_id": 1822, "parent": 2625, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2629,435,0,3072,2,"cuda:1"],[2636,1378,12593152,3072,2,"cuda:1"]], "input_shapes": [[3072],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2625, "rf_id": 1811, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_CopyToModelParallelRegionBackward", "id": 2641, "rf_id": 1824, "parent": 2640, "fw_parent": 2640, "seq_id": 269, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2595,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _CopyToModelParallelRegionBackward", "id": 2640, "rf_id": 1823, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 2645, "rf_id": 1827, "parent": 2643, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2644,466,0,3145728,2,"cuda:1"],"<Stream>"], "input_shapes": [[3072,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2646, "rf_id": 1828, "parent": 2643, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[2647,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2648, "rf_id": 1829, "parent": 2643, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[469,466,0,3145728,2,"cuda:1"],[2647,57,0,0,2,"cuda:1"]], "input_shapes": [[3072,1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2643, "rf_id": 1826, "parent": 2642, "fw_parent": 2642, "seq_id": 268, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2595,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2642, "rf_id": 1825, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2650, "rf_id": 1831, "parent": 2649, "fw_parent": 2649, "seq_id": 266, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2595,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2649, "rf_id": 1830, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2652, "rf_id": 1833, "parent": 2651, "fw_parent": 2651, "seq_id": 265, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2595,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2651, "rf_id": 1832, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 2657, "rf_id": 1837, "parent": 2656, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:1","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2658,2121,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2656, "rf_id": 1836, "parent": 2654, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2655,329,0,163840,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[2658,2121,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 2660, "rf_id": 1839, "parent": 2659, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:1","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[2661,435,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2659, "rf_id": 1838, "parent": 2654, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[422,423,0,1024,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[2661,435,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 2663, "rf_id": 1841, "parent": 2662, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:1","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[2664,2665,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2662, "rf_id": 1840, "parent": 2654, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[424,425,0,1024,2,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[2664,2665,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 2666, "rf_id": 1842, "parent": 2654, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[16,1024],6,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2667,2349,0,16384,4,"cuda:1"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 2669, "rf_id": 1844, "parent": 2668, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[16,1024],[1024,1],6,0,"cuda:1","<None>"], "input_shapes": [[[],[]],[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[2670,2671,0,16384,4,"cuda:1"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 2668, "rf_id": 1843, "parent": 2654, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2667,2349,0,16384,4,"cuda:1"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[16,1024],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[2670,2671,0,16384,4,"cuda:1"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunctionBackward", "id": 2654, "rf_id": 1835, "parent": 2653, "fw_parent": 2653, "seq_id": 264, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2595,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: FusedLayerNormAffineFunctionBackward", "id": 2653, "rf_id": 1834, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2675, "rf_id": 1848, "parent": 2674, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2661,435,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2674, "rf_id": 1847, "parent": 2673, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2661,435,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2676,435,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2673, "rf_id": 1846, "parent": 2672, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2661,435,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2679, "rf_id": 1851, "parent": 2678, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],[1024],[1],12596224], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1438,1378,12596224,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2678, "rf_id": 1850, "parent": 2677, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,12596224,12597248,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1438,1378,12596224,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2677, "rf_id": 1849, "parent": 2672, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,12596224,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1438,1378,12596224,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2681, "rf_id": 1853, "parent": 2680, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1438,1378,12596224,1024,2,"cuda:1"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2682,1378,12596224,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2680, "rf_id": 1852, "parent": 2672, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1438,1378,12596224,1024,2,"cuda:1"],[2676,435,0,1024,2,"cuda:1"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2682,1378,12596224,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2683, "rf_id": 1854, "parent": 2672, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2682,1378,12596224,1024,2,"cuda:1"],[2676,435,0,1024,2,"cuda:1"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2682,1378,12596224,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2684, "rf_id": 1855, "parent": 2672, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2676,435,0,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2685, "rf_id": 1856, "parent": 2672, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2676,435,0,1024,2,"cuda:1"],[2682,1378,12596224,1024,2,"cuda:1"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2672, "rf_id": 1845, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2689, "rf_id": 1860, "parent": 2688, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2664,2665,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2688, "rf_id": 1859, "parent": 2687, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2664,2665,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2690,2665,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2687, "rf_id": 1858, "parent": 2686, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2664,2665,0,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2693, "rf_id": 1863, "parent": 2692, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],[1024],[1],12597248], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2670,1378,12597248,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2692, "rf_id": 1862, "parent": 2691, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,12597248,12598272,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2670,1378,12597248,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2691, "rf_id": 1861, "parent": 2686, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,12597248,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2670,1378,12597248,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2695, "rf_id": 1865, "parent": 2694, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2670,1378,12597248,1024,2,"cuda:1"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2696,1378,12597248,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2694, "rf_id": 1864, "parent": 2686, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2670,1378,12597248,1024,2,"cuda:1"],[2690,2665,0,1024,2,"cuda:1"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2696,1378,12597248,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2697, "rf_id": 1866, "parent": 2686, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2696,1378,12597248,1024,2,"cuda:1"],[2690,2665,0,1024,2,"cuda:1"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2696,1378,12597248,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2698, "rf_id": 1867, "parent": 2686, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2690,2665,0,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2699, "rf_id": 1868, "parent": 2686, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2690,2665,0,1024,2,"cuda:1"],[2696,1378,12597248,1024,2,"cuda:1"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2686, "rf_id": 1857, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2701, "rf_id": 1870, "parent": 2700, "fw_parent": 2700, "seq_id": 263, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2658,2121,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add_", "id": 2702, "rf_id": 1871, "parent": 2700, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)",
      "inputs": [[2165,981,0,163840,2,"cuda:1"],[2658,2121,0,163840,2,"cuda:1"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[2165,981,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2700, "rf_id": 1869, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2704, "rf_id": 1873, "parent": 2703, "fw_parent": 2703, "seq_id": 261, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2165,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2703, "rf_id": 1872, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2708, "rf_id": 1877, "parent": 2707, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2165,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2707, "rf_id": 1876, "parent": 2706, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2165,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2709,981,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2706, "rf_id": 1875, "parent": 2705, "fw_parent": 2705, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2165,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2705, "rf_id": 1874, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "CheckpointFunctionBackward", "id": 1406, "rf_id": 936, "parent": 1404, "fw_parent": 2, "seq_id": 406, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1360,359,0,163840,2,"cuda:1"],[1405,0,0,0,0,""]], "input_shapes": [[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(nullptr (uninitialized))"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: CheckpointFunctionBackward", "id": 1404, "rf_id": 935, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2711, "rf_id": 1879, "parent": 2710, "fw_parent": 2, "seq_id": 404, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2709,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2710, "rf_id": 1878, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2713, "rf_id": 1881, "parent": 2712, "fw_parent": 2, "seq_id": 403, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2709,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2712, "rf_id": 1880, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2715, "rf_id": 1883, "parent": 2714, "fw_parent": 2, "seq_id": 402, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2709,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2714, "rf_id": 1882, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2720, "rf_id": 1888, "parent": 2719, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,1024],15,0,"cuda:1","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[1891,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2719, "rf_id": 1887, "parent": 2718, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2709,981,0,163840,2,"cuda:1"],"<None>","<None>","<None>","<None>",0], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","Int"],
      "outputs": [[1891,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout_backward", "id": 2718, "rf_id": 1886, "parent": 2717, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout_backward(Tensor grad_output, Tensor mask, float scale) -> Tensor",
      "inputs": [[2709,981,0,163840,2,"cuda:1"],[387,388,0,163840,1,"cuda:1"],1.111111], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(bool)","Double"],
      "outputs": [[1891,577,0,163840,2,"cuda:1"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "NativeDropoutBackward0", "id": 2717, "rf_id": 1885, "parent": 2716, "fw_parent": 2, "seq_id": 401, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2709,981,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: NativeDropoutBackward0", "id": 2716, "rf_id": 1884, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2722, "rf_id": 1890, "parent": 2721, "fw_parent": 2, "seq_id": 400, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1891,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2721, "rf_id": 1889, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "CloneBackward0", "id": 2724, "rf_id": 1892, "parent": 2723, "fw_parent": 2, "seq_id": 399, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1891,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: CloneBackward0", "id": 2723, "rf_id": 1891, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2728, "rf_id": 1896, "parent": 2727, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1891,577,0,163840,2,"cuda:1"],[8,20,1024],[1024,8192,1],"<None>"], "input_shapes": [[20,8,1024],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2729,577,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2727, "rf_id": 1895, "parent": 2726, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1891,577,0,163840,2,"cuda:1"],0,1], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2729,577,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "TransposeBackward0", "id": 2726, "rf_id": 1894, "parent": 2725, "fw_parent": 2, "seq_id": 398, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1891,577,0,163840,2,"cuda:1"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 2725, "rf_id": 1893, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "AddBackward0", "id": 2731, "rf_id": 1898, "parent": 2730, "fw_parent": 2, "seq_id": 397, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2729,577,0,163840,2,"cuda:1"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: AddBackward0", "id": 2730, "rf_id": 1897, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2733, "rf_id": 1900, "parent": 2732, "fw_parent": 2, "seq_id": 396, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2729,577,0,163840,2,"cuda:1"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2732, "rf_id": 1899, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2741, "rf_id": 1908, "parent": 2740, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],4,0,"cuda:1","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[2742,132,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_like", "id": 2740, "rf_id": 1907, "parent": 2739, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[343,10,0,160,8,"cuda:1"],4,0,"cuda:1","<None>",0], "input_shapes": [[8,20],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Int"],
      "outputs": [[2742,132,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 2743, "rf_id": 1909, "parent": 2739, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2742,132,0,160,8,"cuda:1"],[343,10,0,160,8,"cuda:1"],false], "input_shapes": [[8,20],[8,20],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[2742,132,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 2739, "rf_id": 1906, "parent": 2738, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[343,10,0,160,8,"cuda:1"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[2742,132,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::contiguous", "id": 2738, "rf_id": 1905, "parent": 2737, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[343,10,0,160,8,"cuda:1"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[2742,132,0,160,8,"cuda:1"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 2747, "rf_id": 1913, "parent": 2746, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20,1024],15,0,"cuda:1","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[2748,329,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2746, "rf_id": 1912, "parent": 2745, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2729,577,0,163840,2,"cuda:1"],15,0,"cuda:1","<None>",0], "input_shapes": [[8,20,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Int"],
      "outputs": [[2748,329,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2749, "rf_id": 1914, "parent": 2745, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2748,329,0,163840,2,"cuda:1"],[2729,577,0,163840,2,"cuda:1"],false], "input_shapes": [[8,20,1024],[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2748,329,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::clone", "id": 2745, "rf_id": 1911, "parent": 2744, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2729,577,0,163840,2,"cuda:1"],0], "input_shapes": [[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2748,329,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::contiguous", "id": 2744, "rf_id": 1910, "parent": 2737, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[2729,577,0,163840,2,"cuda:1"],0], "input_shapes": [[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2748,329,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2750, "rf_id": 1915, "parent": 2737, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2748,329,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[8,20,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2751,329,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 2753, "rf_id": 1917, "parent": 2752, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,1024],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2754,388,0,20480,2,"cuda:1"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2756, "rf_id": 1919, "parent": 2755, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2754,388,0,20480,2,"cuda:1"],0], "input_shapes": [[20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2754,388,0,20480,2,"cuda:1"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2755, "rf_id": 1918, "parent": 2752, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2754,388,0,20480,2,"cuda:1"]], "input_shapes": [[20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2754,388,0,20480,2,"cuda:1"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2752, "rf_id": 1916, "parent": 2737, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,1024],15,0,"cuda:1","<None>"], "input_shapes": [[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[2754,388,0,20480,2,"cuda:1"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding_dense_backward", "id": 2737, "rf_id": 1904, "parent": 2736, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::embedding_dense_backward(Tensor grad_output, Tensor indices, SymInt num_weights, SymInt padding_idx, bool scale_grad_by_freq) -> Tensor",
      "inputs": [[2729,577,0,163840,2,"cuda:1"],[343,10,0,160,8,"cuda:1"],20,-1,false], "input_shapes": [[8,20,1024],[8,20],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Int","Bool"],
      "outputs": [[2754,388,0,20480,2,"cuda:1"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding_backward", "id": 2736, "rf_id": 1903, "parent": 2735, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::embedding_backward(Tensor grad, Tensor indices, SymInt num_weights, SymInt padding_idx, bool scale_grad_by_freq, bool sparse) -> Tensor",
      "inputs": [[2729,577,0,163840,2,"cuda:1"],[343,10,0,160,8,"cuda:1"],20,-1,false,false], "input_shapes": [[8,20,1024],[8,20],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Int","Bool","Bool"],
      "outputs": [[2754,388,0,20480,2,"cuda:1"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "EmbeddingBackward0", "id": 2735, "rf_id": 1902, "parent": 2734, "fw_parent": 2, "seq_id": 395, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2729,577,0,163840,2,"cuda:1"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: EmbeddingBackward0", "id": 2734, "rf_id": 1901, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2760, "rf_id": 1923, "parent": 2759, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2754,388,0,20480,2,"cuda:1"]], "input_shapes": [[20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2759, "rf_id": 1922, "parent": 2758, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2754,388,0,20480,2,"cuda:1"]], "input_shapes": [[20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2761,388,0,20480,2,"cuda:1"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2758, "rf_id": 1921, "parent": 2757, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2754,388,0,20480,2,"cuda:1"]], "input_shapes": [[20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2764, "rf_id": 1926, "parent": 2763, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],[20480],[1],12598272], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2751,1378,12598272,20480,2,"cuda:1"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2763, "rf_id": 1925, "parent": 2762, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,12598272,12618752,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2751,1378,12598272,20480,2,"cuda:1"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2762, "rf_id": 1924, "parent": 2757, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,12598272,20480], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2751,1378,12598272,20480,2,"cuda:1"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2766, "rf_id": 1928, "parent": 2765, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2751,1378,12598272,20480,2,"cuda:1"],[20,1024]], "input_shapes": [[20480],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2767,1378,12598272,20480,2,"cuda:1"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2765, "rf_id": 1927, "parent": 2757, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2751,1378,12598272,20480,2,"cuda:1"],[2761,388,0,20480,2,"cuda:1"]], "input_shapes": [[20480],[20,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2767,1378,12598272,20480,2,"cuda:1"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2768, "rf_id": 1929, "parent": 2757, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2767,1378,12598272,20480,2,"cuda:1"],[2761,388,0,20480,2,"cuda:1"],true], "input_shapes": [[20,1024],[20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2767,1378,12598272,20480,2,"cuda:1"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2769, "rf_id": 1930, "parent": 2757, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2761,388,0,20480,2,"cuda:1"],"<Stream>"], "input_shapes": [[20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2770, "rf_id": 1931, "parent": 2757, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2761,388,0,20480,2,"cuda:1"],[2767,1378,12598272,20480,2,"cuda:1"]], "input_shapes": [[20,1024],[20,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2757, "rf_id": 1920, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2772, "rf_id": 1933, "parent": 2771, "fw_parent": 2, "seq_id": 393, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2729,577,0,163840,2,"cuda:1"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2771, "rf_id": 1932, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_ReduceFromModelParallelRegionBackward", "id": 2774, "rf_id": 1935, "parent": 2773, "fw_parent": 2, "seq_id": 392, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2729,577,0,163840,2,"cuda:1"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _ReduceFromModelParallelRegionBackward", "id": 2773, "rf_id": 1934, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2782, "rf_id": 1943, "parent": 2781, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20,1024],15,0,"cuda:1","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[2783,329,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2781, "rf_id": 1942, "parent": 2780, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2729,577,0,163840,2,"cuda:1"],15,0,"cuda:1","<None>",0], "input_shapes": [[8,20,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Int"],
      "outputs": [[2783,329,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2784, "rf_id": 1944, "parent": 2780, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2783,329,0,163840,2,"cuda:1"],[2729,577,0,163840,2,"cuda:1"],false], "input_shapes": [[8,20,1024],[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2783,329,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::clone", "id": 2780, "rf_id": 1941, "parent": 2779, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2729,577,0,163840,2,"cuda:1"],0], "input_shapes": [[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2783,329,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::contiguous", "id": 2779, "rf_id": 1940, "parent": 2778, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[2729,577,0,163840,2,"cuda:1"],0], "input_shapes": [[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2783,329,0,163840,2,"cuda:1"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2785, "rf_id": 1945, "parent": 2778, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2783,329,0,163840,2,"cuda:1"],[160,1024]], "input_shapes": [[8,20,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2786,329,0,163840,2,"cuda:1"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 2788, "rf_id": 1947, "parent": 2787, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[50304,1024],15,0,"cuda:1","<None>","<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2789,2790,0,51511296,2,"cuda:1"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2792, "rf_id": 1949, "parent": 2791, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2789,2790,0,51511296,2,"cuda:1"],0], "input_shapes": [[50304,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2789,2790,0,51511296,2,"cuda:1"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2791, "rf_id": 1948, "parent": 2787, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2789,2790,0,51511296,2,"cuda:1"]], "input_shapes": [[50304,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2789,2790,0,51511296,2,"cuda:1"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2787, "rf_id": 1946, "parent": 2778, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[50304,1024],15,0,"cuda:1","<None>"], "input_shapes": [[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[2789,2790,0,51511296,2,"cuda:1"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding_dense_backward", "id": 2778, "rf_id": 1939, "parent": 2777, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::embedding_dense_backward(Tensor grad_output, Tensor indices, SymInt num_weights, SymInt padding_idx, bool scale_grad_by_freq) -> Tensor",
      "inputs": [[2729,577,0,163840,2,"cuda:1"],[320,184,0,160,8,"cuda:1"],50304,-1,false], "input_shapes": [[8,20,1024],[8,20],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Int","Bool"],
      "outputs": [[2789,2790,0,51511296,2,"cuda:1"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding_backward", "id": 2777, "rf_id": 1938, "parent": 2776, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::embedding_backward(Tensor grad, Tensor indices, SymInt num_weights, SymInt padding_idx, bool scale_grad_by_freq, bool sparse) -> Tensor",
      "inputs": [[2729,577,0,163840,2,"cuda:1"],[320,184,0,160,8,"cuda:1"],50304,-1,false,false], "input_shapes": [[8,20,1024],[8,20],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Int","Bool","Bool"],
      "outputs": [[2789,2790,0,51511296,2,"cuda:1"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "EmbeddingBackward0", "id": 2776, "rf_id": 1937, "parent": 2775, "fw_parent": 2, "seq_id": 391, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2729,577,0,163840,2,"cuda:1"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add_", "id": 2793, "rf_id": 1950, "parent": 2775, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)",
      "inputs": [[1346,1078,0,51511296,2,"cuda:1"],[2789,2790,0,51511296,2,"cuda:1"],1], "input_shapes": [[50304,1024],[50304,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1346,1078,0,51511296,2,"cuda:1"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: EmbeddingBackward0", "id": 2775, "rf_id": 1936, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2797, "rf_id": 1954, "parent": 2796, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1346,1078,0,51511296,2,"cuda:1"]], "input_shapes": [[50304,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2796, "rf_id": 1953, "parent": 2795, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1346,1078,0,51511296,2,"cuda:1"]], "input_shapes": [[50304,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2798,1078,0,51511296,2,"cuda:1"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2795, "rf_id": 1952, "parent": 2794, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1346,1078,0,51511296,2,"cuda:1"]], "input_shapes": [[50304,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2801, "rf_id": 1957, "parent": 2800, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],[51511296],[1],12618752], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2802,1378,12618752,51511296,2,"cuda:1"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2800, "rf_id": 1956, "parent": 2799, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,12618752,64130048,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2802,1378,12618752,51511296,2,"cuda:1"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2799, "rf_id": 1955, "parent": 2794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1377,1378,0,500000000,2,"cuda:1"],0,12618752,51511296], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2802,1378,12618752,51511296,2,"cuda:1"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2804, "rf_id": 1959, "parent": 2803, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2802,1378,12618752,51511296,2,"cuda:1"],[50304,1024]], "input_shapes": [[51511296],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2805,1378,12618752,51511296,2,"cuda:1"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2803, "rf_id": 1958, "parent": 2794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2802,1378,12618752,51511296,2,"cuda:1"],[2798,1078,0,51511296,2,"cuda:1"]], "input_shapes": [[51511296],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2805,1378,12618752,51511296,2,"cuda:1"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2806, "rf_id": 1960, "parent": 2794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2805,1378,12618752,51511296,2,"cuda:1"],[2798,1078,0,51511296,2,"cuda:1"],true], "input_shapes": [[50304,1024],[50304,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2805,1378,12618752,51511296,2,"cuda:1"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2807, "rf_id": 1961, "parent": 2794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2798,1078,0,51511296,2,"cuda:1"],"<Stream>"], "input_shapes": [[50304,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2808, "rf_id": 1962, "parent": 2794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2798,1078,0,51511296,2,"cuda:1"],[2805,1378,12618752,51511296,2,"cuda:1"]], "input_shapes": [[50304,1024],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2794, "rf_id": 1951, "parent": 1245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2809, "rf_id": 1963, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2798,1378,12618752,51511296,2,"cuda:1"],[-1]], "input_shapes": [[50304,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2810,1378,12618752,51511296,2,"cuda:1"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2812, "rf_id": 1965, "parent": 2811, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2810,1378,12618752,51511296,2,"cuda:1"],[12877824],[1],12618752], "input_shapes": [[51511296],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2813,1378,12618752,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2811, "rf_id": 1964, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2810,1378,12618752,51511296,2,"cuda:1"],0,0,12877824,1], "input_shapes": [[51511296],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2813,1378,12618752,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2815, "rf_id": 1967, "parent": 2814, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2810,1378,12618752,51511296,2,"cuda:1"],[12877824],[1],25496576], "input_shapes": [[51511296],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2816,1378,25496576,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2814, "rf_id": 1966, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2810,1378,12618752,51511296,2,"cuda:1"],0,12877824,25755648,1], "input_shapes": [[51511296],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2816,1378,25496576,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2818, "rf_id": 1969, "parent": 2817, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2810,1378,12618752,51511296,2,"cuda:1"],[12877824],[1],38374400], "input_shapes": [[51511296],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2819,1378,38374400,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2817, "rf_id": 1968, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2810,1378,12618752,51511296,2,"cuda:1"],0,25755648,38633472,1], "input_shapes": [[51511296],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2819,1378,38374400,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2821, "rf_id": 1971, "parent": 2820, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2810,1378,12618752,51511296,2,"cuda:1"],[12877824],[1],51252224], "input_shapes": [[51511296],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2822,1378,51252224,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2820, "rf_id": 1970, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2810,1378,12618752,51511296,2,"cuda:1"],0,38633472,51511296,1], "input_shapes": [[51511296],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2822,1378,51252224,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2823, "rf_id": 1972, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2761,1378,12598272,20480,2,"cuda:1"],[-1]], "input_shapes": [[20,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2824,1378,12598272,20480,2,"cuda:1"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2826, "rf_id": 1974, "parent": 2825, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2824,1378,12598272,20480,2,"cuda:1"],[5120],[1],12598272], "input_shapes": [[20480],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2827,1378,12598272,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2825, "rf_id": 1973, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2824,1378,12598272,20480,2,"cuda:1"],0,0,5120,1], "input_shapes": [[20480],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2827,1378,12598272,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2829, "rf_id": 1976, "parent": 2828, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2824,1378,12598272,20480,2,"cuda:1"],[5120],[1],12603392], "input_shapes": [[20480],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2830,1378,12603392,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2828, "rf_id": 1975, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2824,1378,12598272,20480,2,"cuda:1"],0,5120,10240,1], "input_shapes": [[20480],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2830,1378,12603392,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2832, "rf_id": 1978, "parent": 2831, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2824,1378,12598272,20480,2,"cuda:1"],[5120],[1],12608512], "input_shapes": [[20480],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2833,1378,12608512,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2831, "rf_id": 1977, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2824,1378,12598272,20480,2,"cuda:1"],0,10240,15360,1], "input_shapes": [[20480],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2833,1378,12608512,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2835, "rf_id": 1980, "parent": 2834, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2824,1378,12598272,20480,2,"cuda:1"],[5120],[1],12613632], "input_shapes": [[20480],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2836,1378,12613632,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2834, "rf_id": 1979, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2824,1378,12598272,20480,2,"cuda:1"],0,15360,20480,1], "input_shapes": [[20480],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2836,1378,12613632,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2837, "rf_id": 1981, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2676,1378,12596224,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2838,1378,12596224,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2840, "rf_id": 1983, "parent": 2839, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2838,1378,12596224,1024,2,"cuda:1"],[256],[1],12596224], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2841,1378,12596224,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2839, "rf_id": 1982, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2838,1378,12596224,1024,2,"cuda:1"],0,0,256,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2841,1378,12596224,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2843, "rf_id": 1985, "parent": 2842, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2838,1378,12596224,1024,2,"cuda:1"],[256],[1],12596480], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2844,1378,12596480,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2842, "rf_id": 1984, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2838,1378,12596224,1024,2,"cuda:1"],0,256,512,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2844,1378,12596480,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2846, "rf_id": 1987, "parent": 2845, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2838,1378,12596224,1024,2,"cuda:1"],[256],[1],12596736], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2847,1378,12596736,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2845, "rf_id": 1986, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2838,1378,12596224,1024,2,"cuda:1"],0,512,768,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2847,1378,12596736,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2849, "rf_id": 1989, "parent": 2848, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2838,1378,12596224,1024,2,"cuda:1"],[256],[1],12596992], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2850,1378,12596992,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2848, "rf_id": 1988, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2838,1378,12596224,1024,2,"cuda:1"],0,768,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2850,1378,12596992,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2851, "rf_id": 1990, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2690,1378,12597248,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2852,1378,12597248,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2854, "rf_id": 1992, "parent": 2853, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2852,1378,12597248,1024,2,"cuda:1"],[256],[1],12597248], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2855,1378,12597248,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2853, "rf_id": 1991, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2852,1378,12597248,1024,2,"cuda:1"],0,0,256,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2855,1378,12597248,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2857, "rf_id": 1994, "parent": 2856, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2852,1378,12597248,1024,2,"cuda:1"],[256],[1],12597504], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2858,1378,12597504,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2856, "rf_id": 1993, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2852,1378,12597248,1024,2,"cuda:1"],0,256,512,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2858,1378,12597504,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2860, "rf_id": 1996, "parent": 2859, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2852,1378,12597248,1024,2,"cuda:1"],[256],[1],12597760], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2861,1378,12597760,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2859, "rf_id": 1995, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2852,1378,12597248,1024,2,"cuda:1"],0,512,768,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2861,1378,12597760,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2863, "rf_id": 1998, "parent": 2862, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2852,1378,12597248,1024,2,"cuda:1"],[256],[1],12598016], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2864,1378,12598016,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2862, "rf_id": 1997, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2852,1378,12597248,1024,2,"cuda:1"],0,768,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2864,1378,12598016,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2865, "rf_id": 1999, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2610,1378,9447424,3145728,2,"cuda:1"],[-1]], "input_shapes": [[3072,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2866,1378,9447424,3145728,2,"cuda:1"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2868, "rf_id": 2001, "parent": 2867, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2866,1378,9447424,3145728,2,"cuda:1"],[786432],[1],9447424], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2869,1378,9447424,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2867, "rf_id": 2000, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2866,1378,9447424,3145728,2,"cuda:1"],0,0,786432,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2869,1378,9447424,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2871, "rf_id": 2003, "parent": 2870, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2866,1378,9447424,3145728,2,"cuda:1"],[786432],[1],10233856], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2872,1378,10233856,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2870, "rf_id": 2002, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2866,1378,9447424,3145728,2,"cuda:1"],0,786432,1572864,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2872,1378,10233856,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2874, "rf_id": 2005, "parent": 2873, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2866,1378,9447424,3145728,2,"cuda:1"],[786432],[1],11020288], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2875,1378,11020288,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2873, "rf_id": 2004, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2866,1378,9447424,3145728,2,"cuda:1"],0,1572864,2359296,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2875,1378,11020288,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2877, "rf_id": 2007, "parent": 2876, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2866,1378,9447424,3145728,2,"cuda:1"],[786432],[1],11806720], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2878,1378,11806720,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2876, "rf_id": 2006, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2866,1378,9447424,3145728,2,"cuda:1"],0,2359296,3145728,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2878,1378,11806720,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2879, "rf_id": 2008, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2629,1378,12593152,3072,2,"cuda:1"],[-1]], "input_shapes": [[3072],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2880,1378,12593152,3072,2,"cuda:1"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2882, "rf_id": 2010, "parent": 2881, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2880,1378,12593152,3072,2,"cuda:1"],[768],[1],12593152], "input_shapes": [[3072],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2883,1378,12593152,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2881, "rf_id": 2009, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2880,1378,12593152,3072,2,"cuda:1"],0,0,768,1], "input_shapes": [[3072],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2883,1378,12593152,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2885, "rf_id": 2012, "parent": 2884, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2880,1378,12593152,3072,2,"cuda:1"],[768],[1],12593920], "input_shapes": [[3072],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2886,1378,12593920,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2884, "rf_id": 2011, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2880,1378,12593152,3072,2,"cuda:1"],0,768,1536,1], "input_shapes": [[3072],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2886,1378,12593920,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2888, "rf_id": 2014, "parent": 2887, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2880,1378,12593152,3072,2,"cuda:1"],[768],[1],12594688], "input_shapes": [[3072],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2889,1378,12594688,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2887, "rf_id": 2013, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2880,1378,12593152,3072,2,"cuda:1"],0,1536,2304,1], "input_shapes": [[3072],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2889,1378,12594688,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2891, "rf_id": 2016, "parent": 2890, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2880,1378,12593152,3072,2,"cuda:1"],[768],[1],12595456], "input_shapes": [[3072],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2892,1378,12595456,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2890, "rf_id": 2015, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2880,1378,12593152,3072,2,"cuda:1"],0,2304,3072,1], "input_shapes": [[3072],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2892,1378,12595456,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2893, "rf_id": 2017, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2237,1378,8398848,1048576,2,"cuda:1"],[-1]], "input_shapes": [[1024,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2894,1378,8398848,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2896, "rf_id": 2019, "parent": 2895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2894,1378,8398848,1048576,2,"cuda:1"],[262144],[1],8398848], "input_shapes": [[1048576],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2897,1378,8398848,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2895, "rf_id": 2018, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2894,1378,8398848,1048576,2,"cuda:1"],0,0,262144,1], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2897,1378,8398848,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2899, "rf_id": 2021, "parent": 2898, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2894,1378,8398848,1048576,2,"cuda:1"],[262144],[1],8660992], "input_shapes": [[1048576],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2900,1378,8660992,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2898, "rf_id": 2020, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2894,1378,8398848,1048576,2,"cuda:1"],0,262144,524288,1], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2900,1378,8660992,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2902, "rf_id": 2023, "parent": 2901, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2894,1378,8398848,1048576,2,"cuda:1"],[262144],[1],8923136], "input_shapes": [[1048576],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2903,1378,8923136,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2901, "rf_id": 2022, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2894,1378,8398848,1048576,2,"cuda:1"],0,524288,786432,1], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2903,1378,8923136,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2905, "rf_id": 2025, "parent": 2904, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2894,1378,8398848,1048576,2,"cuda:1"],[262144],[1],9185280], "input_shapes": [[1048576],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2906,1378,9185280,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2904, "rf_id": 2024, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2894,1378,8398848,1048576,2,"cuda:1"],0,786432,1048576,1], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2906,1378,9185280,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2907, "rf_id": 2026, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2197,1378,8397824,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2908,1378,8397824,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2910, "rf_id": 2028, "parent": 2909, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2908,1378,8397824,1024,2,"cuda:1"],[256],[1],8397824], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2911,1378,8397824,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2909, "rf_id": 2027, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2908,1378,8397824,1024,2,"cuda:1"],0,0,256,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2911,1378,8397824,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2913, "rf_id": 2030, "parent": 2912, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2908,1378,8397824,1024,2,"cuda:1"],[256],[1],8398080], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2914,1378,8398080,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2912, "rf_id": 2029, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2908,1378,8397824,1024,2,"cuda:1"],0,256,512,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2914,1378,8398080,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2916, "rf_id": 2032, "parent": 2915, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2908,1378,8397824,1024,2,"cuda:1"],[256],[1],8398336], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2917,1378,8398336,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2915, "rf_id": 2031, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2908,1378,8397824,1024,2,"cuda:1"],0,512,768,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2917,1378,8398336,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2919, "rf_id": 2034, "parent": 2918, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2908,1378,8397824,1024,2,"cuda:1"],[256],[1],8398592], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2920,1378,8398592,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2918, "rf_id": 2033, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2908,1378,8397824,1024,2,"cuda:1"],0,768,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2920,1378,8398592,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2921, "rf_id": 2035, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2138,1378,8395776,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2922,1378,8395776,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2924, "rf_id": 2037, "parent": 2923, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2922,1378,8395776,1024,2,"cuda:1"],[256],[1],8395776], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2925,1378,8395776,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2923, "rf_id": 2036, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2922,1378,8395776,1024,2,"cuda:1"],0,0,256,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2925,1378,8395776,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2927, "rf_id": 2039, "parent": 2926, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2922,1378,8395776,1024,2,"cuda:1"],[256],[1],8396032], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2928,1378,8396032,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2926, "rf_id": 2038, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2922,1378,8395776,1024,2,"cuda:1"],0,256,512,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2928,1378,8396032,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2930, "rf_id": 2041, "parent": 2929, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2922,1378,8395776,1024,2,"cuda:1"],[256],[1],8396288], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2931,1378,8396288,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2929, "rf_id": 2040, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2922,1378,8395776,1024,2,"cuda:1"],0,512,768,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2931,1378,8396288,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2933, "rf_id": 2043, "parent": 2932, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2922,1378,8395776,1024,2,"cuda:1"],[256],[1],8396544], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2934,1378,8396544,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2932, "rf_id": 2042, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2922,1378,8395776,1024,2,"cuda:1"],0,768,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2934,1378,8396544,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2935, "rf_id": 2044, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2152,1378,8396800,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2936,1378,8396800,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2938, "rf_id": 2046, "parent": 2937, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2936,1378,8396800,1024,2,"cuda:1"],[256],[1],8396800], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2939,1378,8396800,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2937, "rf_id": 2045, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2936,1378,8396800,1024,2,"cuda:1"],0,0,256,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2939,1378,8396800,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2941, "rf_id": 2048, "parent": 2940, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2936,1378,8396800,1024,2,"cuda:1"],[256],[1],8397056], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2942,1378,8397056,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2940, "rf_id": 2047, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2936,1378,8396800,1024,2,"cuda:1"],0,256,512,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2942,1378,8397056,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2944, "rf_id": 2050, "parent": 2943, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2936,1378,8396800,1024,2,"cuda:1"],[256],[1],8397312], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2945,1378,8397312,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2943, "rf_id": 2049, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2936,1378,8396800,1024,2,"cuda:1"],0,512,768,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2945,1378,8397312,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2947, "rf_id": 2052, "parent": 2946, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2936,1378,8396800,1024,2,"cuda:1"],[256],[1],8397568], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2948,1378,8397568,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2946, "rf_id": 2051, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2936,1378,8396800,1024,2,"cuda:1"],0,768,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2948,1378,8397568,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2949, "rf_id": 2053, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2091,1378,4201472,4194304,2,"cuda:1"],[-1]], "input_shapes": [[4096,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2950,1378,4201472,4194304,2,"cuda:1"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2952, "rf_id": 2055, "parent": 2951, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2950,1378,4201472,4194304,2,"cuda:1"],[1048576],[1],4201472], "input_shapes": [[4194304],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2953,1378,4201472,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2951, "rf_id": 2054, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2950,1378,4201472,4194304,2,"cuda:1"],0,0,1048576,1], "input_shapes": [[4194304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2953,1378,4201472,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2955, "rf_id": 2057, "parent": 2954, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2950,1378,4201472,4194304,2,"cuda:1"],[1048576],[1],5250048], "input_shapes": [[4194304],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2956,1378,5250048,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2954, "rf_id": 2056, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2950,1378,4201472,4194304,2,"cuda:1"],0,1048576,2097152,1], "input_shapes": [[4194304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2956,1378,5250048,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2958, "rf_id": 2059, "parent": 2957, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2950,1378,4201472,4194304,2,"cuda:1"],[1048576],[1],6298624], "input_shapes": [[4194304],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2959,1378,6298624,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2957, "rf_id": 2058, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2950,1378,4201472,4194304,2,"cuda:1"],0,2097152,3145728,1], "input_shapes": [[4194304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2959,1378,6298624,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2961, "rf_id": 2061, "parent": 2960, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2950,1378,4201472,4194304,2,"cuda:1"],[1048576],[1],7347200], "input_shapes": [[4194304],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2962,1378,7347200,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2960, "rf_id": 2060, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2950,1378,4201472,4194304,2,"cuda:1"],0,3145728,4194304,1], "input_shapes": [[4194304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2962,1378,7347200,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2963, "rf_id": 2062, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2053,1378,4197376,4096,2,"cuda:1"],[-1]], "input_shapes": [[4096],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2964,1378,4197376,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2966, "rf_id": 2064, "parent": 2965, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2964,1378,4197376,4096,2,"cuda:1"],[1024],[1],4197376], "input_shapes": [[4096],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2967,1378,4197376,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2965, "rf_id": 2063, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2964,1378,4197376,4096,2,"cuda:1"],0,0,1024,1], "input_shapes": [[4096],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2967,1378,4197376,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2969, "rf_id": 2066, "parent": 2968, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2964,1378,4197376,4096,2,"cuda:1"],[1024],[1],4198400], "input_shapes": [[4096],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2970,1378,4198400,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2968, "rf_id": 2065, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2964,1378,4197376,4096,2,"cuda:1"],0,1024,2048,1], "input_shapes": [[4096],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2970,1378,4198400,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2972, "rf_id": 2068, "parent": 2971, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2964,1378,4197376,4096,2,"cuda:1"],[1024],[1],4199424], "input_shapes": [[4096],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2973,1378,4199424,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2971, "rf_id": 2067, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2964,1378,4197376,4096,2,"cuda:1"],0,2048,3072,1], "input_shapes": [[4096],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2973,1378,4199424,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2975, "rf_id": 2070, "parent": 2974, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2964,1378,4197376,4096,2,"cuda:1"],[1024],[1],4200448], "input_shapes": [[4096],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2976,1378,4200448,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2974, "rf_id": 2069, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2964,1378,4197376,4096,2,"cuda:1"],0,3072,4096,1], "input_shapes": [[4096],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2976,1378,4200448,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2977, "rf_id": 2071, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1955,1378,3072,4194304,2,"cuda:1"],[-1]], "input_shapes": [[1024,4096],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2978,1378,3072,4194304,2,"cuda:1"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2980, "rf_id": 2073, "parent": 2979, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2978,1378,3072,4194304,2,"cuda:1"],[1048576],[1],3072], "input_shapes": [[4194304],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2981,1378,3072,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2979, "rf_id": 2072, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2978,1378,3072,4194304,2,"cuda:1"],0,0,1048576,1], "input_shapes": [[4194304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2981,1378,3072,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2983, "rf_id": 2075, "parent": 2982, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2978,1378,3072,4194304,2,"cuda:1"],[1048576],[1],1051648], "input_shapes": [[4194304],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2984,1378,1051648,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2982, "rf_id": 2074, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2978,1378,3072,4194304,2,"cuda:1"],0,1048576,2097152,1], "input_shapes": [[4194304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2984,1378,1051648,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2986, "rf_id": 2077, "parent": 2985, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2978,1378,3072,4194304,2,"cuda:1"],[1048576],[1],2100224], "input_shapes": [[4194304],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2987,1378,2100224,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2985, "rf_id": 2076, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2978,1378,3072,4194304,2,"cuda:1"],0,2097152,3145728,1], "input_shapes": [[4194304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2987,1378,2100224,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2989, "rf_id": 2079, "parent": 2988, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2978,1378,3072,4194304,2,"cuda:1"],[1048576],[1],3148800], "input_shapes": [[4194304],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2990,1378,3148800,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2988, "rf_id": 2078, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2978,1378,3072,4194304,2,"cuda:1"],0,3145728,4194304,1], "input_shapes": [[4194304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2990,1378,3148800,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2991, "rf_id": 2080, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1916,1378,2048,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2992,1378,2048,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2994, "rf_id": 2082, "parent": 2993, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2992,1378,2048,1024,2,"cuda:1"],[256],[1],2048], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2995,1378,2048,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2993, "rf_id": 2081, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2992,1378,2048,1024,2,"cuda:1"],0,0,256,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2995,1378,2048,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2997, "rf_id": 2084, "parent": 2996, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2992,1378,2048,1024,2,"cuda:1"],[256],[1],2304], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2998,1378,2304,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2996, "rf_id": 2083, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2992,1378,2048,1024,2,"cuda:1"],0,256,512,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2998,1378,2304,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3000, "rf_id": 2086, "parent": 2999, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2992,1378,2048,1024,2,"cuda:1"],[256],[1],2560], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3001,1378,2560,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2999, "rf_id": 2085, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2992,1378,2048,1024,2,"cuda:1"],0,512,768,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3001,1378,2560,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3003, "rf_id": 2088, "parent": 3002, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2992,1378,2048,1024,2,"cuda:1"],[256],[1],2816], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3004,1378,2816,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3002, "rf_id": 2087, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2992,1378,2048,1024,2,"cuda:1"],0,768,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3004,1378,2816,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3005, "rf_id": 2089, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1376,1378,0,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3006,1378,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3008, "rf_id": 2091, "parent": 3007, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3006,1378,0,1024,2,"cuda:1"],[256],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3009,1378,0,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3007, "rf_id": 2090, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3006,1378,0,1024,2,"cuda:1"],0,0,256,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3009,1378,0,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3011, "rf_id": 2093, "parent": 3010, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3006,1378,0,1024,2,"cuda:1"],[256],[1],256], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3012,1378,256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3010, "rf_id": 2092, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3006,1378,0,1024,2,"cuda:1"],0,256,512,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3012,1378,256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3014, "rf_id": 2095, "parent": 3013, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3006,1378,0,1024,2,"cuda:1"],[256],[1],512], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3015,1378,512,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3013, "rf_id": 2094, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3006,1378,0,1024,2,"cuda:1"],0,512,768,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3015,1378,512,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3017, "rf_id": 2097, "parent": 3016, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3006,1378,0,1024,2,"cuda:1"],[256],[1],768], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3018,1378,768,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3016, "rf_id": 2096, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3006,1378,0,1024,2,"cuda:1"],0,768,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3018,1378,768,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3019, "rf_id": 2098, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1392,1378,1024,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3020,1378,1024,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3022, "rf_id": 2100, "parent": 3021, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3020,1378,1024,1024,2,"cuda:1"],[256],[1],1024], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3023,1378,1024,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3021, "rf_id": 2099, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3020,1378,1024,1024,2,"cuda:1"],0,0,256,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3023,1378,1024,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3025, "rf_id": 2102, "parent": 3024, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3020,1378,1024,1024,2,"cuda:1"],[256],[1],1280], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3026,1378,1280,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3024, "rf_id": 2101, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3020,1378,1024,1024,2,"cuda:1"],0,256,512,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3026,1378,1280,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3028, "rf_id": 2104, "parent": 3027, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3020,1378,1024,1024,2,"cuda:1"],[256],[1],1536], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3029,1378,1536,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3027, "rf_id": 2103, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3020,1378,1024,1024,2,"cuda:1"],0,512,768,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3029,1378,1536,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3031, "rf_id": 2106, "parent": 3030, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3020,1378,1024,1024,2,"cuda:1"],[256],[1],1792], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3032,1378,1792,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3030, "rf_id": 2105, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3020,1378,1024,1024,2,"cuda:1"],0,768,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3032,1378,1792,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 3033, "rf_id": 2107, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[2813,1378,12618752,12877824,2,"cuda:1"],[2827,1378,12598272,5120,2,"cuda:1"],[2841,1378,12596224,256,2,"cuda:1"],[2855,1378,12597248,256,2,"cuda:1"],[2869,1378,9447424,786432,2,"cuda:1"],[2883,1378,12593152,768,2,"cuda:1"],[2897,1378,8398848,262144,2,"cuda:1"],[2911,1378,8397824,256,2,"cuda:1"],[2925,1378,8395776,256,2,"cuda:1"],[2939,1378,8396800,256,2,"cuda:1"],[2953,1378,4201472,1048576,2,"cuda:1"],[2967,1378,4197376,1024,2,"cuda:1"],[2981,1378,3072,1048576,2,"cuda:1"],[2995,1378,2048,256,2,"cuda:1"],[3009,1378,0,256,2,"cuda:1"],[3023,1378,1024,256,2,"cuda:1"],[2816,1378,25496576,12877824,2,"cuda:1"],[2830,1378,12603392,5120,2,"cuda:1"],[2844,1378,12596480,256,2,"cuda:1"],[2858,1378,12597504,256,2,"cuda:1"],[2872,1378,10233856,786432,2,"cuda:1"],[2886,1378,12593920,768,2,"cuda:1"],[2900,1378,8660992,262144,2,"cuda:1"],[2914,1378,8398080,256,2,"cuda:1"],[2928,1378,8396032,256,2,"cuda:1"],[2942,1378,8397056,256,2,"cuda:1"],[2956,1378,5250048,1048576,2,"cuda:1"],[2970,1378,4198400,1024,2,"cuda:1"],[2984,1378,1051648,1048576,2,"cuda:1"],[2998,1378,2304,256,2,"cuda:1"],[3012,1378,256,256,2,"cuda:1"],[3026,1378,1280,256,2,"cuda:1"],[2819,1378,38374400,12877824,2,"cuda:1"],[2833,1378,12608512,5120,2,"cuda:1"],[2847,1378,12596736,256,2,"cuda:1"],[2861,1378,12597760,256,2,"cuda:1"],[2875,1378,11020288,786432,2,"cuda:1"],[2889,1378,12594688,768,2,"cuda:1"],[2903,1378,8923136,262144,2,"cuda:1"],[2917,1378,8398336,256,2,"cuda:1"],[2931,1378,8396288,256,2,"cuda:1"],[2945,1378,8397312,256,2,"cuda:1"],[2959,1378,6298624,1048576,2,"cuda:1"],[2973,1378,4199424,1024,2,"cuda:1"],[2987,1378,2100224,1048576,2,"cuda:1"],[3001,1378,2560,256,2,"cuda:1"],[3015,1378,512,256,2,"cuda:1"],[3029,1378,1536,256,2,"cuda:1"],[2822,1378,51252224,12877824,2,"cuda:1"],[2836,1378,12613632,5120,2,"cuda:1"],[2850,1378,12596992,256,2,"cuda:1"],[2864,1378,12598016,256,2,"cuda:1"],[2878,1378,11806720,786432,2,"cuda:1"],[2892,1378,12595456,768,2,"cuda:1"],[2906,1378,9185280,262144,2,"cuda:1"],[2920,1378,8398592,256,2,"cuda:1"],[2934,1378,8396544,256,2,"cuda:1"],[2948,1378,8397568,256,2,"cuda:1"],[2962,1378,7347200,1048576,2,"cuda:1"],[2976,1378,4200448,1024,2,"cuda:1"],[2990,1378,3148800,1048576,2,"cuda:1"],[3004,1378,2816,256,2,"cuda:1"],[3018,1378,768,256,2,"cuda:1"],[3032,1378,1792,256,2,"cuda:1"]],0], "input_shapes": [[[12877824],[5120],[256],[256],[786432],[768],[262144],[256],[256],[256],[1048576],[1024],[1048576],[256],[256],[256],[12877824],[5120],[256],[256],[786432],[768],[262144],[256],[256],[256],[1048576],[1024],[1048576],[256],[256],[256],[12877824],[5120],[256],[256],[786432],[768],[262144],[256],[256],[256],[1048576],[1024],[1048576],[256],[256],[256],[12877824],[5120],[256],[256],[786432],[768],[262144],[256],[256],[256],[1048576],[1024],[1048576],[256],[256],[256]],[]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int"],
      "outputs": [[3034,3035,0,64130048,2,"cuda:1"]], "output_shapes": [[64130048]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::div_", "id": 3038, "rf_id": 2108, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[3034,3035,0,64130048,2,"cuda:1"],[3036,3037,0,1,8,"cpu"]], "input_shapes": [[64130048],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)"],
      "outputs": [[3034,3035,0,64130048,2,"cuda:1"]], "output_shapes": [[64130048]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3043, "rf_id": 2113, "parent": 3042, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3034,3035,0,64130048,2,"cuda:1"],[16032512],[1],0], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3044,3035,0,16032512,2,"cuda:1"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3042, "rf_id": 2112, "parent": 3041, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3034,3035,0,64130048,2,"cuda:1"],0,0,16032512,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3044,3035,0,16032512,2,"cuda:1"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3041, "rf_id": 2111, "parent": 3040, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3034,3035,0,64130048,2,"cuda:1"],0,0,16032512], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3044,3035,0,16032512,2,"cuda:1"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3047, "rf_id": 2116, "parent": 3046, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3034,3035,0,64130048,2,"cuda:1"],[16032512],[1],16032512], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3048,3035,16032512,16032512,2,"cuda:1"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3046, "rf_id": 2115, "parent": 3045, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3034,3035,0,64130048,2,"cuda:1"],0,16032512,32065024,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3048,3035,16032512,16032512,2,"cuda:1"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3045, "rf_id": 2114, "parent": 3040, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3034,3035,0,64130048,2,"cuda:1"],0,16032512,16032512], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3048,3035,16032512,16032512,2,"cuda:1"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3051, "rf_id": 2119, "parent": 3050, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3034,3035,0,64130048,2,"cuda:1"],[16032512],[1],32065024], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3052,3035,32065024,16032512,2,"cuda:1"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3050, "rf_id": 2118, "parent": 3049, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3034,3035,0,64130048,2,"cuda:1"],0,32065024,48097536,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3052,3035,32065024,16032512,2,"cuda:1"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3049, "rf_id": 2117, "parent": 3040, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3034,3035,0,64130048,2,"cuda:1"],0,32065024,16032512], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3052,3035,32065024,16032512,2,"cuda:1"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3055, "rf_id": 2122, "parent": 3054, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3034,3035,0,64130048,2,"cuda:1"],[16032512],[1],48097536], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3056,3035,48097536,16032512,2,"cuda:1"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3054, "rf_id": 2121, "parent": 3053, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3034,3035,0,64130048,2,"cuda:1"],0,48097536,64130048,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3056,3035,48097536,16032512,2,"cuda:1"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3053, "rf_id": 2120, "parent": 3040, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3034,3035,0,64130048,2,"cuda:1"],0,48097536,16032512], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3056,3035,48097536,16032512,2,"cuda:1"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::split", "id": 3040, "rf_id": 2110, "parent": 3039, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::split.Tensor(Tensor(a -> *) self, SymInt split_size, int dim=0) -> Tensor(a)[]",
      "inputs": [[3034,3035,0,64130048,2,"cuda:1"],16032512,0], "input_shapes": [[64130048],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[[3044,3035,0,16032512,2,"cuda:1"],[3048,3035,16032512,16032512,2,"cuda:1"],[3052,3035,32065024,16032512,2,"cuda:1"],[3056,3035,48097536,16032512,2,"cuda:1"]]], "output_shapes": [[[16032512],[16032512],[16032512],[16032512]]], "output_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"]
    },
    {
      "name": "aten::chunk", "id": 3039, "rf_id": 2109, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::chunk(Tensor(a -> *) self, int chunks, int dim=0) -> Tensor(a)[]",
      "inputs": [[3034,3035,0,64130048,2,"cuda:1"],4,0], "input_shapes": [[64130048],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[[3044,3035,0,16032512,2,"cuda:1"],[3048,3035,16032512,16032512,2,"cuda:1"],[3052,3035,32065024,16032512,2,"cuda:1"],[3056,3035,48097536,16032512,2,"cuda:1"]]], "output_shapes": [[[16032512],[16032512],[16032512],[16032512]]], "output_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"]
    },
    {
      "name": "nccl:_reduce_scatter_base", "id": 3059, "rf_id": 2125, "parent": 3058, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3034,3035,0,64130048,2,"cuda:1"]], "input_shapes": [[64130048]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3058, "rf_id": 2124, "parent": 3057, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3034,3035,0,64130048,2,"cuda:1"],128,94716817711568,1,"_reduce_scatter_base",[],[],4], "input_shapes": [[64130048],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3048,3035,16032512,16032512,2,"cuda:1"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_reduce_scatter_base_", "id": 3057, "rf_id": 2123, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_reduce_scatter_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],[3034,3035,0,64130048,2,"cuda:1"],"<Object>","<Object>",false,-1], "input_shapes": [[16032512],[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Object","Bool","Int"],
      "outputs": [[3048,3035,16032512,16032512,2,"cuda:1"],"<Object>"], "output_shapes": [[16032512],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "record_param_comms", "id": 3060, "rf_id": 2126, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [128,0,1,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3063, "rf_id": 2129, "parent": 3062, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],[12877824],[1],16032512], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3064,3035,16032512,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3062, "rf_id": 2128, "parent": 3061, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,0,12877824,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3064,3035,16032512,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3061, "rf_id": 2127, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,0,12877824], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3064,3035,16032512,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3067, "rf_id": 2132, "parent": 3066, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],[5120],[1],28910336], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3068,3035,28910336,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3066, "rf_id": 2131, "parent": 3065, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,12877824,12882944,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3068,3035,28910336,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3065, "rf_id": 2130, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,12877824,5120], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3068,3035,28910336,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3071, "rf_id": 2135, "parent": 3070, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],[256],[1],28915456], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3072,3035,28915456,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3070, "rf_id": 2134, "parent": 3069, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,12882944,12883200,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3072,3035,28915456,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3069, "rf_id": 2133, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,12882944,256], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3072,3035,28915456,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3075, "rf_id": 2138, "parent": 3074, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],[256],[1],28915712], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3076,3035,28915712,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3074, "rf_id": 2137, "parent": 3073, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,12883200,12883456,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3076,3035,28915712,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3073, "rf_id": 2136, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,12883200,256], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3076,3035,28915712,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3079, "rf_id": 2141, "parent": 3078, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],[786432],[1],28915968], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3080,3035,28915968,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3078, "rf_id": 2140, "parent": 3077, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,12883456,13669888,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3080,3035,28915968,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3077, "rf_id": 2139, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,12883456,786432], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3080,3035,28915968,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3083, "rf_id": 2144, "parent": 3082, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],[768],[1],29702400], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3084,3035,29702400,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3082, "rf_id": 2143, "parent": 3081, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,13669888,13670656,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3084,3035,29702400,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3081, "rf_id": 2142, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,13669888,768], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3084,3035,29702400,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3087, "rf_id": 2147, "parent": 3086, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],[262144],[1],29703168], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3088,3035,29703168,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3086, "rf_id": 2146, "parent": 3085, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,13670656,13932800,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3088,3035,29703168,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3085, "rf_id": 2145, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,13670656,262144], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3088,3035,29703168,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3091, "rf_id": 2150, "parent": 3090, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],[256],[1],29965312], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3092,3035,29965312,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3090, "rf_id": 2149, "parent": 3089, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,13932800,13933056,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3092,3035,29965312,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3089, "rf_id": 2148, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,13932800,256], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3092,3035,29965312,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3095, "rf_id": 2153, "parent": 3094, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],[256],[1],29965568], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3096,3035,29965568,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3094, "rf_id": 2152, "parent": 3093, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,13933056,13933312,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3096,3035,29965568,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3093, "rf_id": 2151, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,13933056,256], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3096,3035,29965568,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3099, "rf_id": 2156, "parent": 3098, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],[256],[1],29965824], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3100,3035,29965824,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3098, "rf_id": 2155, "parent": 3097, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,13933312,13933568,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3100,3035,29965824,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3097, "rf_id": 2154, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,13933312,256], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3100,3035,29965824,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3103, "rf_id": 2159, "parent": 3102, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],[1048576],[1],29966080], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3104,3035,29966080,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3102, "rf_id": 2158, "parent": 3101, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,13933568,14982144,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3104,3035,29966080,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3101, "rf_id": 2157, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,13933568,1048576], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3104,3035,29966080,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3107, "rf_id": 2162, "parent": 3106, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],[1024],[1],31014656], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3108,3035,31014656,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3106, "rf_id": 2161, "parent": 3105, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,14982144,14983168,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3108,3035,31014656,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3105, "rf_id": 2160, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,14982144,1024], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3108,3035,31014656,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3111, "rf_id": 2165, "parent": 3110, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],[1048576],[1],31015680], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3112,3035,31015680,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3110, "rf_id": 2164, "parent": 3109, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,14983168,16031744,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3112,3035,31015680,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3109, "rf_id": 2163, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,14983168,1048576], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3112,3035,31015680,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3115, "rf_id": 2168, "parent": 3114, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],[256],[1],32064256], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3116,3035,32064256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3114, "rf_id": 2167, "parent": 3113, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,16031744,16032000,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3116,3035,32064256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3113, "rf_id": 2166, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,16031744,256], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3116,3035,32064256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3119, "rf_id": 2171, "parent": 3118, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],[256],[1],32064512], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3120,3035,32064512,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3118, "rf_id": 2170, "parent": 3117, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,16032000,16032256,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3120,3035,32064512,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3117, "rf_id": 2169, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,16032000,256], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3120,3035,32064512,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3123, "rf_id": 2174, "parent": 3122, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],[256],[1],32064768], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3124,3035,32064768,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3122, "rf_id": 2173, "parent": 3121, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,16032256,16032512,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3124,3035,32064768,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3121, "rf_id": 2172, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3048,3035,16032512,16032512,2,"cuda:1"],0,16032256,256], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3124,3035,32064768,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3129, "rf_id": 2177, "parent": 3128, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3125,3126,0,12877824,2,"cuda:1"],[12877824],[1],0], "input_shapes": [[12877824],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3044,3126,0,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3128, "rf_id": 2176, "parent": 3127, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3125,3126,0,12877824,2,"cuda:1"],0,0,12877824,1], "input_shapes": [[12877824],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3044,3126,0,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3127, "rf_id": 2175, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3125,3126,0,12877824,2,"cuda:1"],0,0,12877824], "input_shapes": [[12877824],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3044,3126,0,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3130, "rf_id": 2178, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3044,3126,0,12877824,2,"cuda:1"],[3064,3035,16032512,12877824,2,"cuda:1"],true], "input_shapes": [[12877824],[12877824],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3044,3126,0,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3131, "rf_id": 2179, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3044,3126,0,12877824,2,"cuda:1"],15,0,"cuda:1","<None>",true,false,"<None>"], "input_shapes": [[12877824],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3044,3126,0,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3132, "rf_id": 2180, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2798,1378,12618752,51511296,2,"cuda:1"],"<Stream>"], "input_shapes": [[50304,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3136, "rf_id": 2183, "parent": 3135, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3133,3126,12877824,5120,2,"cuda:1"],[5120],[1],12877824], "input_shapes": [[5120],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3052,3126,12877824,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3135, "rf_id": 2182, "parent": 3134, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3133,3126,12877824,5120,2,"cuda:1"],0,0,5120,1], "input_shapes": [[5120],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3052,3126,12877824,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3134, "rf_id": 2181, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3133,3126,12877824,5120,2,"cuda:1"],0,0,5120], "input_shapes": [[5120],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3052,3126,12877824,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3137, "rf_id": 2184, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3052,3126,12877824,5120,2,"cuda:1"],[3068,3035,28910336,5120,2,"cuda:1"],true], "input_shapes": [[5120],[5120],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3052,3126,12877824,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3138, "rf_id": 2185, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3052,3126,12877824,5120,2,"cuda:1"],15,0,"cuda:1","<None>",true,false,"<None>"], "input_shapes": [[5120],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3052,3126,12877824,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3139, "rf_id": 2186, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2761,1378,12598272,20480,2,"cuda:1"],"<Stream>"], "input_shapes": [[20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3143, "rf_id": 2189, "parent": 3142, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3140,3126,16028672,256,2,"cuda:1"],[256],[1],16028672], "input_shapes": [[256],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3056,3126,16028672,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3142, "rf_id": 2188, "parent": 3141, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3140,3126,16028672,256,2,"cuda:1"],0,0,256,1], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3056,3126,16028672,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3141, "rf_id": 2187, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3140,3126,16028672,256,2,"cuda:1"],0,0,256], "input_shapes": [[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3056,3126,16028672,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3144, "rf_id": 2190, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3056,3126,16028672,256,2,"cuda:1"],[3072,3035,28915456,256,2,"cuda:1"],true], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3056,3126,16028672,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3145, "rf_id": 2191, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3056,3126,16028672,256,2,"cuda:1"],15,0,"cuda:1","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3056,3126,16028672,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3146, "rf_id": 2192, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2676,1378,12596224,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3150, "rf_id": 2195, "parent": 3149, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3147,3126,16028928,256,2,"cuda:1"],[256],[1],16028928], "input_shapes": [[256],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3151,3126,16028928,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3149, "rf_id": 2194, "parent": 3148, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3147,3126,16028928,256,2,"cuda:1"],0,0,256,1], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3151,3126,16028928,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3148, "rf_id": 2193, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3147,3126,16028928,256,2,"cuda:1"],0,0,256], "input_shapes": [[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3151,3126,16028928,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3152, "rf_id": 2196, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3151,3126,16028928,256,2,"cuda:1"],[3076,3035,28915712,256,2,"cuda:1"],true], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3151,3126,16028928,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3153, "rf_id": 2197, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3151,3126,16028928,256,2,"cuda:1"],15,0,"cuda:1","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3151,3126,16028928,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3154, "rf_id": 2198, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2690,1378,12597248,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3158, "rf_id": 2201, "parent": 3157, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3155,3126,12882944,786432,2,"cuda:1"],[786432],[1],12882944], "input_shapes": [[786432],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3159,3126,12882944,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3157, "rf_id": 2200, "parent": 3156, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3155,3126,12882944,786432,2,"cuda:1"],0,0,786432,1], "input_shapes": [[786432],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3159,3126,12882944,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3156, "rf_id": 2199, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3155,3126,12882944,786432,2,"cuda:1"],0,0,786432], "input_shapes": [[786432],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3159,3126,12882944,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3160, "rf_id": 2202, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3159,3126,12882944,786432,2,"cuda:1"],[3080,3035,28915968,786432,2,"cuda:1"],true], "input_shapes": [[786432],[786432],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3159,3126,12882944,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3161, "rf_id": 2203, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3159,3126,12882944,786432,2,"cuda:1"],15,0,"cuda:1","<None>",true,false,"<None>"], "input_shapes": [[786432],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3159,3126,12882944,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3162, "rf_id": 2204, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2610,1378,9447424,3145728,2,"cuda:1"],"<Stream>"], "input_shapes": [[3072,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3166, "rf_id": 2207, "parent": 3165, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3163,3126,16029184,768,2,"cuda:1"],[768],[1],16029184], "input_shapes": [[768],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3167,3126,16029184,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3165, "rf_id": 2206, "parent": 3164, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3163,3126,16029184,768,2,"cuda:1"],0,0,768,1], "input_shapes": [[768],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3167,3126,16029184,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3164, "rf_id": 2205, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3163,3126,16029184,768,2,"cuda:1"],0,0,768], "input_shapes": [[768],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3167,3126,16029184,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3168, "rf_id": 2208, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3167,3126,16029184,768,2,"cuda:1"],[3084,3035,29702400,768,2,"cuda:1"],true], "input_shapes": [[768],[768],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3167,3126,16029184,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3169, "rf_id": 2209, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3167,3126,16029184,768,2,"cuda:1"],15,0,"cuda:1","<None>",true,false,"<None>"], "input_shapes": [[768],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3167,3126,16029184,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3170, "rf_id": 2210, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2629,1378,12593152,3072,2,"cuda:1"],"<Stream>"], "input_shapes": [[3072],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3174, "rf_id": 2213, "parent": 3173, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3171,3126,13669376,262144,2,"cuda:1"],[262144],[1],13669376], "input_shapes": [[262144],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3175,3126,13669376,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3173, "rf_id": 2212, "parent": 3172, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3171,3126,13669376,262144,2,"cuda:1"],0,0,262144,1], "input_shapes": [[262144],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3175,3126,13669376,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3172, "rf_id": 2211, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3171,3126,13669376,262144,2,"cuda:1"],0,0,262144], "input_shapes": [[262144],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3175,3126,13669376,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3176, "rf_id": 2214, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3175,3126,13669376,262144,2,"cuda:1"],[3088,3035,29703168,262144,2,"cuda:1"],true], "input_shapes": [[262144],[262144],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3175,3126,13669376,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3177, "rf_id": 2215, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3175,3126,13669376,262144,2,"cuda:1"],15,0,"cuda:1","<None>",true,false,"<None>"], "input_shapes": [[262144],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3175,3126,13669376,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3178, "rf_id": 2216, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2237,1378,8398848,1048576,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3182, "rf_id": 2219, "parent": 3181, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3179,3126,16029952,256,2,"cuda:1"],[256],[1],16029952], "input_shapes": [[256],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3183,3126,16029952,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3181, "rf_id": 2218, "parent": 3180, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3179,3126,16029952,256,2,"cuda:1"],0,0,256,1], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3183,3126,16029952,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3180, "rf_id": 2217, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3179,3126,16029952,256,2,"cuda:1"],0,0,256], "input_shapes": [[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3183,3126,16029952,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3184, "rf_id": 2220, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3183,3126,16029952,256,2,"cuda:1"],[3092,3035,29965312,256,2,"cuda:1"],true], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3183,3126,16029952,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3185, "rf_id": 2221, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3183,3126,16029952,256,2,"cuda:1"],15,0,"cuda:1","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3183,3126,16029952,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3186, "rf_id": 2222, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2197,1378,8397824,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3190, "rf_id": 2225, "parent": 3189, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3187,3126,16030208,256,2,"cuda:1"],[256],[1],16030208], "input_shapes": [[256],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3191,3126,16030208,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3189, "rf_id": 2224, "parent": 3188, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3187,3126,16030208,256,2,"cuda:1"],0,0,256,1], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3191,3126,16030208,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3188, "rf_id": 2223, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3187,3126,16030208,256,2,"cuda:1"],0,0,256], "input_shapes": [[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3191,3126,16030208,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3192, "rf_id": 2226, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3191,3126,16030208,256,2,"cuda:1"],[3096,3035,29965568,256,2,"cuda:1"],true], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3191,3126,16030208,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3193, "rf_id": 2227, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3191,3126,16030208,256,2,"cuda:1"],15,0,"cuda:1","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3191,3126,16030208,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3194, "rf_id": 2228, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2138,1378,8395776,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3198, "rf_id": 2231, "parent": 3197, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3195,3126,16030464,256,2,"cuda:1"],[256],[1],16030464], "input_shapes": [[256],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3199,3126,16030464,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3197, "rf_id": 2230, "parent": 3196, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3195,3126,16030464,256,2,"cuda:1"],0,0,256,1], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3199,3126,16030464,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3196, "rf_id": 2229, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3195,3126,16030464,256,2,"cuda:1"],0,0,256], "input_shapes": [[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3199,3126,16030464,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3200, "rf_id": 2232, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3199,3126,16030464,256,2,"cuda:1"],[3100,3035,29965824,256,2,"cuda:1"],true], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3199,3126,16030464,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3201, "rf_id": 2233, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3199,3126,16030464,256,2,"cuda:1"],15,0,"cuda:1","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3199,3126,16030464,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3202, "rf_id": 2234, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2152,1378,8396800,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3206, "rf_id": 2237, "parent": 3205, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3203,3126,13931520,1048576,2,"cuda:1"],[1048576],[1],13931520], "input_shapes": [[1048576],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3207,3126,13931520,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3205, "rf_id": 2236, "parent": 3204, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3203,3126,13931520,1048576,2,"cuda:1"],0,0,1048576,1], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3207,3126,13931520,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3204, "rf_id": 2235, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3203,3126,13931520,1048576,2,"cuda:1"],0,0,1048576], "input_shapes": [[1048576],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3207,3126,13931520,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3208, "rf_id": 2238, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3207,3126,13931520,1048576,2,"cuda:1"],[3104,3035,29966080,1048576,2,"cuda:1"],true], "input_shapes": [[1048576],[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3207,3126,13931520,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3209, "rf_id": 2239, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3207,3126,13931520,1048576,2,"cuda:1"],15,0,"cuda:1","<None>",true,false,"<None>"], "input_shapes": [[1048576],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3207,3126,13931520,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3210, "rf_id": 2240, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2091,1378,4201472,4194304,2,"cuda:1"],"<Stream>"], "input_shapes": [[4096,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3214, "rf_id": 2243, "parent": 3213, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3211,3126,16030720,1024,2,"cuda:1"],[1024],[1],16030720], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3215,3126,16030720,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3213, "rf_id": 2242, "parent": 3212, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3211,3126,16030720,1024,2,"cuda:1"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3215,3126,16030720,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3212, "rf_id": 2241, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3211,3126,16030720,1024,2,"cuda:1"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3215,3126,16030720,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3216, "rf_id": 2244, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3215,3126,16030720,1024,2,"cuda:1"],[3108,3035,31014656,1024,2,"cuda:1"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3215,3126,16030720,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3217, "rf_id": 2245, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3215,3126,16030720,1024,2,"cuda:1"],15,0,"cuda:1","<None>",true,false,"<None>"], "input_shapes": [[1024],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3215,3126,16030720,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3218, "rf_id": 2246, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2053,1378,4197376,4096,2,"cuda:1"],"<Stream>"], "input_shapes": [[4096],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3222, "rf_id": 2249, "parent": 3221, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3219,3126,14980096,1048576,2,"cuda:1"],[1048576],[1],14980096], "input_shapes": [[1048576],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3223,3126,14980096,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3221, "rf_id": 2248, "parent": 3220, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3219,3126,14980096,1048576,2,"cuda:1"],0,0,1048576,1], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3223,3126,14980096,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3220, "rf_id": 2247, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3219,3126,14980096,1048576,2,"cuda:1"],0,0,1048576], "input_shapes": [[1048576],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3223,3126,14980096,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3224, "rf_id": 2250, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3223,3126,14980096,1048576,2,"cuda:1"],[3112,3035,31015680,1048576,2,"cuda:1"],true], "input_shapes": [[1048576],[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3223,3126,14980096,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3225, "rf_id": 2251, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3223,3126,14980096,1048576,2,"cuda:1"],15,0,"cuda:1","<None>",true,false,"<None>"], "input_shapes": [[1048576],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3223,3126,14980096,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3226, "rf_id": 2252, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1955,1378,3072,4194304,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3230, "rf_id": 2255, "parent": 3229, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3227,3126,16031744,256,2,"cuda:1"],[256],[1],16031744], "input_shapes": [[256],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3231,3126,16031744,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3229, "rf_id": 2254, "parent": 3228, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3227,3126,16031744,256,2,"cuda:1"],0,0,256,1], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3231,3126,16031744,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3228, "rf_id": 2253, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3227,3126,16031744,256,2,"cuda:1"],0,0,256], "input_shapes": [[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3231,3126,16031744,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3232, "rf_id": 2256, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3231,3126,16031744,256,2,"cuda:1"],[3116,3035,32064256,256,2,"cuda:1"],true], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3231,3126,16031744,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3233, "rf_id": 2257, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3231,3126,16031744,256,2,"cuda:1"],15,0,"cuda:1","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3231,3126,16031744,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3234, "rf_id": 2258, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1916,1378,2048,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3238, "rf_id": 2261, "parent": 3237, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3235,3126,16032000,256,2,"cuda:1"],[256],[1],16032000], "input_shapes": [[256],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3239,3126,16032000,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3237, "rf_id": 2260, "parent": 3236, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3235,3126,16032000,256,2,"cuda:1"],0,0,256,1], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3239,3126,16032000,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3236, "rf_id": 2259, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3235,3126,16032000,256,2,"cuda:1"],0,0,256], "input_shapes": [[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3239,3126,16032000,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3240, "rf_id": 2262, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3239,3126,16032000,256,2,"cuda:1"],[3120,3035,32064512,256,2,"cuda:1"],true], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3239,3126,16032000,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3241, "rf_id": 2263, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3239,3126,16032000,256,2,"cuda:1"],15,0,"cuda:1","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3239,3126,16032000,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3242, "rf_id": 2264, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1376,1378,0,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3246, "rf_id": 2267, "parent": 3245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3243,3126,16032256,256,2,"cuda:1"],[256],[1],16032256], "input_shapes": [[256],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3247,3126,16032256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3245, "rf_id": 2266, "parent": 3244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3243,3126,16032256,256,2,"cuda:1"],0,0,256,1], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3247,3126,16032256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3244, "rf_id": 2265, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3243,3126,16032256,256,2,"cuda:1"],0,0,256], "input_shapes": [[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3247,3126,16032256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3248, "rf_id": 2268, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3247,3126,16032256,256,2,"cuda:1"],[3124,3035,32064768,256,2,"cuda:1"],true], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3247,3126,16032256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3249, "rf_id": 2269, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3247,3126,16032256,256,2,"cuda:1"],15,0,"cuda:1","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3247,3126,16032256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3250, "rf_id": 2270, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1392,1378,1024,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3251, "rf_id": 2271, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],0,"<None>","cuda","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","None","None"],
      "outputs": [[3252,171,0,1,1,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(unsigned char)"]
    },
    {
      "name": "aten::empty", "id": 3255, "rf_id": 2274, "parent": 3254, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],0,"<None>","cuda","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","None","None"],
      "outputs": [[3256,10,0,1,1,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(unsigned char)"]
    },
    {
      "name": "nccl:all_reduce", "id": 3258, "rf_id": 2276, "parent": 3257, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3256,10,0,1,1,"cuda:1"]], "input_shapes": [[1]], "input_types": ["Tensor(unsigned char)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3257, "rf_id": 2275, "parent": 3254, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[3256,10,0,1,1,"cuda:1"]],41,94716834063120,1,"allreduce",[],[],4], "input_shapes": [[[1]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(unsigned char)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[3256,10,0,1,1,"cuda:1"]]], "output_shapes": [[[1]]], "output_types": ["GenericList[Tensor(unsigned char)]"]
    },
    {
      "name": "record_param_comms", "id": 3254, "rf_id": 2273, "parent": 3253, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [41,94716834063120,1,"barrier",[],[],4], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "c10d::barrier", "id": 3253, "rf_id": 2272, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::barrier(Tensor tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, int[] device_ids, int timeout) -> __torch__.torch.classes.c10d.Work",
      "inputs": [[3252,171,0,1,1,"cuda:1"],"<Object>",[],-1], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(unsigned char)","Object","GenericList[]","Int"],
      "outputs": ["<Object>"], "output_shapes": [[]], "output_types": ["Object"]
    },
    {
      "name": "record_param_comms", "id": 3259, "rf_id": 2277, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [41,0,1,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3261, "rf_id": 2278, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3260,237,0,51511296,2,"cuda:1"],"<Stream>"], "input_shapes": [[50304,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3262, "rf_id": 2279, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3263,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3264, "rf_id": 2280, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[251,237,0,51511296,2,"cuda:1"],[3263,57,0,0,2,"cuda:1"]], "input_shapes": [[50304,1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3266, "rf_id": 2281, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3265,345,0,20480,2,"cuda:1"],"<Stream>"], "input_shapes": [[20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3267, "rf_id": 2282, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3268,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3269, "rf_id": 2283, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[344,345,0,20480,2,"cuda:1"],[3268,57,0,0,2,"cuda:1"]], "input_shapes": [[20,1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3271, "rf_id": 2284, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3270,423,0,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3272, "rf_id": 2285, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3273,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3274, "rf_id": 2286, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[422,423,0,1024,2,"cuda:1"],[3273,57,0,0,2,"cuda:1"]], "input_shapes": [[1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3276, "rf_id": 2287, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3275,425,0,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3277, "rf_id": 2288, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3278,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3279, "rf_id": 2289, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[424,425,0,1024,2,"cuda:1"],[3278,57,0,0,2,"cuda:1"]], "input_shapes": [[1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3281, "rf_id": 2290, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3280,565,0,3072,2,"cuda:1"],"<Stream>"], "input_shapes": [[3072],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3282, "rf_id": 2291, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3283,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3284, "rf_id": 2292, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[564,565,0,3072,2,"cuda:1"],[3283,57,0,0,2,"cuda:1"]], "input_shapes": [[3072],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3286, "rf_id": 2293, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3285,779,0,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3287, "rf_id": 2294, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3288,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3289, "rf_id": 2295, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[778,779,0,1024,2,"cuda:1"],[3288,57,0,0,2,"cuda:1"]], "input_shapes": [[1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3291, "rf_id": 2296, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3290,818,0,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3292, "rf_id": 2297, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3293,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3294, "rf_id": 2298, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[817,818,0,1024,2,"cuda:1"],[3293,57,0,0,2,"cuda:1"]], "input_shapes": [[1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3296, "rf_id": 2299, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3295,820,0,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3297, "rf_id": 2300, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3298,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3299, "rf_id": 2301, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[819,820,0,1024,2,"cuda:1"],[3298,57,0,0,2,"cuda:1"]], "input_shapes": [[1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3301, "rf_id": 2302, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3300,887,0,4096,2,"cuda:1"],"<Stream>"], "input_shapes": [[4096],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3302, "rf_id": 2303, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3303,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3304, "rf_id": 2304, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[886,887,0,4096,2,"cuda:1"],[3303,57,0,0,2,"cuda:1"]], "input_shapes": [[4096],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3306, "rf_id": 2305, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3305,958,0,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3307, "rf_id": 2306, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3308,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3309, "rf_id": 2307, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[957,958,0,1024,2,"cuda:1"],[3308,57,0,0,2,"cuda:1"]], "input_shapes": [[1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3311, "rf_id": 2308, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3310,995,0,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3312, "rf_id": 2309, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3313,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3314, "rf_id": 2310, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[994,995,0,1024,2,"cuda:1"],[3313,57,0,0,2,"cuda:1"]], "input_shapes": [[1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3316, "rf_id": 2311, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3315,997,0,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3317, "rf_id": 2312, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3318,57,0,0,2,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3319, "rf_id": 2313, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[996,997,0,1024,2,"cuda:1"],[3318,57,0,0,2,"cuda:1"]], "input_shapes": [[1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::to", "id": 3320, "rf_id": 2314, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3125,3126,0,12877824,2,"cuda:1"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[12877824],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3125,3126,0,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3323, "rf_id": 2317, "parent": 3322, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[12877824],[1],7,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3324,1078,0,12877824,8,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3325, "rf_id": 2318, "parent": 3322, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3324,1078,0,12877824,8,"cuda:1"],[3125,3126,0,12877824,2,"cuda:1"],false], "input_shapes": [[12877824],[12877824],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3324,1078,0,12877824,8,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3322, "rf_id": 2316, "parent": 3321, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3125,3126,0,12877824,2,"cuda:1"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[12877824],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3324,1078,0,12877824,8,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3321, "rf_id": 2315, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3125,3126,0,12877824,2,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[12877824],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3324,1078,0,12877824,8,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3328, "rf_id": 2320, "parent": 3326, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3327,10,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3329,10,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3326, "rf_id": 2319, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3324,1078,0,12877824,8,"cuda:1"],2,"<None>",false,"<None>"], "input_shapes": [[12877824],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3327,10,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3330, "rf_id": 2321, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3133,3126,12877824,5120,2,"cuda:1"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[5120],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3133,3126,12877824,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3333, "rf_id": 2324, "parent": 3332, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[5120],[1],7,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3329,345,0,5120,8,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3334, "rf_id": 2325, "parent": 3332, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3329,345,0,5120,8,"cuda:1"],[3133,3126,12877824,5120,2,"cuda:1"],false], "input_shapes": [[5120],[5120],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3329,345,0,5120,8,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3332, "rf_id": 2323, "parent": 3331, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3133,3126,12877824,5120,2,"cuda:1"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[5120],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3329,345,0,5120,8,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3331, "rf_id": 2322, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3133,3126,12877824,5120,2,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[5120],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3329,345,0,5120,8,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3337, "rf_id": 2327, "parent": 3335, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3336,425,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3338,425,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3335, "rf_id": 2326, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3329,345,0,5120,8,"cuda:1"],2,"<None>",false,"<None>"], "input_shapes": [[5120],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3336,425,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3339, "rf_id": 2328, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3155,3126,12882944,786432,2,"cuda:1"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[786432],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3155,3126,12882944,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3342, "rf_id": 2331, "parent": 3341, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[786432],[1],7,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3338,904,0,786432,8,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3343, "rf_id": 2332, "parent": 3341, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3338,904,0,786432,8,"cuda:1"],[3155,3126,12882944,786432,2,"cuda:1"],false], "input_shapes": [[786432],[786432],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3338,904,0,786432,8,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3341, "rf_id": 2330, "parent": 3340, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3155,3126,12882944,786432,2,"cuda:1"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[786432],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3338,904,0,786432,8,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3340, "rf_id": 2329, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3155,3126,12882944,786432,2,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[786432],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3338,904,0,786432,8,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3347, "rf_id": 2334, "parent": 3344, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3345,3346,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3348,3346,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3344, "rf_id": 2333, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3338,904,0,786432,8,"cuda:1"],2,"<None>",false,"<None>"], "input_shapes": [[786432],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3345,3346,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3349, "rf_id": 2335, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3171,3126,13669376,262144,2,"cuda:1"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[262144],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3171,3126,13669376,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3352, "rf_id": 2338, "parent": 3351, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[262144],[1],7,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3348,904,0,262144,8,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3353, "rf_id": 2339, "parent": 3351, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3348,904,0,262144,8,"cuda:1"],[3171,3126,13669376,262144,2,"cuda:1"],false], "input_shapes": [[262144],[262144],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3348,904,0,262144,8,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3351, "rf_id": 2337, "parent": 3350, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3171,3126,13669376,262144,2,"cuda:1"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[262144],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3348,904,0,262144,8,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3350, "rf_id": 2336, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3171,3126,13669376,262144,2,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[262144],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3348,904,0,262144,8,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3357, "rf_id": 2341, "parent": 3354, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3355,3356,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3358,3356,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3354, "rf_id": 2340, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3348,904,0,262144,8,"cuda:1"],2,"<None>",false,"<None>"], "input_shapes": [[262144],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3355,3356,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3359, "rf_id": 2342, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3203,3126,13931520,1048576,2,"cuda:1"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[1048576],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3203,3126,13931520,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3362, "rf_id": 2345, "parent": 3361, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1048576],[1],7,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3358,904,0,1048576,8,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3363, "rf_id": 2346, "parent": 3361, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3358,904,0,1048576,8,"cuda:1"],[3203,3126,13931520,1048576,2,"cuda:1"],false], "input_shapes": [[1048576],[1048576],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3358,904,0,1048576,8,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3361, "rf_id": 2344, "parent": 3360, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3203,3126,13931520,1048576,2,"cuda:1"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[1048576],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3358,904,0,1048576,8,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3360, "rf_id": 2343, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3203,3126,13931520,1048576,2,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3358,904,0,1048576,8,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3367, "rf_id": 2348, "parent": 3364, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3365,3366,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3368,3366,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3364, "rf_id": 2347, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3358,904,0,1048576,8,"cuda:1"],2,"<None>",false,"<None>"], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3365,3366,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3369, "rf_id": 2349, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3219,3126,14980096,1048576,2,"cuda:1"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[1048576],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3219,3126,14980096,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3372, "rf_id": 2352, "parent": 3371, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1048576],[1],7,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3368,904,0,1048576,8,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3373, "rf_id": 2353, "parent": 3371, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3368,904,0,1048576,8,"cuda:1"],[3219,3126,14980096,1048576,2,"cuda:1"],false], "input_shapes": [[1048576],[1048576],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3368,904,0,1048576,8,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3371, "rf_id": 2351, "parent": 3370, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3219,3126,14980096,1048576,2,"cuda:1"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[1048576],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3368,904,0,1048576,8,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3370, "rf_id": 2350, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3219,3126,14980096,1048576,2,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3368,904,0,1048576,8,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3376, "rf_id": 2355, "parent": 3374, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3375,818,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3377,818,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3374, "rf_id": 2354, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3368,904,0,1048576,8,"cuda:1"],2,"<None>",false,"<None>"], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3375,818,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3380, "rf_id": 2358, "parent": 3379, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3327,10,0,1,8,"cuda:1"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3377,10,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3379, "rf_id": 2357, "parent": 3378, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3327,10,0,1,8,"cuda:1"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3377,10,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3382, "rf_id": 2360, "parent": 3381, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3336,425,0,1,8,"cuda:1"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3383,425,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3381, "rf_id": 2359, "parent": 3378, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3336,425,0,1,8,"cuda:1"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3383,425,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3385, "rf_id": 2362, "parent": 3384, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3345,3346,0,1,8,"cuda:1"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3386,3346,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3384, "rf_id": 2361, "parent": 3378, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3345,3346,0,1,8,"cuda:1"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3386,3346,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3388, "rf_id": 2364, "parent": 3387, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3355,3356,0,1,8,"cuda:1"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3389,3356,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3387, "rf_id": 2363, "parent": 3378, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3355,3356,0,1,8,"cuda:1"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3389,3356,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3391, "rf_id": 2366, "parent": 3390, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3365,3366,0,1,8,"cuda:1"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3392,3366,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3390, "rf_id": 2365, "parent": 3378, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3365,3366,0,1,8,"cuda:1"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3392,3366,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3394, "rf_id": 2368, "parent": 3393, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3375,818,0,1,8,"cuda:1"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3395,818,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3393, "rf_id": 2367, "parent": 3378, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3375,818,0,1,8,"cuda:1"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3395,818,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::cat", "id": 3396, "rf_id": 2369, "parent": 3378, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[3377,10,0,1,8,"cuda:1"],[3383,425,0,1,8,"cuda:1"],[3386,3346,0,1,8,"cuda:1"],[3389,3356,0,1,8,"cuda:1"],[3392,3366,0,1,8,"cuda:1"],[3395,818,0,1,8,"cuda:1"]],0], "input_shapes": [[[1],[1],[1],[1],[1],[1]],[]], "input_types": ["GenericList[Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double)]","Int"],
      "outputs": [[3397,3398,0,6,8,"cuda:1"]], "output_shapes": [[6]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::stack", "id": 3378, "rf_id": 2356, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::stack(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[3327,10,0,1,8,"cuda:1"],[3336,425,0,1,8,"cuda:1"],[3345,3346,0,1,8,"cuda:1"],[3355,3356,0,1,8,"cuda:1"],[3365,3366,0,1,8,"cuda:1"],[3375,818,0,1,8,"cuda:1"]],0], "input_shapes": [[[],[],[],[],[],[]],[]], "input_types": ["GenericList[Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double)]","Int"],
      "outputs": [[3397,3398,0,6,8,"cuda:1"]], "output_shapes": [[6]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::result_type", "id": 3400, "rf_id": 2371, "parent": 3399, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::result_type.Scalar(Tensor tensor, Scalar other) -> ScalarType",
      "inputs": [[3397,3398,0,6,8,"cuda:1"],2], "input_shapes": [[6],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [7], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::to", "id": 3401, "rf_id": 2372, "parent": 3399, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3397,3398,0,6,8,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[6],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[3397,3398,0,6,8,"cuda:1"]], "output_shapes": [[6]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::pow", "id": 3399, "rf_id": 2370, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -> Tensor",
      "inputs": [[3397,3398,0,6,8,"cuda:1"],2], "input_shapes": [[6],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3402,3403,0,6,8,"cuda:1"]], "output_shapes": [[6]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3407, "rf_id": 2375, "parent": 3405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3406,3398,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3408,3398,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::sum", "id": 3405, "rf_id": 2374, "parent": 3404, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3402,3403,0,6,8,"cuda:1"],[],false,"<None>"], "input_shapes": [[6],[],[],[]], "input_types": ["Tensor(double)","GenericList[]","Bool","None"],
      "outputs": [[3406,3398,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::sum", "id": 3404, "rf_id": 2373, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum(Tensor self, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3402,3403,0,6,8,"cuda:1"],"<None>"], "input_shapes": [[6],[]], "input_types": ["Tensor(double)","None"],
      "outputs": [[3406,3398,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "nccl:all_reduce", "id": 3411, "rf_id": 2378, "parent": 3410, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3406,3398,0,1,8,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3410, "rf_id": 2377, "parent": 3409, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[3406,3398,0,1,8,"cuda:1"]],129,94716817711568,1,"allreduce",[],[],4], "input_shapes": [[[]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(double)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[3406,3398,0,1,8,"cuda:1"]]], "output_shapes": [[[]]], "output_types": ["GenericList[Tensor(double)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 3409, "rf_id": 2376, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[3406,3398,0,1,8,"cuda:1"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[]],[],[],[],[]], "input_types": ["GenericList[Tensor(double)]","Object","Object","None","Int"],
      "outputs": [[[3406,3398,0,1,8,"cuda:1"]],"<Object>"], "output_shapes": [[[]],[]], "output_types": ["GenericList[Tensor(double)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 3412, "rf_id": 2379, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [129,0,1,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "nccl:all_reduce", "id": 3415, "rf_id": 2382, "parent": 3414, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3406,3398,0,1,8,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3414, "rf_id": 2381, "parent": 3413, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[3406,3398,0,1,8,"cuda:1"]],7,94716817299440,0,"allreduce",[],[],1], "input_shapes": [[[]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(double)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[3406,3398,0,1,8,"cuda:1"]]], "output_shapes": [[[]]], "output_types": ["GenericList[Tensor(double)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 3413, "rf_id": 2380, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[3406,3398,0,1,8,"cuda:1"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[]],[],[],[],[]], "input_types": ["GenericList[Tensor(double)]","Object","Object","None","Int"],
      "outputs": [[[3406,3398,0,1,8,"cuda:1"]],"<Object>"], "output_shapes": [[[]],[]], "output_types": ["GenericList[Tensor(double)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 3416, "rf_id": 2383, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [7,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::result_type", "id": 3418, "rf_id": 2385, "parent": 3417, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::result_type.Scalar(Tensor tensor, Scalar other) -> ScalarType",
      "inputs": [[3406,3398,0,1,8,"cuda:1"],0.500000], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [7], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::to", "id": 3419, "rf_id": 2386, "parent": 3417, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3406,3398,0,1,8,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[3406,3398,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::pow", "id": 3417, "rf_id": 2384, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -> Tensor",
      "inputs": [[3406,3398,0,1,8,"cuda:1"],0.500000], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [[3420,3403,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::empty", "id": 3423, "rf_id": 2389, "parent": 3422, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],7,0,"cuda:1","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[3424,57,0,0,8,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::resize_", "id": 3426, "rf_id": 2391, "parent": 3425, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[3424,57,0,0,8,"cuda:1"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(double)","GenericList[]","None"],
      "outputs": [[3424,3427,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::abs", "id": 3425, "rf_id": 2390, "parent": 3422, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::abs.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[3420,3403,0,1,8,"cuda:1"],[3424,57,0,0,8,"cuda:1"]], "input_shapes": [[],[0]], "input_types": ["Tensor(double)","Tensor(double)"],
      "outputs": [[3424,3427,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::abs", "id": 3422, "rf_id": 2388, "parent": 3421, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::abs(Tensor self) -> Tensor",
      "inputs": [[3420,3403,0,1,8,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [[3424,3427,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::eq", "id": 3428, "rf_id": 2392, "parent": 3421, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::eq.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[3424,3427,0,1,8,"cuda:1"],"inf"], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [[3429,132,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::isinf", "id": 3421, "rf_id": 2387, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::isinf(Tensor self) -> Tensor",
      "inputs": [[3420,3403,0,1,8,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [[3429,132,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::ne", "id": 3431, "rf_id": 2394, "parent": 3430, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ne.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[3420,3403,0,1,8,"cuda:1"],[3420,3403,0,1,8,"cuda:1"]], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Tensor(double)"],
      "outputs": [[3432,3427,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::isnan", "id": 3430, "rf_id": 2393, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::isnan(Tensor self) -> Tensor",
      "inputs": [[3420,3403,0,1,8,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [[3432,3427,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty", "id": 3434, "rf_id": 2396, "parent": 3433, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],11,0,"cuda:1","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[3435,57,0,0,1,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::resize_", "id": 3437, "rf_id": 2398, "parent": 3436, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[3435,57,0,0,1,"cuda:1"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(bool)","GenericList[]","None"],
      "outputs": [[3435,851,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_or", "id": 3436, "rf_id": 2397, "parent": 3433, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_or.out(Tensor self, Tensor other, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[3432,3427,0,1,1,"cuda:1"],[3429,132,0,1,1,"cuda:1"],[3435,57,0,0,1,"cuda:1"]], "input_shapes": [[],[],[0]], "input_types": ["Tensor(bool)","Tensor(bool)","Tensor(bool)"],
      "outputs": [[3435,851,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_or", "id": 3433, "rf_id": 2395, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_or(Tensor self, Tensor other) -> Tensor",
      "inputs": [[3432,3427,0,1,1,"cuda:1"],[3429,132,0,1,1,"cuda:1"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[3435,851,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty", "id": 3438, "rf_id": 2399, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],6,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[3439,3440,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 3443, "rf_id": 2402, "parent": 3442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],6,0,"cuda:1",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[3444,1747,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 3445, "rf_id": 2403, "parent": 3442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3444,1747,0,1,4,"cuda:1"],[3439,3440,0,1,4,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(float)","Bool"],
      "outputs": [[3444,1747,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 3442, "rf_id": 2401, "parent": 3441, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3439,3440,0,1,4,"cpu"],6,"<None>","cuda:1","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(float)","Int","None","Device","None","Bool","None"],
      "outputs": [[3444,1747,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 3441, "rf_id": 2400, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3439,3440,0,1,4,"cpu"],"cuda:1",6,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(float)","Device","Int","Bool","Bool","None"],
      "outputs": [[3444,1747,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::lift_fresh", "id": 3446, "rf_id": 2404, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[3444,1747,0,1,4,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[3444,1747,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "detach_", "id": 3448, "rf_id": 2406, "parent": 3447, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3444,1747,0,1,4,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 3447, "rf_id": 2405, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[3444,1747,0,1,4,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[3444,1747,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul", "id": 3449, "rf_id": 2407, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[3435,851,0,1,1,"cuda:1"],[3444,1747,0,1,4,"cuda:1"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(float)"],
      "outputs": [[3450,423,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 3452, "rf_id": 2409, "parent": 3451, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],11,0,"cuda:1","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[3453,57,0,0,1,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::resize_", "id": 3455, "rf_id": 2411, "parent": 3454, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[3453,57,0,0,1,"cuda:1"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(bool)","GenericList[]","None"],
      "outputs": [[3453,3456,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_not", "id": 3454, "rf_id": 2410, "parent": 3451, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_not.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[3435,851,0,1,1,"cuda:1"],[3453,57,0,0,1,"cuda:1"]], "input_shapes": [[],[0]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[3453,3456,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_not", "id": 3451, "rf_id": 2408, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_not(Tensor self) -> Tensor",
      "inputs": [[3435,851,0,1,1,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [[3453,3456,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::mul", "id": 3457, "rf_id": 2412, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[3453,3456,0,1,1,"cuda:1"],[3420,3403,0,1,8,"cuda:1"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(double)"],
      "outputs": [[3458,3459,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::add", "id": 3460, "rf_id": 2413, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[3450,423,0,1,4,"cuda:1"],[3458,3459,0,1,8,"cuda:1"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(double)","Int"],
      "outputs": [[3461,3456,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3462, "rf_id": 2414, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3140,3126,16028672,256,2,"cuda:1"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3140,3126,16028672,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3465, "rf_id": 2417, "parent": 3464, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[256],[1],7,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3466,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3467, "rf_id": 2418, "parent": 3464, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3466,10,0,256,8,"cuda:1"],[3140,3126,16028672,256,2,"cuda:1"],false], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3466,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3464, "rf_id": 2416, "parent": 3463, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3140,3126,16028672,256,2,"cuda:1"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3466,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3463, "rf_id": 2415, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3140,3126,16028672,256,2,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3466,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3470, "rf_id": 2420, "parent": 3468, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3469,3459,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3408,3459,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3468, "rf_id": 2419, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3466,10,0,256,8,"cuda:1"],2,"<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3469,3459,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3471, "rf_id": 2421, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3147,3126,16028928,256,2,"cuda:1"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3147,3126,16028928,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3474, "rf_id": 2424, "parent": 3473, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[256],[1],7,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3408,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3475, "rf_id": 2425, "parent": 3473, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3408,10,0,256,8,"cuda:1"],[3147,3126,16028928,256,2,"cuda:1"],false], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3408,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3473, "rf_id": 2423, "parent": 3472, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3147,3126,16028928,256,2,"cuda:1"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3408,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3472, "rf_id": 2422, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3147,3126,16028928,256,2,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3408,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3479, "rf_id": 2427, "parent": 3476, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3477,3478,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3480,3478,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3476, "rf_id": 2426, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3408,10,0,256,8,"cuda:1"],2,"<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3477,3478,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3481, "rf_id": 2428, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3163,3126,16029184,768,2,"cuda:1"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[768],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3163,3126,16029184,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3484, "rf_id": 2431, "parent": 3483, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[768],[1],7,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3480,10,0,768,8,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3485, "rf_id": 2432, "parent": 3483, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3480,10,0,768,8,"cuda:1"],[3163,3126,16029184,768,2,"cuda:1"],false], "input_shapes": [[768],[768],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3480,10,0,768,8,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3483, "rf_id": 2430, "parent": 3482, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3163,3126,16029184,768,2,"cuda:1"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[768],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3480,10,0,768,8,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3482, "rf_id": 2429, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3163,3126,16029184,768,2,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[768],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3480,10,0,768,8,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3488, "rf_id": 2434, "parent": 3486, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3487,423,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3489,423,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3486, "rf_id": 2433, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3480,10,0,768,8,"cuda:1"],2,"<None>",false,"<None>"], "input_shapes": [[768],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3487,423,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3490, "rf_id": 2435, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3179,3126,16029952,256,2,"cuda:1"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3179,3126,16029952,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3493, "rf_id": 2438, "parent": 3492, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[256],[1],7,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3489,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3494, "rf_id": 2439, "parent": 3492, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3489,10,0,256,8,"cuda:1"],[3179,3126,16029952,256,2,"cuda:1"],false], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3489,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3492, "rf_id": 2437, "parent": 3491, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3179,3126,16029952,256,2,"cuda:1"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3489,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3491, "rf_id": 2436, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3179,3126,16029952,256,2,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3489,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3497, "rf_id": 2441, "parent": 3495, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3496,3366,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3498,3366,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3495, "rf_id": 2440, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3489,10,0,256,8,"cuda:1"],2,"<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3496,3366,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3499, "rf_id": 2442, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3187,3126,16030208,256,2,"cuda:1"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3187,3126,16030208,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3502, "rf_id": 2445, "parent": 3501, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[256],[1],7,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3498,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3503, "rf_id": 2446, "parent": 3501, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3498,10,0,256,8,"cuda:1"],[3187,3126,16030208,256,2,"cuda:1"],false], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3498,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3501, "rf_id": 2444, "parent": 3500, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3187,3126,16030208,256,2,"cuda:1"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3498,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3500, "rf_id": 2443, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3187,3126,16030208,256,2,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3498,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3506, "rf_id": 2448, "parent": 3504, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3505,818,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3507,818,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3504, "rf_id": 2447, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3498,10,0,256,8,"cuda:1"],2,"<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3505,818,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3508, "rf_id": 2449, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3195,3126,16030464,256,2,"cuda:1"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3195,3126,16030464,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3511, "rf_id": 2452, "parent": 3510, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[256],[1],7,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3507,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3512, "rf_id": 2453, "parent": 3510, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3507,10,0,256,8,"cuda:1"],[3195,3126,16030464,256,2,"cuda:1"],false], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3507,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3510, "rf_id": 2451, "parent": 3509, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3195,3126,16030464,256,2,"cuda:1"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3507,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3509, "rf_id": 2450, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3195,3126,16030464,256,2,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3507,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3515, "rf_id": 2455, "parent": 3513, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3514,3398,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3516,3398,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3513, "rf_id": 2454, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3507,10,0,256,8,"cuda:1"],2,"<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3514,3398,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3517, "rf_id": 2456, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3211,3126,16030720,1024,2,"cuda:1"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[1024],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3211,3126,16030720,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3520, "rf_id": 2459, "parent": 3519, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],7,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3516,5,0,1024,8,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3521, "rf_id": 2460, "parent": 3519, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3516,5,0,1024,8,"cuda:1"],[3211,3126,16030720,1024,2,"cuda:1"],false], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3516,5,0,1024,8,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3519, "rf_id": 2458, "parent": 3518, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3211,3126,16030720,1024,2,"cuda:1"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[1024],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3516,5,0,1024,8,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3518, "rf_id": 2457, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3211,3126,16030720,1024,2,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3516,5,0,1024,8,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3525, "rf_id": 2462, "parent": 3522, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3523,3524,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3526,3524,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3522, "rf_id": 2461, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3516,5,0,1024,8,"cuda:1"],2,"<None>",false,"<None>"], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3523,3524,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3527, "rf_id": 2463, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3227,3126,16031744,256,2,"cuda:1"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3227,3126,16031744,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3530, "rf_id": 2466, "parent": 3529, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[256],[1],7,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3526,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3531, "rf_id": 2467, "parent": 3529, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3526,10,0,256,8,"cuda:1"],[3227,3126,16031744,256,2,"cuda:1"],false], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3526,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3529, "rf_id": 2465, "parent": 3528, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3227,3126,16031744,256,2,"cuda:1"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3526,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3528, "rf_id": 2464, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3227,3126,16031744,256,2,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3526,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3534, "rf_id": 2469, "parent": 3532, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3533,227,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3535,227,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3532, "rf_id": 2468, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3526,10,0,256,8,"cuda:1"],2,"<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3533,227,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3536, "rf_id": 2470, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3235,3126,16032000,256,2,"cuda:1"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3235,3126,16032000,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3539, "rf_id": 2473, "parent": 3538, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[256],[1],7,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3535,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3540, "rf_id": 2474, "parent": 3538, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3535,10,0,256,8,"cuda:1"],[3235,3126,16032000,256,2,"cuda:1"],false], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3535,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3538, "rf_id": 2472, "parent": 3537, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3235,3126,16032000,256,2,"cuda:1"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3535,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3537, "rf_id": 2471, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3235,3126,16032000,256,2,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3535,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3543, "rf_id": 2476, "parent": 3541, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3542,3403,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3544,3403,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3541, "rf_id": 2475, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3535,10,0,256,8,"cuda:1"],2,"<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3542,3403,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3545, "rf_id": 2477, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3243,3126,16032256,256,2,"cuda:1"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3243,3126,16032256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3548, "rf_id": 2480, "parent": 3547, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[256],[1],7,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3544,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3549, "rf_id": 2481, "parent": 3547, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3544,10,0,256,8,"cuda:1"],[3243,3126,16032256,256,2,"cuda:1"],false], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3544,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3547, "rf_id": 2479, "parent": 3546, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3243,3126,16032256,256,2,"cuda:1"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3544,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3546, "rf_id": 2478, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3243,3126,16032256,256,2,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3544,10,0,256,8,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3552, "rf_id": 2483, "parent": 3550, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3551,3427,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3553,3427,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3550, "rf_id": 2482, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3544,10,0,256,8,"cuda:1"],2,"<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3551,3427,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3556, "rf_id": 2486, "parent": 3555, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3469,3459,0,1,8,"cuda:1"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3553,3459,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3555, "rf_id": 2485, "parent": 3554, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3469,3459,0,1,8,"cuda:1"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3553,3459,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3558, "rf_id": 2488, "parent": 3557, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3477,3478,0,1,8,"cuda:1"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3559,3478,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3557, "rf_id": 2487, "parent": 3554, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3477,3478,0,1,8,"cuda:1"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3559,3478,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3561, "rf_id": 2490, "parent": 3560, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3487,423,0,1,8,"cuda:1"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3562,423,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3560, "rf_id": 2489, "parent": 3554, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3487,423,0,1,8,"cuda:1"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3562,423,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3564, "rf_id": 2492, "parent": 3563, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3496,3366,0,1,8,"cuda:1"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3565,3366,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3563, "rf_id": 2491, "parent": 3554, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3496,3366,0,1,8,"cuda:1"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3565,3366,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3567, "rf_id": 2494, "parent": 3566, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3505,818,0,1,8,"cuda:1"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3568,818,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3566, "rf_id": 2493, "parent": 3554, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3505,818,0,1,8,"cuda:1"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3568,818,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3570, "rf_id": 2496, "parent": 3569, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3514,3398,0,1,8,"cuda:1"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3571,3398,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3569, "rf_id": 2495, "parent": 3554, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3514,3398,0,1,8,"cuda:1"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3571,3398,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3573, "rf_id": 2498, "parent": 3572, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3523,3524,0,1,8,"cuda:1"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3574,3524,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3572, "rf_id": 2497, "parent": 3554, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3523,3524,0,1,8,"cuda:1"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3574,3524,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3576, "rf_id": 2500, "parent": 3575, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3533,227,0,1,8,"cuda:1"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3577,227,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3575, "rf_id": 2499, "parent": 3554, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3533,227,0,1,8,"cuda:1"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3577,227,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3579, "rf_id": 2502, "parent": 3578, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3542,3403,0,1,8,"cuda:1"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3580,3403,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3578, "rf_id": 2501, "parent": 3554, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3542,3403,0,1,8,"cuda:1"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3580,3403,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3582, "rf_id": 2504, "parent": 3581, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3551,3427,0,1,8,"cuda:1"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3583,3427,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3581, "rf_id": 2503, "parent": 3554, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3551,3427,0,1,8,"cuda:1"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3583,3427,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::cat", "id": 3584, "rf_id": 2505, "parent": 3554, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[3553,3459,0,1,8,"cuda:1"],[3559,3478,0,1,8,"cuda:1"],[3562,423,0,1,8,"cuda:1"],[3565,3366,0,1,8,"cuda:1"],[3568,818,0,1,8,"cuda:1"],[3571,3398,0,1,8,"cuda:1"],[3574,3524,0,1,8,"cuda:1"],[3577,227,0,1,8,"cuda:1"],[3580,3403,0,1,8,"cuda:1"],[3583,3427,0,1,8,"cuda:1"]],0], "input_shapes": [[[1],[1],[1],[1],[1],[1],[1],[1],[1],[1]],[]], "input_types": ["GenericList[Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double)]","Int"],
      "outputs": [[3585,132,0,10,8,"cuda:1"]], "output_shapes": [[10]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::stack", "id": 3554, "rf_id": 2484, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::stack(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[3469,3459,0,1,8,"cuda:1"],[3477,3478,0,1,8,"cuda:1"],[3487,423,0,1,8,"cuda:1"],[3496,3366,0,1,8,"cuda:1"],[3505,818,0,1,8,"cuda:1"],[3514,3398,0,1,8,"cuda:1"],[3523,3524,0,1,8,"cuda:1"],[3533,227,0,1,8,"cuda:1"],[3542,3403,0,1,8,"cuda:1"],[3551,3427,0,1,8,"cuda:1"]],0], "input_shapes": [[[],[],[],[],[],[],[],[],[],[]],[]], "input_types": ["GenericList[Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double)]","Int"],
      "outputs": [[3585,132,0,10,8,"cuda:1"]], "output_shapes": [[10]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::result_type", "id": 3587, "rf_id": 2507, "parent": 3586, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::result_type.Scalar(Tensor tensor, Scalar other) -> ScalarType",
      "inputs": [[3585,132,0,10,8,"cuda:1"],2], "input_shapes": [[10],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [7], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::to", "id": 3588, "rf_id": 2508, "parent": 3586, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3585,132,0,10,8,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[10],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[3585,132,0,10,8,"cuda:1"]], "output_shapes": [[10]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::pow", "id": 3586, "rf_id": 2506, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -> Tensor",
      "inputs": [[3585,132,0,10,8,"cuda:1"],2], "input_shapes": [[10],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3589,851,0,10,8,"cuda:1"]], "output_shapes": [[10]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3593, "rf_id": 2511, "parent": 3591, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3592,132,0,1,8,"cuda:1"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3594,132,0,1,8,"cuda:1"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::sum", "id": 3591, "rf_id": 2510, "parent": 3590, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3589,851,0,10,8,"cuda:1"],[],false,"<None>"], "input_shapes": [[10],[],[],[]], "input_types": ["Tensor(double)","GenericList[]","Bool","None"],
      "outputs": [[3592,132,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::sum", "id": 3590, "rf_id": 2509, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum(Tensor self, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3589,851,0,10,8,"cuda:1"],"<None>"], "input_shapes": [[10],[]], "input_types": ["Tensor(double)","None"],
      "outputs": [[3592,132,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "nccl:all_reduce", "id": 3597, "rf_id": 2514, "parent": 3596, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3592,132,0,1,8,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3596, "rf_id": 2513, "parent": 3595, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[3592,132,0,1,8,"cuda:1"]],130,94716817711568,1,"allreduce",[],[],4], "input_shapes": [[[]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(double)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[3592,132,0,1,8,"cuda:1"]]], "output_shapes": [[[]]], "output_types": ["GenericList[Tensor(double)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 3595, "rf_id": 2512, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[3592,132,0,1,8,"cuda:1"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[]],[],[],[],[]], "input_types": ["GenericList[Tensor(double)]","Object","Object","None","Int"],
      "outputs": [[[3592,132,0,1,8,"cuda:1"]],"<Object>"], "output_shapes": [[[]],[]], "output_types": ["GenericList[Tensor(double)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 3598, "rf_id": 2515, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [130,0,1,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "nccl:all_reduce", "id": 3601, "rf_id": 2518, "parent": 3600, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3592,132,0,1,8,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3600, "rf_id": 2517, "parent": 3599, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[3592,132,0,1,8,"cuda:1"]],8,94716817299440,0,"allreduce",[],[],1], "input_shapes": [[[]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(double)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[3592,132,0,1,8,"cuda:1"]]], "output_shapes": [[[]]], "output_types": ["GenericList[Tensor(double)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 3599, "rf_id": 2516, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[3592,132,0,1,8,"cuda:1"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[]],[],[],[],[]], "input_types": ["GenericList[Tensor(double)]","Object","Object","None","Int"],
      "outputs": [[[3592,132,0,1,8,"cuda:1"]],"<Object>"], "output_shapes": [[[]],[]], "output_types": ["GenericList[Tensor(double)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 3602, "rf_id": 2519, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [8,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::result_type", "id": 3604, "rf_id": 2521, "parent": 3603, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::result_type.Scalar(Tensor tensor, Scalar other) -> ScalarType",
      "inputs": [[3592,132,0,1,8,"cuda:1"],0.500000], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [7], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::to", "id": 3605, "rf_id": 2522, "parent": 3603, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3592,132,0,1,8,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[3592,132,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::pow", "id": 3603, "rf_id": 2520, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -> Tensor",
      "inputs": [[3592,132,0,1,8,"cuda:1"],0.500000], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [[3606,851,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::empty", "id": 3609, "rf_id": 2525, "parent": 3608, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],7,0,"cuda:1","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[3610,57,0,0,8,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::resize_", "id": 3612, "rf_id": 2527, "parent": 3611, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[3610,57,0,0,8,"cuda:1"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(double)","GenericList[]","None"],
      "outputs": [[3610,1747,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::abs", "id": 3611, "rf_id": 2526, "parent": 3608, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::abs.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[3606,851,0,1,8,"cuda:1"],[3610,57,0,0,8,"cuda:1"]], "input_shapes": [[],[0]], "input_types": ["Tensor(double)","Tensor(double)"],
      "outputs": [[3610,1747,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::abs", "id": 3608, "rf_id": 2524, "parent": 3607, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::abs(Tensor self) -> Tensor",
      "inputs": [[3606,851,0,1,8,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [[3610,1747,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::eq", "id": 3613, "rf_id": 2528, "parent": 3607, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::eq.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[3610,1747,0,1,8,"cuda:1"],"inf"], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [[3614,10,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::isinf", "id": 3607, "rf_id": 2523, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::isinf(Tensor self) -> Tensor",
      "inputs": [[3606,851,0,1,8,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [[3614,10,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::ne", "id": 3616, "rf_id": 2530, "parent": 3615, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ne.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[3606,851,0,1,8,"cuda:1"],[3606,851,0,1,8,"cuda:1"]], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Tensor(double)"],
      "outputs": [[3617,1747,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::isnan", "id": 3615, "rf_id": 2529, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::isnan(Tensor self) -> Tensor",
      "inputs": [[3606,851,0,1,8,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [[3617,1747,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty", "id": 3619, "rf_id": 2532, "parent": 3618, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],11,0,"cuda:1","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[3620,57,0,0,1,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::resize_", "id": 3622, "rf_id": 2534, "parent": 3621, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[3620,57,0,0,1,"cuda:1"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(bool)","GenericList[]","None"],
      "outputs": [[3620,425,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_or", "id": 3621, "rf_id": 2533, "parent": 3618, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_or.out(Tensor self, Tensor other, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[3617,1747,0,1,1,"cuda:1"],[3614,10,0,1,1,"cuda:1"],[3620,57,0,0,1,"cuda:1"]], "input_shapes": [[],[],[0]], "input_types": ["Tensor(bool)","Tensor(bool)","Tensor(bool)"],
      "outputs": [[3620,425,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_or", "id": 3618, "rf_id": 2531, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_or(Tensor self, Tensor other) -> Tensor",
      "inputs": [[3617,1747,0,1,1,"cuda:1"],[3614,10,0,1,1,"cuda:1"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[3620,425,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty", "id": 3623, "rf_id": 2535, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],6,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[3624,3625,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 3628, "rf_id": 2538, "parent": 3627, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],6,0,"cuda:1",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[3629,3346,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 3630, "rf_id": 2539, "parent": 3627, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3629,3346,0,1,4,"cuda:1"],[3624,3625,0,1,4,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(float)","Bool"],
      "outputs": [[3629,3346,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 3627, "rf_id": 2537, "parent": 3626, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3624,3625,0,1,4,"cpu"],6,"<None>","cuda:1","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(float)","Int","None","Device","None","Bool","None"],
      "outputs": [[3629,3346,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 3626, "rf_id": 2536, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3624,3625,0,1,4,"cpu"],"cuda:1",6,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(float)","Device","Int","Bool","Bool","None"],
      "outputs": [[3629,3346,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::lift_fresh", "id": 3631, "rf_id": 2540, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[3629,3346,0,1,4,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[3629,3346,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "detach_", "id": 3633, "rf_id": 2542, "parent": 3632, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3629,3346,0,1,4,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 3632, "rf_id": 2541, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[3629,3346,0,1,4,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[3629,3346,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul", "id": 3634, "rf_id": 2543, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[3620,425,0,1,1,"cuda:1"],[3629,3346,0,1,4,"cuda:1"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(float)"],
      "outputs": [[3635,3356,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 3637, "rf_id": 2545, "parent": 3636, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],11,0,"cuda:1","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[3638,57,0,0,1,"cuda:1"]], "output_shapes": [[0]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::resize_", "id": 3640, "rf_id": 2547, "parent": 3639, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[3638,57,0,0,1,"cuda:1"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(bool)","GenericList[]","None"],
      "outputs": [[3638,5,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_not", "id": 3639, "rf_id": 2546, "parent": 3636, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_not.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[3620,425,0,1,1,"cuda:1"],[3638,57,0,0,1,"cuda:1"]], "input_shapes": [[],[0]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[3638,5,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_not", "id": 3636, "rf_id": 2544, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_not(Tensor self) -> Tensor",
      "inputs": [[3620,425,0,1,1,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [[3638,5,0,1,1,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::mul", "id": 3641, "rf_id": 2548, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[3638,5,0,1,1,"cuda:1"],[3606,851,0,1,8,"cuda:1"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(double)"],
      "outputs": [[3642,565,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::add", "id": 3643, "rf_id": 2549, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[3635,3356,0,1,4,"cuda:1"],[3642,565,0,1,8,"cuda:1"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(double)","Int"],
      "outputs": [[3644,5,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::result_type", "id": 3646, "rf_id": 2551, "parent": 3645, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::result_type.Scalar(Tensor tensor, Scalar other) -> ScalarType",
      "inputs": [[3461,3456,0,1,8,"cuda:1"],2.000000], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [7], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::to", "id": 3647, "rf_id": 2552, "parent": 3645, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3461,3456,0,1,8,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[3461,3456,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::pow", "id": 3645, "rf_id": 2550, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -> Tensor",
      "inputs": [[3461,3456,0,1,8,"cuda:1"],2.000000], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [[3648,3459,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::add", "id": 3650, "rf_id": 2553, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[3648,3459,0,1,8,"cuda:1"],[3594,3649,0,1,8,"cpu"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(double)","Tensor(double)","Int"],
      "outputs": [[3651,3478,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::result_type", "id": 3653, "rf_id": 2555, "parent": 3652, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::result_type.Scalar(Tensor tensor, Scalar other) -> ScalarType",
      "inputs": [[3644,5,0,1,8,"cuda:1"],2.000000], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [7], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::to", "id": 3654, "rf_id": 2556, "parent": 3652, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3644,5,0,1,8,"cuda:1"],7,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[3644,5,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::pow", "id": 3652, "rf_id": 2554, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -> Tensor",
      "inputs": [[3644,5,0,1,8,"cuda:1"],2.000000], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [[3655,3459,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::add_", "id": 3656, "rf_id": 2557, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)",
      "inputs": [[3651,3478,0,1,8,"cuda:1"],[3655,3459,0,1,8,"cuda:1"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(double)","Tensor(double)","Int"],
      "outputs": [[3651,3478,0,1,8,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 3658, "rf_id": 2559, "parent": 3657, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[3651,3478,0,1,8,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [22.060853], "output_shapes": [[]], "output_types": ["Double"]
    },
    {
      "name": "aten::item", "id": 3657, "rf_id": 2558, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[3651,3478,0,1,8,"cuda:1"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [22.060853], "output_shapes": [[]], "output_types": ["Double"]
    },
    {
      "name": "aten::view", "id": 3660, "rf_id": 2561, "parent": 3659, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3125,3126,0,12877824,2,"cuda:1"],[-1]], "input_shapes": [[12877824],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3661,3126,0,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3662, "rf_id": 2562, "parent": 3659, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3133,3126,12877824,5120,2,"cuda:1"],[-1]], "input_shapes": [[5120],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3663,3126,12877824,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3664, "rf_id": 2563, "parent": 3659, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3155,3126,12882944,786432,2,"cuda:1"],[-1]], "input_shapes": [[786432],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3665,3126,12882944,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3666, "rf_id": 2564, "parent": 3659, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3171,3126,13669376,262144,2,"cuda:1"],[-1]], "input_shapes": [[262144],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3667,3126,13669376,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3668, "rf_id": 2565, "parent": 3659, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3203,3126,13931520,1048576,2,"cuda:1"],[-1]], "input_shapes": [[1048576],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3669,3126,13931520,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3670, "rf_id": 2566, "parent": 3659, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3219,3126,14980096,1048576,2,"cuda:1"],[-1]], "input_shapes": [[1048576],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3671,3126,14980096,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 3672, "rf_id": 2567, "parent": 3659, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[3661,3126,0,12877824,2,"cuda:1"],[3663,3126,12877824,5120,2,"cuda:1"],[3665,3126,12882944,786432,2,"cuda:1"],[3667,3126,13669376,262144,2,"cuda:1"],[3669,3126,13931520,1048576,2,"cuda:1"],[3671,3126,14980096,1048576,2,"cuda:1"]],0], "input_shapes": [[[12877824],[5120],[786432],[262144],[1048576],[1048576]],[]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int"],
      "outputs": [[3673,1058,0,16028672,2,"cuda:1"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::flatten_dense_tensors", "id": 3659, "rf_id": 2560, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::flatten_dense_tensors(Tensor[] tensors) -> Tensor",
      "inputs": [[[3125,3126,0,12877824,2,"cuda:1"],[3133,3126,12877824,5120,2,"cuda:1"],[3155,3126,12882944,786432,2,"cuda:1"],[3171,3126,13669376,262144,2,"cuda:1"],[3203,3126,13931520,1048576,2,"cuda:1"],[3219,3126,14980096,1048576,2,"cuda:1"]]], "input_shapes": [[[12877824],[5120],[786432],[262144],[1048576],[1048576]]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"],
      "outputs": [[3673,1058,0,16028672,2,"cuda:1"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3676, "rf_id": 2570, "parent": 3675, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[16028672],[1],6,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3677,1078,0,16028672,4,"cuda:1"]], "output_shapes": [[16028672]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 3678, "rf_id": 2571, "parent": 3675, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3677,1078,0,16028672,4,"cuda:1"],[3673,1058,0,16028672,2,"cuda:1"],false], "input_shapes": [[16028672],[16028672],[]], "input_types": ["Tensor(float)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3677,1078,0,16028672,4,"cuda:1"]], "output_shapes": [[16028672]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 3675, "rf_id": 2569, "parent": 3674, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3673,1058,0,16028672,2,"cuda:1"],6,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[16028672],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3677,1078,0,16028672,4,"cuda:1"]], "output_shapes": [[16028672]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 3674, "rf_id": 2568, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3673,1058,0,16028672,2,"cuda:1"],6,false,false,"<None>"], "input_shapes": [[16028672],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3677,1078,0,16028672,4,"cuda:1"]], "output_shapes": [[16028672]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::record_stream", "id": 3679, "rf_id": 2572, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3125,3126,0,12877824,2,"cuda:1"],"<Stream>"], "input_shapes": [[12877824],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3680, "rf_id": 2573, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3133,3126,12877824,5120,2,"cuda:1"],"<Stream>"], "input_shapes": [[5120],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3681, "rf_id": 2574, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3155,3126,12882944,786432,2,"cuda:1"],"<Stream>"], "input_shapes": [[786432],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3682, "rf_id": 2575, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3171,3126,13669376,262144,2,"cuda:1"],"<Stream>"], "input_shapes": [[262144],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3683, "rf_id": 2576, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3203,3126,13931520,1048576,2,"cuda:1"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3684, "rf_id": 2577, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3219,3126,14980096,1048576,2,"cuda:1"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::mul_", "id": 3687, "rf_id": 2578, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[3677,1078,0,16028672,4,"cuda:1"],[3685,3686,0,1,8,"cpu"]], "input_shapes": [[16028672],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[3677,1078,0,16028672,4,"cuda:1"]], "output_shapes": [[16028672]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "Optimizer.step#FusedAdam.step", "id": 3688, "rf_id": 2579, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::copy_", "id": 3692, "rf_id": 2580, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3689,239,0,16028672,2,"cuda:1"],[3690,3691,0,16028672,4,"cuda:1"],false], "input_shapes": [[16028672],[16028672],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(float)","Bool"],
      "outputs": [[3689,239,0,16028672,2,"cuda:1"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3698, "rf_id": 2584, "parent": 3697, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],[12877824],[1],0], "input_shapes": [[16028672],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3699,239,0,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3697, "rf_id": 2583, "parent": 3696, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],0,0,12877824,1], "input_shapes": [[16028672],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3699,239,0,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3696, "rf_id": 2582, "parent": 3695, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],0,0,12877824], "input_shapes": [[16028672],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3699,239,0,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3700, "rf_id": 2585, "parent": 3695, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3699,239,0,12877824,2,"cuda:1"],[12877824]], "input_shapes": [[12877824],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3701,239,0,12877824,2,"cuda:1"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3704, "rf_id": 2588, "parent": 3703, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],[5120],[1],12877824], "input_shapes": [[16028672],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3705,239,12877824,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3703, "rf_id": 2587, "parent": 3702, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],0,12877824,12882944,1], "input_shapes": [[16028672],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3705,239,12877824,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3702, "rf_id": 2586, "parent": 3695, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],0,12877824,5120], "input_shapes": [[16028672],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3705,239,12877824,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3706, "rf_id": 2589, "parent": 3695, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3705,239,12877824,5120,2,"cuda:1"],[5120]], "input_shapes": [[5120],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3707,239,12877824,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3710, "rf_id": 2592, "parent": 3709, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],[786432],[1],12882944], "input_shapes": [[16028672],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3711,239,12882944,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3709, "rf_id": 2591, "parent": 3708, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],0,12882944,13669376,1], "input_shapes": [[16028672],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3711,239,12882944,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3708, "rf_id": 2590, "parent": 3695, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],0,12882944,786432], "input_shapes": [[16028672],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3711,239,12882944,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3712, "rf_id": 2593, "parent": 3695, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3711,239,12882944,786432,2,"cuda:1"],[786432]], "input_shapes": [[786432],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3713,239,12882944,786432,2,"cuda:1"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3716, "rf_id": 2596, "parent": 3715, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],[262144],[1],13669376], "input_shapes": [[16028672],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3717,239,13669376,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3715, "rf_id": 2595, "parent": 3714, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],0,13669376,13931520,1], "input_shapes": [[16028672],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3717,239,13669376,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3714, "rf_id": 2594, "parent": 3695, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],0,13669376,262144], "input_shapes": [[16028672],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3717,239,13669376,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3718, "rf_id": 2597, "parent": 3695, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3717,239,13669376,262144,2,"cuda:1"],[262144]], "input_shapes": [[262144],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3719,239,13669376,262144,2,"cuda:1"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3722, "rf_id": 2600, "parent": 3721, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],[1048576],[1],13931520], "input_shapes": [[16028672],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3723,239,13931520,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3721, "rf_id": 2599, "parent": 3720, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],0,13931520,14980096,1], "input_shapes": [[16028672],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3723,239,13931520,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3720, "rf_id": 2598, "parent": 3695, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],0,13931520,1048576], "input_shapes": [[16028672],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3723,239,13931520,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3724, "rf_id": 2601, "parent": 3695, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3723,239,13931520,1048576,2,"cuda:1"],[1048576]], "input_shapes": [[1048576],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3725,239,13931520,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3728, "rf_id": 2604, "parent": 3727, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],[1048576],[1],14980096], "input_shapes": [[16028672],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3729,239,14980096,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3727, "rf_id": 2603, "parent": 3726, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],0,14980096,16028672,1], "input_shapes": [[16028672],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3729,239,14980096,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3726, "rf_id": 2602, "parent": 3695, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],0,14980096,1048576], "input_shapes": [[16028672],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3729,239,14980096,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3730, "rf_id": 2605, "parent": 3695, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3729,239,14980096,1048576,2,"cuda:1"],[1048576]], "input_shapes": [[1048576],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3731,239,14980096,1048576,2,"cuda:1"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::unflatten_dense_tensors", "id": 3695, "rf_id": 2581, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unflatten_dense_tensors(Tensor flat, Tensor[] tensors) -> Tensor[]",
      "inputs": [[3693,239,0,16028672,2,"cuda:1"],[[238,239,0,12877824,2,"cuda:1"],[3694,239,12877824,5120,2,"cuda:1"],[273,239,12882944,786432,2,"cuda:1"],[275,239,13669376,262144,2,"cuda:1"],[277,239,13931520,1048576,2,"cuda:1"],[279,239,14980096,1048576,2,"cuda:1"]]], "input_shapes": [[16028672],[[12877824],[5120],[786432],[262144],[1048576],[1048576]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"],
      "outputs": [[[3701,239,0,12877824,2,"cuda:1"],[3707,239,12877824,5120,2,"cuda:1"],[3713,239,12882944,786432,2,"cuda:1"],[3719,239,13669376,262144,2,"cuda:1"],[3725,239,13931520,1048576,2,"cuda:1"],[3731,239,14980096,1048576,2,"cuda:1"]]], "output_shapes": [[[12877824],[5120],[786432],[262144],[1048576],[1048576]]], "output_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3733, "rf_id": 2606, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[238,239,0,12877824,2,"cuda:1"],[3732,239,0,12877824,2,"cuda:1"]], "input_shapes": [[12877824],[12877824]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3735, "rf_id": 2607, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3694,239,12877824,5120,2,"cuda:1"],[3734,239,12877824,5120,2,"cuda:1"]], "input_shapes": [[5120],[5120]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3737, "rf_id": 2608, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[273,239,12882944,786432,2,"cuda:1"],[3736,239,12882944,786432,2,"cuda:1"]], "input_shapes": [[786432],[786432]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3739, "rf_id": 2609, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[275,239,13669376,262144,2,"cuda:1"],[3738,239,13669376,262144,2,"cuda:1"]], "input_shapes": [[262144],[262144]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3741, "rf_id": 2610, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[277,239,13931520,1048576,2,"cuda:1"],[3740,239,13931520,1048576,2,"cuda:1"]], "input_shapes": [[1048576],[1048576]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3743, "rf_id": 2611, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[279,239,14980096,1048576,2,"cuda:1"],[3742,239,14980096,1048576,2,"cuda:1"]], "input_shapes": [[1048576],[1048576]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::view", "id": 3745, "rf_id": 2613, "parent": 3744, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3140,3126,16028672,256,2,"cuda:1"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3731,3126,16028672,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3746, "rf_id": 2614, "parent": 3744, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3147,3126,16028928,256,2,"cuda:1"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3701,3126,16028928,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3747, "rf_id": 2615, "parent": 3744, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3163,3126,16029184,768,2,"cuda:1"],[-1]], "input_shapes": [[768],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3707,3126,16029184,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3748, "rf_id": 2616, "parent": 3744, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3179,3126,16029952,256,2,"cuda:1"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3713,3126,16029952,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3749, "rf_id": 2617, "parent": 3744, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3187,3126,16030208,256,2,"cuda:1"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3719,3126,16030208,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3750, "rf_id": 2618, "parent": 3744, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3195,3126,16030464,256,2,"cuda:1"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3725,3126,16030464,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3751, "rf_id": 2619, "parent": 3744, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3211,3126,16030720,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3752,3126,16030720,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3753, "rf_id": 2620, "parent": 3744, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3227,3126,16031744,256,2,"cuda:1"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3754,3126,16031744,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3755, "rf_id": 2621, "parent": 3744, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3235,3126,16032000,256,2,"cuda:1"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3756,3126,16032000,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3757, "rf_id": 2622, "parent": 3744, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3243,3126,16032256,256,2,"cuda:1"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3758,3126,16032256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 3759, "rf_id": 2623, "parent": 3744, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[3731,3126,16028672,256,2,"cuda:1"],[3701,3126,16028928,256,2,"cuda:1"],[3707,3126,16029184,768,2,"cuda:1"],[3713,3126,16029952,256,2,"cuda:1"],[3719,3126,16030208,256,2,"cuda:1"],[3725,3126,16030464,256,2,"cuda:1"],[3752,3126,16030720,1024,2,"cuda:1"],[3754,3126,16031744,256,2,"cuda:1"],[3756,3126,16032000,256,2,"cuda:1"],[3758,3126,16032256,256,2,"cuda:1"]],0], "input_shapes": [[[256],[256],[768],[256],[256],[256],[1024],[256],[256],[256]],[]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int"],
      "outputs": [[3760,565,0,3840,2,"cuda:1"]], "output_shapes": [[3840]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::flatten_dense_tensors", "id": 3744, "rf_id": 2612, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::flatten_dense_tensors(Tensor[] tensors) -> Tensor",
      "inputs": [[[3140,3126,16028672,256,2,"cuda:1"],[3147,3126,16028928,256,2,"cuda:1"],[3163,3126,16029184,768,2,"cuda:1"],[3179,3126,16029952,256,2,"cuda:1"],[3187,3126,16030208,256,2,"cuda:1"],[3195,3126,16030464,256,2,"cuda:1"],[3211,3126,16030720,1024,2,"cuda:1"],[3227,3126,16031744,256,2,"cuda:1"],[3235,3126,16032000,256,2,"cuda:1"],[3243,3126,16032256,256,2,"cuda:1"]]], "input_shapes": [[[256],[256],[768],[256],[256],[256],[1024],[256],[256],[256]]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"],
      "outputs": [[3760,565,0,3840,2,"cuda:1"]], "output_shapes": [[3840]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3763, "rf_id": 2626, "parent": 3762, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[3840],[1],6,0,"cuda:1",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3764,820,0,3840,4,"cuda:1"]], "output_shapes": [[3840]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 3765, "rf_id": 2627, "parent": 3762, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3764,820,0,3840,4,"cuda:1"],[3760,565,0,3840,2,"cuda:1"],false], "input_shapes": [[3840],[3840],[]], "input_types": ["Tensor(float)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3764,820,0,3840,4,"cuda:1"]], "output_shapes": [[3840]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 3762, "rf_id": 2625, "parent": 3761, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3760,565,0,3840,2,"cuda:1"],6,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[3840],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3764,820,0,3840,4,"cuda:1"]], "output_shapes": [[3840]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 3761, "rf_id": 2624, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3760,565,0,3840,2,"cuda:1"],6,false,false,"<None>"], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3764,820,0,3840,4,"cuda:1"]], "output_shapes": [[3840]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::record_stream", "id": 3766, "rf_id": 2628, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3140,3126,16028672,256,2,"cuda:1"],"<Stream>"], "input_shapes": [[256],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3767, "rf_id": 2629, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3147,3126,16028928,256,2,"cuda:1"],"<Stream>"], "input_shapes": [[256],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3768, "rf_id": 2630, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3163,3126,16029184,768,2,"cuda:1"],"<Stream>"], "input_shapes": [[768],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3769, "rf_id": 2631, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3179,3126,16029952,256,2,"cuda:1"],"<Stream>"], "input_shapes": [[256],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3770, "rf_id": 2632, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3187,3126,16030208,256,2,"cuda:1"],"<Stream>"], "input_shapes": [[256],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3771, "rf_id": 2633, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3195,3126,16030464,256,2,"cuda:1"],"<Stream>"], "input_shapes": [[256],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3772, "rf_id": 2634, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3211,3126,16030720,1024,2,"cuda:1"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3773, "rf_id": 2635, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3227,3126,16031744,256,2,"cuda:1"],"<Stream>"], "input_shapes": [[256],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3774, "rf_id": 2636, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3235,3126,16032000,256,2,"cuda:1"],"<Stream>"], "input_shapes": [[256],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3775, "rf_id": 2637, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3243,3126,16032256,256,2,"cuda:1"],"<Stream>"], "input_shapes": [[256],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::mul_", "id": 3778, "rf_id": 2638, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[3764,820,0,3840,4,"cuda:1"],[3776,3777,0,1,8,"cpu"]], "input_shapes": [[3840],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[3764,820,0,3840,4,"cuda:1"]], "output_shapes": [[3840]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "Optimizer.step#FusedAdam.step", "id": 3779, "rf_id": 2639, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::copy_", "id": 3783, "rf_id": 2640, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3780,239,16028672,3840,2,"cuda:1"],[3781,3782,0,3840,4,"cuda:1"],false], "input_shapes": [[3840],[3840],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(float)","Bool"],
      "outputs": [[3780,239,16028672,3840,2,"cuda:1"]], "output_shapes": [[3840]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3798, "rf_id": 2644, "parent": 3797, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],[256],[1],16028672], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3799,239,16028672,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3797, "rf_id": 2643, "parent": 3796, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,0,256,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3799,239,16028672,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3796, "rf_id": 2642, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,0,256], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3799,239,16028672,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3800, "rf_id": 2645, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3799,239,16028672,256,2,"cuda:1"],[256]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3801,239,16028672,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3804, "rf_id": 2648, "parent": 3803, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],[256],[1],16028928], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3805,239,16028928,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3803, "rf_id": 2647, "parent": 3802, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,256,512,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3805,239,16028928,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3802, "rf_id": 2646, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,256,256], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3805,239,16028928,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3806, "rf_id": 2649, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3805,239,16028928,256,2,"cuda:1"],[256]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3807,239,16028928,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3810, "rf_id": 2652, "parent": 3809, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],[768],[1],16029184], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3811,239,16029184,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3809, "rf_id": 2651, "parent": 3808, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,512,1280,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3811,239,16029184,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3808, "rf_id": 2650, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,512,768], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3811,239,16029184,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3812, "rf_id": 2653, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3811,239,16029184,768,2,"cuda:1"],[768]], "input_shapes": [[768],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3813,239,16029184,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3816, "rf_id": 2656, "parent": 3815, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],[256],[1],16029952], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3817,239,16029952,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3815, "rf_id": 2655, "parent": 3814, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,1280,1536,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3817,239,16029952,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3814, "rf_id": 2654, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,1280,256], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3817,239,16029952,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3818, "rf_id": 2657, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3817,239,16029952,256,2,"cuda:1"],[256]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3819,239,16029952,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3822, "rf_id": 2660, "parent": 3821, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],[256],[1],16030208], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3823,239,16030208,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3821, "rf_id": 2659, "parent": 3820, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,1536,1792,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3823,239,16030208,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3820, "rf_id": 2658, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,1536,256], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3823,239,16030208,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3824, "rf_id": 2661, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3823,239,16030208,256,2,"cuda:1"],[256]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3825,239,16030208,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3828, "rf_id": 2664, "parent": 3827, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],[256],[1],16030464], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3829,239,16030464,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3827, "rf_id": 2663, "parent": 3826, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,1792,2048,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3829,239,16030464,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3826, "rf_id": 2662, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,1792,256], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3829,239,16030464,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3830, "rf_id": 2665, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3829,239,16030464,256,2,"cuda:1"],[256]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3831,239,16030464,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3834, "rf_id": 2668, "parent": 3833, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],[1024],[1],16030720], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3835,239,16030720,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3833, "rf_id": 2667, "parent": 3832, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,2048,3072,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3835,239,16030720,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3832, "rf_id": 2666, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,2048,1024], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3835,239,16030720,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3836, "rf_id": 2669, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3835,239,16030720,1024,2,"cuda:1"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3837,239,16030720,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3840, "rf_id": 2672, "parent": 3839, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],[256],[1],16031744], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3841,239,16031744,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3839, "rf_id": 2671, "parent": 3838, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,3072,3328,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3841,239,16031744,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3838, "rf_id": 2670, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,3072,256], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3841,239,16031744,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3842, "rf_id": 2673, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3841,239,16031744,256,2,"cuda:1"],[256]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3843,239,16031744,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3846, "rf_id": 2676, "parent": 3845, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],[256],[1],16032000], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3847,239,16032000,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3845, "rf_id": 2675, "parent": 3844, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,3328,3584,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3847,239,16032000,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3844, "rf_id": 2674, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,3328,256], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3847,239,16032000,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3848, "rf_id": 2677, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3847,239,16032000,256,2,"cuda:1"],[256]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3849,239,16032000,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3852, "rf_id": 2680, "parent": 3851, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],[256],[1],16032256], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3853,239,16032256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3851, "rf_id": 2679, "parent": 3850, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,3584,3840,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3853,239,16032256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3850, "rf_id": 2678, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],0,3584,256], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3853,239,16032256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3854, "rf_id": 2681, "parent": 3795, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3853,239,16032256,256,2,"cuda:1"],[256]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3855,239,16032256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::unflatten_dense_tensors", "id": 3795, "rf_id": 2641, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unflatten_dense_tensors(Tensor flat, Tensor[] tensors) -> Tensor[]",
      "inputs": [[3784,239,16028672,3840,2,"cuda:1"],[[3785,239,16028672,256,2,"cuda:1"],[3786,239,16028928,256,2,"cuda:1"],[3787,239,16029184,768,2,"cuda:1"],[3788,239,16029952,256,2,"cuda:1"],[3789,239,16030208,256,2,"cuda:1"],[3790,239,16030464,256,2,"cuda:1"],[3791,239,16030720,1024,2,"cuda:1"],[3792,239,16031744,256,2,"cuda:1"],[3793,239,16032000,256,2,"cuda:1"],[3794,239,16032256,256,2,"cuda:1"]]], "input_shapes": [[3840],[[256],[256],[768],[256],[256],[256],[1024],[256],[256],[256]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"],
      "outputs": [[[3801,239,16028672,256,2,"cuda:1"],[3807,239,16028928,256,2,"cuda:1"],[3813,239,16029184,768,2,"cuda:1"],[3819,239,16029952,256,2,"cuda:1"],[3825,239,16030208,256,2,"cuda:1"],[3831,239,16030464,256,2,"cuda:1"],[3837,239,16030720,1024,2,"cuda:1"],[3843,239,16031744,256,2,"cuda:1"],[3849,239,16032000,256,2,"cuda:1"],[3855,239,16032256,256,2,"cuda:1"]]], "output_shapes": [[[256],[256],[768],[256],[256],[256],[1024],[256],[256],[256]]], "output_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3857, "rf_id": 2682, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3785,239,16028672,256,2,"cuda:1"],[3856,239,16028672,256,2,"cuda:1"]], "input_shapes": [[256],[256]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3859, "rf_id": 2683, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3786,239,16028928,256,2,"cuda:1"],[3858,239,16028928,256,2,"cuda:1"]], "input_shapes": [[256],[256]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3861, "rf_id": 2684, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3787,239,16029184,768,2,"cuda:1"],[3860,239,16029184,768,2,"cuda:1"]], "input_shapes": [[768],[768]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3863, "rf_id": 2685, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3788,239,16029952,256,2,"cuda:1"],[3862,239,16029952,256,2,"cuda:1"]], "input_shapes": [[256],[256]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3865, "rf_id": 2686, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3789,239,16030208,256,2,"cuda:1"],[3864,239,16030208,256,2,"cuda:1"]], "input_shapes": [[256],[256]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3867, "rf_id": 2687, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3790,239,16030464,256,2,"cuda:1"],[3866,239,16030464,256,2,"cuda:1"]], "input_shapes": [[256],[256]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3869, "rf_id": 2688, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3791,239,16030720,1024,2,"cuda:1"],[3868,239,16030720,1024,2,"cuda:1"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3871, "rf_id": 2689, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3792,239,16031744,256,2,"cuda:1"],[3870,239,16031744,256,2,"cuda:1"]], "input_shapes": [[256],[256]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3873, "rf_id": 2690, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3793,239,16032000,256,2,"cuda:1"],[3872,239,16032000,256,2,"cuda:1"]], "input_shapes": [[256],[256]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3875, "rf_id": 2691, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3794,239,16032256,256,2,"cuda:1"],[3874,239,16032256,256,2,"cuda:1"]], "input_shapes": [[256],[256]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::to", "id": 3876, "rf_id": 2692, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3694,239,12877824,5120,2,"cuda:1"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[5120],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3694,239,12877824,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3877, "rf_id": 2693, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3785,239,16028672,256,2,"cuda:1"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3785,239,16028672,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3878, "rf_id": 2694, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3786,239,16028928,256,2,"cuda:1"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3786,239,16028928,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3879, "rf_id": 2695, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3787,239,16029184,768,2,"cuda:1"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[768],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3787,239,16029184,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3880, "rf_id": 2696, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3788,239,16029952,256,2,"cuda:1"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3788,239,16029952,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3881, "rf_id": 2697, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3789,239,16030208,256,2,"cuda:1"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3789,239,16030208,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3882, "rf_id": 2698, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3790,239,16030464,256,2,"cuda:1"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3790,239,16030464,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3883, "rf_id": 2699, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3791,239,16030720,1024,2,"cuda:1"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[1024],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3791,239,16030720,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3884, "rf_id": 2700, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3792,239,16031744,256,2,"cuda:1"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3792,239,16031744,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3885, "rf_id": 2701, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3793,239,16032000,256,2,"cuda:1"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3793,239,16032000,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3886, "rf_id": 2702, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3794,239,16032256,256,2,"cuda:1"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3794,239,16032256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3887, "rf_id": 2703, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20480],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3813,345,0,20480,2,"cuda:1"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3888, "rf_id": 2704, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3813,345,0,20480,2,"cuda:1"],[-1]], "input_shapes": [[20480],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3819,345,0,20480,2,"cuda:1"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3889, "rf_id": 2705, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1024],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3825,10,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3890, "rf_id": 2706, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3825,10,0,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3831,10,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3891, "rf_id": 2707, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1024],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3837,3366,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3892, "rf_id": 2708, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3837,3366,0,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3843,3366,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3893, "rf_id": 2709, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3072],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3849,565,0,3072,2,"cuda:1"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3894, "rf_id": 2710, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3849,565,0,3072,2,"cuda:1"],[-1]], "input_shapes": [[3072],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3895,565,0,3072,2,"cuda:1"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3896, "rf_id": 2711, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1024],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3897,3427,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3898, "rf_id": 2712, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3897,3427,0,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3855,3427,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3899, "rf_id": 2713, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1024],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3900,779,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3901, "rf_id": 2714, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3900,779,0,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3902,779,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3903, "rf_id": 2715, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1024],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3904,1196,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3905, "rf_id": 2716, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3904,1196,0,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3906,1196,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3907, "rf_id": 2717, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[4096],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3908,198,0,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3909, "rf_id": 2718, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3908,198,0,4096,2,"cuda:1"],[-1]], "input_shapes": [[4096],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3910,198,0,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3911, "rf_id": 2719, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1024],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3912,820,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3913, "rf_id": 2720, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3912,820,0,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3914,820,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3915, "rf_id": 2721, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1024],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3916,887,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3917, "rf_id": 2722, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3916,887,0,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3918,887,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3919, "rf_id": 2723, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1024],15,"<None>","cuda:1",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3920,3921,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3922, "rf_id": 2724, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3920,3921,0,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3923,3921,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3924, "rf_id": 2725, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3694,239,12877824,5120,2,"cuda:1"],[-1]], "input_shapes": [[5120],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3925,239,12877824,5120,2,"cuda:1"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3928, "rf_id": 2728, "parent": 3927, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3925,239,12877824,5120,2,"cuda:1"]], "input_shapes": [[5120]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3927, "rf_id": 2727, "parent": 3926, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3925,239,12877824,5120,2,"cuda:1"],131,94716817711568,1,"_allgather_base",[],[],4], "input_shapes": [[5120],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3819,345,0,20480,2,"cuda:1"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3926, "rf_id": 2726, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3819,345,0,20480,2,"cuda:1"],[3925,239,12877824,5120,2,"cuda:1"],"<Object>",true,-1], "input_shapes": [[20480],[5120],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3819,345,0,20480,2,"cuda:1"],"<Object>"], "output_shapes": [[20480],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3929, "rf_id": 2729, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3785,239,16028672,256,2,"cuda:1"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3930,239,16028672,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3933, "rf_id": 2732, "parent": 3932, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3930,239,16028672,256,2,"cuda:1"]], "input_shapes": [[256]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3932, "rf_id": 2731, "parent": 3931, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3930,239,16028672,256,2,"cuda:1"],132,94716817711568,1,"_allgather_base",[],[],4], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3831,10,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3931, "rf_id": 2730, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3831,10,0,1024,2,"cuda:1"],[3930,239,16028672,256,2,"cuda:1"],"<Object>",true,-1], "input_shapes": [[1024],[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3831,10,0,1024,2,"cuda:1"],"<Object>"], "output_shapes": [[1024],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3934, "rf_id": 2733, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3786,239,16028928,256,2,"cuda:1"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3935,239,16028928,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3938, "rf_id": 2736, "parent": 3937, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3935,239,16028928,256,2,"cuda:1"]], "input_shapes": [[256]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3937, "rf_id": 2735, "parent": 3936, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3935,239,16028928,256,2,"cuda:1"],133,94716817711568,1,"_allgather_base",[],[],4], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3843,3366,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3936, "rf_id": 2734, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3843,3366,0,1024,2,"cuda:1"],[3935,239,16028928,256,2,"cuda:1"],"<Object>",true,-1], "input_shapes": [[1024],[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3843,3366,0,1024,2,"cuda:1"],"<Object>"], "output_shapes": [[1024],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3939, "rf_id": 2737, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3787,239,16029184,768,2,"cuda:1"],[-1]], "input_shapes": [[768],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3940,239,16029184,768,2,"cuda:1"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3943, "rf_id": 2740, "parent": 3942, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3940,239,16029184,768,2,"cuda:1"]], "input_shapes": [[768]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3942, "rf_id": 2739, "parent": 3941, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3940,239,16029184,768,2,"cuda:1"],134,94716817711568,1,"_allgather_base",[],[],4], "input_shapes": [[768],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3895,565,0,3072,2,"cuda:1"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3941, "rf_id": 2738, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3895,565,0,3072,2,"cuda:1"],[3940,239,16029184,768,2,"cuda:1"],"<Object>",true,-1], "input_shapes": [[3072],[768],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3895,565,0,3072,2,"cuda:1"],"<Object>"], "output_shapes": [[3072],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3944, "rf_id": 2741, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3788,239,16029952,256,2,"cuda:1"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3945,239,16029952,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3948, "rf_id": 2744, "parent": 3947, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3945,239,16029952,256,2,"cuda:1"]], "input_shapes": [[256]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3947, "rf_id": 2743, "parent": 3946, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3945,239,16029952,256,2,"cuda:1"],135,94716817711568,1,"_allgather_base",[],[],4], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3855,3427,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3946, "rf_id": 2742, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3855,3427,0,1024,2,"cuda:1"],[3945,239,16029952,256,2,"cuda:1"],"<Object>",true,-1], "input_shapes": [[1024],[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3855,3427,0,1024,2,"cuda:1"],"<Object>"], "output_shapes": [[1024],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3949, "rf_id": 2745, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3789,239,16030208,256,2,"cuda:1"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3950,239,16030208,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3953, "rf_id": 2748, "parent": 3952, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3950,239,16030208,256,2,"cuda:1"]], "input_shapes": [[256]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3952, "rf_id": 2747, "parent": 3951, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3950,239,16030208,256,2,"cuda:1"],136,94716817711568,1,"_allgather_base",[],[],4], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3902,779,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3951, "rf_id": 2746, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3902,779,0,1024,2,"cuda:1"],[3950,239,16030208,256,2,"cuda:1"],"<Object>",true,-1], "input_shapes": [[1024],[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3902,779,0,1024,2,"cuda:1"],"<Object>"], "output_shapes": [[1024],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3954, "rf_id": 2749, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3790,239,16030464,256,2,"cuda:1"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3955,239,16030464,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3958, "rf_id": 2752, "parent": 3957, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3955,239,16030464,256,2,"cuda:1"]], "input_shapes": [[256]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3957, "rf_id": 2751, "parent": 3956, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3955,239,16030464,256,2,"cuda:1"],137,94716817711568,1,"_allgather_base",[],[],4], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3906,1196,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3956, "rf_id": 2750, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3906,1196,0,1024,2,"cuda:1"],[3955,239,16030464,256,2,"cuda:1"],"<Object>",true,-1], "input_shapes": [[1024],[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3906,1196,0,1024,2,"cuda:1"],"<Object>"], "output_shapes": [[1024],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3959, "rf_id": 2753, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3791,239,16030720,1024,2,"cuda:1"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3960,239,16030720,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3963, "rf_id": 2756, "parent": 3962, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3960,239,16030720,1024,2,"cuda:1"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3962, "rf_id": 2755, "parent": 3961, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3960,239,16030720,1024,2,"cuda:1"],138,94716817711568,1,"_allgather_base",[],[],4], "input_shapes": [[1024],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3910,198,0,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3961, "rf_id": 2754, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3910,198,0,4096,2,"cuda:1"],[3960,239,16030720,1024,2,"cuda:1"],"<Object>",true,-1], "input_shapes": [[4096],[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3910,198,0,4096,2,"cuda:1"],"<Object>"], "output_shapes": [[4096],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3964, "rf_id": 2757, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3792,239,16031744,256,2,"cuda:1"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3965,239,16031744,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3968, "rf_id": 2760, "parent": 3967, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3965,239,16031744,256,2,"cuda:1"]], "input_shapes": [[256]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3967, "rf_id": 2759, "parent": 3966, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3965,239,16031744,256,2,"cuda:1"],139,94716817711568,1,"_allgather_base",[],[],4], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3914,820,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3966, "rf_id": 2758, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3914,820,0,1024,2,"cuda:1"],[3965,239,16031744,256,2,"cuda:1"],"<Object>",true,-1], "input_shapes": [[1024],[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3914,820,0,1024,2,"cuda:1"],"<Object>"], "output_shapes": [[1024],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3969, "rf_id": 2761, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3793,239,16032000,256,2,"cuda:1"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3970,239,16032000,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3973, "rf_id": 2764, "parent": 3972, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3970,239,16032000,256,2,"cuda:1"]], "input_shapes": [[256]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3972, "rf_id": 2763, "parent": 3971, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3970,239,16032000,256,2,"cuda:1"],140,94716817711568,1,"_allgather_base",[],[],4], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3918,887,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3971, "rf_id": 2762, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3918,887,0,1024,2,"cuda:1"],[3970,239,16032000,256,2,"cuda:1"],"<Object>",true,-1], "input_shapes": [[1024],[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3918,887,0,1024,2,"cuda:1"],"<Object>"], "output_shapes": [[1024],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3974, "rf_id": 2765, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3794,239,16032256,256,2,"cuda:1"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3975,239,16032256,256,2,"cuda:1"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3978, "rf_id": 2768, "parent": 3977, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3975,239,16032256,256,2,"cuda:1"]], "input_shapes": [[256]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3977, "rf_id": 2767, "parent": 3976, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3975,239,16032256,256,2,"cuda:1"],141,94716817711568,1,"_allgather_base",[],[],4], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3923,3921,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3976, "rf_id": 2766, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3923,3921,0,1024,2,"cuda:1"],[3975,239,16032256,256,2,"cuda:1"],"<Object>",true,-1], "input_shapes": [[1024],[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3923,3921,0,1024,2,"cuda:1"],"<Object>"], "output_shapes": [[1024],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "record_param_comms", "id": 3979, "rf_id": 2769, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [141,0,1,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3982, "rf_id": 2772, "parent": 3981, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3819,345,0,20480,2,"cuda:1"],[20480],[1],0], "input_shapes": [[20480],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3983,345,0,20480,2,"cuda:1"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3981, "rf_id": 2771, "parent": 3980, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3819,345,0,20480,2,"cuda:1"],0,0,20480,1], "input_shapes": [[20480],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3983,345,0,20480,2,"cuda:1"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3980, "rf_id": 2770, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3819,345,0,20480,2,"cuda:1"],0,0,20480], "input_shapes": [[20480],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3983,345,0,20480,2,"cuda:1"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3984, "rf_id": 2773, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3983,345,0,20480,2,"cuda:1"],[20,1024]], "input_shapes": [[20480],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[3985,345,0,20480,2,"cuda:1"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3987, "rf_id": 2774, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[344,57,0,0,2,"cuda:1"],[3986,345,0,20480,2,"cuda:1"]], "input_shapes": [[0],[20,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 3990, "rf_id": 2777, "parent": 3989, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3831,10,0,1024,2,"cuda:1"],[1024],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3985,10,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3989, "rf_id": 2776, "parent": 3988, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3831,10,0,1024,2,"cuda:1"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3985,10,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3988, "rf_id": 2775, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3831,10,0,1024,2,"cuda:1"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3985,10,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3991, "rf_id": 2778, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3985,10,0,1024,2,"cuda:1"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3992,10,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3994, "rf_id": 2779, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[422,57,0,0,2,"cuda:1"],[3993,10,0,1024,2,"cuda:1"]], "input_shapes": [[0],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 3997, "rf_id": 2782, "parent": 3996, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3843,3366,0,1024,2,"cuda:1"],[1024],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3992,3366,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3996, "rf_id": 2781, "parent": 3995, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3843,3366,0,1024,2,"cuda:1"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3992,3366,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3995, "rf_id": 2780, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3843,3366,0,1024,2,"cuda:1"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3992,3366,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3998, "rf_id": 2783, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3992,3366,0,1024,2,"cuda:1"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3999,3366,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 4001, "rf_id": 2784, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[424,57,0,0,2,"cuda:1"],[4000,3366,0,1024,2,"cuda:1"]], "input_shapes": [[0],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 4004, "rf_id": 2787, "parent": 4003, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3895,565,0,3072,2,"cuda:1"],[3072],[1],0], "input_shapes": [[3072],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3999,565,0,3072,2,"cuda:1"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 4003, "rf_id": 2786, "parent": 4002, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3895,565,0,3072,2,"cuda:1"],0,0,3072,1], "input_shapes": [[3072],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3999,565,0,3072,2,"cuda:1"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 4002, "rf_id": 2785, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3895,565,0,3072,2,"cuda:1"],0,0,3072], "input_shapes": [[3072],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3999,565,0,3072,2,"cuda:1"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 4005, "rf_id": 2788, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3999,565,0,3072,2,"cuda:1"],[3072]], "input_shapes": [[3072],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[4006,565,0,3072,2,"cuda:1"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 4008, "rf_id": 2789, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[564,57,0,0,2,"cuda:1"],[4007,565,0,3072,2,"cuda:1"]], "input_shapes": [[0],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 4011, "rf_id": 2792, "parent": 4010, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3855,3427,0,1024,2,"cuda:1"],[1024],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[4006,3427,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 4010, "rf_id": 2791, "parent": 4009, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3855,3427,0,1024,2,"cuda:1"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[4006,3427,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 4009, "rf_id": 2790, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3855,3427,0,1024,2,"cuda:1"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[4006,3427,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 4012, "rf_id": 2793, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[4006,3427,0,1024,2,"cuda:1"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[4013,3427,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 4015, "rf_id": 2794, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[778,57,0,0,2,"cuda:1"],[4014,3427,0,1024,2,"cuda:1"]], "input_shapes": [[0],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 4018, "rf_id": 2797, "parent": 4017, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3902,779,0,1024,2,"cuda:1"],[1024],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[4013,779,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 4017, "rf_id": 2796, "parent": 4016, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3902,779,0,1024,2,"cuda:1"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[4013,779,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 4016, "rf_id": 2795, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3902,779,0,1024,2,"cuda:1"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[4013,779,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 4019, "rf_id": 2798, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[4013,779,0,1024,2,"cuda:1"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[4020,779,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 4022, "rf_id": 2799, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[817,57,0,0,2,"cuda:1"],[4021,779,0,1024,2,"cuda:1"]], "input_shapes": [[0],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 4025, "rf_id": 2802, "parent": 4024, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3906,1196,0,1024,2,"cuda:1"],[1024],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[4020,1196,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 4024, "rf_id": 2801, "parent": 4023, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3906,1196,0,1024,2,"cuda:1"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[4020,1196,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 4023, "rf_id": 2800, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3906,1196,0,1024,2,"cuda:1"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[4020,1196,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 4026, "rf_id": 2803, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[4020,1196,0,1024,2,"cuda:1"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[4027,1196,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 4029, "rf_id": 2804, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[819,57,0,0,2,"cuda:1"],[4028,1196,0,1024,2,"cuda:1"]], "input_shapes": [[0],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 4032, "rf_id": 2807, "parent": 4031, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3910,198,0,4096,2,"cuda:1"],[4096],[1],0], "input_shapes": [[4096],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[4027,198,0,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 4031, "rf_id": 2806, "parent": 4030, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3910,198,0,4096,2,"cuda:1"],0,0,4096,1], "input_shapes": [[4096],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[4027,198,0,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 4030, "rf_id": 2805, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3910,198,0,4096,2,"cuda:1"],0,0,4096], "input_shapes": [[4096],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[4027,198,0,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 4033, "rf_id": 2808, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[4027,198,0,4096,2,"cuda:1"],[4096]], "input_shapes": [[4096],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[4034,198,0,4096,2,"cuda:1"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 4036, "rf_id": 2809, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[886,57,0,0,2,"cuda:1"],[4035,198,0,4096,2,"cuda:1"]], "input_shapes": [[0],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 4039, "rf_id": 2812, "parent": 4038, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3914,820,0,1024,2,"cuda:1"],[1024],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[4034,820,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 4038, "rf_id": 2811, "parent": 4037, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3914,820,0,1024,2,"cuda:1"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[4034,820,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 4037, "rf_id": 2810, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3914,820,0,1024,2,"cuda:1"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[4034,820,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 4040, "rf_id": 2813, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[4034,820,0,1024,2,"cuda:1"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[4041,820,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 4043, "rf_id": 2814, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[957,57,0,0,2,"cuda:1"],[4042,820,0,1024,2,"cuda:1"]], "input_shapes": [[0],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 4046, "rf_id": 2817, "parent": 4045, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3918,887,0,1024,2,"cuda:1"],[1024],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[4041,887,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 4045, "rf_id": 2816, "parent": 4044, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3918,887,0,1024,2,"cuda:1"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[4041,887,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 4044, "rf_id": 2815, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3918,887,0,1024,2,"cuda:1"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[4041,887,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 4047, "rf_id": 2818, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[4041,887,0,1024,2,"cuda:1"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[4048,887,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 4050, "rf_id": 2819, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[994,57,0,0,2,"cuda:1"],[4049,887,0,1024,2,"cuda:1"]], "input_shapes": [[0],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 4053, "rf_id": 2822, "parent": 4052, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3923,3921,0,1024,2,"cuda:1"],[1024],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[4048,3921,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 4052, "rf_id": 2821, "parent": 4051, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3923,3921,0,1024,2,"cuda:1"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[4048,3921,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 4051, "rf_id": 2820, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3923,3921,0,1024,2,"cuda:1"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[4048,3921,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 4054, "rf_id": 2823, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[4048,3921,0,1024,2,"cuda:1"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[4055,3921,0,1024,2,"cuda:1"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 4057, "rf_id": 2824, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[996,57,0,0,2,"cuda:1"],[4056,3921,0,1024,2,"cuda:1"]], "input_shapes": [[0],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::add", "id": 4060, "rf_id": 2825, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1219,1207,0,1,4,"cuda:1"],[4058,4059,0,1,8,"cpu"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(long int)","Int"],
      "outputs": [[4061,5,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::div", "id": 4064, "rf_id": 2826, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[4061,5,0,1,4,"cuda:1"],[4062,4063,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(long int)"],
      "outputs": [[4065,227,0,1,4,"cuda:1"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "[pytorch|profiler|execution_trace|process]", "id": 1, "rf_id": 0, "parent": 1, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 0, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    }
  ],
  "finish_ts": 11020157
}