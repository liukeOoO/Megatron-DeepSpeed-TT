{
  "schema": "1.0.1", "pid": 667, "time": "2024-02-29 23:00:02", "start_ts": 13001513,
  "nodes": [
    {
      "name": "[pytorch|profiler|execution_trace|thread]", "id": 2, "rf_id": 0, "parent": 1, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3, "rf_id": 1, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],0,"<None>","cuda","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","None","None"],
      "outputs": [[4,5,0,1,1,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(unsigned char)"]
    },
    {
      "name": "aten::empty", "id": 8, "rf_id": 4, "parent": 7, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],0,"<None>","cuda","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","None","None"],
      "outputs": [[9,10,0,1,1,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(unsigned char)"]
    },
    {
      "name": "nccl:all_reduce", "id": 12, "rf_id": 6, "parent": 11, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[9,10,0,1,1,"cuda:0"]], "input_shapes": [[1]], "input_types": ["Tensor(unsigned char)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 11, "rf_id": 5, "parent": 7, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[9,10,0,1,1,"cuda:0"]],34,94136795106832,0,"allreduce",[],[],4], "input_shapes": [[[1]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(unsigned char)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[9,10,0,1,1,"cuda:0"]]], "output_shapes": [[[1]]], "output_types": ["GenericList[Tensor(unsigned char)]"]
    },
    {
      "name": "record_param_comms", "id": 7, "rf_id": 3, "parent": 6, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [34,94136795106832,0,"barrier",[],[],4], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "c10d::barrier", "id": 6, "rf_id": 2, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::barrier(Tensor tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, int[] device_ids, int timeout) -> __torch__.torch.classes.c10d.Work",
      "inputs": [[4,5,0,1,1,"cuda:0"],"<Object>",[],-1], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(unsigned char)","Object","GenericList[]","Int"],
      "outputs": ["<Object>"], "output_shapes": [[]], "output_types": ["Object"]
    },
    {
      "name": "record_param_comms", "id": 13, "rf_id": 7, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [34,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::lift_fresh", "id": 17, "rf_id": 9, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[15,16,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[15,16,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 18, "rf_id": 10, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[15,16,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[15,16,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 21, "rf_id": 11, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[19,20,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[19,20,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 22, "rf_id": 12, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[19,20,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[19,20,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 25, "rf_id": 13, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[23,24,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[23,24,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 26, "rf_id": 14, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[23,24,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[23,24,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 29, "rf_id": 15, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[27,28,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[27,28,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 30, "rf_id": 16, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[27,28,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[27,28,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 33, "rf_id": 17, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[31,32,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[31,32,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 34, "rf_id": 18, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[31,32,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[31,32,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 37, "rf_id": 19, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[35,36,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[35,36,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 38, "rf_id": 20, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[35,36,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[35,36,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 41, "rf_id": 21, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[39,40,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[39,40,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 42, "rf_id": 22, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[39,40,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[39,40,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 45, "rf_id": 23, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[43,44,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[43,44,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 46, "rf_id": 24, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[43,44,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[43,44,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::cat", "id": 48, "rf_id": 26, "parent": 47, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[15,16,0,21,8,"cpu"],[19,20,0,21,8,"cpu"],[23,24,0,21,8,"cpu"],[27,28,0,21,8,"cpu"],[31,32,0,21,8,"cpu"],[35,36,0,21,8,"cpu"],[39,40,0,21,8,"cpu"],[43,44,0,21,8,"cpu"]],0], "input_shapes": [[[21],[21],[21],[21],[21],[21],[21],[21]],[]], "input_types": ["GenericList[Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int)]","Int"],
      "outputs": [[49,50,0,168,8,"cpu"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 51, "rf_id": 27, "parent": 47, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[49,50,0,168,8,"cpu"],[8,21]], "input_shapes": [[168],[[],[]]], "input_types": ["Tensor(long int)","GenericList[Int,Int]"],
      "outputs": [[52,50,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::stack", "id": 47, "rf_id": 25, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::stack(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[15,16,0,21,8,"cpu"],[19,20,0,21,8,"cpu"],[23,24,0,21,8,"cpu"],[27,28,0,21,8,"cpu"],[31,32,0,21,8,"cpu"],[35,36,0,21,8,"cpu"],[39,40,0,21,8,"cpu"],[43,44,0,21,8,"cpu"]],0], "input_shapes": [[[21],[21],[21],[21],[21],[21],[21],[21]],[]], "input_types": ["GenericList[Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int)]","Int"],
      "outputs": [[52,50,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::is_pinned", "id": 54, "rf_id": 29, "parent": 53, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::is_pinned(Tensor self, Device? device=None) -> bool",
      "inputs": [[52,50,0,168,8,"cpu"],"<None>"], "input_shapes": [[8,21],[]], "input_types": ["Tensor(long int)","None"],
      "outputs": [false], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::set_", "id": 58, "rf_id": 31, "parent": 55, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::set_.source_Storage_storage_offset(Tensor(a!) self, Storage source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -> Tensor(a!)",
      "inputs": [[56,57,0,0,8,"cpu"],"<Storage>",0,[8,21],[21,1]], "input_shapes": [[0],[],[],[[],[]],[[],[]]], "input_types": ["Tensor(long int)","Storage","Int","GenericList[Int,Int]","GenericList[Int,Int]"],
      "outputs": [[56,59,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 60, "rf_id": 32, "parent": 55, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[56,59,0,168,8,"cpu"],[52,50,0,168,8,"cpu"],false], "input_shapes": [[8,21],[8,21],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[56,59,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_pin_memory", "id": 55, "rf_id": 30, "parent": 53, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_pin_memory(Tensor self, Device? device=None) -> Tensor",
      "inputs": [[52,50,0,168,8,"cpu"],"<None>"], "input_shapes": [[8,21],[]], "input_types": ["Tensor(long int)","None"],
      "outputs": [[56,59,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::pin_memory", "id": 53, "rf_id": 28, "parent": 14, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pin_memory(Tensor(a) self, Device? device=None) -> Tensor(a)",
      "inputs": [[52,50,0,168,8,"cpu"],"<None>"], "input_shapes": [[8,21],[]], "input_types": ["Tensor(long int)","None"],
      "outputs": [[56,59,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "enumerate(DataLoader)#_SingleProcessDataLoaderIter.__next__", "id": 14, "rf_id": 8, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 61, "rf_id": 33, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[5],4,0,"cpu",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","Bool","None"],
      "outputs": [[62,50,0,5,8,"cpu"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_strided", "id": 65, "rf_id": 36, "parent": 64, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[5],[1],4,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[66,10,0,5,8,"cuda:0"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 67, "rf_id": 37, "parent": 64, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[66,10,0,5,8,"cuda:0"],[62,50,0,5,8,"cpu"],false], "input_shapes": [[5],[5],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[66,10,0,5,8,"cuda:0"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_to_copy", "id": 64, "rf_id": 35, "parent": 63, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[62,50,0,5,8,"cpu"],4,"<None>","cuda:0","<None>",false,"<None>"], "input_shapes": [[5],[],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","None","Device","None","Bool","None"],
      "outputs": [[66,10,0,5,8,"cuda:0"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 63, "rf_id": 34, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[62,50,0,5,8,"cpu"],"cuda",4,false,false,"<None>"], "input_shapes": [[5],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[66,10,0,5,8,"cuda:0"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 68, "rf_id": 38, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[66,10,0,5,8,"cuda:0"]], "input_shapes": [[5]], "input_types": ["Tensor(long int)"],
      "outputs": [[66,10,0,5,8,"cuda:0"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "nccl:broadcast", "id": 71, "rf_id": 41, "parent": 70, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[66,10,0,5,8,"cuda:0"]], "input_shapes": [[5]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 70, "rf_id": 40, "parent": 69, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[66,10,0,5,8,"cuda:0"]],17,94136808529712,0,"broadcast",[],[],1], "input_shapes": [[[5]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(long int)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[66,10,0,5,8,"cuda:0"]]], "output_shapes": [[[5]]], "output_types": ["GenericList[Tensor(long int)]"]
    },
    {
      "name": "c10d::broadcast_", "id": 69, "rf_id": 39, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::broadcast_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, int root_rank, int root_tensor, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[66,10,0,5,8,"cuda:0"]],"<Object>",0,0,-1], "input_shapes": [[[5]],[],[],[],[]], "input_types": ["GenericList[Tensor(long int)]","Object","Int","Int","Int"],
      "outputs": [[[66,10,0,5,8,"cuda:0"]],"<Object>"], "output_shapes": [[[5]],[]], "output_types": ["GenericList[Tensor(long int)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 72, "rf_id": 42, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [17,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 75, "rf_id": 45, "parent": 74, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[5],[1],4,0,"cpu",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[76,77,0,5,8,"cpu"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 78, "rf_id": 46, "parent": 74, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[76,77,0,5,8,"cpu"],[66,10,0,5,8,"cuda:0"],false], "input_shapes": [[5],[5],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[76,77,0,5,8,"cpu"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_to_copy", "id": 74, "rf_id": 44, "parent": 73, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[66,10,0,5,8,"cuda:0"],4,0,"cpu","<None>",false,"<None>"], "input_shapes": [[5],[],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Bool","None"],
      "outputs": [[76,77,0,5,8,"cpu"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 73, "rf_id": 43, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[66,10,0,5,8,"cuda:0"],4,0,"cpu","<None>",false,false,"<None>"], "input_shapes": [[5],[],[],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[76,77,0,5,8,"cpu"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 80, "rf_id": 48, "parent": 79, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],[],[],0], "input_shapes": [[5],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[81,77,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 79, "rf_id": 47, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],0,0], "input_shapes": [[5],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[81,77,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::gt", "id": 82, "rf_id": 49, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::gt.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[81,77,0,1,8,"cpu"],0], "input_shapes": [[],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[83,84,0,1,1,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 87, "rf_id": 52, "parent": 86, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[83,84,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::item", "id": 86, "rf_id": 51, "parent": 85, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[83,84,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::is_nonzero", "id": 85, "rf_id": 50, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::is_nonzero(Tensor self) -> bool",
      "inputs": [[83,84,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 89, "rf_id": 54, "parent": 88, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],[],[],0], "input_shapes": [[5],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[90,77,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 88, "rf_id": 53, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],0,0], "input_shapes": [[5],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[90,77,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::mul", "id": 93, "rf_id": 55, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[90,77,0,1,8,"cpu"],[91,92,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(long int)","Tensor(long int)"],
      "outputs": [[94,95,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 97, "rf_id": 57, "parent": 96, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],[],[],1], "input_shapes": [[5],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[98,77,1,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 96, "rf_id": 56, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],0,1], "input_shapes": [[5],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[98,77,1,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::gt", "id": 99, "rf_id": 58, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::gt.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[98,77,1,1,8,"cpu"],0], "input_shapes": [[],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[100,101,0,1,1,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 104, "rf_id": 61, "parent": 103, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[100,101,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::item", "id": 103, "rf_id": 60, "parent": 102, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[100,101,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::is_nonzero", "id": 102, "rf_id": 59, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::is_nonzero(Tensor self) -> bool",
      "inputs": [[100,101,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 106, "rf_id": 63, "parent": 105, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],[],[],1], "input_shapes": [[5],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[107,77,1,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 105, "rf_id": 62, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],0,1], "input_shapes": [[5],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[107,77,1,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::mul_", "id": 108, "rf_id": 64, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[94,95,0,1,8,"cpu"],[107,77,1,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(long int)","Tensor(long int)"],
      "outputs": [[94,95,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 110, "rf_id": 66, "parent": 109, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],[],[],2], "input_shapes": [[5],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[111,77,2,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 109, "rf_id": 65, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],0,2], "input_shapes": [[5],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[111,77,2,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::gt", "id": 112, "rf_id": 67, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::gt.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[111,77,2,1,8,"cpu"],0], "input_shapes": [[],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[113,114,0,1,1,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 117, "rf_id": 70, "parent": 116, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[113,114,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [false], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::item", "id": 116, "rf_id": 69, "parent": 115, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[113,114,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [false], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::is_nonzero", "id": 115, "rf_id": 68, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::is_nonzero(Tensor self) -> bool",
      "inputs": [[113,114,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [false], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::add", "id": 120, "rf_id": 71, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[94,95,0,1,8,"cpu"],[118,119,0,1,8,"cpu"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Int"],
      "outputs": [[121,122,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 123, "rf_id": 72, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[56,59,0,168,8,"cpu"],[-1]], "input_shapes": [[8,21],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[124,59,0,168,8,"cpu"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::cat", "id": 125, "rf_id": 73, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[124,59,0,168,8,"cpu"]],0], "input_shapes": [[[168]],[]], "input_types": ["GenericList[Tensor(long int)]","Int"],
      "outputs": [[126,127,0,168,8,"cpu"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_strided", "id": 130, "rf_id": 76, "parent": 129, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[168],[1],4,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[131,132,0,168,8,"cuda:0"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 133, "rf_id": 77, "parent": 129, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[131,132,0,168,8,"cuda:0"],[126,127,0,168,8,"cpu"],false], "input_shapes": [[168],[168],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[131,132,0,168,8,"cuda:0"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_to_copy", "id": 129, "rf_id": 75, "parent": 128, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[126,127,0,168,8,"cpu"],4,0,"cuda:0","<None>",false,"<None>"], "input_shapes": [[168],[],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Bool","None"],
      "outputs": [[131,132,0,168,8,"cuda:0"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 128, "rf_id": 74, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[126,127,0,168,8,"cpu"],4,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[168],[],[],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[131,132,0,168,8,"cuda:0"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "nccl:broadcast", "id": 136, "rf_id": 80, "parent": 135, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[131,132,0,168,8,"cuda:0"]], "input_shapes": [[168]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 135, "rf_id": 79, "parent": 134, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[131,132,0,168,8,"cuda:0"]],18,94136808529712,0,"broadcast",[],[],1], "input_shapes": [[[168]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(long int)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[131,132,0,168,8,"cuda:0"]]], "output_shapes": [[[168]]], "output_types": ["GenericList[Tensor(long int)]"]
    },
    {
      "name": "c10d::broadcast_", "id": 134, "rf_id": 78, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::broadcast_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, int root_rank, int root_tensor, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[131,132,0,168,8,"cuda:0"]],"<Object>",0,0,-1], "input_shapes": [[[168]],[],[],[],[]], "input_types": ["GenericList[Tensor(long int)]","Object","Int","Int","Int"],
      "outputs": [[[131,132,0,168,8,"cuda:0"]],"<Object>"], "output_shapes": [[[168]],[]], "output_types": ["GenericList[Tensor(long int)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 137, "rf_id": 81, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [18,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_local_scalar_dense", "id": 139, "rf_id": 83, "parent": 138, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 138, "rf_id": 82, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 141, "rf_id": 85, "parent": 140, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 140, "rf_id": 84, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 143, "rf_id": 87, "parent": 142, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 142, "rf_id": 86, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::as_strided", "id": 146, "rf_id": 90, "parent": 145, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[131,132,0,168,8,"cuda:0"],[168],[1],0], "input_shapes": [[168],[[]],[[]],[]], "input_types": ["Tensor(long int)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[147,132,0,168,8,"cuda:0"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 145, "rf_id": 89, "parent": 144, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[131,132,0,168,8,"cuda:0"],0,0,168,1], "input_shapes": [[168],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[147,132,0,168,8,"cuda:0"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::narrow", "id": 144, "rf_id": 88, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[131,132,0,168,8,"cuda:0"],0,0,168], "input_shapes": [[168],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int"],
      "outputs": [[147,132,0,168,8,"cuda:0"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 149, "rf_id": 92, "parent": 148, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[90,77,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [8], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 148, "rf_id": 91, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[90,77,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [8], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 151, "rf_id": 94, "parent": 150, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[90,77,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [8], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 150, "rf_id": 93, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[90,77,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [8], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 153, "rf_id": 96, "parent": 152, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[107,77,1,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [21], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 152, "rf_id": 95, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[107,77,1,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [21], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::view", "id": 154, "rf_id": 97, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[147,132,0,168,8,"cuda:0"],[8,21]], "input_shapes": [[168],[[],[]]], "input_types": ["Tensor(long int)","GenericList[Int,Int]"],
      "outputs": [[155,132,0,168,8,"cuda:0"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::add", "id": 158, "rf_id": 98, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[94,95,0,1,8,"cpu"],[156,157,0,1,8,"cpu"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Int"],
      "outputs": [[159,160,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 161, "rf_id": 99, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[155,132,0,168,8,"cuda:0"],4,false,false,"<None>"], "input_shapes": [[8,21],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Bool","Bool","None"],
      "outputs": [[155,132,0,168,8,"cuda:0"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 163, "rf_id": 101, "parent": 162, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[155,132,0,168,8,"cuda:0"],[8,21],[21,1],0], "input_shapes": [[8,21],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[159,132,0,168,8,"cuda:0"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 162, "rf_id": 100, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[155,132,0,168,8,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[8,21],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[159,132,0,168,8,"cuda:0"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 165, "rf_id": 103, "parent": 164, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[159,132,0,168,8,"cuda:0"],[8,20],[21,1],1], "input_shapes": [[8,21],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[121,132,1,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 164, "rf_id": 102, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[159,132,0,168,8,"cuda:0"],1,1,9223372036854775807,1], "input_shapes": [[8,21],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[121,132,1,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 169, "rf_id": 107, "parent": 168, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],4,0,"cuda:0","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[170,171,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_like", "id": 168, "rf_id": 106, "parent": 167, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[121,132,1,160,8,"cuda:0"],4,0,"cuda:0","<None>",0], "input_shapes": [[8,20],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Int"],
      "outputs": [[170,171,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 172, "rf_id": 108, "parent": 167, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[170,171,0,160,8,"cuda:0"],[121,132,1,160,8,"cuda:0"],false], "input_shapes": [[8,20],[8,20],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[170,171,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 167, "rf_id": 105, "parent": 166, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[121,132,1,160,8,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[170,171,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::contiguous", "id": 166, "rf_id": 104, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[121,132,1,160,8,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[170,171,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 174, "rf_id": 110, "parent": 173, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[155,132,0,168,8,"cuda:0"],[8,21],[21,1],0], "input_shapes": [[8,21],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[175,132,0,168,8,"cuda:0"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 173, "rf_id": 109, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[155,132,0,168,8,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[8,21],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[175,132,0,168,8,"cuda:0"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 177, "rf_id": 112, "parent": 176, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[175,132,0,168,8,"cuda:0"],[8,20],[21,1],0], "input_shapes": [[8,21],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[178,132,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 176, "rf_id": 111, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[175,132,0,168,8,"cuda:0"],1,0,-1,1], "input_shapes": [[8,21],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[178,132,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 182, "rf_id": 116, "parent": 181, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],4,0,"cuda:0","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[183,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_like", "id": 181, "rf_id": 115, "parent": 180, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[178,132,0,160,8,"cuda:0"],4,0,"cuda:0","<None>",0], "input_shapes": [[8,20],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Int"],
      "outputs": [[183,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 185, "rf_id": 117, "parent": 180, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[183,184,0,160,8,"cuda:0"],[178,132,0,160,8,"cuda:0"],false], "input_shapes": [[8,20],[8,20],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[183,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 180, "rf_id": 114, "parent": 179, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[178,132,0,160,8,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[183,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::contiguous", "id": 179, "rf_id": 113, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[178,132,0,160,8,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[183,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 187, "rf_id": 119, "parent": 186, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1,20,20],6,"<None>","cpu",false,"<None>"], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","None","Device","Bool","None"],
      "outputs": [[188,189,0,400,4,"cpu"]], "output_shapes": [[1,20,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::fill_", "id": 190, "rf_id": 120, "parent": 186, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[188,189,0,400,4,"cpu"],1.000000], "input_shapes": [[1,20,20],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [[188,189,0,400,4,"cpu"]], "output_shapes": [[1,20,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::ones", "id": 186, "rf_id": 118, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ones(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1,20,20],"<None>","<None>","cpu",false], "input_shapes": [[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","None","None","Device","Bool"],
      "outputs": [[188,189,0,400,4,"cpu"]], "output_shapes": [[1,20,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::tril", "id": 191, "rf_id": 121, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::tril(Tensor self, int diagonal=0) -> Tensor",
      "inputs": [[188,189,0,400,4,"cpu"],0], "input_shapes": [[1,20,20],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[192,193,0,400,4,"cpu"]], "output_shapes": [[1,20,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 194, "rf_id": 122, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[192,193,0,400,4,"cpu"],[1,1,20,20]], "input_shapes": [[1,20,20],[[],[],[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[189,193,0,400,4,"cpu"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 196, "rf_id": 124, "parent": 195, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],6,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","None","Device","Bool","None"],
      "outputs": [[197,198,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::fill_", "id": 199, "rf_id": 125, "parent": 195, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[197,198,0,160,4,"cuda:0"],1.000000], "input_shapes": [[8,20],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [[197,198,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::ones", "id": 195, "rf_id": 123, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ones(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[8,20],6,"<None>","cuda:0",false], "input_shapes": [[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","None","Device","Bool"],
      "outputs": [[197,198,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 201, "rf_id": 127, "parent": 200, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],4,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[202,57,0,0,8,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::resize_", "id": 204, "rf_id": 129, "parent": 203, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[202,57,0,0,8,"cuda:0"],[20],"<None>"], "input_shapes": [[0],[[]],[]], "input_types": ["Tensor(long int)","GenericList[Int]","None"],
      "outputs": [[202,10,0,20,8,"cuda:0"]], "output_shapes": [[20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 203, "rf_id": 128, "parent": 200, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::arange.start_out(Scalar start, Scalar end, Scalar step=1, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [0,20,1,[202,57,0,0,8,"cuda:0"]], "input_shapes": [[],[],[],[0]], "input_types": ["Int","Int","Int","Tensor(long int)"],
      "outputs": [[202,10,0,20,8,"cuda:0"]], "output_shapes": [[20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 200, "rf_id": 126, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::arange(Scalar end, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [20,4,"<None>","cuda:0",false], "input_shapes": [[],[],[],[],[]], "input_types": ["Int","Int","None","Device","Bool"],
      "outputs": [[202,10,0,20,8,"cuda:0"]], "output_shapes": [[20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 206, "rf_id": 131, "parent": 205, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[202,10,0,20,8,"cuda:0"],[1,20],[20,1],"<None>"], "input_shapes": [[20],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[207,10,0,20,8,"cuda:0"]], "output_shapes": [[1,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::unsqueeze", "id": 205, "rf_id": 130, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[202,10,0,20,8,"cuda:0"],0], "input_shapes": [[20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[207,10,0,20,8,"cuda:0"]], "output_shapes": [[1,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 210, "rf_id": 134, "parent": 209, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[207,10,0,20,8,"cuda:0"],[8,20],[0,1],"<None>"], "input_shapes": [[1,20],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[211,10,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::expand", "id": 209, "rf_id": 133, "parent": 208, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)",
      "inputs": [[207,10,0,20,8,"cuda:0"],[8,20],false], "input_shapes": [[1,20],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","Bool"],
      "outputs": [[211,10,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::expand_as", "id": 208, "rf_id": 132, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[207,10,0,20,8,"cuda:0"],[183,184,0,160,8,"cuda:0"]], "input_shapes": [[1,20],[8,20]], "input_types": ["Tensor(long int)","Tensor(long int)"],
      "outputs": [[211,10,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_strided", "id": 217, "rf_id": 138, "parent": 216, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],6,0,"cpu",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[218,219,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 220, "rf_id": 139, "parent": 216, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[218,219,0,1,4,"cpu"],[213,214,0,1,8,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(double)","Bool"],
      "outputs": [[218,219,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 216, "rf_id": 137, "parent": 215, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[213,214,0,1,8,"cpu"],6,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","None","None","Bool","None"],
      "outputs": [[218,219,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 215, "rf_id": 136, "parent": 212, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[213,214,0,1,8,"cpu"],6,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[218,219,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::lt", "id": 212, "rf_id": 135, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[189,193,0,400,4,"cpu"],0.500000], "input_shapes": [[1,1,20,20],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [[221,222,0,400,1,"cpu"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 225, "rf_id": 142, "parent": 224, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1,1,20,20],[400,400,20,1],11,0,"cuda:0",false], "input_shapes": [[[],[],[],[]],[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int","Int","Device","Bool"],
      "outputs": [[226,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::copy_", "id": 228, "rf_id": 143, "parent": 224, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[226,227,0,400,1,"cuda:0"],[221,222,0,400,1,"cpu"],false], "input_shapes": [[1,1,20,20],[1,1,20,20],[]], "input_types": ["Tensor(bool)","Tensor(bool)","Bool"],
      "outputs": [[226,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::_to_copy", "id": 224, "rf_id": 141, "parent": 223, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[221,222,0,400,1,"cpu"],11,0,"cuda:0","<None>",false,"<None>"], "input_shapes": [[1,1,20,20],[],[],[],[],[],[]], "input_types": ["Tensor(bool)","Int","Int","Device","None","Bool","None"],
      "outputs": [[226,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::to", "id": 223, "rf_id": 140, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[221,222,0,400,1,"cpu"],11,0,"cuda:0","<None>",false,false,"<None>"], "input_shapes": [[1,1,20,20],[],[],[],[],[],[],[]], "input_types": ["Tensor(bool)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[226,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::as_strided", "id": 230, "rf_id": 145, "parent": 229, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[183,184,0,160,8,"cuda:0"],[8,20],[20,1],0], "input_shapes": [[8,20],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[231,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 229, "rf_id": 144, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[183,184,0,160,8,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[8,20],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[231,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 233, "rf_id": 147, "parent": 232, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[211,10,0,160,8,"cuda:0"],[8,20],[0,1],0], "input_shapes": [[8,20],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[234,10,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 232, "rf_id": 146, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[211,10,0,160,8,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[8,20],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[234,10,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 239, "rf_id": 150, "parent": 238, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[231,184,0,160,8,"cuda:0"],[-1]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[240,184,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 238, "rf_id": 149, "parent": 237, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[231,184,0,160,8,"cuda:0"],[-1]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[240,184,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 242, "rf_id": 152, "parent": 241, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[243,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::resize_", "id": 244, "rf_id": 153, "parent": 241, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[243,57,0,0,2,"cuda:0"],[160,1024],"<None>"], "input_shapes": [[0],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","None"],
      "outputs": [[243,245,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::index_select", "id": 241, "rf_id": 151, "parent": 237, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::index_select(Tensor self, int dim, Tensor index) -> Tensor",
      "inputs": [[235,236,0,51511296,2,"cuda:0"],0,[240,184,0,160,8,"cuda:0"]], "input_shapes": [[50304,1024],[],[160]], "input_types": ["Tensor(c10::BFloat16)","Int","Tensor(long int)"],
      "outputs": [[243,245,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 246, "rf_id": 154, "parent": 237, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[243,245,0,163840,2,"cuda:0"],[8,20,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[247,245,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding", "id": 237, "rf_id": 148, "parent": 2, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::embedding(Tensor weight, Tensor indices, SymInt padding_idx=-1, bool scale_grad_by_freq=False, bool sparse=False) -> Tensor",
      "inputs": [[235,236,0,51511296,2,"cuda:0"],[231,184,0,160,8,"cuda:0"],-1,false,false], "input_shapes": [[50304,1024],[8,20],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Bool","Bool"],
      "outputs": [[247,245,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 250, "rf_id": 157, "parent": 249, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[247,245,0,163840,2,"cuda:0"],[8,20,1024]], "input_shapes": [[8,20,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[251,245,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 249, "rf_id": 156, "parent": 248, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[247,245,0,163840,2,"cuda:0"],[247,245,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024],[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[251,245,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_ReduceFromModelParallelRegion", "id": 248, "rf_id": 155, "parent": 2, "fw_parent": 0, "seq_id": 192, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[247,245,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 257, "rf_id": 162, "parent": 256, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],4,0,"cuda:0","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[258,132,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_like", "id": 256, "rf_id": 161, "parent": 255, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[234,10,0,160,8,"cuda:0"],4,0,"cuda:0","<None>",0], "input_shapes": [[8,20],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Int"],
      "outputs": [[258,132,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 259, "rf_id": 163, "parent": 255, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[258,132,0,160,8,"cuda:0"],[234,10,0,160,8,"cuda:0"],false], "input_shapes": [[8,20],[8,20],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[258,132,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 255, "rf_id": 160, "parent": 254, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[234,10,0,160,8,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[258,132,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 260, "rf_id": 164, "parent": 254, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[258,132,0,160,8,"cuda:0"],[160]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[261,132,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 254, "rf_id": 159, "parent": 253, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[234,10,0,160,8,"cuda:0"],[-1]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[261,132,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 263, "rf_id": 166, "parent": 262, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[264,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::resize_", "id": 265, "rf_id": 167, "parent": 262, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[264,57,0,0,2,"cuda:0"],[160,1024],"<None>"], "input_shapes": [[0],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","None"],
      "outputs": [[264,266,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::index_select", "id": 262, "rf_id": 165, "parent": 253, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::index_select(Tensor self, int dim, Tensor index) -> Tensor",
      "inputs": [[252,236,51511296,20480,2,"cuda:0"],0,[261,132,0,160,8,"cuda:0"]], "input_shapes": [[20,1024],[],[160]], "input_types": ["Tensor(c10::BFloat16)","Int","Tensor(long int)"],
      "outputs": [[264,266,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 267, "rf_id": 168, "parent": 253, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[264,266,0,163840,2,"cuda:0"],[8,20,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[268,266,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding", "id": 253, "rf_id": 158, "parent": 2, "fw_parent": 0, "seq_id": 193, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::embedding(Tensor weight, Tensor indices, SymInt padding_idx=-1, bool scale_grad_by_freq=False, bool sparse=False) -> Tensor",
      "inputs": [[252,236,51511296,20480,2,"cuda:0"],[234,10,0,160,8,"cuda:0"],-1,false,false], "input_shapes": [[20,1024],[8,20],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Bool","Bool"],
      "outputs": [[268,266,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 269, "rf_id": 169, "parent": 2, "fw_parent": 0, "seq_id": 194, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[251,245,0,163840,2,"cuda:0"],[268,266,0,163840,2,"cuda:0"],1], "input_shapes": [[8,20,1024],[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[270,271,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 273, "rf_id": 171, "parent": 272, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[270,271,0,163840,2,"cuda:0"],[20,8,1024],[1024,20480,1],"<None>"], "input_shapes": [[8,20,1024],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[274,271,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 272, "rf_id": 170, "parent": 2, "fw_parent": 0, "seq_id": 195, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[270,271,0,163840,2,"cuda:0"],0,1], "input_shapes": [[8,20,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[274,271,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 278, "rf_id": 175, "parent": 277, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,1024],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[279,280,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 277, "rf_id": 174, "parent": 276, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[274,271,0,163840,2,"cuda:0"],15,0,"cuda:0","<None>",0], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Int"],
      "outputs": [[279,280,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 281, "rf_id": 176, "parent": 276, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[279,280,0,163840,2,"cuda:0"],[274,271,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[279,280,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::clone", "id": 276, "rf_id": 173, "parent": 275, "fw_parent": 0, "seq_id": 196, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[274,271,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[279,280,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::contiguous", "id": 275, "rf_id": 172, "parent": 2, "fw_parent": 0, "seq_id": 196, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[274,271,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[279,280,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 285, "rf_id": 180, "parent": 284, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],11,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[286,271,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 284, "rf_id": 179, "parent": 283, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[279,280,0,163840,2,"cuda:0"],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[286,271,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 288, "rf_id": 182, "parent": 287, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[289,290,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 287, "rf_id": 181, "parent": 283, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[279,280,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[289,290,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 283, "rf_id": 178, "parent": 282, "fw_parent": 0, "seq_id": 197, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[279,280,0,163840,2,"cuda:0"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[289,290,0,163840,2,"cuda:0"],[286,271,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024],[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::dropout", "id": 282, "rf_id": 177, "parent": 2, "fw_parent": 0, "seq_id": 197, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::dropout(Tensor input, float p, bool train) -> Tensor",
      "inputs": [[279,280,0,163840,2,"cuda:0"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[289,290,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 292, "rf_id": 184, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[289,290,0,163840,2,"cuda:0"],15,0,"cuda:0","<None>",false,false,"<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[289,290,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 298, "rf_id": 187, "parent": 297, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[299,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 297, "rf_id": 186, "parent": 296, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[289,290,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[299,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 301, "rf_id": 188, "parent": 296, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[160],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[302,132,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 304, "rf_id": 190, "parent": 303, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[305,306,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 303, "rf_id": 189, "parent": 296, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[302,132,0,160,4,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[160],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[305,306,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunction", "id": 296, "rf_id": 185, "parent": 291, "fw_parent": 0, "seq_id": 199, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[289,290,0,163840,2,"cuda:0"],[293,294,0,1024,2,"cuda:0"],[295,294,1024,1024,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 309, "rf_id": 193, "parent": 308, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[299,300,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[305,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 308, "rf_id": 192, "parent": 307, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[299,300,0,163840,2,"cuda:0"],[299,300,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[305,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_CopyToModelParallelRegion", "id": 307, "rf_id": 191, "parent": 291, "fw_parent": 0, "seq_id": 200, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[299,300,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 315, "rf_id": 197, "parent": 314, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[310,236,51531776,3145728,2,"cuda:0"],[1024,3072],[1,1024],"<None>"], "input_shapes": [[3072,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[316,236,51531776,3145728,2,"cuda:0"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 314, "rf_id": 196, "parent": 313, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[310,236,51531776,3145728,2,"cuda:0"],0,1], "input_shapes": [[3072,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[316,236,51531776,3145728,2,"cuda:0"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 313, "rf_id": 195, "parent": 312, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[310,236,51531776,3145728,2,"cuda:0"]], "input_shapes": [[3072,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[316,236,51531776,3145728,2,"cuda:0"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 319, "rf_id": 200, "parent": 318, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[305,300,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[320,300,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 318, "rf_id": 199, "parent": 317, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[305,300,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[320,300,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 321, "rf_id": 201, "parent": 317, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[320,300,0,163840,2,"cuda:0"],[316,236,51531776,3145728,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[322,323,0,491520,2,"cuda:0"]], "output_shapes": [[160,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 324, "rf_id": 202, "parent": 317, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[322,323,0,491520,2,"cuda:0"],[20,8,3072]], "input_shapes": [[160,3072],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[325,323,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 317, "rf_id": 198, "parent": 312, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[305,300,0,163840,2,"cuda:0"],[316,236,51531776,3145728,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[325,323,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 326, "rf_id": 203, "parent": 312, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[325,323,0,491520,2,"cuda:0"],[311,294,2048,3072,2,"cuda:0"],1], "input_shapes": [[20,8,3072],[3072],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[327,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 312, "rf_id": 194, "parent": 291, "fw_parent": 0, "seq_id": 201, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[305,300,0,163840,2,"cuda:0"],[310,236,51531776,3145728,2,"cuda:0"],[311,294,2048,3072,2,"cuda:0"]], "input_shapes": [[20,8,1024],[3072,1024],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 329, "rf_id": 204, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[327,328,0,491520,2,"cuda:0"],[20,8,-1,3,64]], "input_shapes": [[20,8,3072],[[],[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]"],
      "outputs": [[330,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 332, "rf_id": 206, "parent": 331, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[330,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[333,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 331, "rf_id": 205, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[330,328,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[333,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 335, "rf_id": 208, "parent": 334, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[333,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[336,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 334, "rf_id": 207, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[333,328,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[336,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 338, "rf_id": 210, "parent": 337, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[336,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[339,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 337, "rf_id": 209, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[336,328,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[339,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 341, "rf_id": 212, "parent": 340, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[339,328,0,491520,2,"cuda:0"],[20,8,16,1,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[342,328,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 340, "rf_id": 211, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[339,328,0,491520,2,"cuda:0"],3,0,-2,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[342,328,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 344, "rf_id": 214, "parent": 343, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[342,328,0,163840,2,"cuda:0"],[20,8,16,1,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,1,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[345,328,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 343, "rf_id": 213, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[342,328,0,163840,2,"cuda:0"],4,0,9223372036854775807,1], "input_shapes": [[20,8,16,1,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[345,328,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_reshape_alias", "id": 347, "rf_id": 216, "parent": 346, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[345,328,0,163840,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1]], "input_shapes": [[20,8,16,1,64],[[],[],[],[]],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]"],
      "outputs": [[348,328,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 346, "rf_id": 215, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[345,328,0,163840,2,"cuda:0"],[20,8,-1,64]], "input_shapes": [[20,8,16,1,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[348,328,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 350, "rf_id": 218, "parent": 349, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[330,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[351,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 349, "rf_id": 217, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[330,328,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[351,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 353, "rf_id": 220, "parent": 352, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[351,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[354,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 352, "rf_id": 219, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[351,328,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[354,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 356, "rf_id": 222, "parent": 355, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[354,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[357,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 355, "rf_id": 221, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[354,328,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[357,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 359, "rf_id": 224, "parent": 358, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[357,328,0,491520,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],64], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[360,328,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 358, "rf_id": 223, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[357,328,0,491520,2,"cuda:0"],3,-2], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[360,328,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 362, "rf_id": 226, "parent": 361, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[360,328,64,163840,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],64], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[363,328,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 361, "rf_id": 225, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[360,328,64,163840,2,"cuda:0"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[363,328,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 365, "rf_id": 228, "parent": 364, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[330,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[366,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 364, "rf_id": 227, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[330,328,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[366,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 368, "rf_id": 230, "parent": 367, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[366,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[369,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 367, "rf_id": 229, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[366,328,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[369,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 371, "rf_id": 232, "parent": 370, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[369,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[372,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 370, "rf_id": 231, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[369,328,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[372,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 374, "rf_id": 234, "parent": 373, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[372,328,0,491520,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],128], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[375,328,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 373, "rf_id": 233, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[372,328,0,491520,2,"cuda:0"],3,-1], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[375,328,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 377, "rf_id": 236, "parent": 376, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[375,328,128,163840,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],128], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[378,328,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 376, "rf_id": 235, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[375,328,128,163840,2,"cuda:0"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[378,328,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 379, "rf_id": 237, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[348,328,0,163840,2,"cuda:0"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[380,328,0,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 381, "rf_id": 238, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[363,328,64,163840,2,"cuda:0"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[382,328,64,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 386, "rf_id": 240, "parent": 385, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[383,384,0,51200,2,"cuda:0"],[51200],[1],0], "input_shapes": [[51200],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[387,384,0,51200,2,"cuda:0"]], "output_shapes": [[51200]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 385, "rf_id": 239, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[383,384,0,51200,2,"cuda:0"],0,0,51200,1], "input_shapes": [[51200],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[387,384,0,51200,2,"cuda:0"]], "output_shapes": [[51200]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 388, "rf_id": 241, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[387,384,0,51200,2,"cuda:0"],[128,20,20]], "input_shapes": [[51200],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[389,384,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 391, "rf_id": 243, "parent": 390, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[380,328,0,163840,2,"cuda:0"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[392,328,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 390, "rf_id": 242, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[380,328,0,163840,2,"cuda:0"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[392,328,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 394, "rf_id": 245, "parent": 393, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[382,328,64,163840,2,"cuda:0"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[395,328,64,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 393, "rf_id": 244, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[382,328,64,163840,2,"cuda:0"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[395,328,64,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 397, "rf_id": 247, "parent": 396, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[395,328,64,163840,2,"cuda:0"],[128,64,20],[192,1,24576],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[398,328,64,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 396, "rf_id": 246, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[395,328,64,163840,2,"cuda:0"],1,2], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[398,328,64,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::baddbmm", "id": 399, "rf_id": 248, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor",
      "inputs": [[389,384,0,51200,2,"cuda:0"],[392,328,0,163840,2,"cuda:0"],[398,328,64,163840,2,"cuda:0"],0.000000,0.125000], "input_shapes": [[128,20,20],[128,20,64],[128,64,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Double","Double"],
      "outputs": [[400,401,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 402, "rf_id": 249, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[400,401,0,51200,2,"cuda:0"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[403,401,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 404, "rf_id": 250, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[403,401,0,51200,2,"cuda:0"],[-1,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[405,401,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 407, "rf_id": 252, "parent": 406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],4,0,"cpu",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","Bool","None"],
      "outputs": [[408,409,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 410, "rf_id": 253, "parent": 406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[408,409,0,1,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[1],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[408,409,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 411, "rf_id": 254, "parent": 406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[408,409,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [[408,409,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "detach_", "id": 413, "rf_id": 256, "parent": 412, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[408,409,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 412, "rf_id": 255, "parent": 406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[408,409,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [[408,409,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 415, "rf_id": 258, "parent": 414, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[408,409,0,1,8,"cpu"],[],[],0], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[416,409,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 414, "rf_id": 257, "parent": 406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[408,409,0,1,8,"cpu"],0,0], "input_shapes": [[1],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[416,409,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 418, "rf_id": 260, "parent": 417, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[416,409,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 417, "rf_id": 259, "parent": 406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[416,409,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::empty", "id": 419, "rf_id": 261, "parent": 406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[128,20,20],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[420,421,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ScaledUpperTriangMaskedSoftmax", "id": 406, "rf_id": 251, "parent": 291, "fw_parent": 0, "seq_id": 202, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[405,401,0,51200,2,"cuda:0"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 422, "rf_id": 262, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[420,421,0,51200,2,"cuda:0"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[423,421,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 427, "rf_id": 266, "parent": 426, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[8,16,20,20],[6400,400,20,1],11,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[]],[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[428,429,0,51200,1,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 426, "rf_id": 265, "parent": 425, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[423,421,0,51200,2,"cuda:0"],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[8,16,20,20],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[428,429,0,51200,1,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 431, "rf_id": 268, "parent": 430, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[8,16,20,20],[6400,400,20,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[]],[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[432,433,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 430, "rf_id": 267, "parent": 425, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[423,421,0,51200,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[8,16,20,20],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[432,433,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 425, "rf_id": 264, "parent": 424, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[423,421,0,51200,2,"cuda:0"],0.100000,true], "input_shapes": [[8,16,20,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[432,433,0,51200,2,"cuda:0"],[428,429,0,51200,1,"cuda:0"]], "output_shapes": [[8,16,20,20],[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::dropout", "id": 424, "rf_id": 263, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::dropout(Tensor input, float p, bool train) -> Tensor",
      "inputs": [[423,421,0,51200,2,"cuda:0"],0.100000,true], "input_shapes": [[8,16,20,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[432,433,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 434, "rf_id": 269, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[378,328,128,163840,2,"cuda:0"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[435,328,128,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 436, "rf_id": 270, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[432,433,0,51200,2,"cuda:0"],[128,20,-1]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[437,433,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 439, "rf_id": 272, "parent": 438, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[435,328,128,163840,2,"cuda:0"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[440,328,128,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 438, "rf_id": 271, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[435,328,128,163840,2,"cuda:0"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[440,328,128,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 441, "rf_id": 273, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[437,433,0,51200,2,"cuda:0"],[440,328,128,163840,2,"cuda:0"]], "input_shapes": [[128,20,20],[128,20,64]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[442,245,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 443, "rf_id": 274, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[442,245,0,163840,2,"cuda:0"],[8,16,20,64]], "input_shapes": [[128,20,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[444,245,0,163840,2,"cuda:0"]], "output_shapes": [[8,16,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 446, "rf_id": 276, "parent": 445, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[444,245,0,163840,2,"cuda:0"],[20,8,16,64],[64,20480,1280,1],"<None>"], "input_shapes": [[8,16,20,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","None"],
      "outputs": [[447,245,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::permute", "id": 445, "rf_id": 275, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)",
      "inputs": [[444,245,0,163840,2,"cuda:0"],[2,0,1,3]], "input_shapes": [[8,16,20,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[447,245,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 451, "rf_id": 280, "parent": 450, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[452,266,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 450, "rf_id": 279, "parent": 449, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[447,245,0,163840,2,"cuda:0"],15,0,"cuda:0","<None>",0], "input_shapes": [[20,8,16,64],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Int"],
      "outputs": [[452,266,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 453, "rf_id": 281, "parent": 449, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[452,266,0,163840,2,"cuda:0"],[447,245,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[452,266,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::clone", "id": 449, "rf_id": 278, "parent": 448, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[447,245,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[452,266,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::contiguous", "id": 448, "rf_id": 277, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[447,245,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[452,266,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 454, "rf_id": 282, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[452,266,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[455,266,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 460, "rf_id": 286, "parent": 459, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[456,236,54677504,1048576,2,"cuda:0"],[1024,1024],[1,1024],"<None>"], "input_shapes": [[1024,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[461,236,54677504,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 459, "rf_id": 285, "parent": 458, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[456,236,54677504,1048576,2,"cuda:0"],0,1], "input_shapes": [[1024,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[461,236,54677504,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 458, "rf_id": 284, "parent": 457, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[456,236,54677504,1048576,2,"cuda:0"]], "input_shapes": [[1024,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[461,236,54677504,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 464, "rf_id": 289, "parent": 463, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[455,266,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[465,266,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 463, "rf_id": 288, "parent": 462, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[455,266,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[465,266,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 466, "rf_id": 290, "parent": 462, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[465,266,0,163840,2,"cuda:0"],[461,236,54677504,1048576,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[467,245,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 468, "rf_id": 291, "parent": 462, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[467,245,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[469,245,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 462, "rf_id": 287, "parent": 457, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[455,266,0,163840,2,"cuda:0"],[461,236,54677504,1048576,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[469,245,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 457, "rf_id": 283, "parent": 291, "fw_parent": 0, "seq_id": 203, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[455,266,0,163840,2,"cuda:0"],[456,236,54677504,1048576,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 472, "rf_id": 294, "parent": 471, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[469,245,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[473,245,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 471, "rf_id": 293, "parent": 470, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[469,245,0,163840,2,"cuda:0"],[469,245,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[473,245,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_ReduceFromModelParallelRegion", "id": 470, "rf_id": 292, "parent": 291, "fw_parent": 0, "seq_id": 204, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[469,245,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 477, "rf_id": 297, "parent": 476, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[474,294,5120,1024,2,"cuda:0"],[20,8,1024],[0,0,1],"<None>"], "input_shapes": [[1024],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[478,294,5120,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::expand", "id": 476, "rf_id": 296, "parent": 475, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)",
      "inputs": [[474,294,5120,1024,2,"cuda:0"],[20,8,1024],false], "input_shapes": [[1024],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","Bool"],
      "outputs": [[478,294,5120,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::expand_as", "id": 475, "rf_id": 295, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[474,294,5120,1024,2,"cuda:0"],[289,290,0,163840,2,"cuda:0"]], "input_shapes": [[1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[478,294,5120,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 481, "rf_id": 300, "parent": 480, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[478,294,5120,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 480, "rf_id": 299, "parent": 479, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[478,294,5120,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[482,294,5120,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 484, "rf_id": 302, "parent": 483, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[473,245,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 483, "rf_id": 301, "parent": 479, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[473,245,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[485,245,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 487, "rf_id": 304, "parent": 486, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[485,245,0,163840,2,"cuda:0"],[482,294,5120,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[488,266,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<forward op>", "id": 486, "rf_id": 303, "parent": 479, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[482,294,5120,163840,2,"cuda:0"],[485,245,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 490, "rf_id": 306, "parent": 489, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[289,290,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 489, "rf_id": 305, "parent": 479, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[289,290,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[491,290,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 493, "rf_id": 308, "parent": 492, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[488,266,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 492, "rf_id": 307, "parent": 479, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[488,266,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[494,266,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 498, "rf_id": 312, "parent": 497, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],11,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[499,401,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 497, "rf_id": 311, "parent": 496, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[494,266,0,163840,2,"cuda:0"],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[499,401,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 501, "rf_id": 314, "parent": 500, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[502,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 500, "rf_id": 313, "parent": 496, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[494,266,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[502,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 496, "rf_id": 310, "parent": 495, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[494,266,0,163840,2,"cuda:0"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[502,323,0,163840,2,"cuda:0"],[499,401,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024],[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::add", "id": 503, "rf_id": 315, "parent": 495, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[491,290,0,163840,2,"cuda:0"],[502,323,0,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[504,505,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<forward op>", "id": 495, "rf_id": 309, "parent": 479, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[491,290,0,163840,2,"cuda:0"],0.100000,[494,266,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_dropout_add_fused_train", "id": 479, "rf_id": 298, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[473,245,0,163840,2,"cuda:0"],[478,294,5120,163840,2,"cuda:0"],[289,290,0,163840,2,"cuda:0"],0.100000], "input_shapes": [[20,8,1024],[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Double"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 510, "rf_id": 318, "parent": 509, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[511,266,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 509, "rf_id": 317, "parent": 508, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[504,505,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[511,266,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 512, "rf_id": 319, "parent": 508, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[160],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[513,132,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 515, "rf_id": 321, "parent": 514, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[516,306,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 514, "rf_id": 320, "parent": 508, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[513,132,0,160,4,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[160],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[516,306,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunction", "id": 508, "rf_id": 316, "parent": 291, "fw_parent": 0, "seq_id": 207, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[504,505,0,163840,2,"cuda:0"],[506,294,6144,1024,2,"cuda:0"],[507,294,7168,1024,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 517, "rf_id": 322, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],15,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[516,518,0,1,2,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 521, "rf_id": 325, "parent": 520, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],15,0,"cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[522,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 523, "rf_id": 326, "parent": 520, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[522,132,0,1,2,"cuda:0"],[516,518,0,1,2,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[522,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_to_copy", "id": 520, "rf_id": 324, "parent": 519, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[516,518,0,1,2,"cpu"],15,"<None>","cuda:0","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","Device","None","Bool","None"],
      "outputs": [[522,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 519, "rf_id": 323, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[516,518,0,1,2,"cpu"],"cuda:0",15,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Device","Int","Bool","Bool","None"],
      "outputs": [[522,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::lift_fresh", "id": 524, "rf_id": 327, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[522,132,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[522,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach_", "id": 526, "rf_id": 329, "parent": 525, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[522,132,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 525, "rf_id": 328, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[522,132,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[522,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 527, "rf_id": 330, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],15,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[528,529,0,1,2,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 532, "rf_id": 333, "parent": 531, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],15,0,"cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[533,534,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 535, "rf_id": 334, "parent": 531, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[533,534,0,1,2,"cuda:0"],[528,529,0,1,2,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[533,534,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_to_copy", "id": 531, "rf_id": 332, "parent": 530, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[528,529,0,1,2,"cpu"],15,"<None>","cuda:0","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","Device","None","Bool","None"],
      "outputs": [[533,534,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 530, "rf_id": 331, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[528,529,0,1,2,"cpu"],"cuda:0",15,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Device","Int","Bool","Bool","None"],
      "outputs": [[533,534,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::lift_fresh", "id": 536, "rf_id": 335, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[533,534,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[533,534,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach_", "id": 538, "rf_id": 337, "parent": 537, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[533,534,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 537, "rf_id": 336, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[533,534,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[533,534,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 541, "rf_id": 340, "parent": 540, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[511,266,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[542,266,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 540, "rf_id": 339, "parent": 539, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[511,266,0,163840,2,"cuda:0"],[511,266,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[542,266,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_CopyToModelParallelRegion", "id": 539, "rf_id": 338, "parent": 291, "fw_parent": 0, "seq_id": 208, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[511,266,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 547, "rf_id": 344, "parent": 546, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[543,236,55726080,4194304,2,"cuda:0"],[1024,4096],[1,1024],"<None>"], "input_shapes": [[4096,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[548,236,55726080,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 546, "rf_id": 343, "parent": 545, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[543,236,55726080,4194304,2,"cuda:0"],0,1], "input_shapes": [[4096,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[548,236,55726080,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 545, "rf_id": 342, "parent": 544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[543,236,55726080,4194304,2,"cuda:0"]], "input_shapes": [[4096,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[548,236,55726080,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 551, "rf_id": 347, "parent": 550, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[542,266,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[552,266,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 550, "rf_id": 346, "parent": 549, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[542,266,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[552,266,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 553, "rf_id": 348, "parent": 549, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[552,266,0,163840,2,"cuda:0"],[548,236,55726080,4194304,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[554,555,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 556, "rf_id": 349, "parent": 549, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[554,555,0,655360,2,"cuda:0"],[20,8,4096]], "input_shapes": [[160,4096],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[557,555,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 549, "rf_id": 345, "parent": 544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[542,266,0,163840,2,"cuda:0"],[548,236,55726080,4194304,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[557,555,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 544, "rf_id": 341, "parent": 291, "fw_parent": 0, "seq_id": 209, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[542,266,0,163840,2,"cuda:0"],[543,236,55726080,4194304,2,"cuda:0"]], "input_shapes": [[20,8,1024],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 562, "rf_id": 353, "parent": 561, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[557,555,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 561, "rf_id": 352, "parent": 560, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[557,555,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[563,555,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 565, "rf_id": 355, "parent": 564, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[558,294,8192,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 564, "rf_id": 354, "parent": 560, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[558,294,8192,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[566,294,8192,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 568, "rf_id": 357, "parent": 567, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[566,294,8192,4096,2,"cuda:0"],[563,555,0,655360,2,"cuda:0"],1], "input_shapes": [[4096],[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[569,570,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 574, "rf_id": 359, "parent": 571, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[569,570,0,655360,2,"cuda:0"],[572,573,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[575,576,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 571, "rf_id": 358, "parent": 567, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[569,570,0,655360,2,"cuda:0"],0.500000], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[575,576,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 580, "rf_id": 361, "parent": 577, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[569,570,0,655360,2,"cuda:0"],[578,579,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[581,582,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 577, "rf_id": 360, "parent": 567, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[569,570,0,655360,2,"cuda:0"],0.797885], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[581,582,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 586, "rf_id": 363, "parent": 583, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[569,570,0,655360,2,"cuda:0"],[584,585,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[587,588,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 583, "rf_id": 362, "parent": 567, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[569,570,0,655360,2,"cuda:0"],0.044715], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[587,588,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 589, "rf_id": 364, "parent": 567, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[587,588,0,655360,2,"cuda:0"],[569,570,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[590,591,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 595, "rf_id": 366, "parent": 592, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[590,591,0,655360,2,"cuda:0"],[593,594,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[596,597,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 592, "rf_id": 365, "parent": 567, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[590,591,0,655360,2,"cuda:0"],1,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[596,597,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 598, "rf_id": 367, "parent": 567, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[581,582,0,655360,2,"cuda:0"],[596,597,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[599,591,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::tanh", "id": 600, "rf_id": 368, "parent": 567, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::tanh(Tensor self) -> Tensor",
      "inputs": [[599,591,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[601,602,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 606, "rf_id": 370, "parent": 603, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[601,602,0,655360,2,"cuda:0"],[604,605,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)","Int"],
      "outputs": [[607,591,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 603, "rf_id": 369, "parent": 567, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[601,602,0,655360,2,"cuda:0"],1.000000,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Int"],
      "outputs": [[607,591,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 608, "rf_id": 371, "parent": 567, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[575,576,0,655360,2,"cuda:0"],[607,591,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[609,610,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<forward op>", "id": 567, "rf_id": 356, "parent": 560, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[563,555,0,655360,2,"cuda:0"],[566,294,8192,4096,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_gelu", "id": 560, "rf_id": 351, "parent": 559, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[558,294,8192,4096,2,"cuda:0"],[557,555,0,655360,2,"cuda:0"]], "input_shapes": [[4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach_", "id": 612, "rf_id": 373, "parent": 611, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[609,610,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 611, "rf_id": 372, "parent": 559, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[609,610,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[609,610,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "GeLUFunction", "id": 559, "rf_id": 350, "parent": 291, "fw_parent": 0, "seq_id": 210, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[557,555,0,655360,2,"cuda:0"],[558,294,8192,4096,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 617, "rf_id": 377, "parent": 616, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[613,236,59920384,4194304,2,"cuda:0"],[4096,1024],[1,4096],"<None>"], "input_shapes": [[1024,4096],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[618,236,59920384,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 616, "rf_id": 376, "parent": 615, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[613,236,59920384,4194304,2,"cuda:0"],0,1], "input_shapes": [[1024,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[618,236,59920384,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 615, "rf_id": 375, "parent": 614, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[613,236,59920384,4194304,2,"cuda:0"]], "input_shapes": [[1024,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[618,236,59920384,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 621, "rf_id": 380, "parent": 620, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[609,610,0,655360,2,"cuda:0"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[622,610,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 620, "rf_id": 379, "parent": 619, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[609,610,0,655360,2,"cuda:0"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[622,610,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 623, "rf_id": 381, "parent": 619, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[622,610,0,655360,2,"cuda:0"],[618,236,59920384,4194304,2,"cuda:0"]], "input_shapes": [[160,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[624,300,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 625, "rf_id": 382, "parent": 619, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[624,300,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[626,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 619, "rf_id": 378, "parent": 614, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[609,610,0,655360,2,"cuda:0"],[618,236,59920384,4194304,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[626,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 614, "rf_id": 374, "parent": 291, "fw_parent": 0, "seq_id": 212, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[609,610,0,655360,2,"cuda:0"],[613,236,59920384,4194304,2,"cuda:0"]], "input_shapes": [[20,8,4096],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 629, "rf_id": 385, "parent": 628, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[626,300,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[630,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 628, "rf_id": 384, "parent": 627, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[626,300,0,163840,2,"cuda:0"],[626,300,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[630,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_ReduceFromModelParallelRegion", "id": 627, "rf_id": 383, "parent": 291, "fw_parent": 0, "seq_id": 213, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[626,300,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 632, "rf_id": 386, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[630,300,0,163840,2,"cuda:0"],[631,294,12288,1024,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[633,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 639, "rf_id": 392, "parent": 638, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],11,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[640,421,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 638, "rf_id": 391, "parent": 637, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[633,323,0,163840,2,"cuda:0"],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[640,421,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 642, "rf_id": 394, "parent": 641, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[643,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 641, "rf_id": 393, "parent": 637, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[633,323,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[643,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 637, "rf_id": 390, "parent": 636, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[633,323,0,163840,2,"cuda:0"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[643,300,0,163840,2,"cuda:0"],[640,421,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024],[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::dropout", "id": 636, "rf_id": 389, "parent": 635, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::dropout(Tensor input, float p, bool train) -> Tensor",
      "inputs": [[633,323,0,163840,2,"cuda:0"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[643,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 644, "rf_id": 395, "parent": 635, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[504,505,0,163840,2,"cuda:0"],[643,300,0,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[640,645,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "fallback_function", "id": 635, "rf_id": 388, "parent": 634, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[504,505,0,163840,2,"cuda:0"],0.100000,[633,323,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_dropout_add_fused_train", "id": 634, "rf_id": 387, "parent": 291, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[633,323,0,163840,2,"cuda:0"],"<None>",[504,505,0,163840,2,"cuda:0"],0.100000], "input_shapes": [[20,8,1024],[],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","None","Tensor(c10::BFloat16)","Double"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "CheckpointFunction", "id": 291, "rf_id": 183, "parent": 2, "fw_parent": 0, "seq_id": 198, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[289,290,0,163840,2,"cuda:0"],[226,227,0,400,1,"cuda:0"]], "input_shapes": [[20,8,1024],[1,1,20,20]], "input_types": ["Tensor(c10::BFloat16)","Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 650, "rf_id": 398, "parent": 649, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[499,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 649, "rf_id": 397, "parent": 648, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[640,645,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[499,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 651, "rf_id": 399, "parent": 648, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[160],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[652,534,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 654, "rf_id": 401, "parent": 653, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[655,306,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 653, "rf_id": 400, "parent": 648, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[652,534,0,160,4,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[160],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[655,306,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunction", "id": 648, "rf_id": 396, "parent": 2, "fw_parent": 0, "seq_id": 214, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[640,645,0,163840,2,"cuda:0"],[646,294,13312,1024,2,"cuda:0"],[647,294,14336,1024,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 658, "rf_id": 404, "parent": 657, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[499,300,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[659,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 657, "rf_id": 403, "parent": 656, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[499,300,0,163840,2,"cuda:0"],[499,300,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[659,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_CopyToModelParallelRegion", "id": 656, "rf_id": 402, "parent": 2, "fw_parent": 0, "seq_id": 215, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[499,300,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 663, "rf_id": 408, "parent": 662, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[235,236,0,51511296,2,"cuda:0"],[1024,50304],[1,1024],"<None>"], "input_shapes": [[50304,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[664,236,0,51511296,2,"cuda:0"]], "output_shapes": [[1024,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 662, "rf_id": 407, "parent": 661, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[235,236,0,51511296,2,"cuda:0"],0,1], "input_shapes": [[50304,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[664,236,0,51511296,2,"cuda:0"]], "output_shapes": [[1024,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 661, "rf_id": 406, "parent": 660, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[235,236,0,51511296,2,"cuda:0"]], "input_shapes": [[50304,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[664,236,0,51511296,2,"cuda:0"]], "output_shapes": [[1024,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 667, "rf_id": 411, "parent": 666, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[659,300,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[668,300,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 666, "rf_id": 410, "parent": 665, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[659,300,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[668,300,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 669, "rf_id": 412, "parent": 665, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[668,300,0,163840,2,"cuda:0"],[664,236,0,51511296,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,50304]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[670,576,0,8048640,2,"cuda:0"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 671, "rf_id": 413, "parent": 665, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[670,576,0,8048640,2,"cuda:0"],[20,8,50304]], "input_shapes": [[160,50304],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[672,576,0,8048640,2,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 665, "rf_id": 409, "parent": 660, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[659,300,0,163840,2,"cuda:0"],[664,236,0,51511296,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,50304]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[672,576,0,8048640,2,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 660, "rf_id": 405, "parent": 2, "fw_parent": 0, "seq_id": 216, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[659,300,0,163840,2,"cuda:0"],[235,236,0,51511296,2,"cuda:0"]], "input_shapes": [[20,8,1024],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 674, "rf_id": 415, "parent": 673, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[170,171,0,160,8,"cuda:0"],[20,8],[1,20],"<None>"], "input_shapes": [[8,20],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[675,171,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::transpose", "id": 673, "rf_id": 414, "parent": 2, "fw_parent": 0, "seq_id": 217, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[170,171,0,160,8,"cuda:0"],0,1], "input_shapes": [[8,20],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[675,171,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 679, "rf_id": 419, "parent": 678, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8],4,0,"cuda:0","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[680,681,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_like", "id": 678, "rf_id": 418, "parent": 677, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[675,171,0,160,8,"cuda:0"],4,0,"cuda:0","<None>",0], "input_shapes": [[20,8],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Int"],
      "outputs": [[680,681,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 682, "rf_id": 420, "parent": 677, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[680,681,0,160,8,"cuda:0"],[675,171,0,160,8,"cuda:0"],false], "input_shapes": [[20,8],[20,8],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[680,681,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 677, "rf_id": 417, "parent": 676, "fw_parent": 0, "seq_id": 217, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[675,171,0,160,8,"cuda:0"],0], "input_shapes": [[20,8],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[680,681,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::contiguous", "id": 676, "rf_id": 416, "parent": 2, "fw_parent": 0, "seq_id": 217, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[675,171,0,160,8,"cuda:0"],0], "input_shapes": [[20,8],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[680,681,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_strided", "id": 685, "rf_id": 423, "parent": 684, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,50304],[402432,50304,1],6,0,"cuda:0",false], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","Bool"],
      "outputs": [[686,687,0,8048640,4,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 688, "rf_id": 424, "parent": 684, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[686,687,0,8048640,4,"cuda:0"],[672,576,0,8048640,2,"cuda:0"],false], "input_shapes": [[20,8,50304],[20,8,50304],[]], "input_types": ["Tensor(float)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[686,687,0,8048640,4,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 684, "rf_id": 422, "parent": 683, "fw_parent": 0, "seq_id": 217, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[672,576,0,8048640,2,"cuda:0"],6,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[20,8,50304],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[686,687,0,8048640,4,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 683, "rf_id": 421, "parent": 2, "fw_parent": 0, "seq_id": 217, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[672,576,0,8048640,2,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[20,8,50304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[686,687,0,8048640,4,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 692, "rf_id": 427, "parent": 690, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[691,534,0,160,4,"cuda:0"],[20,8,1],[8,1,0],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[693,534,0,160,4,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 696, "rf_id": 428, "parent": 690, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[694,695,0,160,8,"cuda:0"],[20,8,1],[8,1,0],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[697,695,0,160,8,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::max", "id": 690, "rf_id": 426, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::max.dim(Tensor self, int dim, bool keepdim=False) -> (Tensor values, Tensor indices)",
      "inputs": [[686,687,0,8048640,4,"cuda:0"],-1,false], "input_shapes": [[20,8,50304],[],[]], "input_types": ["Tensor(float)","Int","Bool"],
      "outputs": [[691,534,0,160,4,"cuda:0"],[694,695,0,160,8,"cuda:0"]], "output_shapes": [[20,8],[20,8]], "output_types": ["Tensor(float)","Tensor(long int)"]
    },
    {
      "name": "nccl:all_reduce", "id": 700, "rf_id": 431, "parent": 699, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[691,534,0,160,4,"cuda:0"]], "input_shapes": [[20,8]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 699, "rf_id": 430, "parent": 698, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[691,534,0,160,4,"cuda:0"]],19,94136808529712,0,"allreduce",[],[],1], "input_shapes": [[[20,8]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[691,534,0,160,4,"cuda:0"]]], "output_shapes": [[[20,8]]], "output_types": ["GenericList[Tensor(float)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 698, "rf_id": 429, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[691,534,0,160,4,"cuda:0"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[20,8]],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Object","Object","None","Int"],
      "outputs": [[[691,534,0,160,4,"cuda:0"]],"<Object>"], "output_shapes": [[[20,8]],[]], "output_types": ["GenericList[Tensor(float)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 701, "rf_id": 432, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [19,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 703, "rf_id": 434, "parent": 702, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[691,534,0,160,4,"cuda:0"],[20,8,1],[8,1,1],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[704,534,0,160,4,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::unsqueeze", "id": 702, "rf_id": 433, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[691,534,0,160,4,"cuda:0"],-1], "input_shapes": [[20,8],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[704,534,0,160,4,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sub", "id": 705, "rf_id": 435, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[686,687,0,8048640,4,"cuda:0"],[704,534,0,160,4,"cuda:0"],1], "input_shapes": [[20,8,50304],[20,8,1],[]], "input_types": ["Tensor(float)","Tensor(float)","Int"],
      "outputs": [[706,707,0,8048640,4,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::lt", "id": 708, "rf_id": 436, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[680,681,0,160,8,"cuda:0"],0], "input_shapes": [[20,8],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[709,695,0,160,1,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::ge", "id": 710, "rf_id": 437, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ge.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[680,681,0,160,8,"cuda:0"],50304], "input_shapes": [[20,8],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[711,712,0,160,1,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::bitwise_or", "id": 714, "rf_id": 439, "parent": 713, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::bitwise_or.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[709,695,0,160,1,"cuda:0"],[711,712,0,160,1,"cuda:0"]], "input_shapes": [[20,8],[20,8]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[715,716,0,160,1,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::__or__", "id": 713, "rf_id": 438, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::__or__.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[709,695,0,160,1,"cuda:0"],[711,712,0,160,1,"cuda:0"]], "input_shapes": [[20,8],[20,8]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[715,716,0,160,1,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 718, "rf_id": 441, "parent": 717, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8],[8,1],4,0,"cuda:0","<None>"], "input_shapes": [[[],[]],[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[719,720,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 721, "rf_id": 442, "parent": 717, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[719,720,0,160,8,"cuda:0"],[680,681,0,160,8,"cuda:0"],false], "input_shapes": [[20,8],[20,8],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[719,720,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 717, "rf_id": 440, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[680,681,0,160,8,"cuda:0"],"<None>"], "input_shapes": [[20,8],[]], "input_types": ["Tensor(long int)","None"],
      "outputs": [[719,720,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::sub", "id": 724, "rf_id": 443, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[719,720,0,160,8,"cuda:0"],[722,723,0,1,8,"cpu"],1], "input_shapes": [[20,8],[],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Int"],
      "outputs": [[725,726,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 729, "rf_id": 444, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[727,728,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [[727,728,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 733, "rf_id": 448, "parent": 732, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[727,728,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [0], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 732, "rf_id": 447, "parent": 731, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[727,728,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [0], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::masked_fill_", "id": 734, "rf_id": 449, "parent": 731, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -> Tensor(a!)",
      "inputs": [[725,726,0,160,8,"cuda:0"],[715,716,0,160,1,"cuda:0"],0], "input_shapes": [[20,8],[20,8],[]], "input_types": ["Tensor(long int)","Tensor(bool)","Int"],
      "outputs": [[725,726,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_index_put_impl_", "id": 731, "rf_id": 446, "parent": 730, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_index_put_impl_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False, bool unsafe=False) -> Tensor(a!)",
      "inputs": [[725,726,0,160,8,"cuda:0"],[[715,716,0,160,1,"cuda:0"]],[727,728,0,1,8,"cpu"],false,false], "input_shapes": [[20,8],[[20,8]],[],[],[]], "input_types": ["Tensor(long int)","GenericList[Tensor(bool)]","Tensor(long int)","Bool","Bool"],
      "outputs": [[725,726,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::index_put_", "id": 730, "rf_id": 445, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -> Tensor(a!)",
      "inputs": [[725,726,0,160,8,"cuda:0"],[[715,716,0,160,1,"cuda:0"]],[727,728,0,1,8,"cpu"],false], "input_shapes": [[20,8],[[20,8]],[],[]], "input_types": ["Tensor(long int)","GenericList[Tensor(bool)]","Tensor(long int)","Bool"],
      "outputs": [[725,726,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 735, "rf_id": 450, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[706,707,0,8048640,4,"cuda:0"],[-1,50304]], "input_shapes": [[20,8,50304],[[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int]"],
      "outputs": [[736,707,0,8048640,4,"cuda:0"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 737, "rf_id": 451, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[725,726,0,160,8,"cuda:0"],[-1]], "input_shapes": [[20,8],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[738,726,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 740, "rf_id": 453, "parent": 739, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],4,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[741,57,0,0,8,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::resize_", "id": 743, "rf_id": 455, "parent": 742, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[741,57,0,0,8,"cuda:0"],[160],"<None>"], "input_shapes": [[0],[[]],[]], "input_types": ["Tensor(long int)","GenericList[Int]","None"],
      "outputs": [[741,720,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 742, "rf_id": 454, "parent": 739, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::arange.start_out(Scalar start, Scalar end, Scalar step=1, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [0,160,1,[741,57,0,0,8,"cuda:0"]], "input_shapes": [[],[],[],[0]], "input_types": ["Int","Int","Int","Tensor(long int)"],
      "outputs": [[741,720,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 739, "rf_id": 452, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::arange.start(Scalar start, Scalar end, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [0,160,"<None>","<None>","cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Int","Int","None","None","Device","Bool"],
      "outputs": [[741,720,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 745, "rf_id": 457, "parent": 744, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[736,707,0,8048640,4,"cuda:0"],[160],[0],"<None>"], "input_shapes": [[160,50304],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[746,707,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 748, "rf_id": 459, "parent": 747, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[741,720,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[749,720,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 747, "rf_id": 458, "parent": 744, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[741,720,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[749,720,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 751, "rf_id": 461, "parent": 750, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[738,726,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[752,726,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 750, "rf_id": 460, "parent": 744, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[738,726,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[752,726,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::index", "id": 744, "rf_id": 456, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::index.Tensor(Tensor self, Tensor?[] indices) -> Tensor",
      "inputs": [[736,707,0,8048640,4,"cuda:0"],[[741,720,0,160,8,"cuda:0"],[738,726,0,160,8,"cuda:0"]]], "input_shapes": [[160,50304],[[160],[160]]], "input_types": ["Tensor(float)","GenericList[Tensor(long int),Tensor(long int)]"],
      "outputs": [[753,695,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 755, "rf_id": 463, "parent": 754, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[746,756,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 757, "rf_id": 464, "parent": 754, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[746,756,0,160,4,"cuda:0"],[753,695,0,160,4,"cuda:0"],false], "input_shapes": [[160],[160],[]], "input_types": ["Tensor(float)","Tensor(float)","Bool"],
      "outputs": [[746,756,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::clone", "id": 754, "rf_id": 462, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[753,695,0,160,4,"cuda:0"],"<None>"], "input_shapes": [[160],[]], "input_types": ["Tensor(float)","None"],
      "outputs": [[746,756,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 759, "rf_id": 466, "parent": 758, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[746,756,0,160,4,"cuda:0"],[20,8]], "input_shapes": [[160],[[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int]"],
      "outputs": [[749,756,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view_as", "id": 758, "rf_id": 465, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[746,756,0,160,4,"cuda:0"],[680,681,0,160,8,"cuda:0"]], "input_shapes": [[160],[20,8]], "input_types": ["Tensor(float)","Tensor(long int)"],
      "outputs": [[749,756,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::lift_fresh", "id": 761, "rf_id": 467, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[752,760,0,1,4,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[752,760,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 765, "rf_id": 471, "parent": 764, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[752,760,0,1,4,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [0.000000], "output_shapes": [[]], "output_types": ["Double"]
    },
    {
      "name": "aten::item", "id": 764, "rf_id": 470, "parent": 763, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[752,760,0,1,4,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [0.000000], "output_shapes": [[]], "output_types": ["Double"]
    },
    {
      "name": "aten::masked_fill_", "id": 766, "rf_id": 472, "parent": 763, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -> Tensor(a!)",
      "inputs": [[749,756,0,160,4,"cuda:0"],[715,716,0,160,1,"cuda:0"],0.000000], "input_shapes": [[20,8],[20,8],[]], "input_types": ["Tensor(float)","Tensor(bool)","Double"],
      "outputs": [[749,756,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_index_put_impl_", "id": 763, "rf_id": 469, "parent": 762, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_index_put_impl_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False, bool unsafe=False) -> Tensor(a!)",
      "inputs": [[749,756,0,160,4,"cuda:0"],[[715,716,0,160,1,"cuda:0"]],[752,760,0,1,4,"cpu"],false,false], "input_shapes": [[20,8],[[20,8]],[],[],[]], "input_types": ["Tensor(float)","GenericList[Tensor(bool)]","Tensor(float)","Bool","Bool"],
      "outputs": [[749,756,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::index_put_", "id": 762, "rf_id": 468, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -> Tensor(a!)",
      "inputs": [[749,756,0,160,4,"cuda:0"],[[715,716,0,160,1,"cuda:0"]],[752,760,0,1,4,"cpu"],false], "input_shapes": [[20,8],[[20,8]],[],[]], "input_types": ["Tensor(float)","GenericList[Tensor(bool)]","Tensor(float)","Bool"],
      "outputs": [[749,756,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "nccl:all_reduce", "id": 769, "rf_id": 475, "parent": 768, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[749,756,0,160,4,"cuda:0"]], "input_shapes": [[20,8]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 768, "rf_id": 474, "parent": 767, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[749,756,0,160,4,"cuda:0"]],20,94136808529712,0,"allreduce",[],[],1], "input_shapes": [[[20,8]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[749,756,0,160,4,"cuda:0"]]], "output_shapes": [[[20,8]]], "output_types": ["GenericList[Tensor(float)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 767, "rf_id": 473, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[749,756,0,160,4,"cuda:0"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[20,8]],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Object","Object","None","Int"],
      "outputs": [[[749,756,0,160,4,"cuda:0"]],"<Object>"], "output_shapes": [[[20,8]],[]], "output_types": ["GenericList[Tensor(float)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 770, "rf_id": 476, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [20,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::exp", "id": 771, "rf_id": 477, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::exp.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[706,707,0,8048640,4,"cuda:0"],[706,707,0,8048640,4,"cuda:0"]], "input_shapes": [[20,8,50304],[20,8,50304]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[706,707,0,8048640,4,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 774, "rf_id": 479, "parent": 772, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[773,695,0,160,4,"cuda:0"],[20,8,1],[8,1,0],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[775,695,0,160,4,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sum", "id": 772, "rf_id": 478, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[706,707,0,8048640,4,"cuda:0"],[-1],false,"<None>"], "input_shapes": [[20,8,50304],[[]],[],[]], "input_types": ["Tensor(float)","GenericList[Int]","Bool","None"],
      "outputs": [[773,695,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "nccl:all_reduce", "id": 778, "rf_id": 482, "parent": 777, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[773,695,0,160,4,"cuda:0"]], "input_shapes": [[20,8]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 777, "rf_id": 481, "parent": 776, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[773,695,0,160,4,"cuda:0"]],21,94136808529712,0,"allreduce",[],[],1], "input_shapes": [[[20,8]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[773,695,0,160,4,"cuda:0"]]], "output_shapes": [[[20,8]]], "output_types": ["GenericList[Tensor(float)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 776, "rf_id": 480, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[773,695,0,160,4,"cuda:0"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[20,8]],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Object","Object","None","Int"],
      "outputs": [[[773,695,0,160,4,"cuda:0"]],"<Object>"], "output_shapes": [[[20,8]],[]], "output_types": ["GenericList[Tensor(float)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 779, "rf_id": 483, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [21,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::log", "id": 780, "rf_id": 484, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::log(Tensor self) -> Tensor",
      "inputs": [[773,695,0,160,4,"cuda:0"]], "input_shapes": [[20,8]], "input_types": ["Tensor(float)"],
      "outputs": [[781,782,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sub", "id": 783, "rf_id": 485, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[781,782,0,160,4,"cuda:0"],[749,756,0,160,4,"cuda:0"],1], "input_shapes": [[20,8],[20,8],[]], "input_types": ["Tensor(float)","Tensor(float)","Int"],
      "outputs": [[784,785,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 787, "rf_id": 487, "parent": 786, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[773,695,0,160,4,"cuda:0"],[20,8,1],[8,1,1],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[788,695,0,160,4,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::unsqueeze", "id": 786, "rf_id": 486, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[773,695,0,160,4,"cuda:0"],-1], "input_shapes": [[20,8],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[788,695,0,160,4,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::div_", "id": 789, "rf_id": 488, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[706,707,0,8048640,4,"cuda:0"],[788,695,0,160,4,"cuda:0"]], "input_shapes": [[20,8,50304],[20,8,1]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[706,707,0,8048640,4,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "_VocabParallelCrossEntropy", "id": 689, "rf_id": 425, "parent": 2, "fw_parent": 0, "seq_id": 218, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[686,687,0,8048640,4,"cuda:0"],[680,681,0,160,8,"cuda:0"]], "input_shapes": [[20,8,50304],[20,8]], "input_types": ["Tensor(float)","Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 791, "rf_id": 490, "parent": 790, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[784,785,0,160,4,"cuda:0"],[8,20],[1,8],"<None>"], "input_shapes": [[20,8],[[],[]],[[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[792,785,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::transpose", "id": 790, "rf_id": 489, "parent": 2, "fw_parent": 0, "seq_id": 219, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[784,785,0,160,4,"cuda:0"],0,1], "input_shapes": [[20,8],[],[]], "input_types": ["Tensor(float)","Int","Int"],
      "outputs": [[792,785,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 796, "rf_id": 494, "parent": 795, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],6,0,"cuda:0","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[797,695,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 795, "rf_id": 493, "parent": 794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[792,785,0,160,4,"cuda:0"],6,0,"cuda:0","<None>",0], "input_shapes": [[8,20],[],[],[],[],[]], "input_types": ["Tensor(float)","Int","Int","Device","None","Int"],
      "outputs": [[797,695,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 798, "rf_id": 495, "parent": 794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[797,695,0,160,4,"cuda:0"],[792,785,0,160,4,"cuda:0"],false], "input_shapes": [[8,20],[8,20],[]], "input_types": ["Tensor(float)","Tensor(float)","Bool"],
      "outputs": [[797,695,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::clone", "id": 794, "rf_id": 492, "parent": 793, "fw_parent": 0, "seq_id": 220, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[792,785,0,160,4,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[797,695,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::contiguous", "id": 793, "rf_id": 491, "parent": 2, "fw_parent": 0, "seq_id": 220, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[792,785,0,160,4,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[797,695,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::add", "id": 801, "rf_id": 496, "parent": 2, "fw_parent": 0, "seq_id": 221, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[522,132,0,1,2,"cuda:0"],[799,800,0,1,8,"cpu"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[775,534,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 804, "rf_id": 497, "parent": 2, "fw_parent": 0, "seq_id": 222, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[775,534,0,1,2,"cuda:0"],[802,803,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[805,806,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 807, "rf_id": 498, "parent": 2, "fw_parent": 0, "seq_id": 223, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[797,695,0,160,4,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[8,20],[],[],[],[]], "input_types": ["Tensor(float)","Int","Bool","Bool","None"],
      "outputs": [[797,695,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 808, "rf_id": 499, "parent": 2, "fw_parent": 0, "seq_id": 223, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[197,198,0,160,4,"cuda:0"],[-1]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(float)","GenericList[Int]"],
      "outputs": [[809,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 810, "rf_id": 500, "parent": 2, "fw_parent": 0, "seq_id": 223, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[809,198,0,160,4,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[160],[],[],[],[]], "input_types": ["Tensor(float)","Int","Bool","Bool","None"],
      "outputs": [[809,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 811, "rf_id": 501, "parent": 2, "fw_parent": 0, "seq_id": 223, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[797,695,0,160,4,"cuda:0"],[-1]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(float)","GenericList[Int]"],
      "outputs": [[812,695,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul", "id": 813, "rf_id": 502, "parent": 2, "fw_parent": 0, "seq_id": 224, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[812,695,0,160,4,"cuda:0"],[809,198,0,160,4,"cuda:0"]], "input_shapes": [[160],[160]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[814,132,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 818, "rf_id": 505, "parent": 816, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[817,681,0,1,4,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[819,681,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sum", "id": 816, "rf_id": 504, "parent": 815, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[814,132,0,160,4,"cuda:0"],[],false,"<None>"], "input_shapes": [[160],[],[],[]], "input_types": ["Tensor(float)","GenericList[]","Bool","None"],
      "outputs": [[817,681,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sum", "id": 815, "rf_id": 503, "parent": 2, "fw_parent": 0, "seq_id": 225, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum(Tensor self, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[814,132,0,160,4,"cuda:0"],"<None>"], "input_shapes": [[160],[]], "input_types": ["Tensor(float)","None"],
      "outputs": [[817,681,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 824, "rf_id": 508, "parent": 821, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[822,823,0,1,4,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[825,823,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sum", "id": 821, "rf_id": 507, "parent": 820, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[809,198,0,160,4,"cuda:0"],[],false,"<None>"], "input_shapes": [[160],[],[],[]], "input_types": ["Tensor(float)","GenericList[]","Bool","None"],
      "outputs": [[822,823,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sum", "id": 820, "rf_id": 506, "parent": 2, "fw_parent": 0, "seq_id": 226, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum(Tensor self, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[809,198,0,160,4,"cuda:0"],"<None>"], "input_shapes": [[160],[]], "input_types": ["Tensor(float)","None"],
      "outputs": [[822,823,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::div", "id": 826, "rf_id": 509, "parent": 2, "fw_parent": 0, "seq_id": 226, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[817,681,0,1,4,"cuda:0"],[822,823,0,1,4,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[825,827,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 829, "rf_id": 511, "parent": 828, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],6,0,"cuda:0","<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","None"],
      "outputs": [[819,681,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 830, "rf_id": 512, "parent": 828, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[819,681,0,1,4,"cuda:0"],[825,827,0,1,4,"cuda:0"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(float)","Bool"],
      "outputs": [[819,681,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::clone", "id": 828, "rf_id": 510, "parent": 2, "fw_parent": 0, "seq_id": 227, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[825,827,0,1,4,"cuda:0"],"<None>"], "input_shapes": [[],[]], "input_types": ["Tensor(float)","None"],
      "outputs": [[819,681,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "detach", "id": 832, "rf_id": 514, "parent": 831, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[819,681,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 831, "rf_id": 513, "parent": 2, "fw_parent": 0, "seq_id": 228, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[819,681,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[833,681,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 834, "rf_id": 515, "parent": 2, "fw_parent": 0, "seq_id": 228, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[833,681,0,1,4,"cuda:0"],[1]], "input_shapes": [[],[[]]], "input_types": ["Tensor(float)","GenericList[Int]"],
      "outputs": [[835,681,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 840, "rf_id": 519, "parent": 839, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[837,132,0,1,4,"cuda:0"],[1],[1],0], "input_shapes": [[1],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[841,132,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::slice", "id": 839, "rf_id": 518, "parent": 838, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[837,132,0,1,4,"cuda:0"],0,0,1,1], "input_shapes": [[1],[],[],[],[]], "input_types": ["Tensor(float)","Int","Int","Int","Int"],
      "outputs": [[841,132,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::narrow", "id": 838, "rf_id": 517, "parent": 836, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[837,132,0,1,4,"cuda:0"],0,0,1], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(float)","Int","Int","Int"],
      "outputs": [[841,132,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::cat", "id": 836, "rf_id": 516, "parent": 2, "fw_parent": 0, "seq_id": 228, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[835,681,0,1,4,"cuda:0"]],0], "input_shapes": [[[1]],[]], "input_types": ["GenericList[Tensor(float)]","Int"],
      "outputs": [[837,132,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "nccl:all_reduce", "id": 844, "rf_id": 522, "parent": 843, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[837,132,0,1,4,"cuda:0"]], "input_shapes": [[1]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 843, "rf_id": 521, "parent": 842, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[837,132,0,1,4,"cuda:0"]],37,94136803877936,0,"allreduce",[],[],4], "input_shapes": [[[1]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[837,132,0,1,4,"cuda:0"]]], "output_shapes": [[[1]]], "output_types": ["GenericList[Tensor(float)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 842, "rf_id": 520, "parent": 2, "fw_parent": 0, "seq_id": 228, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[837,132,0,1,4,"cuda:0"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[1]],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Object","Object","None","Int"],
      "outputs": [[[837,132,0,1,4,"cuda:0"]],"<Object>"], "output_shapes": [[[1]],[]], "output_types": ["GenericList[Tensor(float)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 845, "rf_id": 523, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [37,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::div", "id": 848, "rf_id": 524, "parent": 2, "fw_parent": 0, "seq_id": 228, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[837,132,0,1,4,"cuda:0"],[846,847,0,1,8,"cpu"]], "input_shapes": [[1],[]], "input_types": ["Tensor(float)","Tensor(long int)"],
      "outputs": [[849,681,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 851, "rf_id": 526, "parent": 850, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[849,681,0,1,4,"cuda:0"],[],[],0], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(float)","GenericList[]","GenericList[]","Int"],
      "outputs": [[841,681,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::select", "id": 850, "rf_id": 525, "parent": 2, "fw_parent": 0, "seq_id": 228, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[849,681,0,1,4,"cuda:0"],0,0], "input_shapes": [[1],[],[]], "input_types": ["Tensor(float)","Int","Int"],
      "outputs": [[841,681,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 854, "rf_id": 529, "parent": 853, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[805,695,0,1,4,"cuda:0"],[],[],"<None>"], "input_shapes": [[],[],[],[]], "input_types": ["Tensor(float)","GenericList[]","GenericList[]","None"],
      "outputs": [[855,695,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mean", "id": 853, "rf_id": 528, "parent": 852, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mean.dim(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[825,827,0,1,4,"cuda:0"],[],false,"<None>"], "input_shapes": [[],[],[],[]], "input_types": ["Tensor(float)","GenericList[]","Bool","None"],
      "outputs": [[805,695,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mean", "id": 852, "rf_id": 527, "parent": 2, "fw_parent": 0, "seq_id": 228, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mean(Tensor self, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[825,827,0,1,4,"cuda:0"],"<None>"], "input_shapes": [[],[]], "input_types": ["Tensor(float)","None"],
      "outputs": [[805,695,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 857, "rf_id": 531, "parent": 856, "fw_parent": 0, "seq_id": 229, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[805,695,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [10.858118], "output_shapes": [[]], "output_types": ["Double"]
    },
    {
      "name": "aten::item", "id": 856, "rf_id": 530, "parent": 2, "fw_parent": 0, "seq_id": 229, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[805,695,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [10.858118], "output_shapes": [[]], "output_types": ["Double"]
    },
    {
      "name": "aten::empty", "id": 858, "rf_id": 532, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[500000000],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[855,859,0,500000000,2,"cuda:0"]], "output_shapes": [[500000000]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 860, "rf_id": 533, "parent": 2, "fw_parent": 0, "seq_id": 229, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[825,827,0,1,4,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(float)","Int","Bool","Bool","None"],
      "outputs": [[825,827,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul", "id": 862, "rf_id": 534, "parent": 2, "fw_parent": 0, "seq_id": 229, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[825,827,0,1,4,"cuda:0"],[693,861,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[863,695,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 866, "rf_id": 537, "parent": 865, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],6,0,"cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[867,712,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 865, "rf_id": 536, "parent": 864, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[863,695,0,1,4,"cuda:0"],"<None>","<None>","<None>",false,1], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","Bool","Int"],
      "outputs": [[867,712,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::fill_", "id": 868, "rf_id": 538, "parent": 864, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[867,712,0,1,4,"cuda:0"],1.000000], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [[867,712,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::ones_like", "id": 864, "rf_id": 535, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ones_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[863,695,0,1,4,"cuda:0"],"<None>","<None>","<None>",false,1], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","Bool","Int"],
      "outputs": [[867,712,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "[pytorch|profiler|execution_trace|thread]", "id": 869, "rf_id": 0, "parent": 1, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::mul", "id": 872, "rf_id": 541, "parent": 871, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[867,712,0,1,4,"cuda:0"],[693,861,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[873,720,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "MulBackward0", "id": 871, "rf_id": 540, "parent": 870, "fw_parent": 2, "seq_id": 229, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[867,712,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: MulBackward0", "id": 870, "rf_id": 539, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::div", "id": 876, "rf_id": 544, "parent": 875, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::div.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[873,720,0,1,4,"cuda:0"],[822,823,0,1,4,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[877,878,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "DivBackward0", "id": 875, "rf_id": 543, "parent": 874, "fw_parent": 2, "seq_id": 226, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[873,720,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: DivBackward0", "id": 874, "rf_id": 542, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 882, "rf_id": 548, "parent": 881, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[877,878,0,1,4,"cuda:0"],[160],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[883,878,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::expand", "id": 881, "rf_id": 547, "parent": 880, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)",
      "inputs": [[877,878,0,1,4,"cuda:0"],[160],false], "input_shapes": [[],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","Bool"],
      "outputs": [[883,878,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "SumBackward0", "id": 880, "rf_id": 546, "parent": 879, "fw_parent": 2, "seq_id": 225, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[877,878,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SumBackward0", "id": 879, "rf_id": 545, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::mul", "id": 886, "rf_id": 551, "parent": 885, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[883,878,0,160,4,"cuda:0"],[809,198,0,160,4,"cuda:0"]], "input_shapes": [[160],[160]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[887,756,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "MulBackward0", "id": 885, "rf_id": 550, "parent": 884, "fw_parent": 2, "seq_id": 224, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[883,878,0,160,4,"cuda:0"]], "input_shapes": [[160]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: MulBackward0", "id": 884, "rf_id": 549, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 891, "rf_id": 555, "parent": 890, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[887,756,0,160,4,"cuda:0"],[8,20]], "input_shapes": [[160],[[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int]"],
      "outputs": [[892,756,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::reshape", "id": 890, "rf_id": 554, "parent": 889, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[887,756,0,160,4,"cuda:0"],[8,20]], "input_shapes": [[160],[[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int]"],
      "outputs": [[892,756,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "ViewBackward0", "id": 889, "rf_id": 553, "parent": 888, "fw_parent": 2, "seq_id": 223, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[887,756,0,160,4,"cuda:0"]], "input_shapes": [[160]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 888, "rf_id": 552, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "CloneBackward0", "id": 894, "rf_id": 557, "parent": 893, "fw_parent": 2, "seq_id": 220, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[892,756,0,160,4,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: CloneBackward0", "id": 893, "rf_id": 556, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 898, "rf_id": 561, "parent": 897, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[892,756,0,160,4,"cuda:0"],[20,8],[1,20],"<None>"], "input_shapes": [[8,20],[[],[]],[[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[899,756,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::transpose", "id": 897, "rf_id": 560, "parent": 896, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[892,756,0,160,4,"cuda:0"],0,1], "input_shapes": [[8,20],[],[]], "input_types": ["Tensor(float)","Int","Int"],
      "outputs": [[899,756,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "TransposeBackward0", "id": 896, "rf_id": 559, "parent": 895, "fw_parent": 2, "seq_id": 219, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[892,756,0,160,4,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 895, "rf_id": 558, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 902, "rf_id": 564, "parent": 901, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[706,707,0,8048640,4,"cuda:0"],[-1,50304]], "input_shapes": [[20,8,50304],[[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int]"],
      "outputs": [[903,707,0,8048640,4,"cuda:0"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 905, "rf_id": 566, "parent": 904, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],4,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[906,57,0,0,8,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::resize_", "id": 908, "rf_id": 568, "parent": 907, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[906,57,0,0,8,"cuda:0"],[160],"<None>"], "input_shapes": [[0],[[]],[]], "input_types": ["Tensor(long int)","GenericList[Int]","None"],
      "outputs": [[906,720,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 907, "rf_id": 567, "parent": 904, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::arange.start_out(Scalar start, Scalar end, Scalar step=1, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [0,160,1,[906,57,0,0,8,"cuda:0"]], "input_shapes": [[],[],[],[0]], "input_types": ["Int","Int","Int","Tensor(long int)"],
      "outputs": [[906,720,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 904, "rf_id": 565, "parent": 901, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::arange.start(Scalar start, Scalar end, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [0,160,"<None>","<None>","cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Int","Int","None","None","Device","Bool"],
      "outputs": [[906,720,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 909, "rf_id": 569, "parent": 901, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[715,716,0,160,1,"cuda:0"],[-1]], "input_shapes": [[20,8],[[]]], "input_types": ["Tensor(bool)","GenericList[Int]"],
      "outputs": [[910,716,0,160,1,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 913, "rf_id": 572, "parent": 912, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[914,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 915, "rf_id": 573, "parent": 912, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[914,198,0,160,4,"cuda:0"],[910,716,0,160,1,"cuda:0"],false], "input_shapes": [[160],[160],[]], "input_types": ["Tensor(float)","Tensor(bool)","Bool"],
      "outputs": [[914,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 912, "rf_id": 571, "parent": 911, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[910,716,0,160,1,"cuda:0"],6,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[160],[],[],[],[],[],[]], "input_types": ["Tensor(bool)","Int","None","None","None","Bool","None"],
      "outputs": [[914,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 911, "rf_id": 570, "parent": 901, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[910,716,0,160,1,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[160],[],[],[],[]], "input_types": ["Tensor(bool)","Int","Bool","Bool","None"],
      "outputs": [[914,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sub", "id": 919, "rf_id": 575, "parent": 916, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[917,918,0,1,8,"cpu"],[914,198,0,160,4,"cuda:0"],1], "input_shapes": [[],[160],[]], "input_types": ["Tensor(double)","Tensor(float)","Int"],
      "outputs": [[920,782,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::rsub", "id": 916, "rf_id": 574, "parent": 901, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::rsub.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[914,198,0,160,4,"cuda:0"],1.000000,1], "input_shapes": [[160],[],[]], "input_types": ["Tensor(float)","Double","Int"],
      "outputs": [[920,782,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 922, "rf_id": 577, "parent": 921, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[903,707,0,8048640,4,"cuda:0"],[160],[0],"<None>"], "input_shapes": [[160,50304],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[923,707,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 925, "rf_id": 579, "parent": 924, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[906,720,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[926,720,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 924, "rf_id": 578, "parent": 921, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[906,720,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[926,720,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 928, "rf_id": 581, "parent": 927, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[738,726,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[929,726,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 927, "rf_id": 580, "parent": 921, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[738,726,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[929,726,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::index", "id": 921, "rf_id": 576, "parent": 901, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::index.Tensor(Tensor self, Tensor?[] indices) -> Tensor",
      "inputs": [[903,707,0,8048640,4,"cuda:0"],[[906,720,0,160,8,"cuda:0"],[738,726,0,160,8,"cuda:0"]]], "input_shapes": [[160,50304],[[160],[160]]], "input_types": ["Tensor(float)","GenericList[Tensor(long int),Tensor(long int)]"],
      "outputs": [[930,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sub_", "id": 931, "rf_id": 582, "parent": 901, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sub_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)",
      "inputs": [[930,198,0,160,4,"cuda:0"],[920,782,0,160,4,"cuda:0"],1], "input_shapes": [[160],[160],[]], "input_types": ["Tensor(float)","Tensor(float)","Int"],
      "outputs": [[930,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 934, "rf_id": 585, "parent": 933, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[903,707,0,8048640,4,"cuda:0"],[160],[0],"<None>"], "input_shapes": [[160,50304],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[929,707,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 936, "rf_id": 587, "parent": 935, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[906,720,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[937,720,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 935, "rf_id": 586, "parent": 933, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[906,720,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[937,720,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 939, "rf_id": 589, "parent": 938, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[738,726,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[940,726,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 938, "rf_id": 588, "parent": 933, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[738,726,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[940,726,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_index_put_impl_", "id": 933, "rf_id": 584, "parent": 932, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_index_put_impl_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False, bool unsafe=False) -> Tensor(a!)",
      "inputs": [[903,707,0,8048640,4,"cuda:0"],[[906,720,0,160,8,"cuda:0"],[738,726,0,160,8,"cuda:0"]],[930,198,0,160,4,"cuda:0"],false,false], "input_shapes": [[160,50304],[[160],[160]],[160],[],[]], "input_types": ["Tensor(float)","GenericList[Tensor(long int),Tensor(long int)]","Tensor(float)","Bool","Bool"],
      "outputs": [[903,707,0,8048640,4,"cuda:0"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::index_put_", "id": 932, "rf_id": 583, "parent": 901, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -> Tensor(a!)",
      "inputs": [[903,707,0,8048640,4,"cuda:0"],[[906,720,0,160,8,"cuda:0"],[738,726,0,160,8,"cuda:0"]],[930,198,0,160,4,"cuda:0"],false], "input_shapes": [[160,50304],[[160],[160]],[160],[]], "input_types": ["Tensor(float)","GenericList[Tensor(long int),Tensor(long int)]","Tensor(float)","Bool"],
      "outputs": [[903,707,0,8048640,4,"cuda:0"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 942, "rf_id": 591, "parent": 941, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[899,756,0,160,4,"cuda:0"],[20,8,1],[1,20,1],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[929,756,0,160,4,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::unsqueeze", "id": 941, "rf_id": 590, "parent": 901, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[899,756,0,160,4,"cuda:0"],-1], "input_shapes": [[20,8],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[929,756,0,160,4,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul_", "id": 943, "rf_id": 592, "parent": 901, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[706,707,0,8048640,4,"cuda:0"],[929,756,0,160,4,"cuda:0"]], "input_shapes": [[20,8,50304],[20,8,1]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[706,707,0,8048640,4,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "_VocabParallelCrossEntropyBackward", "id": 901, "rf_id": 563, "parent": 900, "fw_parent": 2, "seq_id": 218, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[899,756,0,160,4,"cuda:0"]], "input_shapes": [[20,8]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _VocabParallelCrossEntropyBackward", "id": 900, "rf_id": 562, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 948, "rf_id": 597, "parent": 947, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,50304],[402432,50304,1],15,0,"cuda:0",false], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","Bool"],
      "outputs": [[940,576,0,8048640,2,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 949, "rf_id": 598, "parent": 947, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[940,576,0,8048640,2,"cuda:0"],[706,707,0,8048640,4,"cuda:0"],false], "input_shapes": [[20,8,50304],[20,8,50304],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(float)","Bool"],
      "outputs": [[940,576,0,8048640,2,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_to_copy", "id": 947, "rf_id": 596, "parent": 946, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[706,707,0,8048640,4,"cuda:0"],15,0,"cuda:0","<None>",false,"<None>"], "input_shapes": [[20,8,50304],[],[],[],[],[],[]], "input_types": ["Tensor(float)","Int","Int","Device","None","Bool","None"],
      "outputs": [[940,576,0,8048640,2,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 946, "rf_id": 595, "parent": 945, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[706,707,0,8048640,4,"cuda:0"],15,0,"cuda:0","<None>",false,false,"<None>"], "input_shapes": [[20,8,50304],[],[],[],[],[],[],[]], "input_types": ["Tensor(float)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[940,576,0,8048640,2,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ToCopyBackward0", "id": 945, "rf_id": 594, "parent": 944, "fw_parent": 2, "seq_id": 217, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[706,707,0,8048640,4,"cuda:0"]], "input_shapes": [[20,8,50304]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ToCopyBackward0", "id": 944, "rf_id": 593, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 954, "rf_id": 603, "parent": 953, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[940,576,0,8048640,2,"cuda:0"],[160,50304]], "input_shapes": [[20,8,50304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[955,576,0,8048640,2,"cuda:0"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 953, "rf_id": 602, "parent": 952, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[940,576,0,8048640,2,"cuda:0"],[160,50304]], "input_shapes": [[20,8,50304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[955,576,0,8048640,2,"cuda:0"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 956, "rf_id": 604, "parent": 952, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[955,576,0,8048640,2,"cuda:0"],[235,236,0,51511296,2,"cuda:0"]], "input_shapes": [[160,50304],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[937,245,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 957, "rf_id": 605, "parent": 952, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[937,245,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[958,245,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 952, "rf_id": 601, "parent": 951, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[940,576,0,8048640,2,"cuda:0"],[235,236,0,51511296,2,"cuda:0"]], "input_shapes": [[20,8,50304],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[958,245,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 959, "rf_id": 606, "parent": 951, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[940,576,0,8048640,2,"cuda:0"],[160,50304]], "input_shapes": [[20,8,50304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[960,576,0,8048640,2,"cuda:0"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 961, "rf_id": 607, "parent": 951, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[659,300,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[962,300,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 965, "rf_id": 610, "parent": 964, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[960,576,0,8048640,2,"cuda:0"],[50304,160],[1,50304],"<None>"], "input_shapes": [[160,50304],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[926,576,0,8048640,2,"cuda:0"]], "output_shapes": [[50304,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 964, "rf_id": 609, "parent": 963, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[960,576,0,8048640,2,"cuda:0"],0,1], "input_shapes": [[160,50304],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[926,576,0,8048640,2,"cuda:0"]], "output_shapes": [[50304,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 963, "rf_id": 608, "parent": 951, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[960,576,0,8048640,2,"cuda:0"]], "input_shapes": [[160,50304]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[926,576,0,8048640,2,"cuda:0"]], "output_shapes": [[50304,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 967, "rf_id": 612, "parent": 966, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[926,576,0,8048640,2,"cuda:0"],[962,300,0,163840,2,"cuda:0"]], "input_shapes": [[50304,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[923,707,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 966, "rf_id": 611, "parent": 951, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[926,576,0,8048640,2,"cuda:0"],[962,300,0,163840,2,"cuda:0"]], "input_shapes": [[50304,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[923,707,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 951, "rf_id": 600, "parent": 950, "fw_parent": 2, "seq_id": 216, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[940,576,0,8048640,2,"cuda:0"]], "input_shapes": [[20,8,50304]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 950, "rf_id": 599, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_CopyToModelParallelRegionBackward", "id": 969, "rf_id": 614, "parent": 968, "fw_parent": 2, "seq_id": 215, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[958,245,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _CopyToModelParallelRegionBackward", "id": 968, "rf_id": 613, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 974, "rf_id": 618, "parent": 973, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[975,266,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 973, "rf_id": 617, "parent": 971, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[972,300,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[975,266,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 977, "rf_id": 620, "parent": 976, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[978,132,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 976, "rf_id": 619, "parent": 971, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[646,294,13312,1024,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[978,132,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 980, "rf_id": 622, "parent": 979, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[981,716,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 979, "rf_id": 621, "parent": 971, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[647,294,14336,1024,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[981,716,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 982, "rf_id": 623, "parent": 971, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[16,1024],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[983,401,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 985, "rf_id": 625, "parent": 984, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[16,1024],[1024,1],6,0,"cuda:0","<None>"], "input_shapes": [[[],[]],[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[986,987,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 984, "rf_id": 624, "parent": 971, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[983,401,0,16384,4,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[16,1024],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[986,987,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunctionBackward", "id": 971, "rf_id": 616, "parent": 970, "fw_parent": 2, "seq_id": 214, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[958,245,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: FusedLayerNormAffineFunctionBackward", "id": 970, "rf_id": 615, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 991, "rf_id": 629, "parent": 990, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[978,132,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 990, "rf_id": 628, "parent": 989, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[978,132,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[992,132,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 989, "rf_id": 627, "parent": 988, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[978,132,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 995, "rf_id": 632, "parent": 994, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[1024],[1],0], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[655,859,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 994, "rf_id": 631, "parent": 993, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,0,1024,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[655,859,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 993, "rf_id": 630, "parent": 988, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,0,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[655,859,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 996, "rf_id": 633, "parent": 988, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[992,132,0,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[997,132,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 998, "rf_id": 634, "parent": 988, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[655,859,0,1024,2,"cuda:0"],[997,132,0,1024,2,"cuda:0"],false], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[655,859,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1000, "rf_id": 636, "parent": 999, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[986,859,0,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1001,859,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 999, "rf_id": 635, "parent": 988, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[986,859,0,1024,2,"cuda:0"],[992,132,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1001,859,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1002, "rf_id": 637, "parent": 988, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[992,132,0,1024,2,"cuda:0"],[1001,859,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 988, "rf_id": 626, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1006, "rf_id": 641, "parent": 1005, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[981,716,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1005, "rf_id": 640, "parent": 1004, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[981,716,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1007,716,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 1004, "rf_id": 639, "parent": 1003, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[981,716,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1010, "rf_id": 644, "parent": 1009, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[1024],[1],1024], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1011,859,1024,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1009, "rf_id": 643, "parent": 1008, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,1024,2048,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1011,859,1024,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 1008, "rf_id": 642, "parent": 1003, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,1024,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1011,859,1024,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1012, "rf_id": 645, "parent": 1003, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1007,716,0,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1013,716,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1014, "rf_id": 646, "parent": 1003, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1011,859,1024,1024,2,"cuda:0"],[1013,716,0,1024,2,"cuda:0"],false], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1011,859,1024,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1017, "rf_id": 648, "parent": 1016, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1015,859,1024,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1018,859,1024,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1016, "rf_id": 647, "parent": 1003, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1015,859,1024,1024,2,"cuda:0"],[1007,716,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1018,859,1024,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1019, "rf_id": 649, "parent": 1003, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[1007,716,0,1024,2,"cuda:0"],[1018,859,1024,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 1003, "rf_id": 638, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1024, "rf_id": 653, "parent": 1023, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","None","None"],
      "outputs": [[1025,823,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 1027, "rf_id": 655, "parent": 1026, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1025,823,0,1,2,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1025,823,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 1026, "rf_id": 654, "parent": 1023, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1025,823,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1025,823,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 1023, "rf_id": 652, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],15,0,"cuda:0","<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","None"],
      "outputs": [[1025,823,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1029, "rf_id": 657, "parent": 1028, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[289,290,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1028, "rf_id": 656, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[289,290,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1030,290,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1032, "rf_id": 659, "parent": 1031, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[226,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1031, "rf_id": 658, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[226,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[1033,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 1036, "rf_id": 662, "parent": 1035, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1037,245,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1035, "rf_id": 661, "parent": 1034, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1030,290,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1037,245,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1038, "rf_id": 663, "parent": 1034, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[160],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[1039,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 1041, "rf_id": 665, "parent": 1040, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[1042,306,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 1040, "rf_id": 664, "parent": 1034, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1039,198,0,160,4,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[160],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[1042,306,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunction", "id": 1034, "rf_id": 660, "parent": 1022, "fw_parent": 0, "seq_id": 159, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1030,290,0,163840,2,"cuda:0"],[293,294,0,1024,2,"cuda:0"],[295,294,1024,1024,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1045, "rf_id": 668, "parent": 1044, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1037,245,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1046,245,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1044, "rf_id": 667, "parent": 1043, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1037,245,0,163840,2,"cuda:0"],[1037,245,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1046,245,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_CopyToModelParallelRegion", "id": 1043, "rf_id": 666, "parent": 1022, "fw_parent": 0, "seq_id": 160, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1037,245,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1050, "rf_id": 672, "parent": 1049, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[310,236,51531776,3145728,2,"cuda:0"],[1024,3072],[1,1024],"<None>"], "input_shapes": [[3072,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1051,236,51531776,3145728,2,"cuda:0"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1049, "rf_id": 671, "parent": 1048, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[310,236,51531776,3145728,2,"cuda:0"],0,1], "input_shapes": [[3072,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1051,236,51531776,3145728,2,"cuda:0"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1048, "rf_id": 670, "parent": 1047, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[310,236,51531776,3145728,2,"cuda:0"]], "input_shapes": [[3072,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1051,236,51531776,3145728,2,"cuda:0"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1054, "rf_id": 675, "parent": 1053, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1046,245,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1055,245,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1053, "rf_id": 674, "parent": 1052, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1046,245,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1055,245,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1056, "rf_id": 676, "parent": 1052, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1055,245,0,163840,2,"cuda:0"],[1051,236,51531776,3145728,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1057,323,0,491520,2,"cuda:0"]], "output_shapes": [[160,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1058, "rf_id": 677, "parent": 1052, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1057,323,0,491520,2,"cuda:0"],[20,8,3072]], "input_shapes": [[160,3072],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1059,323,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1052, "rf_id": 673, "parent": 1047, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1046,245,0,163840,2,"cuda:0"],[1051,236,51531776,3145728,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1059,323,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1060, "rf_id": 678, "parent": 1047, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1059,323,0,491520,2,"cuda:0"],[311,294,2048,3072,2,"cuda:0"],1], "input_shapes": [[20,8,3072],[3072],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1061,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 1047, "rf_id": 669, "parent": 1022, "fw_parent": 0, "seq_id": 161, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1046,245,0,163840,2,"cuda:0"],[310,236,51531776,3145728,2,"cuda:0"],[311,294,2048,3072,2,"cuda:0"]], "input_shapes": [[20,8,1024],[3072,1024],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1062, "rf_id": 679, "parent": 1022, "fw_parent": 0, "seq_id": 162, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1061,328,0,491520,2,"cuda:0"],[20,8,-1,3,64]], "input_shapes": [[20,8,3072],[[],[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]"],
      "outputs": [[1063,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1065, "rf_id": 681, "parent": 1064, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1063,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1066,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1064, "rf_id": 680, "parent": 1022, "fw_parent": 0, "seq_id": 163, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1063,328,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1066,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1068, "rf_id": 683, "parent": 1067, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1066,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1069,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1067, "rf_id": 682, "parent": 1022, "fw_parent": 0, "seq_id": 164, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1066,328,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1069,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1071, "rf_id": 685, "parent": 1070, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1069,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1072,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1070, "rf_id": 684, "parent": 1022, "fw_parent": 0, "seq_id": 165, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1069,328,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1072,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1074, "rf_id": 687, "parent": 1073, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1072,328,0,491520,2,"cuda:0"],[20,8,16,1,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1075,328,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1073, "rf_id": 686, "parent": 1022, "fw_parent": 0, "seq_id": 166, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1072,328,0,491520,2,"cuda:0"],3,0,-2,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1075,328,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1077, "rf_id": 689, "parent": 1076, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1075,328,0,163840,2,"cuda:0"],[20,8,16,1,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,1,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1078,328,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1076, "rf_id": 688, "parent": 1022, "fw_parent": 0, "seq_id": 167, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1075,328,0,163840,2,"cuda:0"],4,0,9223372036854775807,1], "input_shapes": [[20,8,16,1,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1078,328,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_reshape_alias", "id": 1080, "rf_id": 691, "parent": 1079, "fw_parent": 0, "seq_id": 168, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[1078,328,0,163840,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1]], "input_shapes": [[20,8,16,1,64],[[],[],[],[]],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1081,328,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1079, "rf_id": 690, "parent": 1022, "fw_parent": 0, "seq_id": 168, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1078,328,0,163840,2,"cuda:0"],[20,8,-1,64]], "input_shapes": [[20,8,16,1,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1081,328,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1083, "rf_id": 693, "parent": 1082, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1063,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1084,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1082, "rf_id": 692, "parent": 1022, "fw_parent": 0, "seq_id": 169, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1063,328,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1084,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1086, "rf_id": 695, "parent": 1085, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1084,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1087,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1085, "rf_id": 694, "parent": 1022, "fw_parent": 0, "seq_id": 170, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1084,328,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1087,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1089, "rf_id": 697, "parent": 1088, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1087,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1090,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1088, "rf_id": 696, "parent": 1022, "fw_parent": 0, "seq_id": 171, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1087,328,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1090,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1092, "rf_id": 699, "parent": 1091, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1090,328,0,491520,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],64], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[1093,328,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 1091, "rf_id": 698, "parent": 1022, "fw_parent": 0, "seq_id": 172, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[1090,328,0,491520,2,"cuda:0"],3,-2], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1093,328,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1095, "rf_id": 701, "parent": 1094, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1093,328,64,163840,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],64], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[1096,328,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1094, "rf_id": 700, "parent": 1022, "fw_parent": 0, "seq_id": 173, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1093,328,64,163840,2,"cuda:0"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1096,328,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1098, "rf_id": 703, "parent": 1097, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1063,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1099,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1097, "rf_id": 702, "parent": 1022, "fw_parent": 0, "seq_id": 174, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1063,328,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1099,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1101, "rf_id": 705, "parent": 1100, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1099,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1102,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1100, "rf_id": 704, "parent": 1022, "fw_parent": 0, "seq_id": 175, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1099,328,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1102,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1104, "rf_id": 707, "parent": 1103, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1102,328,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1105,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1103, "rf_id": 706, "parent": 1022, "fw_parent": 0, "seq_id": 176, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1102,328,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1105,328,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1107, "rf_id": 709, "parent": 1106, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1105,328,0,491520,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],128], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[1108,328,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 1106, "rf_id": 708, "parent": 1022, "fw_parent": 0, "seq_id": 177, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[1105,328,0,491520,2,"cuda:0"],3,-1], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1108,328,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1110, "rf_id": 711, "parent": 1109, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1108,328,128,163840,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],128], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[1111,328,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1109, "rf_id": 710, "parent": 1022, "fw_parent": 0, "seq_id": 178, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1108,328,128,163840,2,"cuda:0"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1111,328,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1112, "rf_id": 712, "parent": 1022, "fw_parent": 0, "seq_id": 179, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1081,328,0,163840,2,"cuda:0"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1113,328,0,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1114, "rf_id": 713, "parent": 1022, "fw_parent": 0, "seq_id": 180, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1096,328,64,163840,2,"cuda:0"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1115,328,64,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1117, "rf_id": 715, "parent": 1116, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[383,384,0,51200,2,"cuda:0"],[51200],[1],0], "input_shapes": [[51200],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1118,384,0,51200,2,"cuda:0"]], "output_shapes": [[51200]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1116, "rf_id": 714, "parent": 1022, "fw_parent": 0, "seq_id": 181, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[383,384,0,51200,2,"cuda:0"],0,0,51200,1], "input_shapes": [[51200],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1118,384,0,51200,2,"cuda:0"]], "output_shapes": [[51200]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1119, "rf_id": 716, "parent": 1022, "fw_parent": 0, "seq_id": 181, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1118,384,0,51200,2,"cuda:0"],[128,20,20]], "input_shapes": [[51200],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1120,384,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1122, "rf_id": 718, "parent": 1121, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1113,328,0,163840,2,"cuda:0"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1123,328,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1121, "rf_id": 717, "parent": 1022, "fw_parent": 0, "seq_id": 181, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1113,328,0,163840,2,"cuda:0"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1123,328,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1125, "rf_id": 720, "parent": 1124, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1115,328,64,163840,2,"cuda:0"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1126,328,64,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1124, "rf_id": 719, "parent": 1022, "fw_parent": 0, "seq_id": 182, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1115,328,64,163840,2,"cuda:0"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1126,328,64,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1128, "rf_id": 722, "parent": 1127, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1126,328,64,163840,2,"cuda:0"],[128,64,20],[192,1,24576],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1129,328,64,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1127, "rf_id": 721, "parent": 1022, "fw_parent": 0, "seq_id": 183, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1126,328,64,163840,2,"cuda:0"],1,2], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1129,328,64,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::baddbmm", "id": 1130, "rf_id": 723, "parent": 1022, "fw_parent": 0, "seq_id": 184, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor",
      "inputs": [[1120,384,0,51200,2,"cuda:0"],[1123,328,0,163840,2,"cuda:0"],[1129,328,64,163840,2,"cuda:0"],0.000000,0.125000], "input_shapes": [[128,20,20],[128,20,64],[128,64,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Double","Double"],
      "outputs": [[1131,421,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1132, "rf_id": 724, "parent": 1022, "fw_parent": 0, "seq_id": 185, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1131,421,0,51200,2,"cuda:0"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1133,421,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1134, "rf_id": 725, "parent": 1022, "fw_parent": 0, "seq_id": 186, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1133,421,0,51200,2,"cuda:0"],[-1,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1135,421,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1137, "rf_id": 727, "parent": 1136, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],4,0,"cpu",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","Bool","None"],
      "outputs": [[1138,1139,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 1140, "rf_id": 728, "parent": 1136, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1138,1139,0,1,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[1],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[1138,1139,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 1141, "rf_id": 729, "parent": 1136, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1138,1139,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [[1138,1139,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "detach_", "id": 1143, "rf_id": 731, "parent": 1142, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1138,1139,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 1142, "rf_id": 730, "parent": 1136, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1138,1139,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [[1138,1139,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 1145, "rf_id": 733, "parent": 1144, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1138,1139,0,1,8,"cpu"],[],[],0], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[1146,1139,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 1144, "rf_id": 732, "parent": 1136, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[1138,1139,0,1,8,"cpu"],0,0], "input_shapes": [[1],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[1146,1139,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 1148, "rf_id": 735, "parent": 1147, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[1146,1139,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 1147, "rf_id": 734, "parent": 1136, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[1146,1139,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::empty", "id": 1149, "rf_id": 736, "parent": 1136, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[128,20,20],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1150,433,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ScaledUpperTriangMaskedSoftmax", "id": 1136, "rf_id": 726, "parent": 1022, "fw_parent": 0, "seq_id": 187, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1135,421,0,51200,2,"cuda:0"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1151, "rf_id": 737, "parent": 1022, "fw_parent": 0, "seq_id": 188, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1150,433,0,51200,2,"cuda:0"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1152,433,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1156, "rf_id": 741, "parent": 1155, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[8,16,20,20],[6400,400,20,1],11,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[]],[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1157,1158,0,51200,1,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 1155, "rf_id": 740, "parent": 1154, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1152,433,0,51200,2,"cuda:0"],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[8,16,20,20],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[1157,1158,0,51200,1,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 1160, "rf_id": 743, "parent": 1159, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[8,16,20,20],[6400,400,20,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[]],[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1161,300,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1159, "rf_id": 742, "parent": 1154, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1152,433,0,51200,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[8,16,20,20],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1161,300,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 1154, "rf_id": 739, "parent": 1153, "fw_parent": 0, "seq_id": 189, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[1152,433,0,51200,2,"cuda:0"],0.100000,true], "input_shapes": [[8,16,20,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[1161,300,0,51200,2,"cuda:0"],[1157,1158,0,51200,1,"cuda:0"]], "output_shapes": [[8,16,20,20],[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::dropout", "id": 1153, "rf_id": 738, "parent": 1022, "fw_parent": 0, "seq_id": 189, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::dropout(Tensor input, float p, bool train) -> Tensor",
      "inputs": [[1152,433,0,51200,2,"cuda:0"],0.100000,true], "input_shapes": [[8,16,20,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[1161,300,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1162, "rf_id": 744, "parent": 1022, "fw_parent": 0, "seq_id": 190, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1111,328,128,163840,2,"cuda:0"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1163,328,128,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1164, "rf_id": 745, "parent": 1022, "fw_parent": 0, "seq_id": 191, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1161,300,0,51200,2,"cuda:0"],[128,20,-1]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1165,300,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1167, "rf_id": 747, "parent": 1166, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1163,328,128,163840,2,"cuda:0"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1168,328,128,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1166, "rf_id": 746, "parent": 1022, "fw_parent": 0, "seq_id": 192, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1163,328,128,163840,2,"cuda:0"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1168,328,128,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 1169, "rf_id": 748, "parent": 1022, "fw_parent": 0, "seq_id": 193, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1165,300,0,51200,2,"cuda:0"],[1168,328,128,163840,2,"cuda:0"]], "input_shapes": [[128,20,20],[128,20,64]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1170,1171,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1172, "rf_id": 749, "parent": 1022, "fw_parent": 0, "seq_id": 194, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1170,1171,0,163840,2,"cuda:0"],[8,16,20,64]], "input_shapes": [[128,20,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1173,1171,0,163840,2,"cuda:0"]], "output_shapes": [[8,16,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1175, "rf_id": 751, "parent": 1174, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1173,1171,0,163840,2,"cuda:0"],[20,8,16,64],[64,20480,1280,1],"<None>"], "input_shapes": [[8,16,20,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","None"],
      "outputs": [[1176,1171,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::permute", "id": 1174, "rf_id": 750, "parent": 1022, "fw_parent": 0, "seq_id": 195, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)",
      "inputs": [[1173,1171,0,163840,2,"cuda:0"],[2,0,1,3]], "input_shapes": [[8,16,20,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1176,1171,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1180, "rf_id": 755, "parent": 1179, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[1181,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1179, "rf_id": 754, "parent": 1178, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1176,1171,0,163840,2,"cuda:0"],15,0,"cuda:0","<None>",0], "input_shapes": [[20,8,16,64],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Int"],
      "outputs": [[1181,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1182, "rf_id": 756, "parent": 1178, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1181,323,0,163840,2,"cuda:0"],[1176,1171,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1181,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::clone", "id": 1178, "rf_id": 753, "parent": 1177, "fw_parent": 0, "seq_id": 196, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1176,1171,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1181,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::contiguous", "id": 1177, "rf_id": 752, "parent": 1022, "fw_parent": 0, "seq_id": 196, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[1176,1171,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1181,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1183, "rf_id": 757, "parent": 1022, "fw_parent": 0, "seq_id": 197, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1181,323,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1184,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1188, "rf_id": 761, "parent": 1187, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[456,236,54677504,1048576,2,"cuda:0"],[1024,1024],[1,1024],"<None>"], "input_shapes": [[1024,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1189,236,54677504,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1187, "rf_id": 760, "parent": 1186, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[456,236,54677504,1048576,2,"cuda:0"],0,1], "input_shapes": [[1024,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1189,236,54677504,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1186, "rf_id": 759, "parent": 1185, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[456,236,54677504,1048576,2,"cuda:0"]], "input_shapes": [[1024,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1189,236,54677504,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1192, "rf_id": 764, "parent": 1191, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1184,323,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1193,323,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1191, "rf_id": 763, "parent": 1190, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1184,323,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1193,323,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1194, "rf_id": 765, "parent": 1190, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1193,323,0,163840,2,"cuda:0"],[1189,236,54677504,1048576,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1195,1171,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1196, "rf_id": 766, "parent": 1190, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1195,1171,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1197,1171,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1190, "rf_id": 762, "parent": 1185, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1184,323,0,163840,2,"cuda:0"],[1189,236,54677504,1048576,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1197,1171,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 1185, "rf_id": 758, "parent": 1022, "fw_parent": 0, "seq_id": 198, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1184,323,0,163840,2,"cuda:0"],[456,236,54677504,1048576,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1200, "rf_id": 769, "parent": 1199, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1197,1171,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1201,1171,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1199, "rf_id": 768, "parent": 1198, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1197,1171,0,163840,2,"cuda:0"],[1197,1171,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1201,1171,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_ReduceFromModelParallelRegion", "id": 1198, "rf_id": 767, "parent": 1022, "fw_parent": 0, "seq_id": 199, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1197,1171,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1204, "rf_id": 772, "parent": 1203, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[474,294,5120,1024,2,"cuda:0"],[20,8,1024],[0,0,1],"<None>"], "input_shapes": [[1024],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1205,294,5120,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::expand", "id": 1203, "rf_id": 771, "parent": 1202, "fw_parent": 0, "seq_id": 200, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)",
      "inputs": [[474,294,5120,1024,2,"cuda:0"],[20,8,1024],false], "input_shapes": [[1024],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","Bool"],
      "outputs": [[1205,294,5120,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::expand_as", "id": 1202, "rf_id": 770, "parent": 1022, "fw_parent": 0, "seq_id": 200, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[474,294,5120,1024,2,"cuda:0"],[1030,290,0,163840,2,"cuda:0"]], "input_shapes": [[1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1205,294,5120,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1209, "rf_id": 776, "parent": 1208, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1205,294,5120,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1208, "rf_id": 775, "parent": 1207, "fw_parent": 0, "seq_id": 202, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1205,294,5120,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1210,294,5120,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1212, "rf_id": 778, "parent": 1211, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1201,1171,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1211, "rf_id": 777, "parent": 1207, "fw_parent": 0, "seq_id": 202, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1201,1171,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1213,1171,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1215, "rf_id": 780, "parent": 1214, "fw_parent": 0, "seq_id": 202, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1213,1171,0,163840,2,"cuda:0"],[1210,294,5120,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1216,505,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<forward op>", "id": 1214, "rf_id": 779, "parent": 1207, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1210,294,5120,163840,2,"cuda:0"],[1213,1171,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "fallback_function", "id": 1207, "rf_id": 774, "parent": 1206, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1205,294,5120,163840,2,"cuda:0"],[1201,1171,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1218, "rf_id": 782, "parent": 1217, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1030,290,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1217, "rf_id": 781, "parent": 1206, "fw_parent": 0, "seq_id": 203, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1030,290,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1219,290,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1221, "rf_id": 784, "parent": 1220, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1216,505,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1220, "rf_id": 783, "parent": 1206, "fw_parent": 0, "seq_id": 203, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1216,505,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1222,505,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1226, "rf_id": 788, "parent": 1225, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],11,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1227,645,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 1225, "rf_id": 787, "parent": 1224, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1222,505,0,163840,2,"cuda:0"],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[1227,645,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 1229, "rf_id": 790, "parent": 1228, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1230,1231,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1228, "rf_id": 789, "parent": 1224, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1222,505,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1230,1231,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 1224, "rf_id": 786, "parent": 1223, "fw_parent": 0, "seq_id": 203, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[1222,505,0,163840,2,"cuda:0"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[1230,1231,0,163840,2,"cuda:0"],[1227,645,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024],[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::add", "id": 1232, "rf_id": 791, "parent": 1223, "fw_parent": 0, "seq_id": 203, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1219,290,0,163840,2,"cuda:0"],[1230,1231,0,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1233,1234,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<forward op>", "id": 1223, "rf_id": 785, "parent": 1206, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1219,290,0,163840,2,"cuda:0"],0.100000,[1222,505,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_dropout_add_fused_train", "id": 1206, "rf_id": 773, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1201,1171,0,163840,2,"cuda:0"],[1205,294,5120,163840,2,"cuda:0"],[1030,290,0,163840,2,"cuda:0"],0.100000], "input_shapes": [[20,8,1024],[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Double"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 1237, "rf_id": 794, "parent": 1236, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1238,1231,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1236, "rf_id": 793, "parent": 1235, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1233,1234,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1238,1231,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1239, "rf_id": 795, "parent": 1235, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[160],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[1240,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 1242, "rf_id": 797, "parent": 1241, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[1243,132,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 1241, "rf_id": 796, "parent": 1235, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1240,198,0,160,4,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[160],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[1243,132,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunction", "id": 1235, "rf_id": 792, "parent": 1022, "fw_parent": 0, "seq_id": 203, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1233,1234,0,163840,2,"cuda:0"],[506,294,6144,1024,2,"cuda:0"],[507,294,7168,1024,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1244, "rf_id": 798, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],15,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[1245,1246,0,1,2,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1249, "rf_id": 801, "parent": 1248, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],15,0,"cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[1250,198,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1251, "rf_id": 802, "parent": 1248, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1250,198,0,1,2,"cuda:0"],[1245,1246,0,1,2,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1250,198,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_to_copy", "id": 1248, "rf_id": 800, "parent": 1247, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1245,1246,0,1,2,"cpu"],15,"<None>","cuda:0","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","Device","None","Bool","None"],
      "outputs": [[1250,198,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 1247, "rf_id": 799, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1245,1246,0,1,2,"cpu"],"cuda:0",15,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Device","Int","Bool","Bool","None"],
      "outputs": [[1250,198,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::lift_fresh", "id": 1252, "rf_id": 803, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1250,198,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1250,198,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach_", "id": 1254, "rf_id": 805, "parent": 1253, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1250,198,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 1253, "rf_id": 804, "parent": 1022, "fw_parent": 0, "seq_id": 204, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1250,198,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1250,198,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1255, "rf_id": 806, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],15,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[1256,1257,0,1,2,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1260, "rf_id": 809, "parent": 1259, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],15,0,"cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[1261,1262,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1263, "rf_id": 810, "parent": 1259, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1261,1262,0,1,2,"cuda:0"],[1256,1257,0,1,2,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1261,1262,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_to_copy", "id": 1259, "rf_id": 808, "parent": 1258, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1256,1257,0,1,2,"cpu"],15,"<None>","cuda:0","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","Device","None","Bool","None"],
      "outputs": [[1261,1262,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 1258, "rf_id": 807, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1256,1257,0,1,2,"cpu"],"cuda:0",15,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Device","Int","Bool","Bool","None"],
      "outputs": [[1261,1262,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::lift_fresh", "id": 1264, "rf_id": 811, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1261,1262,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1261,1262,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach_", "id": 1266, "rf_id": 813, "parent": 1265, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1261,1262,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 1265, "rf_id": 812, "parent": 1022, "fw_parent": 0, "seq_id": 204, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1261,1262,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1261,1262,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1269, "rf_id": 816, "parent": 1268, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1238,1231,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1270,1231,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1268, "rf_id": 815, "parent": 1267, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1238,1231,0,163840,2,"cuda:0"],[1238,1231,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1270,1231,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_CopyToModelParallelRegion", "id": 1267, "rf_id": 814, "parent": 1022, "fw_parent": 0, "seq_id": 204, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1238,1231,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1274, "rf_id": 820, "parent": 1273, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[543,236,55726080,4194304,2,"cuda:0"],[1024,4096],[1,1024],"<None>"], "input_shapes": [[4096,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1275,236,55726080,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1273, "rf_id": 819, "parent": 1272, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[543,236,55726080,4194304,2,"cuda:0"],0,1], "input_shapes": [[4096,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1275,236,55726080,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1272, "rf_id": 818, "parent": 1271, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[543,236,55726080,4194304,2,"cuda:0"]], "input_shapes": [[4096,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1275,236,55726080,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1278, "rf_id": 823, "parent": 1277, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1270,1231,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1279,1231,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1277, "rf_id": 822, "parent": 1276, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1270,1231,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1279,1231,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1280, "rf_id": 824, "parent": 1276, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1279,1231,0,163840,2,"cuda:0"],[1275,236,55726080,4194304,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1281,555,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1282, "rf_id": 825, "parent": 1276, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1281,555,0,655360,2,"cuda:0"],[20,8,4096]], "input_shapes": [[160,4096],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1283,555,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1276, "rf_id": 821, "parent": 1271, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1270,1231,0,163840,2,"cuda:0"],[1275,236,55726080,4194304,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1283,555,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 1271, "rf_id": 817, "parent": 1022, "fw_parent": 0, "seq_id": 205, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1270,1231,0,163840,2,"cuda:0"],[543,236,55726080,4194304,2,"cuda:0"]], "input_shapes": [[20,8,1024],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1288, "rf_id": 830, "parent": 1287, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1283,555,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1287, "rf_id": 829, "parent": 1286, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1283,555,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1289,555,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1291, "rf_id": 832, "parent": 1290, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[558,294,8192,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1290, "rf_id": 831, "parent": 1286, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[558,294,8192,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1292,294,8192,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1294, "rf_id": 834, "parent": 1293, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1292,294,8192,4096,2,"cuda:0"],[1289,555,0,655360,2,"cuda:0"],1], "input_shapes": [[4096],[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1295,570,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1299, "rf_id": 836, "parent": 1296, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1295,570,0,655360,2,"cuda:0"],[1297,1298,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1300,1301,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1296, "rf_id": 835, "parent": 1293, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1295,570,0,655360,2,"cuda:0"],0.500000], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1300,1301,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1305, "rf_id": 838, "parent": 1302, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1295,570,0,655360,2,"cuda:0"],[1303,1304,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1306,576,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1302, "rf_id": 837, "parent": 1293, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1295,570,0,655360,2,"cuda:0"],0.797885], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1306,576,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1310, "rf_id": 840, "parent": 1307, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1295,570,0,655360,2,"cuda:0"],[1308,1309,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1311,582,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1307, "rf_id": 839, "parent": 1293, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1295,570,0,655360,2,"cuda:0"],0.044715], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1311,582,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1312, "rf_id": 841, "parent": 1293, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1311,582,0,655360,2,"cuda:0"],[1295,570,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1313,588,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1317, "rf_id": 843, "parent": 1314, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1313,588,0,655360,2,"cuda:0"],[1315,1316,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[1318,591,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1314, "rf_id": 842, "parent": 1293, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[1313,588,0,655360,2,"cuda:0"],1,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1318,591,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1319, "rf_id": 844, "parent": 1293, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1306,576,0,655360,2,"cuda:0"],[1318,591,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1320,588,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::tanh", "id": 1321, "rf_id": 845, "parent": 1293, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::tanh(Tensor self) -> Tensor",
      "inputs": [[1320,588,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1322,597,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1326, "rf_id": 847, "parent": 1323, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1322,597,0,655360,2,"cuda:0"],[1324,1325,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)","Int"],
      "outputs": [[1327,588,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1323, "rf_id": 846, "parent": 1293, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[1322,597,0,655360,2,"cuda:0"],1.000000,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Int"],
      "outputs": [[1327,588,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1328, "rf_id": 848, "parent": 1293, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1300,1301,0,655360,2,"cuda:0"],[1327,588,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1329,602,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<forward op>", "id": 1293, "rf_id": 833, "parent": 1286, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1289,555,0,655360,2,"cuda:0"],[1292,294,8192,4096,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "fallback_function", "id": 1286, "rf_id": 828, "parent": 1285, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1283,555,0,655360,2,"cuda:0"],[558,294,8192,4096,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_gelu", "id": 1285, "rf_id": 827, "parent": 1284, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[558,294,8192,4096,2,"cuda:0"],[1283,555,0,655360,2,"cuda:0"]], "input_shapes": [[4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "GeLUFunction", "id": 1284, "rf_id": 826, "parent": 1022, "fw_parent": 0, "seq_id": 206, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1283,555,0,655360,2,"cuda:0"],[558,294,8192,4096,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1333, "rf_id": 852, "parent": 1332, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[613,236,59920384,4194304,2,"cuda:0"],[4096,1024],[1,4096],"<None>"], "input_shapes": [[1024,4096],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1334,236,59920384,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1332, "rf_id": 851, "parent": 1331, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[613,236,59920384,4194304,2,"cuda:0"],0,1], "input_shapes": [[1024,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1334,236,59920384,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1331, "rf_id": 850, "parent": 1330, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[613,236,59920384,4194304,2,"cuda:0"]], "input_shapes": [[1024,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1334,236,59920384,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1337, "rf_id": 855, "parent": 1336, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1329,602,0,655360,2,"cuda:0"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1338,602,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1336, "rf_id": 854, "parent": 1335, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1329,602,0,655360,2,"cuda:0"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1338,602,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1339, "rf_id": 856, "parent": 1335, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1338,602,0,655360,2,"cuda:0"],[1334,236,59920384,4194304,2,"cuda:0"]], "input_shapes": [[160,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1340,505,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1341, "rf_id": 857, "parent": 1335, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1340,505,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1342,505,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1335, "rf_id": 853, "parent": 1330, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1329,602,0,655360,2,"cuda:0"],[1334,236,59920384,4194304,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1342,505,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 1330, "rf_id": 849, "parent": 1022, "fw_parent": 0, "seq_id": 208, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1329,602,0,655360,2,"cuda:0"],[613,236,59920384,4194304,2,"cuda:0"]], "input_shapes": [[20,8,4096],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1345, "rf_id": 860, "parent": 1344, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1342,505,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1346,505,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1344, "rf_id": 859, "parent": 1343, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1342,505,0,163840,2,"cuda:0"],[1342,505,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1346,505,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_ReduceFromModelParallelRegion", "id": 1343, "rf_id": 858, "parent": 1022, "fw_parent": 0, "seq_id": 209, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1342,505,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 1347, "rf_id": 861, "parent": 1022, "fw_parent": 0, "seq_id": 210, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1346,505,0,163840,2,"cuda:0"],[631,294,12288,1024,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1348,1349,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1352, "rf_id": 864, "parent": 1351, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1233,1234,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1351, "rf_id": 863, "parent": 1350, "fw_parent": 0, "seq_id": 212, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1233,1234,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1353,1234,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1355, "rf_id": 866, "parent": 1354, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1348,1349,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1354, "rf_id": 865, "parent": 1350, "fw_parent": 0, "seq_id": 212, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1348,1349,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1356,1349,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1360, "rf_id": 870, "parent": 1359, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],11,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1361,1362,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 1359, "rf_id": 869, "parent": 1358, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1356,1349,0,163840,2,"cuda:0"],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[1361,1362,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 1364, "rf_id": 872, "parent": 1363, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1365,505,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1363, "rf_id": 871, "parent": 1358, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1356,1349,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1365,505,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 1358, "rf_id": 868, "parent": 1357, "fw_parent": 0, "seq_id": 212, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[1356,1349,0,163840,2,"cuda:0"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[1365,505,0,163840,2,"cuda:0"],[1361,1362,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024],[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::add", "id": 1366, "rf_id": 873, "parent": 1357, "fw_parent": 0, "seq_id": 212, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1353,1234,0,163840,2,"cuda:0"],[1365,505,0,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1367,1368,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<forward op>", "id": 1357, "rf_id": 867, "parent": 1350, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1353,1234,0,163840,2,"cuda:0"],0.100000,[1356,1349,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_dropout_add_fused_train", "id": 1350, "rf_id": 862, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1348,1349,0,163840,2,"cuda:0"],"<None>",[1233,1234,0,163840,2,"cuda:0"],0.100000], "input_shapes": [[20,8,1024],[],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","None","Tensor(c10::BFloat16)","Double"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::is_same_size", "id": 1369, "rf_id": 874, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::is_same_size(Tensor self, Tensor other) -> bool",
      "inputs": [[1367,1368,0,163840,2,"cuda:0"],[975,266,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::empty", "id": 1375, "rf_id": 880, "parent": 1374, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,1024],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[1376,505,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1374, "rf_id": 879, "parent": 1373, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[975,266,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>",0], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","Int"],
      "outputs": [[1376,505,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout_backward", "id": 1373, "rf_id": 878, "parent": 1372, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout_backward(Tensor grad_output, Tensor mask, float scale) -> Tensor",
      "inputs": [[975,266,0,163840,2,"cuda:0"],[1361,1362,0,163840,1,"cuda:0"],1.111111], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(bool)","Double"],
      "outputs": [[1376,505,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<backward op>", "id": 1372, "rf_id": 877, "parent": 1371, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[975,266,0,163840,2,"cuda:0"],1.111111,[1361,1362,0,163840,1,"cuda:0"],"<None>","<None>"], "input_shapes": [[20,8,1024],[],[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(bool)","None","None"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 1371, "rf_id": 876, "parent": 1370, "fw_parent": 1370, "seq_id": 211, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[975,266,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 1370, "rf_id": 875, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "AddBackward0", "id": 1378, "rf_id": 882, "parent": 1377, "fw_parent": 1377, "seq_id": 210, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1376,505,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::sum", "id": 1379, "rf_id": 883, "parent": 1377, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1376,505,0,163840,2,"cuda:0"],[0,1],true,"<None>"], "input_shapes": [[20,8,1024],[[],[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","Bool","None"],
      "outputs": [[1380,806,0,1024,2,"cuda:0"]], "output_shapes": [[1,1,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1381, "rf_id": 884, "parent": 1377, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1380,806,0,1024,2,"cuda:0"],[1024]], "input_shapes": [[1,1,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1382,806,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: AddBackward0", "id": 1377, "rf_id": 881, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1386, "rf_id": 888, "parent": 1385, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1382,806,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1385, "rf_id": 887, "parent": 1384, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1382,806,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1387,806,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 1384, "rf_id": 886, "parent": 1383, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1382,806,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1390, "rf_id": 891, "parent": 1389, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[1024],[1],2048], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1391,859,2048,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1389, "rf_id": 890, "parent": 1388, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,2048,3072,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1391,859,2048,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 1388, "rf_id": 889, "parent": 1383, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,2048,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1391,859,2048,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1392, "rf_id": 892, "parent": 1383, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1387,806,0,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1393,806,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1394, "rf_id": 893, "parent": 1383, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1391,859,2048,1024,2,"cuda:0"],[1393,806,0,1024,2,"cuda:0"],false], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1391,859,2048,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1397, "rf_id": 895, "parent": 1396, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1395,859,2048,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1398,859,2048,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1396, "rf_id": 894, "parent": 1383, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1395,859,2048,1024,2,"cuda:0"],[1387,806,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1398,859,2048,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1399, "rf_id": 896, "parent": 1383, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[1387,806,0,1024,2,"cuda:0"],[1398,859,2048,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 1383, "rf_id": 885, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_ReduceFromModelParallelRegionBackward", "id": 1401, "rf_id": 898, "parent": 1400, "fw_parent": 1400, "seq_id": 209, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1376,505,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _ReduceFromModelParallelRegionBackward", "id": 1400, "rf_id": 897, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1406, "rf_id": 903, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1376,505,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1407,505,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1405, "rf_id": 902, "parent": 1404, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1376,505,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1407,505,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1408, "rf_id": 904, "parent": 1404, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1407,505,0,163840,2,"cuda:0"],[613,236,59920384,4194304,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1409,570,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1410, "rf_id": 905, "parent": 1404, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1409,570,0,655360,2,"cuda:0"],[20,8,4096]], "input_shapes": [[160,4096],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1411,570,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1404, "rf_id": 901, "parent": 1403, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1376,505,0,163840,2,"cuda:0"],[613,236,59920384,4194304,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1411,570,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1412, "rf_id": 906, "parent": 1403, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1376,505,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1413,505,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1414, "rf_id": 907, "parent": 1403, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1329,602,0,655360,2,"cuda:0"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1415,602,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1418, "rf_id": 910, "parent": 1417, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1413,505,0,163840,2,"cuda:0"],[1024,160],[1,1024],"<None>"], "input_shapes": [[160,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1419,505,0,163840,2,"cuda:0"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1417, "rf_id": 909, "parent": 1416, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1413,505,0,163840,2,"cuda:0"],0,1], "input_shapes": [[160,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1419,505,0,163840,2,"cuda:0"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1416, "rf_id": 908, "parent": 1403, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1413,505,0,163840,2,"cuda:0"]], "input_shapes": [[160,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1419,505,0,163840,2,"cuda:0"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1421, "rf_id": 912, "parent": 1420, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1419,505,0,163840,2,"cuda:0"],[1415,602,0,655360,2,"cuda:0"]], "input_shapes": [[1024,160],[160,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1422,610,0,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1420, "rf_id": 911, "parent": 1403, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1419,505,0,163840,2,"cuda:0"],[1415,602,0,655360,2,"cuda:0"]], "input_shapes": [[1024,160],[160,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1422,610,0,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 1403, "rf_id": 900, "parent": 1402, "fw_parent": 1402, "seq_id": 208, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1376,505,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 1402, "rf_id": 899, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1426, "rf_id": 916, "parent": 1425, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1422,610,0,4194304,2,"cuda:0"]], "input_shapes": [[1024,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1425, "rf_id": 915, "parent": 1424, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1422,610,0,4194304,2,"cuda:0"]], "input_shapes": [[1024,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1427,610,0,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 1424, "rf_id": 914, "parent": 1423, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1422,610,0,4194304,2,"cuda:0"]], "input_shapes": [[1024,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1430, "rf_id": 919, "parent": 1429, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[4194304],[1],3072], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1431,859,3072,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1429, "rf_id": 918, "parent": 1428, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,3072,4197376,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1431,859,3072,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 1428, "rf_id": 917, "parent": 1423, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,3072,4194304], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1431,859,3072,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1432, "rf_id": 920, "parent": 1423, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1427,610,0,4194304,2,"cuda:0"],[-1]], "input_shapes": [[1024,4096],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1433,610,0,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1434, "rf_id": 921, "parent": 1423, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1431,859,3072,4194304,2,"cuda:0"],[1433,610,0,4194304,2,"cuda:0"],false], "input_shapes": [[4194304],[4194304],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1431,859,3072,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1437, "rf_id": 923, "parent": 1436, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1435,859,3072,4194304,2,"cuda:0"],[1024,4096]], "input_shapes": [[4194304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1438,859,3072,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1436, "rf_id": 922, "parent": 1423, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1435,859,3072,4194304,2,"cuda:0"],[1427,610,0,4194304,2,"cuda:0"]], "input_shapes": [[4194304],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1438,859,3072,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1439, "rf_id": 924, "parent": 1423, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[1427,610,0,4194304,2,"cuda:0"],[1438,859,3072,4194304,2,"cuda:0"]], "input_shapes": [[1024,4096],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 1423, "rf_id": 913, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 1443, "rf_id": 928, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[558,294,8192,4096,2,"cuda:0"],[1283,555,0,655360,2,"cuda:0"],1], "input_shapes": [[4096],[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1444,1301,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1448, "rf_id": 930, "parent": 1445, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1444,1301,0,655360,2,"cuda:0"],[1446,1447,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1449,576,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1445, "rf_id": 929, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1444,1301,0,655360,2,"cuda:0"],0.797885], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1449,576,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1453, "rf_id": 932, "parent": 1450, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1444,1301,0,655360,2,"cuda:0"],[1451,1452,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1454,582,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1450, "rf_id": 931, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1444,1301,0,655360,2,"cuda:0"],0.044715], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1454,582,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1455, "rf_id": 933, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1454,582,0,655360,2,"cuda:0"],[1444,1301,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1456,588,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1460, "rf_id": 935, "parent": 1457, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1456,588,0,655360,2,"cuda:0"],[1458,1459,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[1461,582,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1457, "rf_id": 934, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[1456,588,0,655360,2,"cuda:0"],1,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1461,582,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1462, "rf_id": 936, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1449,576,0,655360,2,"cuda:0"],[1461,582,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1463,588,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::tanh", "id": 1464, "rf_id": 937, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::tanh(Tensor self) -> Tensor",
      "inputs": [[1463,588,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1465,576,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1469, "rf_id": 939, "parent": 1466, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1444,1301,0,655360,2,"cuda:0"],[1467,1468,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1470,582,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1466, "rf_id": 938, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1444,1301,0,655360,2,"cuda:0"],0.500000], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1470,582,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1471, "rf_id": 940, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1465,576,0,655360,2,"cuda:0"],[1465,576,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1472,588,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::neg", "id": 1473, "rf_id": 941, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::neg(Tensor self) -> Tensor",
      "inputs": [[1472,588,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1474,591,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1478, "rf_id": 943, "parent": 1475, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1474,591,0,655360,2,"cuda:0"],[1476,1477,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[1479,588,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1475, "rf_id": 942, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[1474,591,0,655360,2,"cuda:0"],1,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1479,588,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1483, "rf_id": 945, "parent": 1480, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1444,1301,0,655360,2,"cuda:0"],[1481,1482,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1484,591,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1480, "rf_id": 944, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1444,1301,0,655360,2,"cuda:0"],0.107032], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1484,591,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1485, "rf_id": 946, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1484,591,0,655360,2,"cuda:0"],[1444,1301,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1486,597,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1490, "rf_id": 948, "parent": 1487, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1486,597,0,655360,2,"cuda:0"],[1488,1489,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)","Int"],
      "outputs": [[1491,591,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1487, "rf_id": 947, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[1486,597,0,655360,2,"cuda:0"],0.797885,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Int"],
      "outputs": [[1491,591,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1492, "rf_id": 949, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1479,588,0,655360,2,"cuda:0"],[1491,591,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1493,1301,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1494, "rf_id": 950, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1470,582,0,655360,2,"cuda:0"],[1493,1301,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1495,588,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1499, "rf_id": 952, "parent": 1496, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1465,576,0,655360,2,"cuda:0"],[1497,1498,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[1500,582,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1496, "rf_id": 951, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[1465,576,0,655360,2,"cuda:0"],1,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1500,582,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1504, "rf_id": 954, "parent": 1501, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1500,582,0,655360,2,"cuda:0"],[1502,1503,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1505,576,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1501, "rf_id": 953, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1500,582,0,655360,2,"cuda:0"],0.500000], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1505,576,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1506, "rf_id": 955, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1495,588,0,655360,2,"cuda:0"],[1505,576,0,655360,2,"cuda:0"],1], "input_shapes": [[20,8,4096],[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1507,582,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1508, "rf_id": 956, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1507,582,0,655360,2,"cuda:0"],[1411,570,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1509,576,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "bias_gelu_back", "id": 1442, "rf_id": 927, "parent": 1441, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1411,570,0,655360,2,"cuda:0"],[558,294,8192,4096,2,"cuda:0"],[1283,555,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "GeLUFunctionBackward", "id": 1441, "rf_id": 926, "parent": 1440, "fw_parent": 1440, "seq_id": 206, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1411,570,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::sum", "id": 1510, "rf_id": 957, "parent": 1440, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1509,576,0,655360,2,"cuda:0"],[0,1],true,"<None>"], "input_shapes": [[20,8,4096],[[],[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","Bool","None"],
      "outputs": [[1511,1512,0,4096,2,"cuda:0"]], "output_shapes": [[1,1,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1513, "rf_id": 958, "parent": 1440, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1511,1512,0,4096,2,"cuda:0"],[4096]], "input_shapes": [[1,1,4096],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1514,1512,0,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: GeLUFunctionBackward", "id": 1440, "rf_id": 925, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1518, "rf_id": 962, "parent": 1517, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1514,1512,0,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1517, "rf_id": 961, "parent": 1516, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1514,1512,0,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1519,1512,0,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 1516, "rf_id": 960, "parent": 1515, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1514,1512,0,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1522, "rf_id": 965, "parent": 1521, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[4096],[1],4197376], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1523,859,4197376,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1521, "rf_id": 964, "parent": 1520, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,4197376,4201472,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1523,859,4197376,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 1520, "rf_id": 963, "parent": 1515, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,4197376,4096], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1523,859,4197376,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1524, "rf_id": 966, "parent": 1515, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1519,1512,0,4096,2,"cuda:0"],[-1]], "input_shapes": [[4096],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1525,1512,0,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1526, "rf_id": 967, "parent": 1515, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1523,859,4197376,4096,2,"cuda:0"],[1525,1512,0,4096,2,"cuda:0"],false], "input_shapes": [[4096],[4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1523,859,4197376,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1529, "rf_id": 969, "parent": 1528, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1527,859,4197376,4096,2,"cuda:0"],[4096]], "input_shapes": [[4096],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1530,859,4197376,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1528, "rf_id": 968, "parent": 1515, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1527,859,4197376,4096,2,"cuda:0"],[1519,1512,0,4096,2,"cuda:0"]], "input_shapes": [[4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1530,859,4197376,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1531, "rf_id": 970, "parent": 1515, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[1519,1512,0,4096,2,"cuda:0"],[1530,859,4197376,4096,2,"cuda:0"]], "input_shapes": [[4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 1515, "rf_id": 959, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1536, "rf_id": 975, "parent": 1535, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1509,576,0,655360,2,"cuda:0"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1537,576,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1535, "rf_id": 974, "parent": 1534, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1509,576,0,655360,2,"cuda:0"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1537,576,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1538, "rf_id": 976, "parent": 1534, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1537,576,0,655360,2,"cuda:0"],[543,236,55726080,4194304,2,"cuda:0"]], "input_shapes": [[160,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1539,505,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1540, "rf_id": 977, "parent": 1534, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1539,505,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1541,505,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1534, "rf_id": 973, "parent": 1533, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1509,576,0,655360,2,"cuda:0"],[543,236,55726080,4194304,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1541,505,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1542, "rf_id": 978, "parent": 1533, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1509,576,0,655360,2,"cuda:0"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1543,576,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1544, "rf_id": 979, "parent": 1533, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1270,1231,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1545,1231,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1548, "rf_id": 982, "parent": 1547, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1543,576,0,655360,2,"cuda:0"],[4096,160],[1,4096],"<None>"], "input_shapes": [[160,4096],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1549,576,0,655360,2,"cuda:0"]], "output_shapes": [[4096,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1547, "rf_id": 981, "parent": 1546, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1543,576,0,655360,2,"cuda:0"],0,1], "input_shapes": [[160,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1549,576,0,655360,2,"cuda:0"]], "output_shapes": [[4096,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1546, "rf_id": 980, "parent": 1533, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1543,576,0,655360,2,"cuda:0"]], "input_shapes": [[160,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1549,576,0,655360,2,"cuda:0"]], "output_shapes": [[4096,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1551, "rf_id": 984, "parent": 1550, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1549,576,0,655360,2,"cuda:0"],[1545,1231,0,163840,2,"cuda:0"]], "input_shapes": [[4096,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1552,582,0,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1550, "rf_id": 983, "parent": 1533, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1549,576,0,655360,2,"cuda:0"],[1545,1231,0,163840,2,"cuda:0"]], "input_shapes": [[4096,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1552,582,0,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 1533, "rf_id": 972, "parent": 1532, "fw_parent": 1532, "seq_id": 205, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1509,576,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 1532, "rf_id": 971, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1556, "rf_id": 988, "parent": 1555, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1552,582,0,4194304,2,"cuda:0"]], "input_shapes": [[4096,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1555, "rf_id": 987, "parent": 1554, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1552,582,0,4194304,2,"cuda:0"]], "input_shapes": [[4096,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1557,582,0,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 1554, "rf_id": 986, "parent": 1553, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1552,582,0,4194304,2,"cuda:0"]], "input_shapes": [[4096,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1560, "rf_id": 991, "parent": 1559, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[4194304],[1],4201472], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1561,859,4201472,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1559, "rf_id": 990, "parent": 1558, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,4201472,8395776,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1561,859,4201472,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 1558, "rf_id": 989, "parent": 1553, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,4201472,4194304], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1561,859,4201472,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1562, "rf_id": 992, "parent": 1553, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1557,582,0,4194304,2,"cuda:0"],[-1]], "input_shapes": [[4096,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1563,582,0,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1564, "rf_id": 993, "parent": 1553, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1561,859,4201472,4194304,2,"cuda:0"],[1563,582,0,4194304,2,"cuda:0"],false], "input_shapes": [[4194304],[4194304],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1561,859,4201472,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1567, "rf_id": 995, "parent": 1566, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1565,859,4201472,4194304,2,"cuda:0"],[4096,1024]], "input_shapes": [[4194304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1568,859,4201472,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1566, "rf_id": 994, "parent": 1553, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1565,859,4201472,4194304,2,"cuda:0"],[1557,582,0,4194304,2,"cuda:0"]], "input_shapes": [[4194304],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1568,859,4201472,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1569, "rf_id": 996, "parent": 1553, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[1557,582,0,4194304,2,"cuda:0"],[1568,859,4201472,4194304,2,"cuda:0"]], "input_shapes": [[4096,1024],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 1553, "rf_id": 985, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_CopyToModelParallelRegionBackward", "id": 1571, "rf_id": 998, "parent": 1570, "fw_parent": 1570, "seq_id": 204, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1541,505,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _CopyToModelParallelRegionBackward", "id": 1570, "rf_id": 997, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 1576, "rf_id": 1002, "parent": 1575, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1577,1171,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1575, "rf_id": 1001, "parent": 1573, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1574,1231,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1577,1171,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1579, "rf_id": 1004, "parent": 1578, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[1580,806,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1578, "rf_id": 1003, "parent": 1573, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[506,294,6144,1024,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1580,806,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1582, "rf_id": 1006, "parent": 1581, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[1583,716,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1581, "rf_id": 1005, "parent": 1573, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[507,294,7168,1024,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1583,716,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1584, "rf_id": 1007, "parent": 1573, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[16,1024],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1585,1586,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 1588, "rf_id": 1009, "parent": 1587, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[16,1024],[1024,1],6,0,"cuda:0","<None>"], "input_shapes": [[[],[]],[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[1589,421,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 1587, "rf_id": 1008, "parent": 1573, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1585,1586,0,16384,4,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[16,1024],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[1589,421,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunctionBackward", "id": 1573, "rf_id": 1000, "parent": 1572, "fw_parent": 1572, "seq_id": 203, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1541,505,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 1590, "rf_id": 1010, "parent": 1572, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[975,266,0,163840,2,"cuda:0"],[1577,1171,0,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1243,505,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: FusedLayerNormAffineFunctionBackward", "id": 1572, "rf_id": 999, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1594, "rf_id": 1014, "parent": 1593, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1580,806,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1593, "rf_id": 1013, "parent": 1592, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1580,806,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1595,806,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 1592, "rf_id": 1012, "parent": 1591, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1580,806,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1598, "rf_id": 1017, "parent": 1597, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[1024],[1],8395776], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1599,859,8395776,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1597, "rf_id": 1016, "parent": 1596, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,8395776,8396800,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1599,859,8395776,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 1596, "rf_id": 1015, "parent": 1591, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,8395776,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1599,859,8395776,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1600, "rf_id": 1018, "parent": 1591, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1595,806,0,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1589,806,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1601, "rf_id": 1019, "parent": 1591, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1599,859,8395776,1024,2,"cuda:0"],[1589,806,0,1024,2,"cuda:0"],false], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1599,859,8395776,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1604, "rf_id": 1021, "parent": 1603, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1602,859,8395776,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1605,859,8395776,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1603, "rf_id": 1020, "parent": 1591, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1602,859,8395776,1024,2,"cuda:0"],[1595,806,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1605,859,8395776,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1606, "rf_id": 1022, "parent": 1591, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[1595,806,0,1024,2,"cuda:0"],[1605,859,8395776,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 1591, "rf_id": 1011, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1610, "rf_id": 1026, "parent": 1609, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1583,716,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1609, "rf_id": 1025, "parent": 1608, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1583,716,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1611,716,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 1608, "rf_id": 1024, "parent": 1607, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1583,716,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1614, "rf_id": 1029, "parent": 1613, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[1024],[1],8396800], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1615,859,8396800,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1613, "rf_id": 1028, "parent": 1612, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,8396800,8397824,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1615,859,8396800,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 1612, "rf_id": 1027, "parent": 1607, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,8396800,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1615,859,8396800,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1616, "rf_id": 1030, "parent": 1607, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1611,716,0,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1617,716,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1618, "rf_id": 1031, "parent": 1607, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1615,859,8396800,1024,2,"cuda:0"],[1617,716,0,1024,2,"cuda:0"],false], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1615,859,8396800,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1621, "rf_id": 1033, "parent": 1620, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1619,859,8396800,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1622,859,8396800,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1620, "rf_id": 1032, "parent": 1607, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1619,859,8396800,1024,2,"cuda:0"],[1611,716,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1622,859,8396800,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1623, "rf_id": 1034, "parent": 1607, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[1611,716,0,1024,2,"cuda:0"],[1622,859,8396800,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 1607, "rf_id": 1023, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1629, "rf_id": 1040, "parent": 1628, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,1024],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[1630,1171,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1628, "rf_id": 1039, "parent": 1627, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1243,505,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>",0], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","Int"],
      "outputs": [[1630,1171,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout_backward", "id": 1627, "rf_id": 1038, "parent": 1626, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout_backward(Tensor grad_output, Tensor mask, float scale) -> Tensor",
      "inputs": [[1243,505,0,163840,2,"cuda:0"],[1227,645,0,163840,1,"cuda:0"],1.111111], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(bool)","Double"],
      "outputs": [[1630,1171,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<backward op>", "id": 1626, "rf_id": 1037, "parent": 1625, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1243,505,0,163840,2,"cuda:0"],1.111111,[1227,645,0,163840,1,"cuda:0"],"<None>","<None>"], "input_shapes": [[20,8,1024],[],[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(bool)","None","None"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 1625, "rf_id": 1036, "parent": 1624, "fw_parent": 1624, "seq_id": 202, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1243,505,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 1624, "rf_id": 1035, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::mul", "id": 1637, "rf_id": 1045, "parent": 1634, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1630,1171,0,163840,2,"cuda:0"],[1635,1636,0,1,8,"cpu"]], "input_shapes": [[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)"],
      "outputs": [[1638,645,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1634, "rf_id": 1044, "parent": 1633, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1630,1171,0,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1638,645,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<backward op>", "id": 1633, "rf_id": 1043, "parent": 1632, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1630,1171,0,163840,2,"cuda:0"],"<None>","<None>"], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 1632, "rf_id": 1042, "parent": 1631, "fw_parent": 1631, "seq_id": 201, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1630,1171,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 1631, "rf_id": 1041, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::sum", "id": 1641, "rf_id": 1048, "parent": 1640, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1638,645,0,163840,2,"cuda:0"],[0,1],true,"<None>"], "input_shapes": [[20,8,1024],[[],[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","Bool","None"],
      "outputs": [[1642,132,0,1024,2,"cuda:0"]], "output_shapes": [[1,1,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1643, "rf_id": 1049, "parent": 1640, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1642,132,0,1024,2,"cuda:0"],[1024]], "input_shapes": [[1,1,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1644,132,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ExpandBackward0", "id": 1640, "rf_id": 1047, "parent": 1639, "fw_parent": 1639, "seq_id": 200, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1638,645,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ExpandBackward0", "id": 1639, "rf_id": 1046, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1648, "rf_id": 1053, "parent": 1647, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1644,132,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1647, "rf_id": 1052, "parent": 1646, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1644,132,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1649,132,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 1646, "rf_id": 1051, "parent": 1645, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1644,132,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1652, "rf_id": 1056, "parent": 1651, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[1024],[1],8397824], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1653,859,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1651, "rf_id": 1055, "parent": 1650, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,8397824,8398848,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1653,859,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 1650, "rf_id": 1054, "parent": 1645, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,8397824,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1653,859,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1654, "rf_id": 1057, "parent": 1645, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1649,132,0,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1655,132,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1656, "rf_id": 1058, "parent": 1645, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1653,859,8397824,1024,2,"cuda:0"],[1655,132,0,1024,2,"cuda:0"],false], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1653,859,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1659, "rf_id": 1060, "parent": 1658, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1657,859,8397824,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1660,859,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1658, "rf_id": 1059, "parent": 1645, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1657,859,8397824,1024,2,"cuda:0"],[1649,132,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1660,859,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1661, "rf_id": 1061, "parent": 1645, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[1649,132,0,1024,2,"cuda:0"],[1660,859,8397824,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 1645, "rf_id": 1050, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_ReduceFromModelParallelRegionBackward", "id": 1663, "rf_id": 1063, "parent": 1662, "fw_parent": 1662, "seq_id": 199, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1630,1171,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _ReduceFromModelParallelRegionBackward", "id": 1662, "rf_id": 1062, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1668, "rf_id": 1068, "parent": 1667, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1630,1171,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1669,1171,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1667, "rf_id": 1067, "parent": 1666, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1630,1171,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1669,1171,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1670, "rf_id": 1069, "parent": 1666, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1669,1171,0,163840,2,"cuda:0"],[456,236,54677504,1048576,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1671,645,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1672, "rf_id": 1070, "parent": 1666, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1671,645,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1673,645,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1666, "rf_id": 1066, "parent": 1665, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1630,1171,0,163840,2,"cuda:0"],[456,236,54677504,1048576,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1673,645,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1674, "rf_id": 1071, "parent": 1665, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1630,1171,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1675,1171,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1676, "rf_id": 1072, "parent": 1665, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1184,323,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1677,323,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1680, "rf_id": 1075, "parent": 1679, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1675,1171,0,163840,2,"cuda:0"],[1024,160],[1,1024],"<None>"], "input_shapes": [[160,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1681,1171,0,163840,2,"cuda:0"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1679, "rf_id": 1074, "parent": 1678, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1675,1171,0,163840,2,"cuda:0"],0,1], "input_shapes": [[160,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1681,1171,0,163840,2,"cuda:0"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1678, "rf_id": 1073, "parent": 1665, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1675,1171,0,163840,2,"cuda:0"]], "input_shapes": [[160,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1681,1171,0,163840,2,"cuda:0"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1683, "rf_id": 1077, "parent": 1682, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1681,1171,0,163840,2,"cuda:0"],[1677,323,0,163840,2,"cuda:0"]], "input_shapes": [[1024,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1684,576,0,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1682, "rf_id": 1076, "parent": 1665, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1681,1171,0,163840,2,"cuda:0"],[1677,323,0,163840,2,"cuda:0"]], "input_shapes": [[1024,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1684,576,0,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 1665, "rf_id": 1065, "parent": 1664, "fw_parent": 1664, "seq_id": 198, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1630,1171,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 1664, "rf_id": 1064, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1688, "rf_id": 1081, "parent": 1687, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1684,576,0,1048576,2,"cuda:0"]], "input_shapes": [[1024,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1687, "rf_id": 1080, "parent": 1686, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1684,576,0,1048576,2,"cuda:0"]], "input_shapes": [[1024,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1689,576,0,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 1686, "rf_id": 1079, "parent": 1685, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1684,576,0,1048576,2,"cuda:0"]], "input_shapes": [[1024,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1692, "rf_id": 1084, "parent": 1691, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[1048576],[1],8398848], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1693,859,8398848,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1691, "rf_id": 1083, "parent": 1690, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,8398848,9447424,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1693,859,8398848,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 1690, "rf_id": 1082, "parent": 1685, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,8398848,1048576], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1693,859,8398848,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1694, "rf_id": 1085, "parent": 1685, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1689,576,0,1048576,2,"cuda:0"],[-1]], "input_shapes": [[1024,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1695,576,0,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1696, "rf_id": 1086, "parent": 1685, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1693,859,8398848,1048576,2,"cuda:0"],[1695,576,0,1048576,2,"cuda:0"],false], "input_shapes": [[1048576],[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1693,859,8398848,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1699, "rf_id": 1088, "parent": 1698, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1697,859,8398848,1048576,2,"cuda:0"],[1024,1024]], "input_shapes": [[1048576],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1700,859,8398848,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1698, "rf_id": 1087, "parent": 1685, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1697,859,8398848,1048576,2,"cuda:0"],[1689,576,0,1048576,2,"cuda:0"]], "input_shapes": [[1048576],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1700,859,8398848,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1701, "rf_id": 1089, "parent": 1685, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[1689,576,0,1048576,2,"cuda:0"],[1700,859,8398848,1048576,2,"cuda:0"]], "input_shapes": [[1024,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 1685, "rf_id": 1078, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1705, "rf_id": 1093, "parent": 1704, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1673,645,0,163840,2,"cuda:0"],[20,8,16,64]], "input_shapes": [[20,8,1024],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1706,645,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1704, "rf_id": 1092, "parent": 1703, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1673,645,0,163840,2,"cuda:0"],[20,8,16,64]], "input_shapes": [[20,8,1024],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1706,645,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 1703, "rf_id": 1091, "parent": 1702, "fw_parent": 1702, "seq_id": 197, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1673,645,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 1702, "rf_id": 1090, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "CloneBackward0", "id": 1708, "rf_id": 1095, "parent": 1707, "fw_parent": 1707, "seq_id": 196, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1706,645,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: CloneBackward0", "id": 1707, "rf_id": 1094, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1712, "rf_id": 1099, "parent": 1711, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1706,645,0,163840,2,"cuda:0"],[8,16,20,64],[1024,64,8192,1],"<None>"], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","None"],
      "outputs": [[1713,645,0,163840,2,"cuda:0"]], "output_shapes": [[8,16,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::permute", "id": 1711, "rf_id": 1098, "parent": 1710, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)",
      "inputs": [[1706,645,0,163840,2,"cuda:0"],[1,2,0,3]], "input_shapes": [[20,8,16,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1713,645,0,163840,2,"cuda:0"]], "output_shapes": [[8,16,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PermuteBackward0", "id": 1710, "rf_id": 1097, "parent": 1709, "fw_parent": 1709, "seq_id": 195, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1706,645,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PermuteBackward0", "id": 1709, "rf_id": 1096, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_reshape_alias", "id": 1717, "rf_id": 1103, "parent": 1716, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[1713,645,0,163840,2,"cuda:0"],[128,20,64],[64,8192,1]], "input_shapes": [[8,16,20,64],[[],[],[]],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]"],
      "outputs": [[1718,645,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1716, "rf_id": 1102, "parent": 1715, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1713,645,0,163840,2,"cuda:0"],[128,20,64]], "input_shapes": [[8,16,20,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1718,645,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 1715, "rf_id": 1101, "parent": 1714, "fw_parent": 1714, "seq_id": 194, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1713,645,0,163840,2,"cuda:0"]], "input_shapes": [[8,16,20,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 1714, "rf_id": 1100, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1722, "rf_id": 1107, "parent": 1721, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1165,300,0,51200,2,"cuda:0"],[128,20,20],[400,1,20],"<None>"], "input_shapes": [[128,20,20],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1723,300,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1721, "rf_id": 1106, "parent": 1720, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1165,300,0,51200,2,"cuda:0"],1,2], "input_shapes": [[128,20,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1723,300,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 1724, "rf_id": 1108, "parent": 1720, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1723,300,0,51200,2,"cuda:0"],[1718,645,0,163840,2,"cuda:0"]], "input_shapes": [[128,20,20],[128,20,64]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1725,323,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1727, "rf_id": 1110, "parent": 1726, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1168,328,128,163840,2,"cuda:0"],[128,64,20],[192,1,24576],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1728,328,128,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1726, "rf_id": 1109, "parent": 1720, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1168,328,128,163840,2,"cuda:0"],1,2], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1728,328,128,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 1729, "rf_id": 1111, "parent": 1720, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1718,645,0,163840,2,"cuda:0"],[1728,328,128,163840,2,"cuda:0"]], "input_shapes": [[128,20,64],[128,64,20]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1730,421,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "BmmBackward0", "id": 1720, "rf_id": 1105, "parent": 1719, "fw_parent": 1719, "seq_id": 193, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1718,645,0,163840,2,"cuda:0"]], "input_shapes": [[128,20,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: BmmBackward0", "id": 1719, "rf_id": 1104, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1734, "rf_id": 1115, "parent": 1733, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1725,323,0,163840,2,"cuda:0"],[20,128,64],[64,1280,1],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1735,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1733, "rf_id": 1114, "parent": 1732, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1725,323,0,163840,2,"cuda:0"],0,1], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1735,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "TransposeBackward0", "id": 1732, "rf_id": 1113, "parent": 1731, "fw_parent": 1731, "seq_id": 192, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1725,323,0,163840,2,"cuda:0"]], "input_shapes": [[128,20,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 1731, "rf_id": 1112, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1739, "rf_id": 1119, "parent": 1738, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1730,421,0,51200,2,"cuda:0"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1740,421,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1738, "rf_id": 1118, "parent": 1737, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1730,421,0,51200,2,"cuda:0"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1740,421,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 1737, "rf_id": 1117, "parent": 1736, "fw_parent": 1736, "seq_id": 191, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1730,421,0,51200,2,"cuda:0"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 1736, "rf_id": 1116, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_reshape_alias", "id": 1744, "rf_id": 1123, "parent": 1743, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[1735,323,0,163840,2,"cuda:0"],[20,8,16,64],[64,20480,1280,1]], "input_shapes": [[20,128,64],[[],[],[],[]],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1745,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1743, "rf_id": 1122, "parent": 1742, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1735,323,0,163840,2,"cuda:0"],[20,8,16,64]], "input_shapes": [[20,128,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1745,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 1742, "rf_id": 1121, "parent": 1741, "fw_parent": 1741, "seq_id": 190, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1735,323,0,163840,2,"cuda:0"]], "input_shapes": [[20,128,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 1741, "rf_id": 1120, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1750, "rf_id": 1128, "parent": 1749, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,16,20,20],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[1751,645,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1749, "rf_id": 1127, "parent": 1748, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1740,421,0,51200,2,"cuda:0"],"<None>","<None>","<None>","<None>",0], "input_shapes": [[8,16,20,20],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","Int"],
      "outputs": [[1751,645,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout_backward", "id": 1748, "rf_id": 1126, "parent": 1747, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout_backward(Tensor grad_output, Tensor mask, float scale) -> Tensor",
      "inputs": [[1740,421,0,51200,2,"cuda:0"],[1157,1158,0,51200,1,"cuda:0"],1.111111], "input_shapes": [[8,16,20,20],[8,16,20,20],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(bool)","Double"],
      "outputs": [[1751,645,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "NativeDropoutBackward0", "id": 1747, "rf_id": 1125, "parent": 1746, "fw_parent": 1746, "seq_id": 189, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1740,421,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: NativeDropoutBackward0", "id": 1746, "rf_id": 1124, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1755, "rf_id": 1132, "parent": 1754, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1751,645,0,51200,2,"cuda:0"],[128,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1756,645,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1754, "rf_id": 1131, "parent": 1753, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1751,645,0,51200,2,"cuda:0"],[128,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1756,645,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 1753, "rf_id": 1130, "parent": 1752, "fw_parent": 1752, "seq_id": 188, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1751,645,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 1752, "rf_id": 1129, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1760, "rf_id": 1136, "parent": 1759, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1138,1139,0,1,8,"cpu"],[],[],0], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[1761,1139,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 1759, "rf_id": 1135, "parent": 1758, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[1138,1139,0,1,8,"cpu"],0,0], "input_shapes": [[1],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[1761,1139,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 1763, "rf_id": 1138, "parent": 1762, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[1761,1139,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 1762, "rf_id": 1137, "parent": 1758, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[1761,1139,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "ScaledUpperTriangMaskedSoftmaxBackward", "id": 1758, "rf_id": 1134, "parent": 1757, "fw_parent": 1757, "seq_id": 187, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1756,645,0,51200,2,"cuda:0"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ScaledUpperTriangMaskedSoftmaxBackward", "id": 1757, "rf_id": 1133, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1767, "rf_id": 1142, "parent": 1766, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1756,645,0,51200,2,"cuda:0"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1768,645,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1766, "rf_id": 1141, "parent": 1765, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1756,645,0,51200,2,"cuda:0"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1768,645,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 1765, "rf_id": 1140, "parent": 1764, "fw_parent": 1764, "seq_id": 186, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1756,645,0,51200,2,"cuda:0"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 1764, "rf_id": 1139, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1772, "rf_id": 1146, "parent": 1771, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1768,645,0,51200,2,"cuda:0"],[128,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1773,645,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1771, "rf_id": 1145, "parent": 1770, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1768,645,0,51200,2,"cuda:0"],[128,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1773,645,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 1770, "rf_id": 1144, "parent": 1769, "fw_parent": 1769, "seq_id": 185, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1768,645,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 1769, "rf_id": 1143, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1777, "rf_id": 1150, "parent": 1776, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1129,328,64,163840,2,"cuda:0"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[128,64,20],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1778,328,64,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1776, "rf_id": 1149, "parent": 1775, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1129,328,64,163840,2,"cuda:0"],1,2], "input_shapes": [[128,64,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1778,328,64,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 1779, "rf_id": 1151, "parent": 1775, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1773,645,0,51200,2,"cuda:0"],[1778,328,64,163840,2,"cuda:0"]], "input_shapes": [[128,20,20],[128,20,64]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1780,300,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1784, "rf_id": 1153, "parent": 1781, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1780,300,0,163840,2,"cuda:0"],[1782,1783,0,1,8,"cpu"]], "input_shapes": [[128,20,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1785,1786,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1781, "rf_id": 1152, "parent": 1775, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1780,300,0,163840,2,"cuda:0"],0.125000], "input_shapes": [[128,20,64],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1785,1786,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1788, "rf_id": 1155, "parent": 1787, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1123,328,0,163840,2,"cuda:0"],[128,64,20],[192,1,24576],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1789,328,0,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1787, "rf_id": 1154, "parent": 1775, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1123,328,0,163840,2,"cuda:0"],1,2], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1789,328,0,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 1790, "rf_id": 1156, "parent": 1775, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1789,328,0,163840,2,"cuda:0"],[1773,645,0,51200,2,"cuda:0"]], "input_shapes": [[128,64,20],[128,20,20]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1791,1792,0,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1796, "rf_id": 1158, "parent": 1793, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1791,1792,0,163840,2,"cuda:0"],[1794,1795,0,1,8,"cpu"]], "input_shapes": [[128,64,20],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1797,300,0,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1793, "rf_id": 1157, "parent": 1775, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1791,1792,0,163840,2,"cuda:0"],0.125000], "input_shapes": [[128,64,20],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1797,300,0,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "BaddbmmBackward0", "id": 1775, "rf_id": 1148, "parent": 1774, "fw_parent": 1774, "seq_id": 184, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1773,645,0,51200,2,"cuda:0"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: BaddbmmBackward0", "id": 1774, "rf_id": 1147, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1801, "rf_id": 1162, "parent": 1800, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1797,300,0,163840,2,"cuda:0"],[128,20,64],[1280,1,20],"<None>"], "input_shapes": [[128,64,20],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1802,300,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1800, "rf_id": 1161, "parent": 1799, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1797,300,0,163840,2,"cuda:0"],1,2], "input_shapes": [[128,64,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1802,300,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "TransposeBackward0", "id": 1799, "rf_id": 1160, "parent": 1798, "fw_parent": 1798, "seq_id": 183, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1797,300,0,163840,2,"cuda:0"]], "input_shapes": [[128,64,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 1798, "rf_id": 1159, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1806, "rf_id": 1166, "parent": 1805, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1802,300,0,163840,2,"cuda:0"],[20,128,64],[1,1280,20],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1807,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1805, "rf_id": 1165, "parent": 1804, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1802,300,0,163840,2,"cuda:0"],0,1], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1807,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "TransposeBackward0", "id": 1804, "rf_id": 1164, "parent": 1803, "fw_parent": 1803, "seq_id": 182, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1802,300,0,163840,2,"cuda:0"]], "input_shapes": [[128,20,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 1803, "rf_id": 1163, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1811, "rf_id": 1170, "parent": 1810, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1785,1786,0,163840,2,"cuda:0"],[20,128,64],[64,1280,1],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1812,1786,0,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1810, "rf_id": 1169, "parent": 1809, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1785,1786,0,163840,2,"cuda:0"],0,1], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1812,1786,0,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "TransposeBackward0", "id": 1809, "rf_id": 1168, "parent": 1808, "fw_parent": 1808, "seq_id": 181, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1785,1786,0,163840,2,"cuda:0"]], "input_shapes": [[128,20,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 1808, "rf_id": 1167, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_reshape_alias", "id": 1816, "rf_id": 1174, "parent": 1815, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[1807,300,0,163840,2,"cuda:0"],[20,8,16,64],[1,20480,1280,20]], "input_shapes": [[20,128,64],[[],[],[],[]],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1817,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1815, "rf_id": 1173, "parent": 1814, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1807,300,0,163840,2,"cuda:0"],[20,8,16,64]], "input_shapes": [[20,128,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1817,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 1814, "rf_id": 1172, "parent": 1813, "fw_parent": 1813, "seq_id": 180, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1807,300,0,163840,2,"cuda:0"]], "input_shapes": [[20,128,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 1813, "rf_id": 1171, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_reshape_alias", "id": 1821, "rf_id": 1178, "parent": 1820, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[1812,1786,0,163840,2,"cuda:0"],[20,8,16,64],[64,20480,1280,1]], "input_shapes": [[20,128,64],[[],[],[],[]],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1822,1786,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1820, "rf_id": 1177, "parent": 1819, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1812,1786,0,163840,2,"cuda:0"],[20,8,16,64]], "input_shapes": [[20,128,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1822,1786,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 1819, "rf_id": 1176, "parent": 1818, "fw_parent": 1818, "seq_id": 179, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1812,1786,0,163840,2,"cuda:0"]], "input_shapes": [[20,128,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 1818, "rf_id": 1175, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1827, "rf_id": 1183, "parent": 1826, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1828,1792,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 1830, "rf_id": 1185, "parent": 1829, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1828,1792,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1828,1792,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 1829, "rf_id": 1184, "parent": 1826, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1828,1792,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1828,1792,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 1826, "rf_id": 1182, "parent": 1825, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1828,1792,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1832, "rf_id": 1187, "parent": 1831, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1828,1792,0,163840,2,"cuda:0"],[20,8,16,64],[8192,1024,64,1],0], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[1833,1792,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1831, "rf_id": 1186, "parent": 1825, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1828,1792,0,163840,2,"cuda:0"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1833,1792,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1834, "rf_id": 1188, "parent": 1825, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1833,1792,0,163840,2,"cuda:0"],[1745,323,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1833,1792,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 1825, "rf_id": 1181, "parent": 1824, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[1745,323,0,163840,2,"cuda:0"],[20,8,16,64],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[1828,1792,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 1824, "rf_id": 1180, "parent": 1823, "fw_parent": 1823, "seq_id": 178, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1745,323,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 1823, "rf_id": 1179, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1839, "rf_id": 1193, "parent": 1838, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1840,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 1842, "rf_id": 1195, "parent": 1841, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1840,1231,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1840,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 1841, "rf_id": 1194, "parent": 1838, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1840,1231,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1840,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 1838, "rf_id": 1192, "parent": 1837, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1840,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1844, "rf_id": 1197, "parent": 1843, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1840,1231,0,491520,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],128], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[1845,1231,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 1843, "rf_id": 1196, "parent": 1837, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[1840,1231,0,491520,2,"cuda:0"],3,-1], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1845,1231,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1846, "rf_id": 1198, "parent": 1837, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1845,1231,128,163840,2,"cuda:0"],[1828,1792,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1845,1231,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select_backward", "id": 1837, "rf_id": 1191, "parent": 1836, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt index) -> Tensor",
      "inputs": [[1828,1792,0,163840,2,"cuda:0"],[20,8,16,3,64],3,-1], "input_shapes": [[20,8,16,64],[[],[],[],[],[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int"],
      "outputs": [[1840,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SelectBackward0", "id": 1836, "rf_id": 1190, "parent": 1835, "fw_parent": 1835, "seq_id": 177, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1828,1792,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SelectBackward0", "id": 1835, "rf_id": 1189, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1851, "rf_id": 1203, "parent": 1850, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1852,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 1854, "rf_id": 1205, "parent": 1853, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1852,645,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1852,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 1853, "rf_id": 1204, "parent": 1850, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1852,645,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1852,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 1850, "rf_id": 1202, "parent": 1849, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1852,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1856, "rf_id": 1207, "parent": 1855, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1852,645,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1857,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1855, "rf_id": 1206, "parent": 1849, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1852,645,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1857,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1858, "rf_id": 1208, "parent": 1849, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1857,645,0,491520,2,"cuda:0"],[1840,1231,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1857,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 1849, "rf_id": 1201, "parent": 1848, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[1840,1231,0,491520,2,"cuda:0"],[20,8,16,3,64],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[1852,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 1848, "rf_id": 1200, "parent": 1847, "fw_parent": 1847, "seq_id": 176, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1840,1231,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 1847, "rf_id": 1199, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1863, "rf_id": 1213, "parent": 1862, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1864,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 1866, "rf_id": 1215, "parent": 1865, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1864,1231,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1864,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 1865, "rf_id": 1214, "parent": 1862, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1864,1231,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1864,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 1862, "rf_id": 1212, "parent": 1861, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1864,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1868, "rf_id": 1217, "parent": 1867, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1864,1231,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1869,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1867, "rf_id": 1216, "parent": 1861, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1864,1231,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1869,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1870, "rf_id": 1218, "parent": 1861, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1869,1231,0,491520,2,"cuda:0"],[1852,645,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1869,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 1861, "rf_id": 1211, "parent": 1860, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[1852,645,0,491520,2,"cuda:0"],[20,8,16,3,64],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[1864,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 1860, "rf_id": 1210, "parent": 1859, "fw_parent": 1859, "seq_id": 175, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1852,645,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 1859, "rf_id": 1209, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1875, "rf_id": 1223, "parent": 1874, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1876,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 1878, "rf_id": 1225, "parent": 1877, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1876,645,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1876,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 1877, "rf_id": 1224, "parent": 1874, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1876,645,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1876,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 1874, "rf_id": 1222, "parent": 1873, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1876,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1880, "rf_id": 1227, "parent": 1879, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1876,645,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1881,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1879, "rf_id": 1226, "parent": 1873, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1876,645,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1881,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1882, "rf_id": 1228, "parent": 1873, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1881,645,0,491520,2,"cuda:0"],[1864,1231,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1881,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 1873, "rf_id": 1221, "parent": 1872, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[1864,1231,0,491520,2,"cuda:0"],[20,8,16,3,64],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[1876,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 1872, "rf_id": 1220, "parent": 1871, "fw_parent": 1871, "seq_id": 174, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1864,1231,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 1871, "rf_id": 1219, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1887, "rf_id": 1233, "parent": 1886, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1888,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 1890, "rf_id": 1235, "parent": 1889, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1888,323,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1888,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 1889, "rf_id": 1234, "parent": 1886, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1888,323,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1888,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 1886, "rf_id": 1232, "parent": 1885, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1888,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1892, "rf_id": 1237, "parent": 1891, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1888,323,0,163840,2,"cuda:0"],[20,8,16,64],[8192,1024,64,1],0], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[1893,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1891, "rf_id": 1236, "parent": 1885, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1888,323,0,163840,2,"cuda:0"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1893,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1894, "rf_id": 1238, "parent": 1885, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1893,323,0,163840,2,"cuda:0"],[1817,300,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1893,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 1885, "rf_id": 1231, "parent": 1884, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[1817,300,0,163840,2,"cuda:0"],[20,8,16,64],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[1888,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 1884, "rf_id": 1230, "parent": 1883, "fw_parent": 1883, "seq_id": 173, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1817,300,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 1883, "rf_id": 1229, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1899, "rf_id": 1243, "parent": 1898, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1900,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 1902, "rf_id": 1245, "parent": 1901, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1900,1231,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1900,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 1901, "rf_id": 1244, "parent": 1898, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1900,1231,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1900,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 1898, "rf_id": 1242, "parent": 1897, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1900,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1904, "rf_id": 1247, "parent": 1903, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1900,1231,0,491520,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],64], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[1905,1231,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 1903, "rf_id": 1246, "parent": 1897, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[1900,1231,0,491520,2,"cuda:0"],3,-2], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1905,1231,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1906, "rf_id": 1248, "parent": 1897, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1905,1231,64,163840,2,"cuda:0"],[1888,323,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1905,1231,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select_backward", "id": 1897, "rf_id": 1241, "parent": 1896, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt index) -> Tensor",
      "inputs": [[1888,323,0,163840,2,"cuda:0"],[20,8,16,3,64],3,-2], "input_shapes": [[20,8,16,64],[[],[],[],[],[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int"],
      "outputs": [[1900,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SelectBackward0", "id": 1896, "rf_id": 1240, "parent": 1895, "fw_parent": 1895, "seq_id": 172, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1888,323,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SelectBackward0", "id": 1895, "rf_id": 1239, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1911, "rf_id": 1253, "parent": 1910, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1912,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 1915, "rf_id": 1255, "parent": 1914, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1912,1913,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1912,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 1914, "rf_id": 1254, "parent": 1910, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1912,1913,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1912,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 1910, "rf_id": 1252, "parent": 1909, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1912,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1917, "rf_id": 1257, "parent": 1916, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1912,1913,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1918,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1916, "rf_id": 1256, "parent": 1909, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1912,1913,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1918,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1919, "rf_id": 1258, "parent": 1909, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1918,1913,0,491520,2,"cuda:0"],[1900,1231,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1918,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 1909, "rf_id": 1251, "parent": 1908, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[1900,1231,0,491520,2,"cuda:0"],[20,8,16,3,64],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[1912,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 1908, "rf_id": 1250, "parent": 1907, "fw_parent": 1907, "seq_id": 171, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1900,1231,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 1907, "rf_id": 1249, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1924, "rf_id": 1263, "parent": 1923, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1925,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 1927, "rf_id": 1265, "parent": 1926, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1925,1231,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1925,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 1926, "rf_id": 1264, "parent": 1923, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1925,1231,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1925,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 1923, "rf_id": 1262, "parent": 1922, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1925,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1929, "rf_id": 1267, "parent": 1928, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1925,1231,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1930,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1928, "rf_id": 1266, "parent": 1922, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1925,1231,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1930,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1931, "rf_id": 1268, "parent": 1922, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1930,1231,0,491520,2,"cuda:0"],[1912,1913,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1930,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 1922, "rf_id": 1261, "parent": 1921, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[1912,1913,0,491520,2,"cuda:0"],[20,8,16,3,64],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[1925,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 1921, "rf_id": 1260, "parent": 1920, "fw_parent": 1920, "seq_id": 170, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1912,1913,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 1920, "rf_id": 1259, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1936, "rf_id": 1273, "parent": 1935, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1937,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 1939, "rf_id": 1275, "parent": 1938, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1937,1913,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1937,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 1938, "rf_id": 1274, "parent": 1935, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1937,1913,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1937,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 1935, "rf_id": 1272, "parent": 1934, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1937,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1941, "rf_id": 1277, "parent": 1940, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1937,1913,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1942,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1940, "rf_id": 1276, "parent": 1934, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1937,1913,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1942,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1943, "rf_id": 1278, "parent": 1934, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1942,1913,0,491520,2,"cuda:0"],[1925,1231,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1942,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 1934, "rf_id": 1271, "parent": 1933, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[1925,1231,0,491520,2,"cuda:0"],[20,8,16,3,64],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[1937,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 1933, "rf_id": 1270, "parent": 1932, "fw_parent": 1932, "seq_id": 169, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1925,1231,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add_", "id": 1944, "rf_id": 1279, "parent": 1932, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)",
      "inputs": [[1876,645,0,491520,2,"cuda:0"],[1937,1913,0,491520,2,"cuda:0"],1], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1876,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 1932, "rf_id": 1269, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_reshape_alias", "id": 1948, "rf_id": 1283, "parent": 1947, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[1822,1786,0,163840,2,"cuda:0"],[20,8,16,1,64],[64,20480,1280,64,1]], "input_shapes": [[20,8,16,64],[[],[],[],[],[]],[[],[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]"],
      "outputs": [[1949,1786,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1947, "rf_id": 1282, "parent": 1946, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1822,1786,0,163840,2,"cuda:0"],[20,8,16,1,64]], "input_shapes": [[20,8,16,64],[[],[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]"],
      "outputs": [[1949,1786,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ReshapeAliasBackward0", "id": 1946, "rf_id": 1281, "parent": 1945, "fw_parent": 1945, "seq_id": 168, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1822,1786,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ReshapeAliasBackward0", "id": 1945, "rf_id": 1280, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1954, "rf_id": 1288, "parent": 1953, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,1,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1955,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 1957, "rf_id": 1290, "parent": 1956, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1955,323,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,16,1,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1955,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 1956, "rf_id": 1289, "parent": 1953, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1955,323,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,1,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1955,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 1953, "rf_id": 1287, "parent": 1952, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,1,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1955,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1959, "rf_id": 1292, "parent": 1958, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1955,323,0,163840,2,"cuda:0"],[20,8,16,1,64],[8192,1024,64,64,1],0], "input_shapes": [[20,8,16,1,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1960,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1958, "rf_id": 1291, "parent": 1952, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1955,323,0,163840,2,"cuda:0"],4,0,9223372036854775807,1], "input_shapes": [[20,8,16,1,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1960,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1961, "rf_id": 1293, "parent": 1952, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1960,323,0,163840,2,"cuda:0"],[1949,1786,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,16,1,64],[20,8,16,1,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1960,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 1952, "rf_id": 1286, "parent": 1951, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[1949,1786,0,163840,2,"cuda:0"],[20,8,16,1,64],4,0,9223372036854775807,1], "input_shapes": [[20,8,16,1,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[1955,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 1951, "rf_id": 1285, "parent": 1950, "fw_parent": 1950, "seq_id": 167, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1949,1786,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,1,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 1950, "rf_id": 1284, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1966, "rf_id": 1298, "parent": 1965, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1967,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 1969, "rf_id": 1300, "parent": 1968, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1967,1231,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1967,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 1968, "rf_id": 1299, "parent": 1965, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1967,1231,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1967,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 1965, "rf_id": 1297, "parent": 1964, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1967,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1971, "rf_id": 1302, "parent": 1970, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1967,1231,0,491520,2,"cuda:0"],[20,8,16,1,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1972,1231,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1970, "rf_id": 1301, "parent": 1964, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1967,1231,0,491520,2,"cuda:0"],3,0,-2,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1972,1231,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1973, "rf_id": 1303, "parent": 1964, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1972,1231,0,163840,2,"cuda:0"],[1955,323,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,16,1,64],[20,8,16,1,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1972,1231,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 1964, "rf_id": 1296, "parent": 1963, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[1955,323,0,163840,2,"cuda:0"],[20,8,16,3,64],3,0,-2,1], "input_shapes": [[20,8,16,1,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[1967,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 1963, "rf_id": 1295, "parent": 1962, "fw_parent": 1962, "seq_id": 166, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1955,323,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,1,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 1962, "rf_id": 1294, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1978, "rf_id": 1308, "parent": 1977, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1979,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 1981, "rf_id": 1310, "parent": 1980, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1979,1913,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1979,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 1980, "rf_id": 1309, "parent": 1977, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1979,1913,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1979,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 1977, "rf_id": 1307, "parent": 1976, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1979,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1983, "rf_id": 1312, "parent": 1982, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1979,1913,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1984,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1982, "rf_id": 1311, "parent": 1976, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1979,1913,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1984,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1985, "rf_id": 1313, "parent": 1976, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1984,1913,0,491520,2,"cuda:0"],[1967,1231,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1984,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 1976, "rf_id": 1306, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[1967,1231,0,491520,2,"cuda:0"],[20,8,16,3,64],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[1979,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 1975, "rf_id": 1305, "parent": 1974, "fw_parent": 1974, "seq_id": 165, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1967,1231,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 1974, "rf_id": 1304, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1990, "rf_id": 1318, "parent": 1989, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1991,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 1993, "rf_id": 1320, "parent": 1992, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1991,1231,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1991,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 1992, "rf_id": 1319, "parent": 1989, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1991,1231,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1991,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 1989, "rf_id": 1317, "parent": 1988, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1991,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1995, "rf_id": 1322, "parent": 1994, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1991,1231,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1996,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1994, "rf_id": 1321, "parent": 1988, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1991,1231,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1996,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1997, "rf_id": 1323, "parent": 1988, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1996,1231,0,491520,2,"cuda:0"],[1979,1913,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1996,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 1988, "rf_id": 1316, "parent": 1987, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[1979,1913,0,491520,2,"cuda:0"],[20,8,16,3,64],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[1991,1231,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 1987, "rf_id": 1315, "parent": 1986, "fw_parent": 1986, "seq_id": 164, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1979,1913,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 1986, "rf_id": 1314, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2002, "rf_id": 1328, "parent": 2001, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2003,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2005, "rf_id": 1330, "parent": 2004, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2003,1913,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2003,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2004, "rf_id": 1329, "parent": 2001, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2003,1913,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2003,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2001, "rf_id": 1327, "parent": 2000, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2003,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2007, "rf_id": 1332, "parent": 2006, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2003,1913,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2008,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2006, "rf_id": 1331, "parent": 2000, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2003,1913,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2008,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2009, "rf_id": 1333, "parent": 2000, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2008,1913,0,491520,2,"cuda:0"],[1991,1231,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2008,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2000, "rf_id": 1326, "parent": 1999, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[1991,1231,0,491520,2,"cuda:0"],[20,8,16,3,64],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2003,1913,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 1999, "rf_id": 1325, "parent": 1998, "fw_parent": 1998, "seq_id": 163, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1991,1231,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add_", "id": 2010, "rf_id": 1334, "parent": 1998, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)",
      "inputs": [[1876,645,0,491520,2,"cuda:0"],[2003,1913,0,491520,2,"cuda:0"],1], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1876,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 1998, "rf_id": 1324, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2014, "rf_id": 1338, "parent": 2013, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1876,645,0,491520,2,"cuda:0"],[20,8,3072]], "input_shapes": [[20,8,16,3,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2015,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2013, "rf_id": 1337, "parent": 2012, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1876,645,0,491520,2,"cuda:0"],[20,8,3072]], "input_shapes": [[20,8,16,3,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2015,645,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2012, "rf_id": 1336, "parent": 2011, "fw_parent": 2011, "seq_id": 162, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1876,645,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2011, "rf_id": 1335, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2020, "rf_id": 1343, "parent": 2019, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2015,645,0,491520,2,"cuda:0"],[160,3072]], "input_shapes": [[20,8,3072],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2021,645,0,491520,2,"cuda:0"]], "output_shapes": [[160,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2019, "rf_id": 1342, "parent": 2018, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2015,645,0,491520,2,"cuda:0"],[160,3072]], "input_shapes": [[20,8,3072],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2021,645,0,491520,2,"cuda:0"]], "output_shapes": [[160,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 2022, "rf_id": 1344, "parent": 2018, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2021,645,0,491520,2,"cuda:0"],[310,236,51531776,3145728,2,"cuda:0"]], "input_shapes": [[160,3072],[3072,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2023,323,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 2024, "rf_id": 1345, "parent": 2018, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[2023,323,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2025,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 2018, "rf_id": 1341, "parent": 2017, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2015,645,0,491520,2,"cuda:0"],[310,236,51531776,3145728,2,"cuda:0"]], "input_shapes": [[20,8,3072],[3072,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2025,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2026, "rf_id": 1346, "parent": 2017, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2015,645,0,491520,2,"cuda:0"],[160,3072]], "input_shapes": [[20,8,3072],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2027,645,0,491520,2,"cuda:0"]], "output_shapes": [[160,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2028, "rf_id": 1347, "parent": 2017, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1046,245,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2029,245,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2032, "rf_id": 1350, "parent": 2031, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2027,645,0,491520,2,"cuda:0"],[3072,160],[1,3072],"<None>"], "input_shapes": [[160,3072],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[2033,645,0,491520,2,"cuda:0"]], "output_shapes": [[3072,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2031, "rf_id": 1349, "parent": 2030, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[2027,645,0,491520,2,"cuda:0"],0,1], "input_shapes": [[160,3072],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2033,645,0,491520,2,"cuda:0"]], "output_shapes": [[3072,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 2030, "rf_id": 1348, "parent": 2017, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2027,645,0,491520,2,"cuda:0"]], "input_shapes": [[160,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2033,645,0,491520,2,"cuda:0"]], "output_shapes": [[3072,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 2035, "rf_id": 1352, "parent": 2034, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2033,645,0,491520,2,"cuda:0"],[2029,245,0,163840,2,"cuda:0"]], "input_shapes": [[3072,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2036,576,0,3145728,2,"cuda:0"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 2034, "rf_id": 1351, "parent": 2017, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2033,645,0,491520,2,"cuda:0"],[2029,245,0,163840,2,"cuda:0"]], "input_shapes": [[3072,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2036,576,0,3145728,2,"cuda:0"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2039, "rf_id": 1354, "parent": 2037, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2038,716,0,3072,2,"cuda:0"],[1,3072],[0,1],"<None>"], "input_shapes": [[3072],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[2040,716,0,3072,2,"cuda:0"]], "output_shapes": [[1,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::sum", "id": 2037, "rf_id": 1353, "parent": 2017, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[2027,645,0,491520,2,"cuda:0"],[0],false,"<None>"], "input_shapes": [[160,3072],[[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","Bool","None"],
      "outputs": [[2038,716,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 2017, "rf_id": 1340, "parent": 2016, "fw_parent": 2016, "seq_id": 161, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2015,645,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 2016, "rf_id": 1339, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2044, "rf_id": 1358, "parent": 2043, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2036,576,0,3145728,2,"cuda:0"]], "input_shapes": [[3072,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2043, "rf_id": 1357, "parent": 2042, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2036,576,0,3145728,2,"cuda:0"]], "input_shapes": [[3072,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2040,576,0,3145728,2,"cuda:0"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2042, "rf_id": 1356, "parent": 2041, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2036,576,0,3145728,2,"cuda:0"]], "input_shapes": [[3072,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2047, "rf_id": 1361, "parent": 2046, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[3145728],[1],9447424], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2048,859,9447424,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2046, "rf_id": 1360, "parent": 2045, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,9447424,12593152,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2048,859,9447424,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2045, "rf_id": 1359, "parent": 2041, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,9447424,3145728], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2048,859,9447424,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2049, "rf_id": 1362, "parent": 2041, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2040,576,0,3145728,2,"cuda:0"],[-1]], "input_shapes": [[3072,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2050,576,0,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2051, "rf_id": 1363, "parent": 2041, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2048,859,9447424,3145728,2,"cuda:0"],[2050,576,0,3145728,2,"cuda:0"],false], "input_shapes": [[3145728],[3145728],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2048,859,9447424,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2054, "rf_id": 1365, "parent": 2053, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2052,859,9447424,3145728,2,"cuda:0"],[3072,1024]], "input_shapes": [[3145728],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2055,859,9447424,3145728,2,"cuda:0"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2053, "rf_id": 1364, "parent": 2041, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2052,859,9447424,3145728,2,"cuda:0"],[2040,576,0,3145728,2,"cuda:0"]], "input_shapes": [[3145728],[3072,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2055,859,9447424,3145728,2,"cuda:0"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2056, "rf_id": 1366, "parent": 2041, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2040,576,0,3145728,2,"cuda:0"],[2055,859,9447424,3145728,2,"cuda:0"]], "input_shapes": [[3072,1024],[3072,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2041, "rf_id": 1355, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2060, "rf_id": 1370, "parent": 2059, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2038,716,0,3072,2,"cuda:0"]], "input_shapes": [[3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2059, "rf_id": 1369, "parent": 2058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2038,716,0,3072,2,"cuda:0"]], "input_shapes": [[3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2061,716,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2058, "rf_id": 1368, "parent": 2057, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2038,716,0,3072,2,"cuda:0"]], "input_shapes": [[3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2064, "rf_id": 1373, "parent": 2063, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[3072],[1],12593152], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2065,859,12593152,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2063, "rf_id": 1372, "parent": 2062, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12593152,12596224,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2065,859,12593152,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2062, "rf_id": 1371, "parent": 2057, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12593152,3072], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2065,859,12593152,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2066, "rf_id": 1374, "parent": 2057, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2061,716,0,3072,2,"cuda:0"],[-1]], "input_shapes": [[3072],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2067,716,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2068, "rf_id": 1375, "parent": 2057, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2065,859,12593152,3072,2,"cuda:0"],[2067,716,0,3072,2,"cuda:0"],false], "input_shapes": [[3072],[3072],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2065,859,12593152,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2071, "rf_id": 1377, "parent": 2070, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2069,859,12593152,3072,2,"cuda:0"],[3072]], "input_shapes": [[3072],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2072,859,12593152,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2070, "rf_id": 1376, "parent": 2057, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2069,859,12593152,3072,2,"cuda:0"],[2061,716,0,3072,2,"cuda:0"]], "input_shapes": [[3072],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2072,859,12593152,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2073, "rf_id": 1378, "parent": 2057, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2061,716,0,3072,2,"cuda:0"],[2072,859,12593152,3072,2,"cuda:0"]], "input_shapes": [[3072],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2057, "rf_id": 1367, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_CopyToModelParallelRegionBackward", "id": 2075, "rf_id": 1380, "parent": 2074, "fw_parent": 2074, "seq_id": 160, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2025,323,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _CopyToModelParallelRegionBackward", "id": 2074, "rf_id": 1379, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 2080, "rf_id": 1384, "parent": 2079, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2081,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2079, "rf_id": 1383, "parent": 2077, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2078,245,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[2081,300,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 2083, "rf_id": 1386, "parent": 2082, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[2084,132,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2082, "rf_id": 1385, "parent": 2077, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[293,294,0,1024,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[2084,132,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 2086, "rf_id": 1388, "parent": 2085, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[2087,716,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2085, "rf_id": 1387, "parent": 2077, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[295,294,1024,1024,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[2087,716,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 2088, "rf_id": 1389, "parent": 2077, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[16,1024],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2089,401,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 2091, "rf_id": 1391, "parent": 2090, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[16,1024],[1024,1],6,0,"cuda:0","<None>"], "input_shapes": [[[],[]],[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[2092,987,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 2090, "rf_id": 1390, "parent": 2077, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2089,401,0,16384,4,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[16,1024],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[2092,987,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunctionBackward", "id": 2077, "rf_id": 1382, "parent": 2076, "fw_parent": 2076, "seq_id": 159, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2025,323,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add_", "id": 2093, "rf_id": 1392, "parent": 2076, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)",
      "inputs": [[1243,505,0,163840,2,"cuda:0"],[2081,300,0,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1243,505,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: FusedLayerNormAffineFunctionBackward", "id": 2076, "rf_id": 1381, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2097, "rf_id": 1396, "parent": 2096, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1243,505,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2096, "rf_id": 1395, "parent": 2095, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1243,505,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2098,505,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2095, "rf_id": 1394, "parent": 2094, "fw_parent": 2094, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1243,505,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2094, "rf_id": 1393, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2102, "rf_id": 1400, "parent": 2101, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2084,132,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2101, "rf_id": 1399, "parent": 2100, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2084,132,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2103,132,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2100, "rf_id": 1398, "parent": 2099, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2084,132,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2106, "rf_id": 1403, "parent": 2105, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[1024],[1],12596224], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1042,859,12596224,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2105, "rf_id": 1402, "parent": 2104, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12596224,12597248,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1042,859,12596224,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2104, "rf_id": 1401, "parent": 2099, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12596224,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1042,859,12596224,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2107, "rf_id": 1404, "parent": 2099, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2103,132,0,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2092,132,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2108, "rf_id": 1405, "parent": 2099, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1042,859,12596224,1024,2,"cuda:0"],[2092,132,0,1024,2,"cuda:0"],false], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1042,859,12596224,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2111, "rf_id": 1407, "parent": 2110, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2109,859,12596224,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2112,859,12596224,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2110, "rf_id": 1406, "parent": 2099, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2109,859,12596224,1024,2,"cuda:0"],[2103,132,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2112,859,12596224,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2113, "rf_id": 1408, "parent": 2099, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2103,132,0,1024,2,"cuda:0"],[2112,859,12596224,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2099, "rf_id": 1397, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2117, "rf_id": 1412, "parent": 2116, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2087,716,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2116, "rf_id": 1411, "parent": 2115, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2087,716,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2118,716,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2115, "rf_id": 1410, "parent": 2114, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2087,716,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2121, "rf_id": 1415, "parent": 2120, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[1024],[1],12597248], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2122,859,12597248,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2120, "rf_id": 1414, "parent": 2119, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12597248,12598272,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2122,859,12597248,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2119, "rf_id": 1413, "parent": 2114, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12597248,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2122,859,12597248,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2123, "rf_id": 1416, "parent": 2114, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2118,716,0,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2124,716,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2125, "rf_id": 1417, "parent": 2114, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2122,859,12597248,1024,2,"cuda:0"],[2124,716,0,1024,2,"cuda:0"],false], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2122,859,12597248,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2128, "rf_id": 1419, "parent": 2127, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2126,859,12597248,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2129,859,12597248,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2127, "rf_id": 1418, "parent": 2114, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2126,859,12597248,1024,2,"cuda:0"],[2118,716,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2129,859,12597248,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2130, "rf_id": 1420, "parent": 2114, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2118,716,0,1024,2,"cuda:0"],[2129,859,12597248,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2114, "rf_id": 1409, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "CheckpointFunctionBackward", "id": 1022, "rf_id": 651, "parent": 1020, "fw_parent": 2, "seq_id": 198, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[975,266,0,163840,2,"cuda:0"],[1021,0,0,0,0,""]], "input_shapes": [[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(nullptr (uninitialized))"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: CheckpointFunctionBackward", "id": 1020, "rf_id": 650, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2135, "rf_id": 1425, "parent": 2134, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,1024],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[2136,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2134, "rf_id": 1424, "parent": 2133, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2098,505,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>",0], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","Int"],
      "outputs": [[2136,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout_backward", "id": 2133, "rf_id": 1423, "parent": 2132, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout_backward(Tensor grad_output, Tensor mask, float scale) -> Tensor",
      "inputs": [[2098,505,0,163840,2,"cuda:0"],[286,271,0,163840,1,"cuda:0"],1.111111], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(bool)","Double"],
      "outputs": [[2136,323,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "NativeDropoutBackward0", "id": 2132, "rf_id": 1422, "parent": 2131, "fw_parent": 2, "seq_id": 197, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2098,505,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: NativeDropoutBackward0", "id": 2131, "rf_id": 1421, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "CloneBackward0", "id": 2138, "rf_id": 1427, "parent": 2137, "fw_parent": 2, "seq_id": 196, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2136,323,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: CloneBackward0", "id": 2137, "rf_id": 1426, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2142, "rf_id": 1431, "parent": 2141, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2136,323,0,163840,2,"cuda:0"],[8,20,1024],[1024,8192,1],"<None>"], "input_shapes": [[20,8,1024],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2143,323,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2141, "rf_id": 1430, "parent": 2140, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[2136,323,0,163840,2,"cuda:0"],0,1], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2143,323,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "TransposeBackward0", "id": 2140, "rf_id": 1429, "parent": 2139, "fw_parent": 2, "seq_id": 195, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2136,323,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 2139, "rf_id": 1428, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "AddBackward0", "id": 2145, "rf_id": 1433, "parent": 2144, "fw_parent": 2, "seq_id": 194, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2143,323,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: AddBackward0", "id": 2144, "rf_id": 1432, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2153, "rf_id": 1441, "parent": 2152, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],4,0,"cuda:0","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[2154,198,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_like", "id": 2152, "rf_id": 1440, "parent": 2151, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[234,10,0,160,8,"cuda:0"],4,0,"cuda:0","<None>",0], "input_shapes": [[8,20],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Int"],
      "outputs": [[2154,198,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 2155, "rf_id": 1442, "parent": 2151, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2154,198,0,160,8,"cuda:0"],[234,10,0,160,8,"cuda:0"],false], "input_shapes": [[8,20],[8,20],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[2154,198,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 2151, "rf_id": 1439, "parent": 2150, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[234,10,0,160,8,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[2154,198,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::contiguous", "id": 2150, "rf_id": 1438, "parent": 2149, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[234,10,0,160,8,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[2154,198,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 2159, "rf_id": 1446, "parent": 2158, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20,1024],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[2160,505,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2158, "rf_id": 1445, "parent": 2157, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2143,323,0,163840,2,"cuda:0"],15,0,"cuda:0","<None>",0], "input_shapes": [[8,20,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Int"],
      "outputs": [[2160,505,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2161, "rf_id": 1447, "parent": 2157, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2160,505,0,163840,2,"cuda:0"],[2143,323,0,163840,2,"cuda:0"],false], "input_shapes": [[8,20,1024],[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2160,505,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::clone", "id": 2157, "rf_id": 1444, "parent": 2156, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2143,323,0,163840,2,"cuda:0"],0], "input_shapes": [[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2160,505,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::contiguous", "id": 2156, "rf_id": 1443, "parent": 2149, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[2143,323,0,163840,2,"cuda:0"],0], "input_shapes": [[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2160,505,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2162, "rf_id": 1448, "parent": 2149, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2160,505,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[8,20,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2163,505,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 2165, "rf_id": 1450, "parent": 2164, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,1024],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1033,645,0,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2167, "rf_id": 1452, "parent": 2166, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1033,645,0,20480,2,"cuda:0"],0], "input_shapes": [[20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1033,645,0,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2166, "rf_id": 1451, "parent": 2164, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1033,645,0,20480,2,"cuda:0"]], "input_shapes": [[20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1033,645,0,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2164, "rf_id": 1449, "parent": 2149, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,1024],15,0,"cuda:0","<None>"], "input_shapes": [[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[1033,645,0,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding_dense_backward", "id": 2149, "rf_id": 1437, "parent": 2148, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::embedding_dense_backward(Tensor grad_output, Tensor indices, SymInt num_weights, SymInt padding_idx, bool scale_grad_by_freq) -> Tensor",
      "inputs": [[2143,323,0,163840,2,"cuda:0"],[234,10,0,160,8,"cuda:0"],20,-1,false], "input_shapes": [[8,20,1024],[8,20],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Int","Bool"],
      "outputs": [[1033,645,0,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding_backward", "id": 2148, "rf_id": 1436, "parent": 2147, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::embedding_backward(Tensor grad, Tensor indices, SymInt num_weights, SymInt padding_idx, bool scale_grad_by_freq, bool sparse) -> Tensor",
      "inputs": [[2143,323,0,163840,2,"cuda:0"],[234,10,0,160,8,"cuda:0"],20,-1,false,false], "input_shapes": [[8,20,1024],[8,20],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Int","Bool","Bool"],
      "outputs": [[1033,645,0,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "EmbeddingBackward0", "id": 2147, "rf_id": 1435, "parent": 2146, "fw_parent": 2, "seq_id": 193, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2143,323,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: EmbeddingBackward0", "id": 2146, "rf_id": 1434, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2171, "rf_id": 1456, "parent": 2170, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1033,645,0,20480,2,"cuda:0"]], "input_shapes": [[20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2170, "rf_id": 1455, "parent": 2169, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1033,645,0,20480,2,"cuda:0"]], "input_shapes": [[20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2172,645,0,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2169, "rf_id": 1454, "parent": 2168, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1033,645,0,20480,2,"cuda:0"]], "input_shapes": [[20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2175, "rf_id": 1459, "parent": 2174, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[20480],[1],12598272], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2163,859,12598272,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2174, "rf_id": 1458, "parent": 2173, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12598272,12618752,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2163,859,12598272,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2173, "rf_id": 1457, "parent": 2168, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12598272,20480], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2163,859,12598272,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2176, "rf_id": 1460, "parent": 2168, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2172,645,0,20480,2,"cuda:0"],[-1]], "input_shapes": [[20,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2177,645,0,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2178, "rf_id": 1461, "parent": 2168, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2163,859,12598272,20480,2,"cuda:0"],[2177,645,0,20480,2,"cuda:0"],false], "input_shapes": [[20480],[20480],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2163,859,12598272,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2181, "rf_id": 1463, "parent": 2180, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2179,859,12598272,20480,2,"cuda:0"],[20,1024]], "input_shapes": [[20480],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2182,859,12598272,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2180, "rf_id": 1462, "parent": 2168, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2179,859,12598272,20480,2,"cuda:0"],[2172,645,0,20480,2,"cuda:0"]], "input_shapes": [[20480],[20,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2182,859,12598272,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2183, "rf_id": 1464, "parent": 2168, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2172,645,0,20480,2,"cuda:0"],[2182,859,12598272,20480,2,"cuda:0"]], "input_shapes": [[20,1024],[20,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2168, "rf_id": 1453, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_ReduceFromModelParallelRegionBackward", "id": 2185, "rf_id": 1466, "parent": 2184, "fw_parent": 2, "seq_id": 192, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2143,323,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _ReduceFromModelParallelRegionBackward", "id": 2184, "rf_id": 1465, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2193, "rf_id": 1474, "parent": 2192, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20,1024],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[2194,505,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2192, "rf_id": 1473, "parent": 2191, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2143,323,0,163840,2,"cuda:0"],15,0,"cuda:0","<None>",0], "input_shapes": [[8,20,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Int"],
      "outputs": [[2194,505,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2195, "rf_id": 1475, "parent": 2191, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2194,505,0,163840,2,"cuda:0"],[2143,323,0,163840,2,"cuda:0"],false], "input_shapes": [[8,20,1024],[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2194,505,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::clone", "id": 2191, "rf_id": 1472, "parent": 2190, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2143,323,0,163840,2,"cuda:0"],0], "input_shapes": [[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2194,505,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::contiguous", "id": 2190, "rf_id": 1471, "parent": 2189, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[2143,323,0,163840,2,"cuda:0"],0], "input_shapes": [[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2194,505,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2196, "rf_id": 1476, "parent": 2189, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2194,505,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[8,20,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2197,505,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 2199, "rf_id": 1478, "parent": 2198, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[50304,1024],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2200,2201,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2203, "rf_id": 1480, "parent": 2202, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2200,2201,0,51511296,2,"cuda:0"],0], "input_shapes": [[50304,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2200,2201,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2202, "rf_id": 1479, "parent": 2198, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2200,2201,0,51511296,2,"cuda:0"]], "input_shapes": [[50304,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2200,2201,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2198, "rf_id": 1477, "parent": 2189, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[50304,1024],15,0,"cuda:0","<None>"], "input_shapes": [[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[2200,2201,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding_dense_backward", "id": 2189, "rf_id": 1470, "parent": 2188, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::embedding_dense_backward(Tensor grad_output, Tensor indices, SymInt num_weights, SymInt padding_idx, bool scale_grad_by_freq) -> Tensor",
      "inputs": [[2143,323,0,163840,2,"cuda:0"],[231,184,0,160,8,"cuda:0"],50304,-1,false], "input_shapes": [[8,20,1024],[8,20],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Int","Bool"],
      "outputs": [[2200,2201,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding_backward", "id": 2188, "rf_id": 1469, "parent": 2187, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::embedding_backward(Tensor grad, Tensor indices, SymInt num_weights, SymInt padding_idx, bool scale_grad_by_freq, bool sparse) -> Tensor",
      "inputs": [[2143,323,0,163840,2,"cuda:0"],[231,184,0,160,8,"cuda:0"],50304,-1,false,false], "input_shapes": [[8,20,1024],[8,20],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Int","Bool","Bool"],
      "outputs": [[2200,2201,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "EmbeddingBackward0", "id": 2187, "rf_id": 1468, "parent": 2186, "fw_parent": 2, "seq_id": 191, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2143,323,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add_", "id": 2204, "rf_id": 1481, "parent": 2186, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)",
      "inputs": [[923,707,0,51511296,2,"cuda:0"],[2200,2201,0,51511296,2,"cuda:0"],1], "input_shapes": [[50304,1024],[50304,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[923,707,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: EmbeddingBackward0", "id": 2186, "rf_id": 1467, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2208, "rf_id": 1485, "parent": 2207, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[923,707,0,51511296,2,"cuda:0"]], "input_shapes": [[50304,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2207, "rf_id": 1484, "parent": 2206, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[923,707,0,51511296,2,"cuda:0"]], "input_shapes": [[50304,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2209,707,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2206, "rf_id": 1483, "parent": 2205, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[923,707,0,51511296,2,"cuda:0"]], "input_shapes": [[50304,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2212, "rf_id": 1488, "parent": 2211, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[51511296],[1],12618752], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2213,859,12618752,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2211, "rf_id": 1487, "parent": 2210, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12618752,64130048,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2213,859,12618752,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2210, "rf_id": 1486, "parent": 2205, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12618752,51511296], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2213,859,12618752,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2214, "rf_id": 1489, "parent": 2205, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2209,707,0,51511296,2,"cuda:0"],[-1]], "input_shapes": [[50304,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2215,707,0,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2216, "rf_id": 1490, "parent": 2205, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2213,859,12618752,51511296,2,"cuda:0"],[2215,707,0,51511296,2,"cuda:0"],false], "input_shapes": [[51511296],[51511296],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2213,859,12618752,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2219, "rf_id": 1492, "parent": 2218, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2217,859,12618752,51511296,2,"cuda:0"],[50304,1024]], "input_shapes": [[51511296],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2220,859,12618752,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2218, "rf_id": 1491, "parent": 2205, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2217,859,12618752,51511296,2,"cuda:0"],[2209,707,0,51511296,2,"cuda:0"]], "input_shapes": [[51511296],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2220,859,12618752,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2221, "rf_id": 1493, "parent": 2205, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2209,707,0,51511296,2,"cuda:0"],[2220,859,12618752,51511296,2,"cuda:0"]], "input_shapes": [[50304,1024],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2205, "rf_id": 1482, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::div_", "id": 2224, "rf_id": 1494, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[2222,2223,0,1,8,"cpu"]], "input_shapes": [[500000000],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[855,859,0,500000000,2,"cuda:0"]], "output_shapes": [[500000000]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2227, "rf_id": 1497, "parent": 2226, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[4197376],[1],0], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2228,859,0,4197376,2,"cuda:0"]], "output_shapes": [[4197376]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2226, "rf_id": 1496, "parent": 2225, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,0,4197376,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2228,859,0,4197376,2,"cuda:0"]], "output_shapes": [[4197376]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2225, "rf_id": 1495, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,0,4197376], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2228,859,0,4197376,2,"cuda:0"]], "output_shapes": [[4197376]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2231, "rf_id": 1500, "parent": 2230, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[3328],[1],4197376], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2232,859,4197376,3328,2,"cuda:0"]], "output_shapes": [[3328]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2230, "rf_id": 1499, "parent": 2229, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,4197376,4200704,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2232,859,4197376,3328,2,"cuda:0"]], "output_shapes": [[3328]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2229, "rf_id": 1498, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,4197376,3328], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2232,859,4197376,3328,2,"cuda:0"]], "output_shapes": [[3328]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2235, "rf_id": 1503, "parent": 2234, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[4195072],[1],4200704], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2236,859,4200704,4195072,2,"cuda:0"]], "output_shapes": [[4195072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2234, "rf_id": 1502, "parent": 2233, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,4200704,8395776,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2236,859,4200704,4195072,2,"cuda:0"]], "output_shapes": [[4195072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2233, "rf_id": 1501, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,4200704,4195072], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2236,859,4200704,4195072,2,"cuda:0"]], "output_shapes": [[4195072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2239, "rf_id": 1506, "parent": 2238, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[1536],[1],8395776], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2240,859,8395776,1536,2,"cuda:0"]], "output_shapes": [[1536]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2238, "rf_id": 1505, "parent": 2237, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,8395776,8397312,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2240,859,8395776,1536,2,"cuda:0"]], "output_shapes": [[1536]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2237, "rf_id": 1504, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,8395776,1536], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2240,859,8395776,1536,2,"cuda:0"]], "output_shapes": [[1536]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2243, "rf_id": 1509, "parent": 2242, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[512],[1],8397312], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2244,859,8397312,512,2,"cuda:0"]], "output_shapes": [[512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2242, "rf_id": 1508, "parent": 2241, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,8397312,8397824,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2244,859,8397312,512,2,"cuda:0"]], "output_shapes": [[512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2241, "rf_id": 1507, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,8397312,512], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2244,859,8397312,512,2,"cuda:0"]], "output_shapes": [[512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2247, "rf_id": 1512, "parent": 2246, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[1024],[1],8397824], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2248,859,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2246, "rf_id": 1511, "parent": 2245, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,8397824,8398848,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2248,859,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2245, "rf_id": 1510, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,8397824,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2248,859,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2251, "rf_id": 1515, "parent": 2250, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[4194304],[1],8398848], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2252,859,8398848,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2250, "rf_id": 1514, "parent": 2249, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,8398848,12593152,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2252,859,8398848,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2249, "rf_id": 1513, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,8398848,4194304], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2252,859,8398848,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2255, "rf_id": 1518, "parent": 2254, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[1792],[1],12593152], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2256,859,12593152,1792,2,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2254, "rf_id": 1517, "parent": 2253, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12593152,12594944,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2256,859,12593152,1792,2,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2253, "rf_id": 1516, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12593152,1792], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2256,859,12593152,1792,2,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2259, "rf_id": 1521, "parent": 2258, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[1280],[1],12594944], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2260,859,12594944,1280,2,"cuda:0"]], "output_shapes": [[1280]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2258, "rf_id": 1520, "parent": 2257, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12594944,12596224,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2260,859,12594944,1280,2,"cuda:0"]], "output_shapes": [[1280]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2257, "rf_id": 1519, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12594944,1280], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2260,859,12594944,1280,2,"cuda:0"]], "output_shapes": [[1280]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2263, "rf_id": 1524, "parent": 2262, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[2048],[1],12596224], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2264,859,12596224,2048,2,"cuda:0"]], "output_shapes": [[2048]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2262, "rf_id": 1523, "parent": 2261, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12596224,12598272,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2264,859,12596224,2048,2,"cuda:0"]], "output_shapes": [[2048]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2261, "rf_id": 1522, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12596224,2048], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2264,859,12596224,2048,2,"cuda:0"]], "output_shapes": [[2048]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2267, "rf_id": 1527, "parent": 2266, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[20480],[1],12598272], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2268,859,12598272,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2266, "rf_id": 1526, "parent": 2265, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12598272,12618752,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2268,859,12598272,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2265, "rf_id": 1525, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12598272,20480], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2268,859,12598272,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2271, "rf_id": 1530, "parent": 2270, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[16028672],[1],12618752], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2272,859,12618752,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2270, "rf_id": 1529, "parent": 2269, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12618752,28647424,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2272,859,12618752,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2269, "rf_id": 1528, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,12618752,16028672], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2272,859,12618752,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2275, "rf_id": 1533, "parent": 2274, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[16028672],[1],28647424], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2276,859,28647424,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2274, "rf_id": 1532, "parent": 2273, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,28647424,44676096,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2276,859,28647424,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2273, "rf_id": 1531, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,28647424,16028672], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2276,859,28647424,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2279, "rf_id": 1536, "parent": 2278, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[16028672],[1],44676096], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2280,859,44676096,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2278, "rf_id": 1535, "parent": 2277, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,44676096,60704768,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2280,859,44676096,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2277, "rf_id": 1534, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,44676096,16028672], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2280,859,44676096,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2283, "rf_id": 1539, "parent": 2282, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],[3425280],[1],60704768], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2284,859,60704768,3425280,2,"cuda:0"]], "output_shapes": [[3425280]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2282, "rf_id": 1538, "parent": 2281, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,60704768,64130048,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2284,859,60704768,3425280,2,"cuda:0"]], "output_shapes": [[3425280]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2281, "rf_id": 1537, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[855,859,0,500000000,2,"cuda:0"],0,60704768,3425280], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2284,859,60704768,3425280,2,"cuda:0"]], "output_shapes": [[3425280]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2286, "rf_id": 1541, "parent": 2285, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2228,859,0,4197376,2,"cuda:0"],[-1]], "input_shapes": [[4197376],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2287,859,0,4197376,2,"cuda:0"]], "output_shapes": [[4197376]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2288, "rf_id": 1542, "parent": 2285, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2232,859,4197376,3328,2,"cuda:0"],[-1]], "input_shapes": [[3328],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2289,859,4197376,3328,2,"cuda:0"]], "output_shapes": [[3328]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2290, "rf_id": 1543, "parent": 2285, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2236,859,4200704,4195072,2,"cuda:0"],[-1]], "input_shapes": [[4195072],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2291,859,4200704,4195072,2,"cuda:0"]], "output_shapes": [[4195072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2292, "rf_id": 1544, "parent": 2285, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2240,859,8395776,1536,2,"cuda:0"],[-1]], "input_shapes": [[1536],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2293,859,8395776,1536,2,"cuda:0"]], "output_shapes": [[1536]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2294, "rf_id": 1545, "parent": 2285, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2244,859,8397312,512,2,"cuda:0"],[-1]], "input_shapes": [[512],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2295,859,8397312,512,2,"cuda:0"]], "output_shapes": [[512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2296, "rf_id": 1546, "parent": 2285, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2248,859,8397824,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2297,859,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2298, "rf_id": 1547, "parent": 2285, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2252,859,8398848,4194304,2,"cuda:0"],[-1]], "input_shapes": [[4194304],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2299,859,8398848,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2300, "rf_id": 1548, "parent": 2285, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2256,859,12593152,1792,2,"cuda:0"],[-1]], "input_shapes": [[1792],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2301,859,12593152,1792,2,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2302, "rf_id": 1549, "parent": 2285, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2260,859,12594944,1280,2,"cuda:0"],[-1]], "input_shapes": [[1280],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2303,859,12594944,1280,2,"cuda:0"]], "output_shapes": [[1280]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2304, "rf_id": 1550, "parent": 2285, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2264,859,12596224,2048,2,"cuda:0"],[-1]], "input_shapes": [[2048],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2305,859,12596224,2048,2,"cuda:0"]], "output_shapes": [[2048]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2306, "rf_id": 1551, "parent": 2285, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2268,859,12598272,20480,2,"cuda:0"],[-1]], "input_shapes": [[20480],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2307,859,12598272,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2308, "rf_id": 1552, "parent": 2285, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2272,859,12618752,16028672,2,"cuda:0"],[-1]], "input_shapes": [[16028672],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2309,859,12618752,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2310, "rf_id": 1553, "parent": 2285, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2276,859,28647424,16028672,2,"cuda:0"],[-1]], "input_shapes": [[16028672],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2311,859,28647424,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2312, "rf_id": 1554, "parent": 2285, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2280,859,44676096,16028672,2,"cuda:0"],[-1]], "input_shapes": [[16028672],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2313,859,44676096,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2314, "rf_id": 1555, "parent": 2285, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2284,859,60704768,3425280,2,"cuda:0"],[-1]], "input_shapes": [[3425280],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2315,859,60704768,3425280,2,"cuda:0"]], "output_shapes": [[3425280]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 2316, "rf_id": 1556, "parent": 2285, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[2287,859,0,4197376,2,"cuda:0"],[2289,859,4197376,3328,2,"cuda:0"],[2291,859,4200704,4195072,2,"cuda:0"],[2293,859,8395776,1536,2,"cuda:0"],[2295,859,8397312,512,2,"cuda:0"],[2297,859,8397824,1024,2,"cuda:0"],[2299,859,8398848,4194304,2,"cuda:0"],[2301,859,12593152,1792,2,"cuda:0"],[2303,859,12594944,1280,2,"cuda:0"],[2305,859,12596224,2048,2,"cuda:0"],[2307,859,12598272,20480,2,"cuda:0"],[2309,859,12618752,16028672,2,"cuda:0"],[2311,859,28647424,16028672,2,"cuda:0"],[2313,859,44676096,16028672,2,"cuda:0"],[2315,859,60704768,3425280,2,"cuda:0"]],0], "input_shapes": [[[4197376],[3328],[4195072],[1536],[512],[1024],[4194304],[1792],[1280],[2048],[20480],[16028672],[16028672],[16028672],[3425280]],[]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int"],
      "outputs": [[2317,2318,0,64130048,2,"cuda:0"]], "output_shapes": [[64130048]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::flatten_dense_tensors", "id": 2285, "rf_id": 1540, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::flatten_dense_tensors(Tensor[] tensors) -> Tensor",
      "inputs": [[[2228,859,0,4197376,2,"cuda:0"],[2232,859,4197376,3328,2,"cuda:0"],[2236,859,4200704,4195072,2,"cuda:0"],[2240,859,8395776,1536,2,"cuda:0"],[2244,859,8397312,512,2,"cuda:0"],[2248,859,8397824,1024,2,"cuda:0"],[2252,859,8398848,4194304,2,"cuda:0"],[2256,859,12593152,1792,2,"cuda:0"],[2260,859,12594944,1280,2,"cuda:0"],[2264,859,12596224,2048,2,"cuda:0"],[2268,859,12598272,20480,2,"cuda:0"],[2272,859,12618752,16028672,2,"cuda:0"],[2276,859,28647424,16028672,2,"cuda:0"],[2280,859,44676096,16028672,2,"cuda:0"],[2284,859,60704768,3425280,2,"cuda:0"]]], "input_shapes": [[[4197376],[3328],[4195072],[1536],[512],[1024],[4194304],[1792],[1280],[2048],[20480],[16028672],[16028672],[16028672],[3425280]]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"],
      "outputs": [[2317,2318,0,64130048,2,"cuda:0"]], "output_shapes": [[64130048]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:all_reduce", "id": 2321, "rf_id": 1559, "parent": 2320, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"]], "input_shapes": [[64130048]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 2320, "rf_id": 1558, "parent": 2319, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[2317,2318,0,64130048,2,"cuda:0"]],38,94136803877936,0,"allreduce",[],[],4], "input_shapes": [[[64130048]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(c10::BFloat16)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[2317,2318,0,64130048,2,"cuda:0"]]], "output_shapes": [[[64130048]]], "output_types": ["GenericList[Tensor(c10::BFloat16)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 2319, "rf_id": 1557, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[2317,2318,0,64130048,2,"cuda:0"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[64130048]],[],[],[],[]], "input_types": ["GenericList[Tensor(c10::BFloat16)]","Object","Object","None","Int"],
      "outputs": [[[2317,2318,0,64130048,2,"cuda:0"]],"<Object>"], "output_shapes": [[[64130048]],[]], "output_types": ["GenericList[Tensor(c10::BFloat16)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 2322, "rf_id": 1560, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [38,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2326, "rf_id": 1564, "parent": 2325, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],[4197376],[1],0], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2327,2318,0,4197376,2,"cuda:0"]], "output_shapes": [[4197376]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2325, "rf_id": 1563, "parent": 2324, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,0,4197376,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2327,2318,0,4197376,2,"cuda:0"]], "output_shapes": [[4197376]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2324, "rf_id": 1562, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,0,4197376], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2327,2318,0,4197376,2,"cuda:0"]], "output_shapes": [[4197376]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2328, "rf_id": 1565, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2327,2318,0,4197376,2,"cuda:0"],[4197376]], "input_shapes": [[4197376],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2329,2318,0,4197376,2,"cuda:0"]], "output_shapes": [[4197376]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2332, "rf_id": 1568, "parent": 2331, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],[3328],[1],4197376], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2333,2318,4197376,3328,2,"cuda:0"]], "output_shapes": [[3328]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2331, "rf_id": 1567, "parent": 2330, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,4197376,4200704,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2333,2318,4197376,3328,2,"cuda:0"]], "output_shapes": [[3328]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2330, "rf_id": 1566, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,4197376,3328], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2333,2318,4197376,3328,2,"cuda:0"]], "output_shapes": [[3328]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2334, "rf_id": 1569, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2333,2318,4197376,3328,2,"cuda:0"],[3328]], "input_shapes": [[3328],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2335,2318,4197376,3328,2,"cuda:0"]], "output_shapes": [[3328]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2338, "rf_id": 1572, "parent": 2337, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],[4195072],[1],4200704], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2339,2318,4200704,4195072,2,"cuda:0"]], "output_shapes": [[4195072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2337, "rf_id": 1571, "parent": 2336, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,4200704,8395776,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2339,2318,4200704,4195072,2,"cuda:0"]], "output_shapes": [[4195072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2336, "rf_id": 1570, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,4200704,4195072], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2339,2318,4200704,4195072,2,"cuda:0"]], "output_shapes": [[4195072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2340, "rf_id": 1573, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2339,2318,4200704,4195072,2,"cuda:0"],[4195072]], "input_shapes": [[4195072],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2341,2318,4200704,4195072,2,"cuda:0"]], "output_shapes": [[4195072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2344, "rf_id": 1576, "parent": 2343, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],[1536],[1],8395776], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2345,2318,8395776,1536,2,"cuda:0"]], "output_shapes": [[1536]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2343, "rf_id": 1575, "parent": 2342, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,8395776,8397312,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2345,2318,8395776,1536,2,"cuda:0"]], "output_shapes": [[1536]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2342, "rf_id": 1574, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,8395776,1536], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2345,2318,8395776,1536,2,"cuda:0"]], "output_shapes": [[1536]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2346, "rf_id": 1577, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2345,2318,8395776,1536,2,"cuda:0"],[1536]], "input_shapes": [[1536],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2347,2318,8395776,1536,2,"cuda:0"]], "output_shapes": [[1536]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2350, "rf_id": 1580, "parent": 2349, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],[512],[1],8397312], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2351,2318,8397312,512,2,"cuda:0"]], "output_shapes": [[512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2349, "rf_id": 1579, "parent": 2348, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,8397312,8397824,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2351,2318,8397312,512,2,"cuda:0"]], "output_shapes": [[512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2348, "rf_id": 1578, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,8397312,512], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2351,2318,8397312,512,2,"cuda:0"]], "output_shapes": [[512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2352, "rf_id": 1581, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2351,2318,8397312,512,2,"cuda:0"],[512]], "input_shapes": [[512],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2353,2318,8397312,512,2,"cuda:0"]], "output_shapes": [[512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2356, "rf_id": 1584, "parent": 2355, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],[1024],[1],8397824], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2357,2318,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2355, "rf_id": 1583, "parent": 2354, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,8397824,8398848,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2357,2318,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2354, "rf_id": 1582, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,8397824,1024], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2357,2318,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2358, "rf_id": 1585, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2357,2318,8397824,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2359,2318,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2362, "rf_id": 1588, "parent": 2361, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],[4194304],[1],8398848], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2363,2318,8398848,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2361, "rf_id": 1587, "parent": 2360, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,8398848,12593152,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2363,2318,8398848,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2360, "rf_id": 1586, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,8398848,4194304], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2363,2318,8398848,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2364, "rf_id": 1589, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2363,2318,8398848,4194304,2,"cuda:0"],[4194304]], "input_shapes": [[4194304],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2365,2318,8398848,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2368, "rf_id": 1592, "parent": 2367, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],[1792],[1],12593152], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2369,2318,12593152,1792,2,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2367, "rf_id": 1591, "parent": 2366, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,12593152,12594944,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2369,2318,12593152,1792,2,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2366, "rf_id": 1590, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,12593152,1792], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2369,2318,12593152,1792,2,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2370, "rf_id": 1593, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2369,2318,12593152,1792,2,"cuda:0"],[1792]], "input_shapes": [[1792],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2371,2318,12593152,1792,2,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2374, "rf_id": 1596, "parent": 2373, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],[1280],[1],12594944], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2375,2318,12594944,1280,2,"cuda:0"]], "output_shapes": [[1280]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2373, "rf_id": 1595, "parent": 2372, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,12594944,12596224,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2375,2318,12594944,1280,2,"cuda:0"]], "output_shapes": [[1280]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2372, "rf_id": 1594, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,12594944,1280], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2375,2318,12594944,1280,2,"cuda:0"]], "output_shapes": [[1280]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2376, "rf_id": 1597, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2375,2318,12594944,1280,2,"cuda:0"],[1280]], "input_shapes": [[1280],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2377,2318,12594944,1280,2,"cuda:0"]], "output_shapes": [[1280]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2380, "rf_id": 1600, "parent": 2379, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],[2048],[1],12596224], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2381,2318,12596224,2048,2,"cuda:0"]], "output_shapes": [[2048]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2379, "rf_id": 1599, "parent": 2378, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,12596224,12598272,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2381,2318,12596224,2048,2,"cuda:0"]], "output_shapes": [[2048]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2378, "rf_id": 1598, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,12596224,2048], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2381,2318,12596224,2048,2,"cuda:0"]], "output_shapes": [[2048]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2382, "rf_id": 1601, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2381,2318,12596224,2048,2,"cuda:0"],[2048]], "input_shapes": [[2048],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2383,2318,12596224,2048,2,"cuda:0"]], "output_shapes": [[2048]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2386, "rf_id": 1604, "parent": 2385, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],[20480],[1],12598272], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2387,2318,12598272,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2385, "rf_id": 1603, "parent": 2384, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,12598272,12618752,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2387,2318,12598272,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2384, "rf_id": 1602, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,12598272,20480], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2387,2318,12598272,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2388, "rf_id": 1605, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2387,2318,12598272,20480,2,"cuda:0"],[20480]], "input_shapes": [[20480],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2389,2318,12598272,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2392, "rf_id": 1608, "parent": 2391, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],[16028672],[1],12618752], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2393,2318,12618752,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2391, "rf_id": 1607, "parent": 2390, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,12618752,28647424,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2393,2318,12618752,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2390, "rf_id": 1606, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,12618752,16028672], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2393,2318,12618752,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2394, "rf_id": 1609, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2393,2318,12618752,16028672,2,"cuda:0"],[16028672]], "input_shapes": [[16028672],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2395,2318,12618752,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2398, "rf_id": 1612, "parent": 2397, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],[16028672],[1],28647424], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2399,2318,28647424,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2397, "rf_id": 1611, "parent": 2396, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,28647424,44676096,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2399,2318,28647424,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2396, "rf_id": 1610, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,28647424,16028672], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2399,2318,28647424,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2400, "rf_id": 1613, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2399,2318,28647424,16028672,2,"cuda:0"],[16028672]], "input_shapes": [[16028672],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2401,2318,28647424,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2404, "rf_id": 1616, "parent": 2403, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],[16028672],[1],44676096], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2405,2318,44676096,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2403, "rf_id": 1615, "parent": 2402, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,44676096,60704768,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2405,2318,44676096,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2402, "rf_id": 1614, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,44676096,16028672], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2405,2318,44676096,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2406, "rf_id": 1617, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2405,2318,44676096,16028672,2,"cuda:0"],[16028672]], "input_shapes": [[16028672],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2407,2318,44676096,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2410, "rf_id": 1620, "parent": 2409, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],[3425280],[1],60704768], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2411,2318,60704768,3425280,2,"cuda:0"]], "output_shapes": [[3425280]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2409, "rf_id": 1619, "parent": 2408, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,60704768,64130048,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2411,2318,60704768,3425280,2,"cuda:0"]], "output_shapes": [[3425280]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2408, "rf_id": 1618, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],0,60704768,3425280], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2411,2318,60704768,3425280,2,"cuda:0"]], "output_shapes": [[3425280]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2412, "rf_id": 1621, "parent": 2323, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2411,2318,60704768,3425280,2,"cuda:0"],[3425280]], "input_shapes": [[3425280],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2413,2318,60704768,3425280,2,"cuda:0"]], "output_shapes": [[3425280]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::unflatten_dense_tensors", "id": 2323, "rf_id": 1561, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unflatten_dense_tensors(Tensor flat, Tensor[] tensors) -> Tensor[]",
      "inputs": [[2317,2318,0,64130048,2,"cuda:0"],[[2228,859,0,4197376,2,"cuda:0"],[2232,859,4197376,3328,2,"cuda:0"],[2236,859,4200704,4195072,2,"cuda:0"],[2240,859,8395776,1536,2,"cuda:0"],[2244,859,8397312,512,2,"cuda:0"],[2248,859,8397824,1024,2,"cuda:0"],[2252,859,8398848,4194304,2,"cuda:0"],[2256,859,12593152,1792,2,"cuda:0"],[2260,859,12594944,1280,2,"cuda:0"],[2264,859,12596224,2048,2,"cuda:0"],[2268,859,12598272,20480,2,"cuda:0"],[2272,859,12618752,16028672,2,"cuda:0"],[2276,859,28647424,16028672,2,"cuda:0"],[2280,859,44676096,16028672,2,"cuda:0"],[2284,859,60704768,3425280,2,"cuda:0"]]], "input_shapes": [[64130048],[[4197376],[3328],[4195072],[1536],[512],[1024],[4194304],[1792],[1280],[2048],[20480],[16028672],[16028672],[16028672],[3425280]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"],
      "outputs": [[[2329,2318,0,4197376,2,"cuda:0"],[2335,2318,4197376,3328,2,"cuda:0"],[2341,2318,4200704,4195072,2,"cuda:0"],[2347,2318,8395776,1536,2,"cuda:0"],[2353,2318,8397312,512,2,"cuda:0"],[2359,2318,8397824,1024,2,"cuda:0"],[2365,2318,8398848,4194304,2,"cuda:0"],[2371,2318,12593152,1792,2,"cuda:0"],[2377,2318,12594944,1280,2,"cuda:0"],[2383,2318,12596224,2048,2,"cuda:0"],[2389,2318,12598272,20480,2,"cuda:0"],[2395,2318,12618752,16028672,2,"cuda:0"],[2401,2318,28647424,16028672,2,"cuda:0"],[2407,2318,44676096,16028672,2,"cuda:0"],[2413,2318,60704768,3425280,2,"cuda:0"]]], "output_shapes": [[[4197376],[3328],[4195072],[1536],[512],[1024],[4194304],[1792],[1280],[2048],[20480],[16028672],[16028672],[16028672],[3425280]]], "output_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"]
    },
    {
      "name": "aten::copy_", "id": 2414, "rf_id": 1622, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2256,859,12593152,1792,2,"cuda:0"],[2371,2318,12593152,1792,2,"cuda:0"],false], "input_shapes": [[1792],[1792],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2256,859,12593152,1792,2,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2415, "rf_id": 1623, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2264,859,12596224,2048,2,"cuda:0"],[2383,2318,12596224,2048,2,"cuda:0"],false], "input_shapes": [[2048],[2048],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2264,859,12596224,2048,2,"cuda:0"]], "output_shapes": [[2048]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2416, "rf_id": 1624, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2272,859,12618752,16028672,2,"cuda:0"],[2395,2318,12618752,16028672,2,"cuda:0"],false], "input_shapes": [[16028672],[16028672],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2272,859,12618752,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 2417, "rf_id": 1625, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[51516416],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[2353,707,0,51516416,2,"cuda:0"]], "output_shapes": [[51516416]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2418, "rf_id": 1626, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2353,707,0,51516416,2,"cuda:0"],[-1]], "input_shapes": [[51516416],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2359,707,0,51516416,2,"cuda:0"]], "output_shapes": [[51516416]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2421, "rf_id": 1629, "parent": 2420, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2359,707,0,51516416,2,"cuda:0"],[3072],[1],0], "input_shapes": [[51516416],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2365,707,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2420, "rf_id": 1628, "parent": 2419, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2359,707,0,51516416,2,"cuda:0"],0,0,3072,1], "input_shapes": [[51516416],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2365,707,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2419, "rf_id": 1627, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2359,707,0,51516416,2,"cuda:0"],0,0,3072], "input_shapes": [[51516416],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2365,707,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2422, "rf_id": 1630, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2061,859,12593152,3072,2,"cuda:0"],[-1]], "input_shapes": [[3072],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2377,859,12593152,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2423, "rf_id": 1631, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2365,707,0,3072,2,"cuda:0"],[2377,859,12593152,3072,2,"cuda:0"],false], "input_shapes": [[3072],[3072],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2365,707,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2425, "rf_id": 1633, "parent": 2424, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2389,707,0,3072,2,"cuda:0"],[3072]], "input_shapes": [[3072],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2401,707,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2424, "rf_id": 1632, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2389,707,0,3072,2,"cuda:0"],[2061,859,12593152,3072,2,"cuda:0"]], "input_shapes": [[3072],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2401,707,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2426, "rf_id": 1634, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2061,859,12593152,3072,2,"cuda:0"],[2401,707,0,3072,2,"cuda:0"]], "input_shapes": [[3072],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::view", "id": 2427, "rf_id": 1635, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2353,707,0,51516416,2,"cuda:0"],[-1]], "input_shapes": [[51516416],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2407,707,0,51516416,2,"cuda:0"]], "output_shapes": [[51516416]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2430, "rf_id": 1638, "parent": 2429, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2407,707,0,51516416,2,"cuda:0"],[1024],[1],3072], "input_shapes": [[51516416],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2431,707,3072,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2429, "rf_id": 1637, "parent": 2428, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2407,707,0,51516416,2,"cuda:0"],0,3072,4096,1], "input_shapes": [[51516416],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2431,707,3072,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2428, "rf_id": 1636, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2407,707,0,51516416,2,"cuda:0"],0,3072,1024], "input_shapes": [[51516416],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2431,707,3072,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2432, "rf_id": 1639, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2103,859,12596224,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2433,859,12596224,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2434, "rf_id": 1640, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2431,707,3072,1024,2,"cuda:0"],[2433,859,12596224,1024,2,"cuda:0"],false], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2431,707,3072,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2437, "rf_id": 1642, "parent": 2436, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2435,707,3072,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2438,707,3072,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2436, "rf_id": 1641, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2435,707,3072,1024,2,"cuda:0"],[2103,859,12596224,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2438,707,3072,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2439, "rf_id": 1643, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2103,859,12596224,1024,2,"cuda:0"],[2438,707,3072,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::view", "id": 2440, "rf_id": 1644, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2353,707,0,51516416,2,"cuda:0"],[-1]], "input_shapes": [[51516416],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2441,707,0,51516416,2,"cuda:0"]], "output_shapes": [[51516416]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2444, "rf_id": 1647, "parent": 2443, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2441,707,0,51516416,2,"cuda:0"],[1024],[1],4096], "input_shapes": [[51516416],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2445,707,4096,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2443, "rf_id": 1646, "parent": 2442, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2441,707,0,51516416,2,"cuda:0"],0,4096,5120,1], "input_shapes": [[51516416],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2445,707,4096,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2442, "rf_id": 1645, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2441,707,0,51516416,2,"cuda:0"],0,4096,1024], "input_shapes": [[51516416],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2445,707,4096,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2446, "rf_id": 1648, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2118,859,12597248,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2447,859,12597248,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2448, "rf_id": 1649, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2445,707,4096,1024,2,"cuda:0"],[2447,859,12597248,1024,2,"cuda:0"],false], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2445,707,4096,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2451, "rf_id": 1651, "parent": 2450, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2449,707,4096,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2452,707,4096,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2450, "rf_id": 1650, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2449,707,4096,1024,2,"cuda:0"],[2118,859,12597248,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2452,707,4096,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2453, "rf_id": 1652, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2118,859,12597248,1024,2,"cuda:0"],[2452,707,4096,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::view", "id": 2454, "rf_id": 1653, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2353,707,0,51516416,2,"cuda:0"],[-1]], "input_shapes": [[51516416],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2455,707,0,51516416,2,"cuda:0"]], "output_shapes": [[51516416]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2458, "rf_id": 1656, "parent": 2457, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2455,707,0,51516416,2,"cuda:0"],[51511296],[1],5120], "input_shapes": [[51516416],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2459,707,5120,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2457, "rf_id": 1655, "parent": 2456, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2455,707,0,51516416,2,"cuda:0"],0,5120,51516416,1], "input_shapes": [[51516416],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2459,707,5120,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2456, "rf_id": 1654, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2455,707,0,51516416,2,"cuda:0"],0,5120,51511296], "input_shapes": [[51516416],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2459,707,5120,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2460, "rf_id": 1657, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2209,859,12618752,51511296,2,"cuda:0"],[-1]], "input_shapes": [[50304,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2461,859,12618752,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2462, "rf_id": 1658, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2459,707,5120,51511296,2,"cuda:0"],[2461,859,12618752,51511296,2,"cuda:0"],false], "input_shapes": [[51511296],[51511296],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2459,707,5120,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2465, "rf_id": 1660, "parent": 2464, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2463,707,5120,51511296,2,"cuda:0"],[50304,1024]], "input_shapes": [[51511296],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2466,707,5120,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2464, "rf_id": 1659, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2463,707,5120,51511296,2,"cuda:0"],[2209,859,12618752,51511296,2,"cuda:0"]], "input_shapes": [[51511296],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2466,707,5120,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2467, "rf_id": 1661, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2209,859,12618752,51511296,2,"cuda:0"],[2466,707,5120,51511296,2,"cuda:0"]], "input_shapes": [[50304,1024],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::view", "id": 2468, "rf_id": 1662, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2209,707,5120,51511296,2,"cuda:0"],[-1]], "input_shapes": [[50304,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2413,707,5120,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2471, "rf_id": 1665, "parent": 2470, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2413,707,5120,51511296,2,"cuda:0"],[16028672],[1],5120], "input_shapes": [[51511296],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2472,707,5120,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2470, "rf_id": 1664, "parent": 2469, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2413,707,5120,51511296,2,"cuda:0"],0,0,16028672,1], "input_shapes": [[51511296],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2472,707,5120,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2469, "rf_id": 1663, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2413,707,5120,51511296,2,"cuda:0"],0,0,16028672], "input_shapes": [[51511296],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2472,707,5120,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2473, "rf_id": 1666, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2061,707,0,3072,2,"cuda:0"],[-1]], "input_shapes": [[3072],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2474,707,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2477, "rf_id": 1669, "parent": 2476, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2474,707,0,3072,2,"cuda:0"],[1792],[1],0], "input_shapes": [[3072],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2478,707,0,1792,2,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2476, "rf_id": 1668, "parent": 2475, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2474,707,0,3072,2,"cuda:0"],0,0,1792,1], "input_shapes": [[3072],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2478,707,0,1792,2,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2475, "rf_id": 1667, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2474,707,0,3072,2,"cuda:0"],0,0,1792], "input_shapes": [[3072],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2478,707,0,1792,2,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 2479, "rf_id": 1670, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],0,"<None>","cuda","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","None","None"],
      "outputs": [[2480,10,0,1,1,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(unsigned char)"]
    },
    {
      "name": "aten::empty", "id": 2483, "rf_id": 1673, "parent": 2482, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],0,"<None>","cuda","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","None","None"],
      "outputs": [[2484,5,0,1,1,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(unsigned char)"]
    },
    {
      "name": "nccl:all_reduce", "id": 2486, "rf_id": 1675, "parent": 2485, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[2484,5,0,1,1,"cuda:0"]], "input_shapes": [[1]], "input_types": ["Tensor(unsigned char)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 2485, "rf_id": 1674, "parent": 2482, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[2484,5,0,1,1,"cuda:0"]],35,94136795106832,0,"allreduce",[],[],4], "input_shapes": [[[1]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(unsigned char)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[2484,5,0,1,1,"cuda:0"]]], "output_shapes": [[[1]]], "output_types": ["GenericList[Tensor(unsigned char)]"]
    },
    {
      "name": "record_param_comms", "id": 2482, "rf_id": 1672, "parent": 2481, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [35,94136795106832,0,"barrier",[],[],4], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "c10d::barrier", "id": 2481, "rf_id": 1671, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::barrier(Tensor tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, int[] device_ids, int timeout) -> __torch__.torch.classes.c10d.Work",
      "inputs": [[2480,10,0,1,1,"cuda:0"],"<Object>",[],-1], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(unsigned char)","Object","GenericList[]","Int"],
      "outputs": ["<Object>"], "output_shapes": [[]], "output_types": ["Object"]
    },
    {
      "name": "record_param_comms", "id": 2487, "rf_id": 1676, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [35,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 2491, "rf_id": 1679, "parent": 2490, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[16028672],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[2492,2318,0,16028672,8,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 2493, "rf_id": 1680, "parent": 2490, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2492,2318,0,16028672,8,"cuda:0"],[2488,707,5120,16028672,2,"cuda:0"],false], "input_shapes": [[16028672],[16028672],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2492,2318,0,16028672,8,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 2490, "rf_id": 1678, "parent": 2489, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2488,707,5120,16028672,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[16028672],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[2492,2318,0,16028672,8,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 2489, "rf_id": 1677, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2488,707,5120,16028672,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[16028672],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[2492,2318,0,16028672,8,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "detach", "id": 2495, "rf_id": 1682, "parent": 2494, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[2492,2318,0,16028672,8,"cuda:0"]], "input_shapes": [[16028672]], "input_types": ["Tensor(double)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2494, "rf_id": 1681, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2492,2318,0,16028672,8,"cuda:0"]], "input_shapes": [[16028672]], "input_types": ["Tensor(double)"],
      "outputs": [[2496,2318,0,16028672,8,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 2499, "rf_id": 1684, "parent": 2497, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2498,5,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[2500,5,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 2497, "rf_id": 1683, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[2496,2318,0,16028672,8,"cuda:0"],2.000000,"<None>",false,"<None>"], "input_shapes": [[16028672],[],[],[],[]], "input_types": ["Tensor(double)","Double","None","Bool","None"],
      "outputs": [[2498,5,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 2501, "rf_id": 1685, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2498,5,0,1,8,"cuda:0"],7,0,"cuda:0","<None>",false,false,"<None>"], "input_shapes": [[],[],[],[],[],[],[],[]], "input_types": ["Tensor(double)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[2498,5,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 2504, "rf_id": 1688, "parent": 2503, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2498,5,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[2500,5,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 2503, "rf_id": 1687, "parent": 2502, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[2498,5,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[2500,5,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 2509, "rf_id": 1692, "parent": 2508, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2506,198,0,1,8,"cuda:0"],[1],[1],0], "input_shapes": [[1],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2510,198,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::slice", "id": 2508, "rf_id": 1691, "parent": 2507, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2506,198,0,1,8,"cuda:0"],0,0,1,1], "input_shapes": [[1],[],[],[],[]], "input_types": ["Tensor(double)","Int","Int","Int","Int"],
      "outputs": [[2510,198,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::narrow", "id": 2507, "rf_id": 1690, "parent": 2505, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2506,198,0,1,8,"cuda:0"],0,0,1], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(double)","Int","Int","Int"],
      "outputs": [[2510,198,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::cat", "id": 2505, "rf_id": 1689, "parent": 2502, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[2500,5,0,1,8,"cuda:0"]],0], "input_shapes": [[[1]],[]], "input_types": ["GenericList[Tensor(double)]","Int"],
      "outputs": [[2506,198,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::stack", "id": 2502, "rf_id": 1686, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::stack(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[2498,5,0,1,8,"cuda:0"]],0], "input_shapes": [[[]],[]], "input_types": ["GenericList[Tensor(double)]","Int"],
      "outputs": [[2506,198,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::result_type", "id": 2513, "rf_id": 1695, "parent": 2512, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::result_type.Scalar(Tensor tensor, Scalar other) -> ScalarType",
      "inputs": [[2506,198,0,1,8,"cuda:0"],2], "input_shapes": [[1],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [7], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::to", "id": 2514, "rf_id": 1696, "parent": 2512, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2506,198,0,1,8,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[1],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[2506,198,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::pow", "id": 2512, "rf_id": 1694, "parent": 2511, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -> Tensor",
      "inputs": [[2506,198,0,1,8,"cuda:0"],2], "input_shapes": [[1],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[2510,1262,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::square", "id": 2511, "rf_id": 1693, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::square(Tensor self) -> Tensor",
      "inputs": [[2506,198,0,1,8,"cuda:0"]], "input_shapes": [[1]], "input_types": ["Tensor(double)"],
      "outputs": [[2510,1262,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 2518, "rf_id": 1699, "parent": 2516, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2517,198,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[2519,198,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::sum", "id": 2516, "rf_id": 1698, "parent": 2515, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[2510,1262,0,1,8,"cuda:0"],[],false,"<None>"], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(double)","GenericList[]","Bool","None"],
      "outputs": [[2517,198,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::sum", "id": 2515, "rf_id": 1697, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum(Tensor self, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[2510,1262,0,1,8,"cuda:0"],"<None>"], "input_shapes": [[1],[]], "input_types": ["Tensor(double)","None"],
      "outputs": [[2517,198,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::empty_strided", "id": 2522, "rf_id": 1702, "parent": 2521, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],6,0,"cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[2519,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 2523, "rf_id": 1703, "parent": 2521, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2519,1262,0,1,4,"cuda:0"],[2517,198,0,1,8,"cuda:0"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(double)","Bool"],
      "outputs": [[2519,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 2521, "rf_id": 1701, "parent": 2520, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2517,198,0,1,8,"cuda:0"],6,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","None","None","Bool","None"],
      "outputs": [[2519,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 2520, "rf_id": 1700, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2517,198,0,1,8,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[2519,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "nccl:all_reduce", "id": 2526, "rf_id": 1706, "parent": 2525, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[2519,1262,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 2525, "rf_id": 1705, "parent": 2524, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[2519,1262,0,1,4,"cuda:0"]],39,94136803877936,0,"allreduce",[],[],4], "input_shapes": [[[]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[2519,1262,0,1,4,"cuda:0"]]], "output_shapes": [[[]]], "output_types": ["GenericList[Tensor(float)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 2524, "rf_id": 1704, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[2519,1262,0,1,4,"cuda:0"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[]],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Object","Object","None","Int"],
      "outputs": [[[2519,1262,0,1,4,"cuda:0"]],"<Object>"], "output_shapes": [[[]],[]], "output_types": ["GenericList[Tensor(float)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 2527, "rf_id": 1707, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [39,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::result_type", "id": 2529, "rf_id": 1709, "parent": 2528, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::result_type.Scalar(Tensor tensor, Scalar other) -> ScalarType",
      "inputs": [[2519,1262,0,1,4,"cuda:0"],0.500000], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [6], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::to", "id": 2530, "rf_id": 1710, "parent": 2528, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2519,1262,0,1,4,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(float)","Int","Bool","Bool","None"],
      "outputs": [[2519,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::pow", "id": 2528, "rf_id": 1708, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -> Tensor",
      "inputs": [[2519,1262,0,1,4,"cuda:0"],0.500000], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [[2531,198,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 2534, "rf_id": 1713, "parent": 2533, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[2535,57,0,0,4,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::resize_", "id": 2537, "rf_id": 1715, "parent": 2536, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[2535,57,0,0,4,"cuda:0"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(float)","GenericList[]","None"],
      "outputs": [[2535,306,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::abs", "id": 2536, "rf_id": 1714, "parent": 2533, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::abs.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[2531,198,0,1,4,"cuda:0"],[2535,57,0,0,4,"cuda:0"]], "input_shapes": [[],[0]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[2535,306,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::abs", "id": 2533, "rf_id": 1712, "parent": 2532, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::abs(Tensor self) -> Tensor",
      "inputs": [[2531,198,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[2535,306,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::eq", "id": 2538, "rf_id": 1716, "parent": 2532, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::eq.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[2535,306,0,1,4,"cuda:0"],"inf"], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [[2539,2540,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::isinf", "id": 2532, "rf_id": 1711, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::isinf(Tensor self) -> Tensor",
      "inputs": [[2531,198,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[2539,2540,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::ne", "id": 2542, "rf_id": 1718, "parent": 2541, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ne.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2531,198,0,1,4,"cuda:0"],[2531,198,0,1,4,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[2543,306,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::isnan", "id": 2541, "rf_id": 1717, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::isnan(Tensor self) -> Tensor",
      "inputs": [[2531,198,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[2543,306,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty", "id": 2545, "rf_id": 1720, "parent": 2544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[2546,57,0,0,1,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::resize_", "id": 2548, "rf_id": 1722, "parent": 2547, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[2546,57,0,0,1,"cuda:0"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(bool)","GenericList[]","None"],
      "outputs": [[2546,132,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_or", "id": 2547, "rf_id": 1721, "parent": 2544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_or.out(Tensor self, Tensor other, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[2543,306,0,1,1,"cuda:0"],[2539,2540,0,1,1,"cuda:0"],[2546,57,0,0,1,"cuda:0"]], "input_shapes": [[],[],[0]], "input_types": ["Tensor(bool)","Tensor(bool)","Tensor(bool)"],
      "outputs": [[2546,132,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_or", "id": 2544, "rf_id": 1719, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_or(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2543,306,0,1,1,"cuda:0"],[2539,2540,0,1,1,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[2546,132,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty", "id": 2549, "rf_id": 1723, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],6,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[2550,2551,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 2554, "rf_id": 1726, "parent": 2553, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],6,0,"cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[2555,534,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 2556, "rf_id": 1727, "parent": 2553, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2555,534,0,1,4,"cuda:0"],[2550,2551,0,1,4,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(float)","Bool"],
      "outputs": [[2555,534,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 2553, "rf_id": 1725, "parent": 2552, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2550,2551,0,1,4,"cpu"],6,"<None>","cuda:0","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(float)","Int","None","Device","None","Bool","None"],
      "outputs": [[2555,534,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 2552, "rf_id": 1724, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2550,2551,0,1,4,"cpu"],"cuda:0",6,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(float)","Device","Int","Bool","Bool","None"],
      "outputs": [[2555,534,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::lift_fresh", "id": 2557, "rf_id": 1728, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2555,534,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[2555,534,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "detach_", "id": 2559, "rf_id": 1730, "parent": 2558, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[2555,534,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 2558, "rf_id": 1729, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2555,534,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[2555,534,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul", "id": 2560, "rf_id": 1731, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2546,132,0,1,1,"cuda:0"],[2555,534,0,1,4,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(float)"],
      "outputs": [[2561,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 2563, "rf_id": 1733, "parent": 2562, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[2564,57,0,0,1,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::resize_", "id": 2566, "rf_id": 1735, "parent": 2565, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[2564,57,0,0,1,"cuda:0"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(bool)","GenericList[]","None"],
      "outputs": [[2564,806,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_not", "id": 2565, "rf_id": 1734, "parent": 2562, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_not.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[2546,132,0,1,1,"cuda:0"],[2564,57,0,0,1,"cuda:0"]], "input_shapes": [[],[0]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[2564,806,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_not", "id": 2562, "rf_id": 1732, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_not(Tensor self) -> Tensor",
      "inputs": [[2546,132,0,1,1,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [[2564,806,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::mul", "id": 2567, "rf_id": 1736, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2564,806,0,1,1,"cuda:0"],[2531,198,0,1,4,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(float)"],
      "outputs": [[2568,171,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::add", "id": 2569, "rf_id": 1737, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[2561,1262,0,1,4,"cuda:0"],[2568,171,0,1,4,"cuda:0"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(float)","Int"],
      "outputs": [[2570,806,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 2574, "rf_id": 1740, "parent": 2573, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[2575,823,0,1024,8,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 2576, "rf_id": 1741, "parent": 2573, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2575,823,0,1024,8,"cuda:0"],[2571,707,3072,1024,2,"cuda:0"],false], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2575,823,0,1024,8,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 2573, "rf_id": 1739, "parent": 2572, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2571,707,3072,1024,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[1024],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[2575,823,0,1024,8,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 2572, "rf_id": 1738, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2571,707,3072,1024,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[2575,823,0,1024,8,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "detach", "id": 2578, "rf_id": 1743, "parent": 2577, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[2575,823,0,1024,8,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(double)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2577, "rf_id": 1742, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2575,823,0,1024,8,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(double)"],
      "outputs": [[2579,823,0,1024,8,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 2582, "rf_id": 1745, "parent": 2580, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2581,5,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[2583,5,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 2580, "rf_id": 1744, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[2579,823,0,1024,8,"cuda:0"],2.000000,"<None>",false,"<None>"], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(double)","Double","None","Bool","None"],
      "outputs": [[2581,5,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 2584, "rf_id": 1746, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2581,5,0,1,8,"cuda:0"],7,0,"cuda:0","<None>",false,false,"<None>"], "input_shapes": [[],[],[],[],[],[],[],[]], "input_types": ["Tensor(double)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[2581,5,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::empty_strided", "id": 2587, "rf_id": 1749, "parent": 2586, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[2588,823,0,1024,8,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 2589, "rf_id": 1750, "parent": 2586, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2588,823,0,1024,8,"cuda:0"],[2583,707,4096,1024,2,"cuda:0"],false], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2588,823,0,1024,8,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 2586, "rf_id": 1748, "parent": 2585, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2583,707,4096,1024,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[1024],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[2588,823,0,1024,8,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 2585, "rf_id": 1747, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2583,707,4096,1024,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[2588,823,0,1024,8,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "detach", "id": 2591, "rf_id": 1752, "parent": 2590, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[2588,823,0,1024,8,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(double)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2590, "rf_id": 1751, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2588,823,0,1024,8,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(double)"],
      "outputs": [[2592,823,0,1024,8,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 2595, "rf_id": 1754, "parent": 2593, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2594,132,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[2596,132,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 2593, "rf_id": 1753, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[2592,823,0,1024,8,"cuda:0"],2.000000,"<None>",false,"<None>"], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(double)","Double","None","Bool","None"],
      "outputs": [[2594,132,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 2597, "rf_id": 1755, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2594,132,0,1,8,"cuda:0"],7,0,"cuda:0","<None>",false,false,"<None>"], "input_shapes": [[],[],[],[],[],[],[],[]], "input_types": ["Tensor(double)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[2594,132,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::empty_strided", "id": 2600, "rf_id": 1758, "parent": 2599, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1792],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[2601,785,0,1792,8,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 2602, "rf_id": 1759, "parent": 2599, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2601,785,0,1792,8,"cuda:0"],[2596,707,0,1792,2,"cuda:0"],false], "input_shapes": [[1792],[1792],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2601,785,0,1792,8,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 2599, "rf_id": 1757, "parent": 2598, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2596,707,0,1792,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[1792],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[2601,785,0,1792,8,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 2598, "rf_id": 1756, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2596,707,0,1792,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[1792],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[2601,785,0,1792,8,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "detach", "id": 2604, "rf_id": 1761, "parent": 2603, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[2601,785,0,1792,8,"cuda:0"]], "input_shapes": [[1792]], "input_types": ["Tensor(double)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2603, "rf_id": 1760, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2601,785,0,1792,8,"cuda:0"]], "input_shapes": [[1792]], "input_types": ["Tensor(double)"],
      "outputs": [[2605,785,0,1792,8,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 2608, "rf_id": 1763, "parent": 2606, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2607,534,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[2609,534,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 2606, "rf_id": 1762, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[2605,785,0,1792,8,"cuda:0"],2.000000,"<None>",false,"<None>"], "input_shapes": [[1792],[],[],[],[]], "input_types": ["Tensor(double)","Double","None","Bool","None"],
      "outputs": [[2607,534,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 2610, "rf_id": 1764, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2607,534,0,1,8,"cuda:0"],7,0,"cuda:0","<None>",false,false,"<None>"], "input_shapes": [[],[],[],[],[],[],[],[]], "input_types": ["Tensor(double)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[2607,534,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 2613, "rf_id": 1767, "parent": 2612, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2581,5,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[2609,5,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 2612, "rf_id": 1766, "parent": 2611, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[2581,5,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[2609,5,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 2615, "rf_id": 1769, "parent": 2614, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2594,132,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[2616,132,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 2614, "rf_id": 1768, "parent": 2611, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[2594,132,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[2616,132,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 2618, "rf_id": 1771, "parent": 2617, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2607,534,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[2619,534,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 2617, "rf_id": 1770, "parent": 2611, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[2607,534,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[2619,534,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::cat", "id": 2620, "rf_id": 1772, "parent": 2611, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[2609,5,0,1,8,"cuda:0"],[2616,132,0,1,8,"cuda:0"],[2619,534,0,1,8,"cuda:0"]],0], "input_shapes": [[[1],[1],[1]],[]], "input_types": ["GenericList[Tensor(double),Tensor(double),Tensor(double)]","Int"],
      "outputs": [[2621,198,0,3,8,"cuda:0"]], "output_shapes": [[3]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::stack", "id": 2611, "rf_id": 1765, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::stack(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[2581,5,0,1,8,"cuda:0"],[2594,132,0,1,8,"cuda:0"],[2607,534,0,1,8,"cuda:0"]],0], "input_shapes": [[[],[],[]],[]], "input_types": ["GenericList[Tensor(double),Tensor(double),Tensor(double)]","Int"],
      "outputs": [[2621,198,0,3,8,"cuda:0"]], "output_shapes": [[3]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::result_type", "id": 2624, "rf_id": 1775, "parent": 2623, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::result_type.Scalar(Tensor tensor, Scalar other) -> ScalarType",
      "inputs": [[2621,198,0,3,8,"cuda:0"],2], "input_shapes": [[3],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [7], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::to", "id": 2625, "rf_id": 1776, "parent": 2623, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2621,198,0,3,8,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[3],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[2621,198,0,3,8,"cuda:0"]], "output_shapes": [[3]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::pow", "id": 2623, "rf_id": 1774, "parent": 2622, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -> Tensor",
      "inputs": [[2621,198,0,3,8,"cuda:0"],2], "input_shapes": [[3],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[2626,1262,0,3,8,"cuda:0"]], "output_shapes": [[3]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::square", "id": 2622, "rf_id": 1773, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::square(Tensor self) -> Tensor",
      "inputs": [[2621,198,0,3,8,"cuda:0"]], "input_shapes": [[3]], "input_types": ["Tensor(double)"],
      "outputs": [[2626,1262,0,3,8,"cuda:0"]], "output_shapes": [[3]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 2630, "rf_id": 1779, "parent": 2628, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2629,198,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[2631,198,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::sum", "id": 2628, "rf_id": 1778, "parent": 2627, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[2626,1262,0,3,8,"cuda:0"],[],false,"<None>"], "input_shapes": [[3],[],[],[]], "input_types": ["Tensor(double)","GenericList[]","Bool","None"],
      "outputs": [[2629,198,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::sum", "id": 2627, "rf_id": 1777, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum(Tensor self, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[2626,1262,0,3,8,"cuda:0"],"<None>"], "input_shapes": [[3],[]], "input_types": ["Tensor(double)","None"],
      "outputs": [[2629,198,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::empty_strided", "id": 2634, "rf_id": 1782, "parent": 2633, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],6,0,"cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[2631,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 2635, "rf_id": 1783, "parent": 2633, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2631,1262,0,1,4,"cuda:0"],[2629,198,0,1,8,"cuda:0"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(double)","Bool"],
      "outputs": [[2631,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 2633, "rf_id": 1781, "parent": 2632, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2629,198,0,1,8,"cuda:0"],6,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","None","None","Bool","None"],
      "outputs": [[2631,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 2632, "rf_id": 1780, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2629,198,0,1,8,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[2631,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "nccl:all_reduce", "id": 2638, "rf_id": 1786, "parent": 2637, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[2631,1262,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 2637, "rf_id": 1785, "parent": 2636, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[2631,1262,0,1,4,"cuda:0"]],40,94136803877936,0,"allreduce",[],[],4], "input_shapes": [[[]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[2631,1262,0,1,4,"cuda:0"]]], "output_shapes": [[[]]], "output_types": ["GenericList[Tensor(float)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 2636, "rf_id": 1784, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[2631,1262,0,1,4,"cuda:0"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[]],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Object","Object","None","Int"],
      "outputs": [[[2631,1262,0,1,4,"cuda:0"]],"<Object>"], "output_shapes": [[[]],[]], "output_types": ["GenericList[Tensor(float)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 2639, "rf_id": 1787, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [40,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::result_type", "id": 2641, "rf_id": 1789, "parent": 2640, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::result_type.Scalar(Tensor tensor, Scalar other) -> ScalarType",
      "inputs": [[2631,1262,0,1,4,"cuda:0"],0.500000], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [6], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::to", "id": 2642, "rf_id": 1790, "parent": 2640, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2631,1262,0,1,4,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(float)","Int","Bool","Bool","None"],
      "outputs": [[2631,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::pow", "id": 2640, "rf_id": 1788, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -> Tensor",
      "inputs": [[2631,1262,0,1,4,"cuda:0"],0.500000], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [[2643,198,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 2646, "rf_id": 1793, "parent": 2645, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[2647,57,0,0,4,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::resize_", "id": 2649, "rf_id": 1795, "parent": 2648, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[2647,57,0,0,4,"cuda:0"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(float)","GenericList[]","None"],
      "outputs": [[2647,306,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::abs", "id": 2648, "rf_id": 1794, "parent": 2645, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::abs.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[2643,198,0,1,4,"cuda:0"],[2647,57,0,0,4,"cuda:0"]], "input_shapes": [[],[0]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[2647,306,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::abs", "id": 2645, "rf_id": 1792, "parent": 2644, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::abs(Tensor self) -> Tensor",
      "inputs": [[2643,198,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[2647,306,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::eq", "id": 2650, "rf_id": 1796, "parent": 2644, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::eq.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[2647,306,0,1,4,"cuda:0"],"inf"], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [[2651,2540,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::isinf", "id": 2644, "rf_id": 1791, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::isinf(Tensor self) -> Tensor",
      "inputs": [[2643,198,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[2651,2540,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::ne", "id": 2653, "rf_id": 1798, "parent": 2652, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ne.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2643,198,0,1,4,"cuda:0"],[2643,198,0,1,4,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[2654,306,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::isnan", "id": 2652, "rf_id": 1797, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::isnan(Tensor self) -> Tensor",
      "inputs": [[2643,198,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[2654,306,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty", "id": 2656, "rf_id": 1800, "parent": 2655, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[2657,57,0,0,1,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::resize_", "id": 2659, "rf_id": 1802, "parent": 2658, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[2657,57,0,0,1,"cuda:0"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(bool)","GenericList[]","None"],
      "outputs": [[2657,171,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_or", "id": 2658, "rf_id": 1801, "parent": 2655, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_or.out(Tensor self, Tensor other, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[2654,306,0,1,1,"cuda:0"],[2651,2540,0,1,1,"cuda:0"],[2657,57,0,0,1,"cuda:0"]], "input_shapes": [[],[],[0]], "input_types": ["Tensor(bool)","Tensor(bool)","Tensor(bool)"],
      "outputs": [[2657,171,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_or", "id": 2655, "rf_id": 1799, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_or(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2654,306,0,1,1,"cuda:0"],[2651,2540,0,1,1,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[2657,171,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty", "id": 2660, "rf_id": 1803, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],6,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[2661,2662,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 2665, "rf_id": 1806, "parent": 2664, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],6,0,"cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[2666,2667,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 2668, "rf_id": 1807, "parent": 2664, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2666,2667,0,1,4,"cuda:0"],[2661,2662,0,1,4,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(float)","Bool"],
      "outputs": [[2666,2667,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 2664, "rf_id": 1805, "parent": 2663, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2661,2662,0,1,4,"cpu"],6,"<None>","cuda:0","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(float)","Int","None","Device","None","Bool","None"],
      "outputs": [[2666,2667,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 2663, "rf_id": 1804, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2661,2662,0,1,4,"cpu"],"cuda:0",6,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(float)","Device","Int","Bool","Bool","None"],
      "outputs": [[2666,2667,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::lift_fresh", "id": 2669, "rf_id": 1808, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2666,2667,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[2666,2667,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "detach_", "id": 2671, "rf_id": 1810, "parent": 2670, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[2666,2667,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 2670, "rf_id": 1809, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2666,2667,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[2666,2667,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul", "id": 2672, "rf_id": 1811, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2657,171,0,1,1,"cuda:0"],[2666,2667,0,1,4,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(float)"],
      "outputs": [[2673,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 2675, "rf_id": 1813, "parent": 2674, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[2676,57,0,0,1,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::resize_", "id": 2678, "rf_id": 1815, "parent": 2677, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[2676,57,0,0,1,"cuda:0"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(bool)","GenericList[]","None"],
      "outputs": [[2676,2679,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_not", "id": 2677, "rf_id": 1814, "parent": 2674, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_not.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[2657,171,0,1,1,"cuda:0"],[2676,57,0,0,1,"cuda:0"]], "input_shapes": [[],[0]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[2676,2679,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_not", "id": 2674, "rf_id": 1812, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_not(Tensor self) -> Tensor",
      "inputs": [[2657,171,0,1,1,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [[2676,2679,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::mul", "id": 2680, "rf_id": 1816, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2676,2679,0,1,1,"cuda:0"],[2643,198,0,1,4,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(float)"],
      "outputs": [[2681,184,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::add", "id": 2682, "rf_id": 1817, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[2673,1262,0,1,4,"cuda:0"],[2681,184,0,1,4,"cuda:0"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(float)","Int"],
      "outputs": [[2683,2679,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 2686, "rf_id": 1820, "parent": 2685, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2570,806,0,1,4,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[2687,806,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::unsqueeze", "id": 2685, "rf_id": 1819, "parent": 2684, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[2570,806,0,1,4,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[2687,806,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 2689, "rf_id": 1822, "parent": 2688, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2683,2679,0,1,4,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[2690,2679,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::unsqueeze", "id": 2688, "rf_id": 1821, "parent": 2684, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[2683,2679,0,1,4,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[2690,2679,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::cat", "id": 2691, "rf_id": 1823, "parent": 2684, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[2687,806,0,1,4,"cuda:0"],[2690,2679,0,1,4,"cuda:0"]],0], "input_shapes": [[[1],[1]],[]], "input_types": ["GenericList[Tensor(float),Tensor(float)]","Int"],
      "outputs": [[2692,5,0,2,4,"cuda:0"]], "output_shapes": [[2]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::stack", "id": 2684, "rf_id": 1818, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::stack(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[2570,806,0,1,4,"cuda:0"],[2683,2679,0,1,4,"cuda:0"]],0], "input_shapes": [[[],[]],[]], "input_types": ["GenericList[Tensor(float),Tensor(float)]","Int"],
      "outputs": [[2692,5,0,2,4,"cuda:0"]], "output_shapes": [[2]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 2695, "rf_id": 1825, "parent": 2693, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2694,132,0,1,4,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[2696,132,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 2693, "rf_id": 1824, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[2692,5,0,2,4,"cuda:0"],2,"<None>",false,"<None>"], "input_shapes": [[2],[],[],[],[]], "input_types": ["Tensor(float)","Int","None","Bool","None"],
      "outputs": [[2694,132,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::div", "id": 2698, "rf_id": 1826, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2694,132,0,1,4,"cuda:0"],[2696,2697,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[2699,5,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 2701, "rf_id": 1828, "parent": 2700, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2472,707,5120,16028672,2,"cuda:0"],[-1]], "input_shapes": [[16028672],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2702,707,5120,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::flatten_dense_tensors", "id": 2700, "rf_id": 1827, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::flatten_dense_tensors(Tensor[] tensors) -> Tensor",
      "inputs": [[[2472,707,5120,16028672,2,"cuda:0"]]], "input_shapes": [[[16028672]]], "input_types": ["GenericList[Tensor(c10::BFloat16)]"],
      "outputs": [[2702,707,5120,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 2705, "rf_id": 1831, "parent": 2704, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[16028672],[1],6,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[2706,2201,0,16028672,4,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 2707, "rf_id": 1832, "parent": 2704, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2706,2201,0,16028672,4,"cuda:0"],[2702,707,5120,16028672,2,"cuda:0"],false], "input_shapes": [[16028672],[16028672],[]], "input_types": ["Tensor(float)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2706,2201,0,16028672,4,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 2704, "rf_id": 1830, "parent": 2703, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2702,707,5120,16028672,2,"cuda:0"],6,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[16028672],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[2706,2201,0,16028672,4,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 2703, "rf_id": 1829, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2702,707,5120,16028672,2,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[16028672],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[2706,2201,0,16028672,4,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::div", "id": 2710, "rf_id": 1833, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2694,132,0,1,4,"cuda:0"],[2708,2709,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[2711,198,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::add", "id": 2714, "rf_id": 1834, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[2711,198,0,1,4,"cuda:0"],[2712,2713,0,1,8,"cpu"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(double)","Int"],
      "outputs": [[2715,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::div", "id": 2718, "rf_id": 1835, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2715,1262,0,1,4,"cuda:0"],[2716,2717,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[2719,198,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::gt", "id": 2720, "rf_id": 1836, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::gt.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[2719,198,0,1,4,"cuda:0"],1], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[2721,1262,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 2724, "rf_id": 1839, "parent": 2723, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[2721,1262,0,1,1,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::item", "id": 2723, "rf_id": 1838, "parent": 2722, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[2721,1262,0,1,1,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::is_nonzero", "id": 2722, "rf_id": 1837, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::is_nonzero(Tensor self) -> bool",
      "inputs": [[2721,1262,0,1,1,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::mul", "id": 2727, "rf_id": 1840, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2719,198,0,1,4,"cuda:0"],[2725,2726,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[2728,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::reciprocal", "id": 2729, "rf_id": 1841, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reciprocal(Tensor self) -> Tensor",
      "inputs": [[2728,1262,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[2730,306,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul", "id": 2733, "rf_id": 1842, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2730,306,0,1,4,"cuda:0"],[2731,2732,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[2734,2540,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul_", "id": 2736, "rf_id": 1843, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[2735,2201,0,16028672,4,"cuda:0"],[2734,2540,0,1,4,"cuda:0"]], "input_shapes": [[16028672],[]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[2735,2201,0,16028672,4,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "Optimizer.step#FusedAdam.step", "id": 2737, "rf_id": 1844, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::copy_", "id": 2741, "rf_id": 1845, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2738,236,0,16028672,2,"cuda:0"],[2739,2740,0,16028672,4,"cuda:0"],false], "input_shapes": [[16028672],[16028672],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(float)","Bool"],
      "outputs": [[2738,236,0,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2743, "rf_id": 1847, "parent": 2742, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2103,707,3072,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2744,707,3072,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2745, "rf_id": 1848, "parent": 2742, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2118,707,4096,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2746,707,4096,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2747, "rf_id": 1849, "parent": 2742, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2478,707,0,1792,2,"cuda:0"],[-1]], "input_shapes": [[1792],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2748,707,0,1792,2,"cuda:0"]], "output_shapes": [[1792]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 2749, "rf_id": 1850, "parent": 2742, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[2744,707,3072,1024,2,"cuda:0"],[2746,707,4096,1024,2,"cuda:0"],[2748,707,0,1792,2,"cuda:0"]],0], "input_shapes": [[[1024],[1024],[1792]],[]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int"],
      "outputs": [[2750,823,0,3840,2,"cuda:0"]], "output_shapes": [[3840]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::flatten_dense_tensors", "id": 2742, "rf_id": 1846, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::flatten_dense_tensors(Tensor[] tensors) -> Tensor",
      "inputs": [[[2103,707,3072,1024,2,"cuda:0"],[2118,707,4096,1024,2,"cuda:0"],[2478,707,0,1792,2,"cuda:0"]]], "input_shapes": [[[1024],[1024],[1792]]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"],
      "outputs": [[2750,823,0,3840,2,"cuda:0"]], "output_shapes": [[3840]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 2753, "rf_id": 1853, "parent": 2752, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[3840],[1],6,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[2754,785,0,3840,4,"cuda:0"]], "output_shapes": [[3840]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 2755, "rf_id": 1854, "parent": 2752, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2754,785,0,3840,4,"cuda:0"],[2750,823,0,3840,2,"cuda:0"],false], "input_shapes": [[3840],[3840],[]], "input_types": ["Tensor(float)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2754,785,0,3840,4,"cuda:0"]], "output_shapes": [[3840]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 2752, "rf_id": 1852, "parent": 2751, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2750,823,0,3840,2,"cuda:0"],6,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[3840],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[2754,785,0,3840,4,"cuda:0"]], "output_shapes": [[3840]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 2751, "rf_id": 1851, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[2750,823,0,3840,2,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[2754,785,0,3840,4,"cuda:0"]], "output_shapes": [[3840]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::div", "id": 2758, "rf_id": 1855, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2694,132,0,1,4,"cuda:0"],[2756,2757,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[2759,198,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::add", "id": 2762, "rf_id": 1856, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[2759,198,0,1,4,"cuda:0"],[2760,2761,0,1,8,"cpu"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(double)","Int"],
      "outputs": [[2763,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::div", "id": 2766, "rf_id": 1857, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2763,1262,0,1,4,"cuda:0"],[2764,2765,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[2767,198,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::gt", "id": 2768, "rf_id": 1858, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::gt.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[2767,198,0,1,4,"cuda:0"],1], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[2769,1262,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 2772, "rf_id": 1861, "parent": 2771, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[2769,1262,0,1,1,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::item", "id": 2771, "rf_id": 1860, "parent": 2770, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[2769,1262,0,1,1,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::is_nonzero", "id": 2770, "rf_id": 1859, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::is_nonzero(Tensor self) -> bool",
      "inputs": [[2769,1262,0,1,1,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::mul", "id": 2775, "rf_id": 1862, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2767,198,0,1,4,"cuda:0"],[2773,2774,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[2776,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::reciprocal", "id": 2777, "rf_id": 1863, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reciprocal(Tensor self) -> Tensor",
      "inputs": [[2776,1262,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[2778,306,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul", "id": 2781, "rf_id": 1864, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2778,306,0,1,4,"cuda:0"],[2779,2780,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[2782,2540,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul_", "id": 2784, "rf_id": 1865, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[2783,785,0,3840,4,"cuda:0"],[2782,2540,0,1,4,"cuda:0"]], "input_shapes": [[3840],[]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[2783,785,0,3840,4,"cuda:0"]], "output_shapes": [[3840]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "Optimizer.step#FusedAdam.step", "id": 2785, "rf_id": 1866, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::copy_", "id": 2789, "rf_id": 1867, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2786,294,0,3840,2,"cuda:0"],[2787,2788,0,3840,4,"cuda:0"],false], "input_shapes": [[3840],[3840],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(float)","Bool"],
      "outputs": [[2786,294,0,3840,2,"cuda:0"]], "output_shapes": [[3840]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 2794, "rf_id": 1870, "parent": 2793, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[2791,236,0,16028672,2,"cuda:0"]], "input_shapes": [[16028672]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 2793, "rf_id": 1869, "parent": 2792, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[2791,236,0,16028672,2,"cuda:0"],41,94136803877936,0,"_allgather_base",[],[],4], "input_shapes": [[16028672],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[2790,236,0,64114688,2,"cuda:0"]], "output_shapes": [[64114688]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 2792, "rf_id": 1868, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],[2791,236,0,16028672,2,"cuda:0"],"<Object>",false,-1], "input_shapes": [[64114688],[16028672],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[2790,236,0,64114688,2,"cuda:0"],"<Object>"], "output_shapes": [[64114688],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "record_param_comms", "id": 2795, "rf_id": 1871, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [41,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "nccl:_all_gather_base", "id": 2800, "rf_id": 1874, "parent": 2799, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[2797,294,0,3840,2,"cuda:0"]], "input_shapes": [[3840]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 2799, "rf_id": 1873, "parent": 2798, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[2797,294,0,3840,2,"cuda:0"],42,94136803877936,0,"_allgather_base",[],[],4], "input_shapes": [[3840],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[2796,294,0,15360,2,"cuda:0"]], "output_shapes": [[15360]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 2798, "rf_id": 1872, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],[2797,294,0,3840,2,"cuda:0"],"<Object>",false,-1], "input_shapes": [[15360],[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[2796,294,0,15360,2,"cuda:0"],"<Object>"], "output_shapes": [[15360],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "record_param_comms", "id": 2801, "rf_id": 1875, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [42,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2811, "rf_id": 1879, "parent": 2810, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],[51511296],[1],0], "input_shapes": [[64114688],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2812,236,0,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2810, "rf_id": 1878, "parent": 2809, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],0,0,51511296,1], "input_shapes": [[64114688],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2812,236,0,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2809, "rf_id": 1877, "parent": 2808, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],0,0,51511296], "input_shapes": [[64114688],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2812,236,0,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2813, "rf_id": 1880, "parent": 2808, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2812,236,0,51511296,2,"cuda:0"],[50304,1024]], "input_shapes": [[51511296],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2814,236,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2817, "rf_id": 1883, "parent": 2816, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],[20480],[1],51511296], "input_shapes": [[64114688],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2818,236,51511296,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2816, "rf_id": 1882, "parent": 2815, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],0,51511296,51531776,1], "input_shapes": [[64114688],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2818,236,51511296,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2815, "rf_id": 1881, "parent": 2808, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],0,51511296,20480], "input_shapes": [[64114688],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2818,236,51511296,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2819, "rf_id": 1884, "parent": 2808, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2818,236,51511296,20480,2,"cuda:0"],[20,1024]], "input_shapes": [[20480],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2820,236,51511296,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2823, "rf_id": 1887, "parent": 2822, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],[3145728],[1],51531776], "input_shapes": [[64114688],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2824,236,51531776,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2822, "rf_id": 1886, "parent": 2821, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],0,51531776,54677504,1], "input_shapes": [[64114688],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2824,236,51531776,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2821, "rf_id": 1885, "parent": 2808, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],0,51531776,3145728], "input_shapes": [[64114688],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2824,236,51531776,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2825, "rf_id": 1888, "parent": 2808, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2824,236,51531776,3145728,2,"cuda:0"],[3072,1024]], "input_shapes": [[3145728],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2826,236,51531776,3145728,2,"cuda:0"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2829, "rf_id": 1891, "parent": 2828, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],[1048576],[1],54677504], "input_shapes": [[64114688],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2830,236,54677504,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2828, "rf_id": 1890, "parent": 2827, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],0,54677504,55726080,1], "input_shapes": [[64114688],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2830,236,54677504,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2827, "rf_id": 1889, "parent": 2808, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],0,54677504,1048576], "input_shapes": [[64114688],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2830,236,54677504,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2831, "rf_id": 1892, "parent": 2808, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2830,236,54677504,1048576,2,"cuda:0"],[1024,1024]], "input_shapes": [[1048576],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2832,236,54677504,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2835, "rf_id": 1895, "parent": 2834, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],[4194304],[1],55726080], "input_shapes": [[64114688],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2836,236,55726080,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2834, "rf_id": 1894, "parent": 2833, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],0,55726080,59920384,1], "input_shapes": [[64114688],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2836,236,55726080,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2833, "rf_id": 1893, "parent": 2808, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],0,55726080,4194304], "input_shapes": [[64114688],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2836,236,55726080,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2837, "rf_id": 1896, "parent": 2808, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2836,236,55726080,4194304,2,"cuda:0"],[4096,1024]], "input_shapes": [[4194304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2838,236,55726080,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2841, "rf_id": 1899, "parent": 2840, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],[4194304],[1],59920384], "input_shapes": [[64114688],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2842,236,59920384,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2840, "rf_id": 1898, "parent": 2839, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],0,59920384,64114688,1], "input_shapes": [[64114688],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2842,236,59920384,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2839, "rf_id": 1897, "parent": 2808, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],0,59920384,4194304], "input_shapes": [[64114688],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2842,236,59920384,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2843, "rf_id": 1900, "parent": 2808, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2842,236,59920384,4194304,2,"cuda:0"],[1024,4096]], "input_shapes": [[4194304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2844,236,59920384,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::unflatten_dense_tensors", "id": 2808, "rf_id": 1876, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unflatten_dense_tensors(Tensor flat, Tensor[] tensors) -> Tensor[]",
      "inputs": [[2790,236,0,64114688,2,"cuda:0"],[[2802,57,0,51511296,2,"meta"],[2803,57,0,20480,2,"meta"],[2804,57,0,3145728,2,"meta"],[2805,57,0,1048576,2,"meta"],[2806,57,0,4194304,2,"meta"],[2807,57,0,4194304,2,"meta"]]], "input_shapes": [[64114688],[[50304,1024],[20,1024],[3072,1024],[1024,1024],[4096,1024],[1024,4096]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"],
      "outputs": [[[2814,236,0,51511296,2,"cuda:0"],[2820,236,51511296,20480,2,"cuda:0"],[2826,236,51531776,3145728,2,"cuda:0"],[2832,236,54677504,1048576,2,"cuda:0"],[2838,236,55726080,4194304,2,"cuda:0"],[2844,236,59920384,4194304,2,"cuda:0"]]], "output_shapes": [[[50304,1024],[20,1024],[3072,1024],[1024,1024],[4096,1024],[1024,4096]]], "output_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2846, "rf_id": 1901, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[235,236,0,51511296,2,"cuda:0"],[2845,236,0,51511296,2,"cuda:0"]], "input_shapes": [[50304,1024],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2848, "rf_id": 1902, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[252,236,51511296,20480,2,"cuda:0"],[2847,236,51511296,20480,2,"cuda:0"]], "input_shapes": [[20,1024],[20,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2850, "rf_id": 1903, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[310,236,51531776,3145728,2,"cuda:0"],[2849,236,51531776,3145728,2,"cuda:0"]], "input_shapes": [[3072,1024],[3072,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2852, "rf_id": 1904, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[456,236,54677504,1048576,2,"cuda:0"],[2851,236,54677504,1048576,2,"cuda:0"]], "input_shapes": [[1024,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2854, "rf_id": 1905, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[543,236,55726080,4194304,2,"cuda:0"],[2853,236,55726080,4194304,2,"cuda:0"]], "input_shapes": [[4096,1024],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2856, "rf_id": 1906, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[613,236,59920384,4194304,2,"cuda:0"],[2855,236,59920384,4194304,2,"cuda:0"]], "input_shapes": [[1024,4096],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2858, "rf_id": 1907, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[235,236,0,51511296,2,"cuda:0"],[2857,236,0,51511296,2,"cuda:0"]], "input_shapes": [[50304,1024],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2860, "rf_id": 1908, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[252,236,51511296,20480,2,"cuda:0"],[2859,236,51511296,20480,2,"cuda:0"]], "input_shapes": [[20,1024],[20,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2862, "rf_id": 1909, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[310,236,51531776,3145728,2,"cuda:0"],[2861,236,51531776,3145728,2,"cuda:0"]], "input_shapes": [[3072,1024],[3072,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2864, "rf_id": 1910, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[456,236,54677504,1048576,2,"cuda:0"],[2863,236,54677504,1048576,2,"cuda:0"]], "input_shapes": [[1024,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2866, "rf_id": 1911, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[543,236,55726080,4194304,2,"cuda:0"],[2865,236,55726080,4194304,2,"cuda:0"]], "input_shapes": [[4096,1024],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2868, "rf_id": 1912, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[613,236,59920384,4194304,2,"cuda:0"],[2867,236,59920384,4194304,2,"cuda:0"]], "input_shapes": [[1024,4096],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 2882, "rf_id": 1916, "parent": 2881, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],[1024],[1],0], "input_shapes": [[15360],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2844,294,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2881, "rf_id": 1915, "parent": 2880, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,0,1024,1], "input_shapes": [[15360],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2844,294,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2880, "rf_id": 1914, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,0,1024], "input_shapes": [[15360],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2844,294,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2883, "rf_id": 1917, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2844,294,0,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2814,294,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2886, "rf_id": 1920, "parent": 2885, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],[1024],[1],1024], "input_shapes": [[15360],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2820,294,1024,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2885, "rf_id": 1919, "parent": 2884, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,1024,2048,1], "input_shapes": [[15360],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2820,294,1024,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2884, "rf_id": 1918, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,1024,1024], "input_shapes": [[15360],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2820,294,1024,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2887, "rf_id": 1921, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2820,294,1024,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2826,294,1024,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2890, "rf_id": 1924, "parent": 2889, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],[3072],[1],2048], "input_shapes": [[15360],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2832,294,2048,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2889, "rf_id": 1923, "parent": 2888, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,2048,5120,1], "input_shapes": [[15360],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2832,294,2048,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2888, "rf_id": 1922, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,2048,3072], "input_shapes": [[15360],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2832,294,2048,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2891, "rf_id": 1925, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2832,294,2048,3072,2,"cuda:0"],[3072]], "input_shapes": [[3072],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2838,294,2048,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2894, "rf_id": 1928, "parent": 2893, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],[1024],[1],5120], "input_shapes": [[15360],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2895,294,5120,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2893, "rf_id": 1927, "parent": 2892, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,5120,6144,1], "input_shapes": [[15360],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2895,294,5120,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2892, "rf_id": 1926, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,5120,1024], "input_shapes": [[15360],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2895,294,5120,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2896, "rf_id": 1929, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2895,294,5120,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2897,294,5120,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2900, "rf_id": 1932, "parent": 2899, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],[1024],[1],6144], "input_shapes": [[15360],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2901,294,6144,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2899, "rf_id": 1931, "parent": 2898, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,6144,7168,1], "input_shapes": [[15360],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2901,294,6144,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2898, "rf_id": 1930, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,6144,1024], "input_shapes": [[15360],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2901,294,6144,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2902, "rf_id": 1933, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2901,294,6144,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2903,294,6144,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2906, "rf_id": 1936, "parent": 2905, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],[1024],[1],7168], "input_shapes": [[15360],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2907,294,7168,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2905, "rf_id": 1935, "parent": 2904, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,7168,8192,1], "input_shapes": [[15360],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2907,294,7168,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2904, "rf_id": 1934, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,7168,1024], "input_shapes": [[15360],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2907,294,7168,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2908, "rf_id": 1937, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2907,294,7168,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2909,294,7168,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2912, "rf_id": 1940, "parent": 2911, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],[4096],[1],8192], "input_shapes": [[15360],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2913,294,8192,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2911, "rf_id": 1939, "parent": 2910, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,8192,12288,1], "input_shapes": [[15360],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2913,294,8192,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2910, "rf_id": 1938, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,8192,4096], "input_shapes": [[15360],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2913,294,8192,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2914, "rf_id": 1941, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2913,294,8192,4096,2,"cuda:0"],[4096]], "input_shapes": [[4096],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2915,294,8192,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2918, "rf_id": 1944, "parent": 2917, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],[1024],[1],12288], "input_shapes": [[15360],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2919,294,12288,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2917, "rf_id": 1943, "parent": 2916, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,12288,13312,1], "input_shapes": [[15360],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2919,294,12288,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2916, "rf_id": 1942, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,12288,1024], "input_shapes": [[15360],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2919,294,12288,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2920, "rf_id": 1945, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2919,294,12288,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2921,294,12288,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2924, "rf_id": 1948, "parent": 2923, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],[1024],[1],13312], "input_shapes": [[15360],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2925,294,13312,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2923, "rf_id": 1947, "parent": 2922, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,13312,14336,1], "input_shapes": [[15360],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2925,294,13312,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2922, "rf_id": 1946, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,13312,1024], "input_shapes": [[15360],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2925,294,13312,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2926, "rf_id": 1949, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2925,294,13312,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2927,294,13312,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2930, "rf_id": 1952, "parent": 2929, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],[1024],[1],14336], "input_shapes": [[15360],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2931,294,14336,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2929, "rf_id": 1951, "parent": 2928, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,14336,15360,1], "input_shapes": [[15360],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2931,294,14336,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2928, "rf_id": 1950, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],0,14336,1024], "input_shapes": [[15360],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2931,294,14336,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2932, "rf_id": 1953, "parent": 2879, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2931,294,14336,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2933,294,14336,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::unflatten_dense_tensors", "id": 2879, "rf_id": 1913, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unflatten_dense_tensors(Tensor flat, Tensor[] tensors) -> Tensor[]",
      "inputs": [[2796,294,0,15360,2,"cuda:0"],[[2869,57,0,1024,2,"meta"],[2870,57,0,1024,2,"meta"],[2871,57,0,3072,2,"meta"],[2872,57,0,1024,2,"meta"],[2873,57,0,1024,2,"meta"],[2874,57,0,1024,2,"meta"],[2875,57,0,4096,2,"meta"],[2876,57,0,1024,2,"meta"],[2877,57,0,1024,2,"meta"],[2878,57,0,1024,2,"meta"]]], "input_shapes": [[15360],[[1024],[1024],[3072],[1024],[1024],[1024],[4096],[1024],[1024],[1024]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"],
      "outputs": [[[2814,294,0,1024,2,"cuda:0"],[2826,294,1024,1024,2,"cuda:0"],[2838,294,2048,3072,2,"cuda:0"],[2897,294,5120,1024,2,"cuda:0"],[2903,294,6144,1024,2,"cuda:0"],[2909,294,7168,1024,2,"cuda:0"],[2915,294,8192,4096,2,"cuda:0"],[2921,294,12288,1024,2,"cuda:0"],[2927,294,13312,1024,2,"cuda:0"],[2933,294,14336,1024,2,"cuda:0"]]], "output_shapes": [[[1024],[1024],[3072],[1024],[1024],[1024],[4096],[1024],[1024],[1024]]], "output_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2935, "rf_id": 1954, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[293,294,0,1024,2,"cuda:0"],[2934,294,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2937, "rf_id": 1955, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[295,294,1024,1024,2,"cuda:0"],[2936,294,1024,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2939, "rf_id": 1956, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[311,294,2048,3072,2,"cuda:0"],[2938,294,2048,3072,2,"cuda:0"]], "input_shapes": [[3072],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2941, "rf_id": 1957, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[474,294,5120,1024,2,"cuda:0"],[2940,294,5120,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2943, "rf_id": 1958, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[506,294,6144,1024,2,"cuda:0"],[2942,294,6144,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2945, "rf_id": 1959, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[507,294,7168,1024,2,"cuda:0"],[2944,294,7168,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2947, "rf_id": 1960, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[558,294,8192,4096,2,"cuda:0"],[2946,294,8192,4096,2,"cuda:0"]], "input_shapes": [[4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2949, "rf_id": 1961, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[631,294,12288,1024,2,"cuda:0"],[2948,294,12288,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2951, "rf_id": 1962, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[646,294,13312,1024,2,"cuda:0"],[2950,294,13312,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2953, "rf_id": 1963, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[647,294,14336,1024,2,"cuda:0"],[2952,294,14336,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2955, "rf_id": 1964, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[293,294,0,1024,2,"cuda:0"],[2954,294,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2957, "rf_id": 1965, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[295,294,1024,1024,2,"cuda:0"],[2956,294,1024,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2959, "rf_id": 1966, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[311,294,2048,3072,2,"cuda:0"],[2958,294,2048,3072,2,"cuda:0"]], "input_shapes": [[3072],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2961, "rf_id": 1967, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[474,294,5120,1024,2,"cuda:0"],[2960,294,5120,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2963, "rf_id": 1968, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[506,294,6144,1024,2,"cuda:0"],[2962,294,6144,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2965, "rf_id": 1969, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[507,294,7168,1024,2,"cuda:0"],[2964,294,7168,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2967, "rf_id": 1970, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[558,294,8192,4096,2,"cuda:0"],[2966,294,8192,4096,2,"cuda:0"]], "input_shapes": [[4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2969, "rf_id": 1971, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[631,294,12288,1024,2,"cuda:0"],[2968,294,12288,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2971, "rf_id": 1972, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[646,294,13312,1024,2,"cuda:0"],[2970,294,13312,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2973, "rf_id": 1973, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[647,294,14336,1024,2,"cuda:0"],[2972,294,14336,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::add", "id": 2975, "rf_id": 1974, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[841,681,0,1,4,"cuda:0"],[2838,2974,0,1,8,"cpu"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(long int)","Int"],
      "outputs": [[2897,198,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::div", "id": 2977, "rf_id": 1975, "parent": 2, "fw_parent": 0, "seq_id": 230, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2897,198,0,1,4,"cuda:0"],[2903,2976,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(long int)"],
      "outputs": [[2909,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "[pytorch|profiler|execution_trace|process]", "id": 1, "rf_id": 0, "parent": 1, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 0, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    }
  ],
  "finish_ts": 13002946
}