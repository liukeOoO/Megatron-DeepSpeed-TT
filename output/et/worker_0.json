{
  "schema": "1.0.1", "pid": 18801, "time": "2024-02-29 22:27:00", "start_ts": 11018678,
  "nodes": [
    {
      "name": "[pytorch|profiler|execution_trace|thread]", "id": 2, "rf_id": 0, "parent": 1, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3, "rf_id": 1, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],0,"<None>","cuda","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","None","None"],
      "outputs": [[4,5,0,1,1,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(unsigned char)"]
    },
    {
      "name": "aten::empty", "id": 8, "rf_id": 4, "parent": 7, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],0,"<None>","cuda","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","None","None"],
      "outputs": [[9,10,0,1,1,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(unsigned char)"]
    },
    {
      "name": "nccl:all_reduce", "id": 12, "rf_id": 6, "parent": 11, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[9,10,0,1,1,"cuda:0"]], "input_shapes": [[1]], "input_types": ["Tensor(unsigned char)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 11, "rf_id": 5, "parent": 7, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[9,10,0,1,1,"cuda:0"]],40,93827882298608,0,"allreduce",[],[],4], "input_shapes": [[[1]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(unsigned char)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[9,10,0,1,1,"cuda:0"]]], "output_shapes": [[[1]]], "output_types": ["GenericList[Tensor(unsigned char)]"]
    },
    {
      "name": "record_param_comms", "id": 7, "rf_id": 3, "parent": 6, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [40,93827882298608,0,"barrier",[],[],4], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "c10d::barrier", "id": 6, "rf_id": 2, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::barrier(Tensor tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, int[] device_ids, int timeout) -> __torch__.torch.classes.c10d.Work",
      "inputs": [[4,5,0,1,1,"cuda:0"],"<Object>",[],-1], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(unsigned char)","Object","GenericList[]","Int"],
      "outputs": ["<Object>"], "output_shapes": [[]], "output_types": ["Object"]
    },
    {
      "name": "record_param_comms", "id": 13, "rf_id": 7, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [40,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::lift_fresh", "id": 17, "rf_id": 9, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[15,16,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[15,16,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 18, "rf_id": 10, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[15,16,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[15,16,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 21, "rf_id": 11, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[19,20,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[19,20,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 22, "rf_id": 12, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[19,20,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[19,20,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 25, "rf_id": 13, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[23,24,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[23,24,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 26, "rf_id": 14, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[23,24,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[23,24,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 29, "rf_id": 15, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[27,28,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[27,28,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 30, "rf_id": 16, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[27,28,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[27,28,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 33, "rf_id": 17, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[31,32,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[31,32,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 34, "rf_id": 18, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[31,32,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[31,32,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 37, "rf_id": 19, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[35,36,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[35,36,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 38, "rf_id": 20, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[35,36,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[35,36,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 41, "rf_id": 21, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[39,40,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[39,40,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 42, "rf_id": 22, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[39,40,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[39,40,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 45, "rf_id": 23, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[43,44,0,21,8,"cpu"]], "input_shapes": [[21]], "input_types": ["Tensor(long int)"],
      "outputs": [[43,44,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 46, "rf_id": 24, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[43,44,0,21,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[21],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[43,44,0,21,8,"cpu"]], "output_shapes": [[21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::cat", "id": 48, "rf_id": 26, "parent": 47, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[15,16,0,21,8,"cpu"],[19,20,0,21,8,"cpu"],[23,24,0,21,8,"cpu"],[27,28,0,21,8,"cpu"],[31,32,0,21,8,"cpu"],[35,36,0,21,8,"cpu"],[39,40,0,21,8,"cpu"],[43,44,0,21,8,"cpu"]],0], "input_shapes": [[[21],[21],[21],[21],[21],[21],[21],[21]],[]], "input_types": ["GenericList[Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int)]","Int"],
      "outputs": [[49,50,0,168,8,"cpu"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 51, "rf_id": 27, "parent": 47, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[49,50,0,168,8,"cpu"],[8,21]], "input_shapes": [[168],[[],[]]], "input_types": ["Tensor(long int)","GenericList[Int,Int]"],
      "outputs": [[52,50,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::stack", "id": 47, "rf_id": 25, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::stack(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[15,16,0,21,8,"cpu"],[19,20,0,21,8,"cpu"],[23,24,0,21,8,"cpu"],[27,28,0,21,8,"cpu"],[31,32,0,21,8,"cpu"],[35,36,0,21,8,"cpu"],[39,40,0,21,8,"cpu"],[43,44,0,21,8,"cpu"]],0], "input_shapes": [[[21],[21],[21],[21],[21],[21],[21],[21]],[]], "input_types": ["GenericList[Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int),Tensor(long int)]","Int"],
      "outputs": [[52,50,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::is_pinned", "id": 54, "rf_id": 29, "parent": 53, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::is_pinned(Tensor self, Device? device=None) -> bool",
      "inputs": [[52,50,0,168,8,"cpu"],"<None>"], "input_shapes": [[8,21],[]], "input_types": ["Tensor(long int)","None"],
      "outputs": [false], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::set_", "id": 58, "rf_id": 31, "parent": 55, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::set_.source_Storage_storage_offset(Tensor(a!) self, Storage source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -> Tensor(a!)",
      "inputs": [[56,57,0,0,8,"cpu"],"<Storage>",0,[8,21],[21,1]], "input_shapes": [[0],[],[],[[],[]],[[],[]]], "input_types": ["Tensor(long int)","Storage","Int","GenericList[Int,Int]","GenericList[Int,Int]"],
      "outputs": [[56,59,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 60, "rf_id": 32, "parent": 55, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[56,59,0,168,8,"cpu"],[52,50,0,168,8,"cpu"],false], "input_shapes": [[8,21],[8,21],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[56,59,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_pin_memory", "id": 55, "rf_id": 30, "parent": 53, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_pin_memory(Tensor self, Device? device=None) -> Tensor",
      "inputs": [[52,50,0,168,8,"cpu"],"<None>"], "input_shapes": [[8,21],[]], "input_types": ["Tensor(long int)","None"],
      "outputs": [[56,59,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::pin_memory", "id": 53, "rf_id": 28, "parent": 14, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pin_memory(Tensor(a) self, Device? device=None) -> Tensor(a)",
      "inputs": [[52,50,0,168,8,"cpu"],"<None>"], "input_shapes": [[8,21],[]], "input_types": ["Tensor(long int)","None"],
      "outputs": [[56,59,0,168,8,"cpu"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "enumerate(DataLoader)#_SingleProcessDataLoaderIter.__next__", "id": 14, "rf_id": 8, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 61, "rf_id": 33, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[5],4,0,"cpu",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","Bool","None"],
      "outputs": [[62,50,0,5,8,"cpu"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_strided", "id": 65, "rf_id": 36, "parent": 64, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[5],[1],4,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[66,10,0,5,8,"cuda:0"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 67, "rf_id": 37, "parent": 64, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[66,10,0,5,8,"cuda:0"],[62,50,0,5,8,"cpu"],false], "input_shapes": [[5],[5],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[66,10,0,5,8,"cuda:0"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_to_copy", "id": 64, "rf_id": 35, "parent": 63, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[62,50,0,5,8,"cpu"],4,"<None>","cuda:0","<None>",false,"<None>"], "input_shapes": [[5],[],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","None","Device","None","Bool","None"],
      "outputs": [[66,10,0,5,8,"cuda:0"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 63, "rf_id": 34, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[62,50,0,5,8,"cpu"],"cuda",4,false,false,"<None>"], "input_shapes": [[5],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[66,10,0,5,8,"cuda:0"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 68, "rf_id": 38, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[66,10,0,5,8,"cuda:0"]], "input_shapes": [[5]], "input_types": ["Tensor(long int)"],
      "outputs": [[66,10,0,5,8,"cuda:0"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "nccl:broadcast", "id": 71, "rf_id": 41, "parent": 70, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[66,10,0,5,8,"cuda:0"]], "input_shapes": [[5]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 70, "rf_id": 40, "parent": 69, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[66,10,0,5,8,"cuda:0"]],17,93827882282480,0,"broadcast",[],[],1], "input_shapes": [[[5]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(long int)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[66,10,0,5,8,"cuda:0"]]], "output_shapes": [[[5]]], "output_types": ["GenericList[Tensor(long int)]"]
    },
    {
      "name": "c10d::broadcast_", "id": 69, "rf_id": 39, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::broadcast_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, int root_rank, int root_tensor, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[66,10,0,5,8,"cuda:0"]],"<Object>",0,0,-1], "input_shapes": [[[5]],[],[],[],[]], "input_types": ["GenericList[Tensor(long int)]","Object","Int","Int","Int"],
      "outputs": [[[66,10,0,5,8,"cuda:0"]],"<Object>"], "output_shapes": [[[5]],[]], "output_types": ["GenericList[Tensor(long int)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 72, "rf_id": 42, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [17,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 75, "rf_id": 45, "parent": 74, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[5],[1],4,0,"cpu",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[76,77,0,5,8,"cpu"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 78, "rf_id": 46, "parent": 74, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[76,77,0,5,8,"cpu"],[66,10,0,5,8,"cuda:0"],false], "input_shapes": [[5],[5],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[76,77,0,5,8,"cpu"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_to_copy", "id": 74, "rf_id": 44, "parent": 73, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[66,10,0,5,8,"cuda:0"],4,0,"cpu","<None>",false,"<None>"], "input_shapes": [[5],[],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Bool","None"],
      "outputs": [[76,77,0,5,8,"cpu"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 73, "rf_id": 43, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[66,10,0,5,8,"cuda:0"],4,0,"cpu","<None>",false,false,"<None>"], "input_shapes": [[5],[],[],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[76,77,0,5,8,"cpu"]], "output_shapes": [[5]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 80, "rf_id": 48, "parent": 79, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],[],[],0], "input_shapes": [[5],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[81,77,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 79, "rf_id": 47, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],0,0], "input_shapes": [[5],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[81,77,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::gt", "id": 82, "rf_id": 49, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::gt.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[81,77,0,1,8,"cpu"],0], "input_shapes": [[],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[83,84,0,1,1,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 87, "rf_id": 52, "parent": 86, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[83,84,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::item", "id": 86, "rf_id": 51, "parent": 85, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[83,84,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::is_nonzero", "id": 85, "rf_id": 50, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::is_nonzero(Tensor self) -> bool",
      "inputs": [[83,84,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 89, "rf_id": 54, "parent": 88, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],[],[],0], "input_shapes": [[5],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[90,77,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 88, "rf_id": 53, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],0,0], "input_shapes": [[5],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[90,77,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::mul", "id": 93, "rf_id": 55, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[90,77,0,1,8,"cpu"],[91,92,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(long int)","Tensor(long int)"],
      "outputs": [[94,95,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 97, "rf_id": 57, "parent": 96, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],[],[],1], "input_shapes": [[5],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[98,77,1,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 96, "rf_id": 56, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],0,1], "input_shapes": [[5],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[98,77,1,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::gt", "id": 99, "rf_id": 58, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::gt.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[98,77,1,1,8,"cpu"],0], "input_shapes": [[],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[100,101,0,1,1,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 104, "rf_id": 61, "parent": 103, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[100,101,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::item", "id": 103, "rf_id": 60, "parent": 102, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[100,101,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::is_nonzero", "id": 102, "rf_id": 59, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::is_nonzero(Tensor self) -> bool",
      "inputs": [[100,101,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 106, "rf_id": 63, "parent": 105, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],[],[],1], "input_shapes": [[5],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[107,77,1,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 105, "rf_id": 62, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],0,1], "input_shapes": [[5],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[107,77,1,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::mul_", "id": 108, "rf_id": 64, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[94,95,0,1,8,"cpu"],[107,77,1,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(long int)","Tensor(long int)"],
      "outputs": [[94,95,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 110, "rf_id": 66, "parent": 109, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],[],[],2], "input_shapes": [[5],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[111,77,2,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 109, "rf_id": 65, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[76,77,0,5,8,"cpu"],0,2], "input_shapes": [[5],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[111,77,2,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::gt", "id": 112, "rf_id": 67, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::gt.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[111,77,2,1,8,"cpu"],0], "input_shapes": [[],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[113,114,0,1,1,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 117, "rf_id": 70, "parent": 116, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[113,114,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [false], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::item", "id": 116, "rf_id": 69, "parent": 115, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[113,114,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [false], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::is_nonzero", "id": 115, "rf_id": 68, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::is_nonzero(Tensor self) -> bool",
      "inputs": [[113,114,0,1,1,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [false], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::add", "id": 120, "rf_id": 71, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[94,95,0,1,8,"cpu"],[118,119,0,1,8,"cpu"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Int"],
      "outputs": [[121,122,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 123, "rf_id": 72, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[56,59,0,168,8,"cpu"],[-1]], "input_shapes": [[8,21],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[124,59,0,168,8,"cpu"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::cat", "id": 125, "rf_id": 73, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[124,59,0,168,8,"cpu"]],0], "input_shapes": [[[168]],[]], "input_types": ["GenericList[Tensor(long int)]","Int"],
      "outputs": [[126,127,0,168,8,"cpu"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_strided", "id": 130, "rf_id": 76, "parent": 129, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[168],[1],4,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[131,132,0,168,8,"cuda:0"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 133, "rf_id": 77, "parent": 129, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[131,132,0,168,8,"cuda:0"],[126,127,0,168,8,"cpu"],false], "input_shapes": [[168],[168],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[131,132,0,168,8,"cuda:0"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_to_copy", "id": 129, "rf_id": 75, "parent": 128, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[126,127,0,168,8,"cpu"],4,0,"cuda:0","<None>",false,"<None>"], "input_shapes": [[168],[],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Bool","None"],
      "outputs": [[131,132,0,168,8,"cuda:0"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 128, "rf_id": 74, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[126,127,0,168,8,"cpu"],4,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[168],[],[],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[131,132,0,168,8,"cuda:0"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "nccl:broadcast", "id": 136, "rf_id": 80, "parent": 135, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[131,132,0,168,8,"cuda:0"]], "input_shapes": [[168]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 135, "rf_id": 79, "parent": 134, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[131,132,0,168,8,"cuda:0"]],18,93827882282480,0,"broadcast",[],[],1], "input_shapes": [[[168]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(long int)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[131,132,0,168,8,"cuda:0"]]], "output_shapes": [[[168]]], "output_types": ["GenericList[Tensor(long int)]"]
    },
    {
      "name": "c10d::broadcast_", "id": 134, "rf_id": 78, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::broadcast_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, int root_rank, int root_tensor, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[131,132,0,168,8,"cuda:0"]],"<Object>",0,0,-1], "input_shapes": [[[168]],[],[],[],[]], "input_types": ["GenericList[Tensor(long int)]","Object","Int","Int","Int"],
      "outputs": [[[131,132,0,168,8,"cuda:0"]],"<Object>"], "output_shapes": [[[168]],[]], "output_types": ["GenericList[Tensor(long int)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 137, "rf_id": 81, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [18,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_local_scalar_dense", "id": 139, "rf_id": 83, "parent": 138, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 138, "rf_id": 82, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 141, "rf_id": 85, "parent": 140, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 140, "rf_id": 84, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 143, "rf_id": 87, "parent": 142, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 142, "rf_id": 86, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[94,95,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [168], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::as_strided", "id": 146, "rf_id": 90, "parent": 145, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[131,132,0,168,8,"cuda:0"],[168],[1],0], "input_shapes": [[168],[[]],[[]],[]], "input_types": ["Tensor(long int)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[147,132,0,168,8,"cuda:0"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 145, "rf_id": 89, "parent": 144, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[131,132,0,168,8,"cuda:0"],0,0,168,1], "input_shapes": [[168],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[147,132,0,168,8,"cuda:0"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::narrow", "id": 144, "rf_id": 88, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[131,132,0,168,8,"cuda:0"],0,0,168], "input_shapes": [[168],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int"],
      "outputs": [[147,132,0,168,8,"cuda:0"]], "output_shapes": [[168]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 149, "rf_id": 92, "parent": 148, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[90,77,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [8], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 148, "rf_id": 91, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[90,77,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [8], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 151, "rf_id": 94, "parent": 150, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[90,77,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [8], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 150, "rf_id": 93, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[90,77,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [8], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 153, "rf_id": 96, "parent": 152, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[107,77,1,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [21], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 152, "rf_id": 95, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[107,77,1,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [21], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::view", "id": 154, "rf_id": 97, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[147,132,0,168,8,"cuda:0"],[8,21]], "input_shapes": [[168],[[],[]]], "input_types": ["Tensor(long int)","GenericList[Int,Int]"],
      "outputs": [[155,132,0,168,8,"cuda:0"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::add", "id": 158, "rf_id": 98, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[94,95,0,1,8,"cpu"],[156,157,0,1,8,"cpu"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Int"],
      "outputs": [[159,160,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 161, "rf_id": 99, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[155,132,0,168,8,"cuda:0"],4,false,false,"<None>"], "input_shapes": [[8,21],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Bool","Bool","None"],
      "outputs": [[155,132,0,168,8,"cuda:0"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 163, "rf_id": 101, "parent": 162, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[155,132,0,168,8,"cuda:0"],[8,21],[21,1],0], "input_shapes": [[8,21],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[159,132,0,168,8,"cuda:0"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 162, "rf_id": 100, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[155,132,0,168,8,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[8,21],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[159,132,0,168,8,"cuda:0"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 165, "rf_id": 103, "parent": 164, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[159,132,0,168,8,"cuda:0"],[8,20],[21,1],1], "input_shapes": [[8,21],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[121,132,1,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 164, "rf_id": 102, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[159,132,0,168,8,"cuda:0"],1,1,9223372036854775807,1], "input_shapes": [[8,21],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[121,132,1,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 169, "rf_id": 107, "parent": 168, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],4,0,"cuda:0","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[170,171,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_like", "id": 168, "rf_id": 106, "parent": 167, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[121,132,1,160,8,"cuda:0"],4,0,"cuda:0","<None>",0], "input_shapes": [[8,20],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Int"],
      "outputs": [[170,171,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 172, "rf_id": 108, "parent": 167, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[170,171,0,160,8,"cuda:0"],[121,132,1,160,8,"cuda:0"],false], "input_shapes": [[8,20],[8,20],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[170,171,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 167, "rf_id": 105, "parent": 166, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[121,132,1,160,8,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[170,171,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::contiguous", "id": 166, "rf_id": 104, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[121,132,1,160,8,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[170,171,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 174, "rf_id": 110, "parent": 173, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[155,132,0,168,8,"cuda:0"],[8,21],[21,1],0], "input_shapes": [[8,21],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[175,132,0,168,8,"cuda:0"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 173, "rf_id": 109, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[155,132,0,168,8,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[8,21],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[175,132,0,168,8,"cuda:0"]], "output_shapes": [[8,21]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 177, "rf_id": 112, "parent": 176, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[175,132,0,168,8,"cuda:0"],[8,20],[21,1],0], "input_shapes": [[8,21],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[178,132,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 176, "rf_id": 111, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[175,132,0,168,8,"cuda:0"],1,0,-1,1], "input_shapes": [[8,21],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[178,132,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 182, "rf_id": 116, "parent": 181, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],4,0,"cuda:0","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[183,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_like", "id": 181, "rf_id": 115, "parent": 180, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[178,132,0,160,8,"cuda:0"],4,0,"cuda:0","<None>",0], "input_shapes": [[8,20],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Int"],
      "outputs": [[183,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 185, "rf_id": 117, "parent": 180, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[183,184,0,160,8,"cuda:0"],[178,132,0,160,8,"cuda:0"],false], "input_shapes": [[8,20],[8,20],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[183,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 180, "rf_id": 114, "parent": 179, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[178,132,0,160,8,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[183,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::contiguous", "id": 179, "rf_id": 113, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[178,132,0,160,8,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[183,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 187, "rf_id": 119, "parent": 186, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1,20,20],6,"<None>","cpu",false,"<None>"], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","None","Device","Bool","None"],
      "outputs": [[188,189,0,400,4,"cpu"]], "output_shapes": [[1,20,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::fill_", "id": 190, "rf_id": 120, "parent": 186, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[188,189,0,400,4,"cpu"],1.000000], "input_shapes": [[1,20,20],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [[188,189,0,400,4,"cpu"]], "output_shapes": [[1,20,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::ones", "id": 186, "rf_id": 118, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ones(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1,20,20],"<None>","<None>","cpu",false], "input_shapes": [[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","None","None","Device","Bool"],
      "outputs": [[188,189,0,400,4,"cpu"]], "output_shapes": [[1,20,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::tril", "id": 191, "rf_id": 121, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::tril(Tensor self, int diagonal=0) -> Tensor",
      "inputs": [[188,189,0,400,4,"cpu"],0], "input_shapes": [[1,20,20],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[192,193,0,400,4,"cpu"]], "output_shapes": [[1,20,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 194, "rf_id": 122, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[192,193,0,400,4,"cpu"],[1,1,20,20]], "input_shapes": [[1,20,20],[[],[],[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[189,193,0,400,4,"cpu"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 196, "rf_id": 124, "parent": 195, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],6,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","None","Device","Bool","None"],
      "outputs": [[197,198,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::fill_", "id": 199, "rf_id": 125, "parent": 195, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[197,198,0,160,4,"cuda:0"],1.000000], "input_shapes": [[8,20],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [[197,198,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::ones", "id": 195, "rf_id": 123, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ones(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[8,20],6,"<None>","cuda:0",false], "input_shapes": [[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","None","Device","Bool"],
      "outputs": [[197,198,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 201, "rf_id": 127, "parent": 200, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],4,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[202,57,0,0,8,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::resize_", "id": 204, "rf_id": 129, "parent": 203, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[202,57,0,0,8,"cuda:0"],[20],"<None>"], "input_shapes": [[0],[[]],[]], "input_types": ["Tensor(long int)","GenericList[Int]","None"],
      "outputs": [[202,10,0,20,8,"cuda:0"]], "output_shapes": [[20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 203, "rf_id": 128, "parent": 200, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::arange.start_out(Scalar start, Scalar end, Scalar step=1, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [0,20,1,[202,57,0,0,8,"cuda:0"]], "input_shapes": [[],[],[],[0]], "input_types": ["Int","Int","Int","Tensor(long int)"],
      "outputs": [[202,10,0,20,8,"cuda:0"]], "output_shapes": [[20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 200, "rf_id": 126, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::arange(Scalar end, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [20,4,"<None>","cuda:0",false], "input_shapes": [[],[],[],[],[]], "input_types": ["Int","Int","None","Device","Bool"],
      "outputs": [[202,10,0,20,8,"cuda:0"]], "output_shapes": [[20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 206, "rf_id": 131, "parent": 205, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[202,10,0,20,8,"cuda:0"],[1,20],[20,1],"<None>"], "input_shapes": [[20],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[207,10,0,20,8,"cuda:0"]], "output_shapes": [[1,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::unsqueeze", "id": 205, "rf_id": 130, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[202,10,0,20,8,"cuda:0"],0], "input_shapes": [[20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[207,10,0,20,8,"cuda:0"]], "output_shapes": [[1,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 210, "rf_id": 134, "parent": 209, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[207,10,0,20,8,"cuda:0"],[8,20],[0,1],"<None>"], "input_shapes": [[1,20],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[211,10,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::expand", "id": 209, "rf_id": 133, "parent": 208, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)",
      "inputs": [[207,10,0,20,8,"cuda:0"],[8,20],false], "input_shapes": [[1,20],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","Bool"],
      "outputs": [[211,10,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::expand_as", "id": 208, "rf_id": 132, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[207,10,0,20,8,"cuda:0"],[183,184,0,160,8,"cuda:0"]], "input_shapes": [[1,20],[8,20]], "input_types": ["Tensor(long int)","Tensor(long int)"],
      "outputs": [[211,10,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_strided", "id": 217, "rf_id": 138, "parent": 216, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],6,0,"cpu",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[218,219,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 220, "rf_id": 139, "parent": 216, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[218,219,0,1,4,"cpu"],[213,214,0,1,8,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(double)","Bool"],
      "outputs": [[218,219,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 216, "rf_id": 137, "parent": 215, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[213,214,0,1,8,"cpu"],6,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","None","None","Bool","None"],
      "outputs": [[218,219,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 215, "rf_id": 136, "parent": 212, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[213,214,0,1,8,"cpu"],6,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[218,219,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::lt", "id": 212, "rf_id": 135, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[189,193,0,400,4,"cpu"],0.500000], "input_shapes": [[1,1,20,20],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [[221,222,0,400,1,"cpu"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 225, "rf_id": 142, "parent": 224, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1,1,20,20],[400,400,20,1],11,0,"cuda:0",false], "input_shapes": [[[],[],[],[]],[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int","Int","Device","Bool"],
      "outputs": [[226,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::copy_", "id": 228, "rf_id": 143, "parent": 224, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[226,227,0,400,1,"cuda:0"],[221,222,0,400,1,"cpu"],false], "input_shapes": [[1,1,20,20],[1,1,20,20],[]], "input_types": ["Tensor(bool)","Tensor(bool)","Bool"],
      "outputs": [[226,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::_to_copy", "id": 224, "rf_id": 141, "parent": 223, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[221,222,0,400,1,"cpu"],11,0,"cuda:0","<None>",false,"<None>"], "input_shapes": [[1,1,20,20],[],[],[],[],[],[]], "input_types": ["Tensor(bool)","Int","Int","Device","None","Bool","None"],
      "outputs": [[226,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::to", "id": 223, "rf_id": 140, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[221,222,0,400,1,"cpu"],11,0,"cuda:0","<None>",false,false,"<None>"], "input_shapes": [[1,1,20,20],[],[],[],[],[],[],[]], "input_types": ["Tensor(bool)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[226,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::as_strided", "id": 230, "rf_id": 145, "parent": 229, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[183,184,0,160,8,"cuda:0"],[8,20],[20,1],0], "input_shapes": [[8,20],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[231,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 229, "rf_id": 144, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[183,184,0,160,8,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[8,20],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[231,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 233, "rf_id": 147, "parent": 232, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[211,10,0,160,8,"cuda:0"],[8,20],[0,1],0], "input_shapes": [[8,20],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","Int"],
      "outputs": [[234,10,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::slice", "id": 232, "rf_id": 146, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[211,10,0,160,8,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[8,20],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Int","Int"],
      "outputs": [[234,10,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 235, "rf_id": 148, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[51511296],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[236,237,0,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 240, "rf_id": 149, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[238,239,0,12877824,2,"cuda:0"],15,0,"cuda:0","<None>",false,false,"<None>"], "input_shapes": [[12877824],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[238,239,0,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 243, "rf_id": 152, "parent": 242, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[238,239,0,12877824,2,"cuda:0"]], "input_shapes": [[12877824]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 242, "rf_id": 151, "parent": 241, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[238,239,0,12877824,2,"cuda:0"],125,93827882276192,0,"_allgather_base",[],[],4], "input_shapes": [[12877824],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[236,237,0,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 241, "rf_id": 150, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[236,237,0,51511296,2,"cuda:0"],[238,239,0,12877824,2,"cuda:0"],"<Object>",true,-1], "input_shapes": [[51511296],[12877824],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[236,237,0,51511296,2,"cuda:0"],"<Object>"], "output_shapes": [[51511296],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::as_strided", "id": 246, "rf_id": 155, "parent": 245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[236,237,0,51511296,2,"cuda:0"],[51511296],[1],0], "input_shapes": [[51511296],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[247,237,0,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 245, "rf_id": 154, "parent": 244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[236,237,0,51511296,2,"cuda:0"],0,0,51511296,1], "input_shapes": [[51511296],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[247,237,0,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 244, "rf_id": 153, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[236,237,0,51511296,2,"cuda:0"],0,0,51511296], "input_shapes": [[51511296],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[247,237,0,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 248, "rf_id": 156, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[247,237,0,51511296,2,"cuda:0"],[50304,1024]], "input_shapes": [[51511296],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[249,237,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 250, "rf_id": 157, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[249,237,0,51511296,2,"cuda:0"],15,0,"cuda:0","<None>",false,false,"<None>"], "input_shapes": [[50304,1024],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[249,237,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 252, "rf_id": 158, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[251,57,0,0,2,"cuda:0"],[249,237,0,51511296,2,"cuda:0"]], "input_shapes": [[0],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "record_param_comms", "id": 253, "rf_id": 159, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [125,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 254, "rf_id": 160, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[12582912],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[255,256,0,12582912,2,"cuda:0"]], "output_shapes": [[12582912]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 259, "rf_id": 163, "parent": 258, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:0"],[3145728],[1],0], "input_shapes": [[12582912],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[260,256,0,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 258, "rf_id": 162, "parent": 257, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:0"],0,0,3145728,1], "input_shapes": [[12582912],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[260,256,0,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 257, "rf_id": 161, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:0"],0,0,3145728], "input_shapes": [[12582912],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[260,256,0,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 263, "rf_id": 166, "parent": 262, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:0"],[3145728],[1],3145728], "input_shapes": [[12582912],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[264,256,3145728,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 262, "rf_id": 165, "parent": 261, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:0"],0,3145728,6291456,1], "input_shapes": [[12582912],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[264,256,3145728,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 261, "rf_id": 164, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:0"],0,3145728,3145728], "input_shapes": [[12582912],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[264,256,3145728,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 267, "rf_id": 169, "parent": 266, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:0"],[3145728],[1],6291456], "input_shapes": [[12582912],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[268,256,6291456,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 266, "rf_id": 168, "parent": 265, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:0"],0,6291456,9437184,1], "input_shapes": [[12582912],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[268,256,6291456,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 265, "rf_id": 167, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:0"],0,6291456,3145728], "input_shapes": [[12582912],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[268,256,6291456,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 271, "rf_id": 172, "parent": 270, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:0"],[3145728],[1],9437184], "input_shapes": [[12582912],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[272,256,9437184,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 270, "rf_id": 171, "parent": 269, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:0"],0,9437184,12582912,1], "input_shapes": [[12582912],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[272,256,9437184,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 269, "rf_id": 170, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[255,256,0,12582912,2,"cuda:0"],0,9437184,3145728], "input_shapes": [[12582912],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[272,256,9437184,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 274, "rf_id": 173, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[273,239,12882944,786432,2,"cuda:0"],15,0,"cuda:0","<None>",false,false,"<None>"], "input_shapes": [[786432],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[273,239,12882944,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 276, "rf_id": 174, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[275,239,13669376,262144,2,"cuda:0"],15,0,"cuda:0","<None>",false,false,"<None>"], "input_shapes": [[262144],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[275,239,13669376,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 278, "rf_id": 175, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[277,239,13931520,1048576,2,"cuda:0"],15,0,"cuda:0","<None>",false,false,"<None>"], "input_shapes": [[1048576],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[277,239,13931520,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 280, "rf_id": 176, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[279,239,14980096,1048576,2,"cuda:0"],15,0,"cuda:0","<None>",false,false,"<None>"], "input_shapes": [[1048576],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[279,239,14980096,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 281, "rf_id": 177, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat.out(Tensor[] tensors, int dim=0, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[[273,239,12882944,786432,2,"cuda:0"],[275,239,13669376,262144,2,"cuda:0"],[277,239,13931520,1048576,2,"cuda:0"],[279,239,14980096,1048576,2,"cuda:0"]],0,[260,256,0,3145728,2,"cuda:0"]], "input_shapes": [[[786432],[262144],[1048576],[1048576]],[],[3145728]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int","Tensor(c10::BFloat16)"],
      "outputs": [[260,256,0,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 284, "rf_id": 180, "parent": 283, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[260,256,0,3145728,2,"cuda:0"]], "input_shapes": [[3145728]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 283, "rf_id": 179, "parent": 282, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[260,256,0,3145728,2,"cuda:0"],126,93827882276192,0,"_allgather_base",[],[],4], "input_shapes": [[3145728],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[255,256,0,12582912,2,"cuda:0"]], "output_shapes": [[12582912]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 282, "rf_id": 178, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[255,256,0,12582912,2,"cuda:0"],[260,256,0,3145728,2,"cuda:0"],"<Object>",true,-1], "input_shapes": [[12582912],[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[255,256,0,12582912,2,"cuda:0"],"<Object>"], "output_shapes": [[12582912],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "detach", "id": 287, "rf_id": 183, "parent": 286, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[231,184,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 286, "rf_id": 182, "parent": 285, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[231,184,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [[288,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 285, "rf_id": 181, "parent": 2, "fw_parent": 0, "seq_id": 382, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[231,184,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 291, "rf_id": 186, "parent": 290, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[234,10,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 290, "rf_id": 185, "parent": 289, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[234,10,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [[292,10,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 289, "rf_id": 184, "parent": 2, "fw_parent": 0, "seq_id": 383, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[234,10,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 295, "rf_id": 189, "parent": 294, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[226,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 294, "rf_id": 188, "parent": 293, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[226,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[296,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 293, "rf_id": 187, "parent": 2, "fw_parent": 0, "seq_id": 384, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[226,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 299, "rf_id": 192, "parent": 298, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[288,184,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 298, "rf_id": 191, "parent": 297, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[288,184,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [[300,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 297, "rf_id": 190, "parent": 2, "fw_parent": 0, "seq_id": 385, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[288,184,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 303, "rf_id": 195, "parent": 302, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[292,10,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 302, "rf_id": 194, "parent": 301, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[292,10,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [[304,10,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 301, "rf_id": 193, "parent": 2, "fw_parent": 0, "seq_id": 386, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[292,10,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 307, "rf_id": 198, "parent": 306, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[296,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 306, "rf_id": 197, "parent": 305, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[296,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[308,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 305, "rf_id": 196, "parent": 2, "fw_parent": 0, "seq_id": 387, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[296,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 311, "rf_id": 201, "parent": 310, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[300,184,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 310, "rf_id": 200, "parent": 309, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[300,184,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [[312,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 309, "rf_id": 199, "parent": 2, "fw_parent": 0, "seq_id": 388, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[300,184,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 315, "rf_id": 204, "parent": 314, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[304,10,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 314, "rf_id": 203, "parent": 313, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[304,10,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [[316,10,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 313, "rf_id": 202, "parent": 2, "fw_parent": 0, "seq_id": 389, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[304,10,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 319, "rf_id": 207, "parent": 318, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[312,184,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 318, "rf_id": 206, "parent": 317, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[312,184,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [[320,184,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 317, "rf_id": 205, "parent": 2, "fw_parent": 0, "seq_id": 390, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[312,184,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 323, "rf_id": 210, "parent": 322, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[320,184,0,160,8,"cuda:0"],[-1]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[324,184,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 322, "rf_id": 209, "parent": 321, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[320,184,0,160,8,"cuda:0"],[-1]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[324,184,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 326, "rf_id": 212, "parent": 325, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[327,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::resize_", "id": 328, "rf_id": 213, "parent": 325, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[327,57,0,0,2,"cuda:0"],[160,1024],"<None>"], "input_shapes": [[0],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","None"],
      "outputs": [[327,329,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::index_select", "id": 325, "rf_id": 211, "parent": 321, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::index_select(Tensor self, int dim, Tensor index) -> Tensor",
      "inputs": [[251,237,0,51511296,2,"cuda:0"],0,[324,184,0,160,8,"cuda:0"]], "input_shapes": [[50304,1024],[],[160]], "input_types": ["Tensor(c10::BFloat16)","Int","Tensor(long int)"],
      "outputs": [[327,329,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 330, "rf_id": 214, "parent": 321, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[327,329,0,163840,2,"cuda:0"],[8,20,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[331,329,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding", "id": 321, "rf_id": 208, "parent": 2, "fw_parent": 0, "seq_id": 391, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::embedding(Tensor weight, Tensor indices, SymInt padding_idx=-1, bool scale_grad_by_freq=False, bool sparse=False) -> Tensor",
      "inputs": [[251,237,0,51511296,2,"cuda:0"],[320,184,0,160,8,"cuda:0"],-1,false,false], "input_shapes": [[50304,1024],[8,20],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Bool","Bool"],
      "outputs": [[331,329,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 334, "rf_id": 217, "parent": 333, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[331,329,0,163840,2,"cuda:0"],[8,20,1024]], "input_shapes": [[8,20,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[335,329,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 333, "rf_id": 216, "parent": 332, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[331,329,0,163840,2,"cuda:0"],[331,329,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024],[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[335,329,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_ReduceFromModelParallelRegion", "id": 332, "rf_id": 215, "parent": 2, "fw_parent": 0, "seq_id": 392, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[331,329,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 338, "rf_id": 220, "parent": 337, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[335,329,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 337, "rf_id": 219, "parent": 336, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[335,329,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[339,329,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 336, "rf_id": 218, "parent": 2, "fw_parent": 0, "seq_id": 393, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[335,329,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 342, "rf_id": 223, "parent": 341, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[316,10,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 341, "rf_id": 222, "parent": 340, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[316,10,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [[343,10,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 340, "rf_id": 221, "parent": 2, "fw_parent": 0, "seq_id": 394, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[316,10,0,160,8,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 350, "rf_id": 228, "parent": 349, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],4,0,"cuda:0","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[351,132,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_like", "id": 349, "rf_id": 227, "parent": 348, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[343,10,0,160,8,"cuda:0"],4,0,"cuda:0","<None>",0], "input_shapes": [[8,20],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Int"],
      "outputs": [[351,132,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 352, "rf_id": 229, "parent": 348, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[351,132,0,160,8,"cuda:0"],[343,10,0,160,8,"cuda:0"],false], "input_shapes": [[8,20],[8,20],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[351,132,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 348, "rf_id": 226, "parent": 347, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[343,10,0,160,8,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[351,132,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 353, "rf_id": 230, "parent": 347, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[351,132,0,160,8,"cuda:0"],[160]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[354,132,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 347, "rf_id": 225, "parent": 346, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[343,10,0,160,8,"cuda:0"],[-1]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[354,132,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 356, "rf_id": 232, "parent": 355, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[357,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::resize_", "id": 358, "rf_id": 233, "parent": 355, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[357,57,0,0,2,"cuda:0"],[160,1024],"<None>"], "input_shapes": [[0],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","None"],
      "outputs": [[357,359,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::index_select", "id": 355, "rf_id": 231, "parent": 346, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::index_select(Tensor self, int dim, Tensor index) -> Tensor",
      "inputs": [[344,345,0,20480,2,"cuda:0"],0,[354,132,0,160,8,"cuda:0"]], "input_shapes": [[20,1024],[],[160]], "input_types": ["Tensor(c10::BFloat16)","Int","Tensor(long int)"],
      "outputs": [[357,359,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 360, "rf_id": 234, "parent": 346, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[357,359,0,163840,2,"cuda:0"],[8,20,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[361,359,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding", "id": 346, "rf_id": 224, "parent": 2, "fw_parent": 0, "seq_id": 395, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::embedding(Tensor weight, Tensor indices, SymInt padding_idx=-1, bool scale_grad_by_freq=False, bool sparse=False) -> Tensor",
      "inputs": [[344,345,0,20480,2,"cuda:0"],[343,10,0,160,8,"cuda:0"],-1,false,false], "input_shapes": [[20,1024],[8,20],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Bool","Bool"],
      "outputs": [[361,359,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 364, "rf_id": 237, "parent": 363, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[361,359,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 363, "rf_id": 236, "parent": 362, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[361,359,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[365,359,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 362, "rf_id": 235, "parent": 2, "fw_parent": 0, "seq_id": 396, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[361,359,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 366, "rf_id": 238, "parent": 2, "fw_parent": 0, "seq_id": 397, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[339,329,0,163840,2,"cuda:0"],[365,359,0,163840,2,"cuda:0"],1], "input_shapes": [[8,20,1024],[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[367,368,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 370, "rf_id": 240, "parent": 369, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[367,368,0,163840,2,"cuda:0"],[20,8,1024],[1024,20480,1],"<None>"], "input_shapes": [[8,20,1024],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[371,368,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 369, "rf_id": 239, "parent": 2, "fw_parent": 0, "seq_id": 398, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[367,368,0,163840,2,"cuda:0"],0,1], "input_shapes": [[8,20,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[371,368,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 375, "rf_id": 244, "parent": 374, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,1024],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[376,377,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 374, "rf_id": 243, "parent": 373, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[371,368,0,163840,2,"cuda:0"],15,0,"cuda:0","<None>",0], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Int"],
      "outputs": [[376,377,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 378, "rf_id": 245, "parent": 373, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[376,377,0,163840,2,"cuda:0"],[371,368,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[376,377,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::clone", "id": 373, "rf_id": 242, "parent": 372, "fw_parent": 0, "seq_id": 399, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[371,368,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[376,377,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::contiguous", "id": 372, "rf_id": 241, "parent": 2, "fw_parent": 0, "seq_id": 399, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[371,368,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[376,377,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 381, "rf_id": 248, "parent": 380, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[376,377,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 380, "rf_id": 247, "parent": 379, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[376,377,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[382,377,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 379, "rf_id": 246, "parent": 2, "fw_parent": 0, "seq_id": 400, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[376,377,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 386, "rf_id": 252, "parent": 385, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],11,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[387,368,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 385, "rf_id": 251, "parent": 384, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[382,377,0,163840,2,"cuda:0"],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[387,368,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 389, "rf_id": 254, "parent": 388, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[390,391,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 388, "rf_id": 253, "parent": 384, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[382,377,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[390,391,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 384, "rf_id": 250, "parent": 383, "fw_parent": 0, "seq_id": 401, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[382,377,0,163840,2,"cuda:0"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[390,391,0,163840,2,"cuda:0"],[387,368,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024],[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::dropout", "id": 383, "rf_id": 249, "parent": 2, "fw_parent": 0, "seq_id": 401, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::dropout(Tensor input, float p, bool train) -> Tensor",
      "inputs": [[382,377,0,163840,2,"cuda:0"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[390,391,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 394, "rf_id": 257, "parent": 393, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[390,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 393, "rf_id": 256, "parent": 392, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[390,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[395,391,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 392, "rf_id": 255, "parent": 2, "fw_parent": 0, "seq_id": 402, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[390,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 398, "rf_id": 260, "parent": 397, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[395,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 397, "rf_id": 259, "parent": 396, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[395,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[399,391,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 396, "rf_id": 258, "parent": 2, "fw_parent": 0, "seq_id": 403, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[395,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 402, "rf_id": 263, "parent": 401, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[399,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 401, "rf_id": 262, "parent": 400, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[399,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[403,391,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 400, "rf_id": 261, "parent": 2, "fw_parent": 0, "seq_id": 404, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[399,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 406, "rf_id": 266, "parent": 405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[308,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 405, "rf_id": 265, "parent": 404, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[308,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[407,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 404, "rf_id": 264, "parent": 2, "fw_parent": 0, "seq_id": 405, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[308,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::to", "id": 409, "rf_id": 268, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[403,391,0,163840,2,"cuda:0"],15,0,"cuda:0","<None>",false,false,"<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[403,391,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 412, "rf_id": 271, "parent": 411, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[403,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 411, "rf_id": 270, "parent": 410, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[403,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[413,391,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 410, "rf_id": 269, "parent": 408, "fw_parent": 0, "seq_id": 407, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[403,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 416, "rf_id": 274, "parent": 415, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[407,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 415, "rf_id": 273, "parent": 414, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[407,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[417,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 414, "rf_id": 272, "parent": 408, "fw_parent": 0, "seq_id": 408, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[407,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 420, "rf_id": 277, "parent": 419, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[413,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 419, "rf_id": 276, "parent": 418, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[413,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[421,391,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 418, "rf_id": 275, "parent": 408, "fw_parent": 0, "seq_id": 409, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[413,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 428, "rf_id": 280, "parent": 427, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[429,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 427, "rf_id": 279, "parent": 426, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[421,391,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[429,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 431, "rf_id": 281, "parent": 426, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[160],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[432,132,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 434, "rf_id": 283, "parent": 433, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[435,436,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 433, "rf_id": 282, "parent": 426, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[432,132,0,160,4,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[160],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[435,436,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunction", "id": 426, "rf_id": 278, "parent": 408, "fw_parent": 0, "seq_id": 410, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[421,391,0,163840,2,"cuda:0"],[422,423,0,1024,2,"cuda:0"],[424,425,0,1024,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 439, "rf_id": 286, "parent": 438, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[429,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 438, "rf_id": 285, "parent": 437, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[429,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[440,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 437, "rf_id": 284, "parent": 408, "fw_parent": 0, "seq_id": 411, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[429,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 443, "rf_id": 289, "parent": 442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[440,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 442, "rf_id": 288, "parent": 441, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[440,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[444,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 441, "rf_id": 287, "parent": 408, "fw_parent": 0, "seq_id": 412, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[440,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 447, "rf_id": 292, "parent": 446, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[417,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 446, "rf_id": 291, "parent": 445, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[417,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[448,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 445, "rf_id": 290, "parent": 408, "fw_parent": 0, "seq_id": 413, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[417,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 449, "rf_id": 293, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [126,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 452, "rf_id": 296, "parent": 451, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:0"],[786432],[1],0], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[453,256,0,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 451, "rf_id": 295, "parent": 450, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:0"],0,0,786432,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[453,256,0,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 450, "rf_id": 294, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:0"],0,0,786432], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[453,256,0,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 456, "rf_id": 299, "parent": 455, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:0"],[786432],[1],3145728], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[435,256,3145728,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 455, "rf_id": 298, "parent": 454, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:0"],0,0,786432,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[435,256,3145728,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 454, "rf_id": 297, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:0"],0,0,786432], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[435,256,3145728,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 459, "rf_id": 302, "parent": 458, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:0"],[786432],[1],6291456], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[460,256,6291456,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 458, "rf_id": 301, "parent": 457, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:0"],0,0,786432,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[460,256,6291456,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 457, "rf_id": 300, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:0"],0,0,786432], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[460,256,6291456,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 463, "rf_id": 305, "parent": 462, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:0"],[786432],[1],9437184], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[464,256,9437184,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 462, "rf_id": 304, "parent": 461, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:0"],0,0,786432,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[464,256,9437184,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 461, "rf_id": 303, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:0"],0,0,786432], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[464,256,9437184,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 465, "rf_id": 306, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[453,256,0,786432,2,"cuda:0"],[435,256,3145728,786432,2,"cuda:0"],[460,256,6291456,786432,2,"cuda:0"],[464,256,9437184,786432,2,"cuda:0"]],0], "input_shapes": [[[786432],[786432],[786432],[786432]],[]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int"],
      "outputs": [[466,467,0,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 468, "rf_id": 307, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[466,467,0,3145728,2,"cuda:0"],[3072,1024]], "input_shapes": [[3145728],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[469,467,0,3145728,2,"cuda:0"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 471, "rf_id": 308, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[470,57,0,0,2,"cuda:0"],[469,467,0,3145728,2,"cuda:0"]], "input_shapes": [[0],[3072,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 472, "rf_id": 309, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[453,256,0,786432,2,"cuda:0"],"<Stream>"], "input_shapes": [[786432],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 473, "rf_id": 310, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[435,256,3145728,786432,2,"cuda:0"],"<Stream>"], "input_shapes": [[786432],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 474, "rf_id": 311, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[460,256,6291456,786432,2,"cuda:0"],"<Stream>"], "input_shapes": [[786432],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 475, "rf_id": 312, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[464,256,9437184,786432,2,"cuda:0"],"<Stream>"], "input_shapes": [[786432],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 478, "rf_id": 315, "parent": 477, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:0"],[262144],[1],786432], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[479,256,786432,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 477, "rf_id": 314, "parent": 476, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:0"],0,786432,1048576,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[479,256,786432,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 476, "rf_id": 313, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:0"],0,786432,262144], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[479,256,786432,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 482, "rf_id": 318, "parent": 481, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:0"],[262144],[1],3932160], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[483,256,3932160,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 481, "rf_id": 317, "parent": 480, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:0"],0,786432,1048576,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[483,256,3932160,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 480, "rf_id": 316, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:0"],0,786432,262144], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[483,256,3932160,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 486, "rf_id": 321, "parent": 485, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:0"],[262144],[1],7077888], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[487,256,7077888,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 485, "rf_id": 320, "parent": 484, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:0"],0,786432,1048576,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[487,256,7077888,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 484, "rf_id": 319, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:0"],0,786432,262144], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[487,256,7077888,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 490, "rf_id": 324, "parent": 489, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:0"],[262144],[1],10223616], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[491,256,10223616,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 489, "rf_id": 323, "parent": 488, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:0"],0,786432,1048576,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[491,256,10223616,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 488, "rf_id": 322, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:0"],0,786432,262144], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[491,256,10223616,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 492, "rf_id": 325, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[479,256,786432,262144,2,"cuda:0"],[483,256,3932160,262144,2,"cuda:0"],[487,256,7077888,262144,2,"cuda:0"],[491,256,10223616,262144,2,"cuda:0"]],0], "input_shapes": [[[262144],[262144],[262144],[262144]],[]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int"],
      "outputs": [[493,494,0,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 495, "rf_id": 326, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[493,494,0,1048576,2,"cuda:0"],[1024,1024]], "input_shapes": [[1048576],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[496,494,0,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 498, "rf_id": 327, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[497,57,0,0,2,"cuda:0"],[496,494,0,1048576,2,"cuda:0"]], "input_shapes": [[0],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 499, "rf_id": 328, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[479,256,786432,262144,2,"cuda:0"],"<Stream>"], "input_shapes": [[262144],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 500, "rf_id": 329, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[483,256,3932160,262144,2,"cuda:0"],"<Stream>"], "input_shapes": [[262144],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 501, "rf_id": 330, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[487,256,7077888,262144,2,"cuda:0"],"<Stream>"], "input_shapes": [[262144],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 502, "rf_id": 331, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[491,256,10223616,262144,2,"cuda:0"],"<Stream>"], "input_shapes": [[262144],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 505, "rf_id": 334, "parent": 504, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:0"],[1048576],[1],1048576], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[506,256,1048576,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 504, "rf_id": 333, "parent": 503, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:0"],0,1048576,2097152,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[506,256,1048576,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 503, "rf_id": 332, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:0"],0,1048576,1048576], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[506,256,1048576,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 509, "rf_id": 337, "parent": 508, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:0"],[1048576],[1],4194304], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[510,256,4194304,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 508, "rf_id": 336, "parent": 507, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:0"],0,1048576,2097152,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[510,256,4194304,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 507, "rf_id": 335, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:0"],0,1048576,1048576], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[510,256,4194304,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 513, "rf_id": 340, "parent": 512, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:0"],[1048576],[1],7340032], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[514,256,7340032,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 512, "rf_id": 339, "parent": 511, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:0"],0,1048576,2097152,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[514,256,7340032,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 511, "rf_id": 338, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:0"],0,1048576,1048576], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[514,256,7340032,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 517, "rf_id": 343, "parent": 516, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:0"],[1048576],[1],10485760], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[518,256,10485760,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 516, "rf_id": 342, "parent": 515, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:0"],0,1048576,2097152,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[518,256,10485760,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 515, "rf_id": 341, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:0"],0,1048576,1048576], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[518,256,10485760,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 519, "rf_id": 344, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[506,256,1048576,1048576,2,"cuda:0"],[510,256,4194304,1048576,2,"cuda:0"],[514,256,7340032,1048576,2,"cuda:0"],[518,256,10485760,1048576,2,"cuda:0"]],0], "input_shapes": [[[1048576],[1048576],[1048576],[1048576]],[]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int"],
      "outputs": [[520,521,0,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 522, "rf_id": 345, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[520,521,0,4194304,2,"cuda:0"],[4096,1024]], "input_shapes": [[4194304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[523,521,0,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 525, "rf_id": 346, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[524,57,0,0,2,"cuda:0"],[523,521,0,4194304,2,"cuda:0"]], "input_shapes": [[0],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 526, "rf_id": 347, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[506,256,1048576,1048576,2,"cuda:0"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 527, "rf_id": 348, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[510,256,4194304,1048576,2,"cuda:0"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 528, "rf_id": 349, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[514,256,7340032,1048576,2,"cuda:0"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 529, "rf_id": 350, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[518,256,10485760,1048576,2,"cuda:0"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 532, "rf_id": 353, "parent": 531, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:0"],[1048576],[1],2097152], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[533,256,2097152,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 531, "rf_id": 352, "parent": 530, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:0"],0,2097152,3145728,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[533,256,2097152,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 530, "rf_id": 351, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[260,256,0,3145728,2,"cuda:0"],0,2097152,1048576], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[533,256,2097152,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 536, "rf_id": 356, "parent": 535, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:0"],[1048576],[1],5242880], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[537,256,5242880,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 535, "rf_id": 355, "parent": 534, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:0"],0,2097152,3145728,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[537,256,5242880,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 534, "rf_id": 354, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[264,256,3145728,3145728,2,"cuda:0"],0,2097152,1048576], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[537,256,5242880,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 540, "rf_id": 359, "parent": 539, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:0"],[1048576],[1],8388608], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[541,256,8388608,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 539, "rf_id": 358, "parent": 538, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:0"],0,2097152,3145728,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[541,256,8388608,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 538, "rf_id": 357, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[268,256,6291456,3145728,2,"cuda:0"],0,2097152,1048576], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[541,256,8388608,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 544, "rf_id": 362, "parent": 543, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:0"],[1048576],[1],11534336], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[545,256,11534336,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 543, "rf_id": 361, "parent": 542, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:0"],0,2097152,3145728,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[545,256,11534336,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 542, "rf_id": 360, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[272,256,9437184,3145728,2,"cuda:0"],0,2097152,1048576], "input_shapes": [[3145728],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[545,256,11534336,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 546, "rf_id": 363, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[533,256,2097152,1048576,2,"cuda:0"],[537,256,5242880,1048576,2,"cuda:0"],[541,256,8388608,1048576,2,"cuda:0"],[545,256,11534336,1048576,2,"cuda:0"]],0], "input_shapes": [[[1048576],[1048576],[1048576],[1048576]],[]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int"],
      "outputs": [[547,548,0,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 549, "rf_id": 364, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[547,548,0,4194304,2,"cuda:0"],[1024,4096]], "input_shapes": [[4194304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[550,548,0,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 552, "rf_id": 365, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[551,57,0,0,2,"cuda:0"],[550,548,0,4194304,2,"cuda:0"]], "input_shapes": [[0],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 553, "rf_id": 366, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[533,256,2097152,1048576,2,"cuda:0"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 554, "rf_id": 367, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[537,256,5242880,1048576,2,"cuda:0"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 555, "rf_id": 368, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[541,256,8388608,1048576,2,"cuda:0"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 556, "rf_id": 369, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[545,256,11534336,1048576,2,"cuda:0"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 559, "rf_id": 372, "parent": 558, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[444,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 558, "rf_id": 371, "parent": 557, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[444,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[560,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 557, "rf_id": 370, "parent": 408, "fw_parent": 0, "seq_id": 414, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[444,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 563, "rf_id": 375, "parent": 562, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[560,430,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[564,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 562, "rf_id": 374, "parent": 561, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[560,430,0,163840,2,"cuda:0"],[560,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[564,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_CopyToModelParallelRegion", "id": 561, "rf_id": 373, "parent": 408, "fw_parent": 0, "seq_id": 415, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[560,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 570, "rf_id": 379, "parent": 569, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[470,467,0,3145728,2,"cuda:0"],[1024,3072],[1,1024],"<None>"], "input_shapes": [[3072,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[571,467,0,3145728,2,"cuda:0"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 569, "rf_id": 378, "parent": 568, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[470,467,0,3145728,2,"cuda:0"],0,1], "input_shapes": [[3072,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[571,467,0,3145728,2,"cuda:0"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 568, "rf_id": 377, "parent": 567, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[470,467,0,3145728,2,"cuda:0"]], "input_shapes": [[3072,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[571,467,0,3145728,2,"cuda:0"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 574, "rf_id": 382, "parent": 573, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[564,430,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[575,430,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 573, "rf_id": 381, "parent": 572, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[564,430,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[575,430,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 576, "rf_id": 383, "parent": 572, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[575,430,0,163840,2,"cuda:0"],[571,467,0,3145728,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[577,578,0,491520,2,"cuda:0"]], "output_shapes": [[160,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 579, "rf_id": 384, "parent": 572, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[577,578,0,491520,2,"cuda:0"],[20,8,3072]], "input_shapes": [[160,3072],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[580,578,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 572, "rf_id": 380, "parent": 567, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[564,430,0,163840,2,"cuda:0"],[571,467,0,3145728,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[580,578,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 581, "rf_id": 385, "parent": 567, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[580,578,0,491520,2,"cuda:0"],[565,566,0,3072,2,"cuda:0"],1], "input_shapes": [[20,8,3072],[3072],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[582,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 567, "rf_id": 376, "parent": 408, "fw_parent": 0, "seq_id": 416, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[564,430,0,163840,2,"cuda:0"],[470,467,0,3145728,2,"cuda:0"],[565,566,0,3072,2,"cuda:0"]], "input_shapes": [[20,8,1024],[3072,1024],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 586, "rf_id": 388, "parent": 585, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[582,583,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 585, "rf_id": 387, "parent": 584, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[582,583,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[587,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 584, "rf_id": 386, "parent": 408, "fw_parent": 0, "seq_id": 417, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[582,583,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 588, "rf_id": 389, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[587,583,0,491520,2,"cuda:0"],[20,8,-1,3,64]], "input_shapes": [[20,8,3072],[[],[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]"],
      "outputs": [[589,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 591, "rf_id": 391, "parent": 590, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[589,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[592,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 590, "rf_id": 390, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[589,583,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[592,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 594, "rf_id": 393, "parent": 593, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[592,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[595,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 593, "rf_id": 392, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[592,583,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[595,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 597, "rf_id": 395, "parent": 596, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[595,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[598,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 596, "rf_id": 394, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[595,583,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[598,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 600, "rf_id": 397, "parent": 599, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[598,583,0,491520,2,"cuda:0"],[20,8,16,1,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[601,583,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 599, "rf_id": 396, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[598,583,0,491520,2,"cuda:0"],3,0,-2,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[601,583,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 603, "rf_id": 399, "parent": 602, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[601,583,0,163840,2,"cuda:0"],[20,8,16,1,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,1,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[604,583,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 602, "rf_id": 398, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[601,583,0,163840,2,"cuda:0"],4,0,9223372036854775807,1], "input_shapes": [[20,8,16,1,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[604,583,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_reshape_alias", "id": 606, "rf_id": 401, "parent": 605, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[604,583,0,163840,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1]], "input_shapes": [[20,8,16,1,64],[[],[],[],[]],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]"],
      "outputs": [[607,583,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 605, "rf_id": 400, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[604,583,0,163840,2,"cuda:0"],[20,8,-1,64]], "input_shapes": [[20,8,16,1,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[607,583,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 609, "rf_id": 403, "parent": 608, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[589,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[610,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 608, "rf_id": 402, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[589,583,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[610,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 612, "rf_id": 405, "parent": 611, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[610,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[613,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 611, "rf_id": 404, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[610,583,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[613,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 615, "rf_id": 407, "parent": 614, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[613,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[616,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 614, "rf_id": 406, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[613,583,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[616,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 618, "rf_id": 409, "parent": 617, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[616,583,0,491520,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],64], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[619,583,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 617, "rf_id": 408, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[616,583,0,491520,2,"cuda:0"],3,-2], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[619,583,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 621, "rf_id": 411, "parent": 620, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[619,583,64,163840,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],64], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[622,583,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 620, "rf_id": 410, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[619,583,64,163840,2,"cuda:0"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[622,583,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 624, "rf_id": 413, "parent": 623, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[589,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[625,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 623, "rf_id": 412, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[589,583,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[625,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 627, "rf_id": 415, "parent": 626, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[625,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[628,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 626, "rf_id": 414, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[625,583,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[628,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 630, "rf_id": 417, "parent": 629, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[628,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[631,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 629, "rf_id": 416, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[628,583,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[631,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 633, "rf_id": 419, "parent": 632, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[631,583,0,491520,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],128], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[634,583,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 632, "rf_id": 418, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[631,583,0,491520,2,"cuda:0"],3,-1], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[634,583,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 636, "rf_id": 421, "parent": 635, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[634,583,128,163840,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],128], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[637,583,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 635, "rf_id": 420, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[634,583,128,163840,2,"cuda:0"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[637,583,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 640, "rf_id": 424, "parent": 639, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[607,583,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 639, "rf_id": 423, "parent": 638, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[607,583,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[641,583,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 638, "rf_id": 422, "parent": 408, "fw_parent": 0, "seq_id": 418, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[607,583,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 644, "rf_id": 427, "parent": 643, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[622,583,64,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 643, "rf_id": 426, "parent": 642, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[622,583,64,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[645,583,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 642, "rf_id": 425, "parent": 408, "fw_parent": 0, "seq_id": 419, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[622,583,64,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 648, "rf_id": 430, "parent": 647, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[637,583,128,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 647, "rf_id": 429, "parent": 646, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[637,583,128,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[649,583,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 646, "rf_id": 428, "parent": 408, "fw_parent": 0, "seq_id": 420, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[637,583,128,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 652, "rf_id": 433, "parent": 651, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[448,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 651, "rf_id": 432, "parent": 650, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[448,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[653,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 650, "rf_id": 431, "parent": 408, "fw_parent": 0, "seq_id": 421, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[448,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 654, "rf_id": 434, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[641,583,0,163840,2,"cuda:0"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[655,583,0,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 656, "rf_id": 435, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[645,583,64,163840,2,"cuda:0"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[657,583,64,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 661, "rf_id": 437, "parent": 660, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[658,659,0,51200,2,"cuda:0"],[51200],[1],0], "input_shapes": [[51200],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[662,659,0,51200,2,"cuda:0"]], "output_shapes": [[51200]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 660, "rf_id": 436, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[658,659,0,51200,2,"cuda:0"],0,0,51200,1], "input_shapes": [[51200],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[662,659,0,51200,2,"cuda:0"]], "output_shapes": [[51200]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 663, "rf_id": 438, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[662,659,0,51200,2,"cuda:0"],[128,20,20]], "input_shapes": [[51200],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[664,659,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 666, "rf_id": 440, "parent": 665, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[655,583,0,163840,2,"cuda:0"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[667,583,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 665, "rf_id": 439, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[655,583,0,163840,2,"cuda:0"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[667,583,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 669, "rf_id": 442, "parent": 668, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[657,583,64,163840,2,"cuda:0"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[670,583,64,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 668, "rf_id": 441, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[657,583,64,163840,2,"cuda:0"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[670,583,64,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 672, "rf_id": 444, "parent": 671, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[670,583,64,163840,2,"cuda:0"],[128,64,20],[192,1,24576],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[673,583,64,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 671, "rf_id": 443, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[670,583,64,163840,2,"cuda:0"],1,2], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[673,583,64,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::baddbmm", "id": 674, "rf_id": 445, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor",
      "inputs": [[664,659,0,51200,2,"cuda:0"],[667,583,0,163840,2,"cuda:0"],[673,583,64,163840,2,"cuda:0"],0.000000,0.125000], "input_shapes": [[128,20,20],[128,20,64],[128,64,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Double","Double"],
      "outputs": [[675,676,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 677, "rf_id": 446, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[675,676,0,51200,2,"cuda:0"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[678,676,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 681, "rf_id": 449, "parent": 680, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[678,676,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 680, "rf_id": 448, "parent": 679, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[678,676,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[682,676,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 679, "rf_id": 447, "parent": 408, "fw_parent": 0, "seq_id": 422, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[678,676,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 685, "rf_id": 452, "parent": 684, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[653,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 684, "rf_id": 451, "parent": 683, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[653,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[686,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 683, "rf_id": 450, "parent": 408, "fw_parent": 0, "seq_id": 423, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[653,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 687, "rf_id": 453, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[682,676,0,51200,2,"cuda:0"],[-1,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[688,676,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 690, "rf_id": 455, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],4,0,"cpu",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","Bool","None"],
      "outputs": [[691,692,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 693, "rf_id": 456, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[691,692,0,1,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[1],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[691,692,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 694, "rf_id": 457, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[691,692,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [[691,692,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "detach_", "id": 696, "rf_id": 459, "parent": 695, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[691,692,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 695, "rf_id": 458, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[691,692,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [[691,692,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 698, "rf_id": 461, "parent": 697, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[691,692,0,1,8,"cpu"],[],[],0], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[699,692,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 697, "rf_id": 460, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[691,692,0,1,8,"cpu"],0,0], "input_shapes": [[1],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[699,692,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 701, "rf_id": 463, "parent": 700, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[699,692,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 700, "rf_id": 462, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[699,692,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::empty", "id": 702, "rf_id": 464, "parent": 689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[128,20,20],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[703,704,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ScaledUpperTriangMaskedSoftmax", "id": 689, "rf_id": 454, "parent": 408, "fw_parent": 0, "seq_id": 424, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[688,676,0,51200,2,"cuda:0"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 705, "rf_id": 465, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[703,704,0,51200,2,"cuda:0"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[706,704,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 709, "rf_id": 468, "parent": 708, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[706,704,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 708, "rf_id": 467, "parent": 707, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[706,704,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[710,704,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 707, "rf_id": 466, "parent": 408, "fw_parent": 0, "seq_id": 425, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[706,704,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 713, "rf_id": 471, "parent": 712, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[710,704,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 712, "rf_id": 470, "parent": 711, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[710,704,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[714,704,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 711, "rf_id": 469, "parent": 408, "fw_parent": 0, "seq_id": 426, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[710,704,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 718, "rf_id": 475, "parent": 717, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[8,16,20,20],[6400,400,20,1],11,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[]],[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[719,720,0,51200,1,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 717, "rf_id": 474, "parent": 716, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[714,704,0,51200,2,"cuda:0"],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[8,16,20,20],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[719,720,0,51200,1,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 722, "rf_id": 477, "parent": 721, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[8,16,20,20],[6400,400,20,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[]],[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[723,724,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 721, "rf_id": 476, "parent": 716, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[714,704,0,51200,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[8,16,20,20],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[723,724,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 716, "rf_id": 473, "parent": 715, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[714,704,0,51200,2,"cuda:0"],0.100000,true], "input_shapes": [[8,16,20,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[723,724,0,51200,2,"cuda:0"],[719,720,0,51200,1,"cuda:0"]], "output_shapes": [[8,16,20,20],[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::dropout", "id": 715, "rf_id": 472, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::dropout(Tensor input, float p, bool train) -> Tensor",
      "inputs": [[714,704,0,51200,2,"cuda:0"],0.100000,true], "input_shapes": [[8,16,20,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[723,724,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 727, "rf_id": 480, "parent": 726, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[723,724,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 726, "rf_id": 479, "parent": 725, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[723,724,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[728,724,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 725, "rf_id": 478, "parent": 408, "fw_parent": 0, "seq_id": 427, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[723,724,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 729, "rf_id": 481, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[649,583,128,163840,2,"cuda:0"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[686,583,128,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 730, "rf_id": 482, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[728,724,0,51200,2,"cuda:0"],[128,20,-1]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[731,724,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 733, "rf_id": 484, "parent": 732, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[686,583,128,163840,2,"cuda:0"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[734,583,128,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 732, "rf_id": 483, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[686,583,128,163840,2,"cuda:0"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[734,583,128,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 735, "rf_id": 485, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[731,724,0,51200,2,"cuda:0"],[734,583,128,163840,2,"cuda:0"]], "input_shapes": [[128,20,20],[128,20,64]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[736,329,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 737, "rf_id": 486, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[736,329,0,163840,2,"cuda:0"],[8,16,20,64]], "input_shapes": [[128,20,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[738,329,0,163840,2,"cuda:0"]], "output_shapes": [[8,16,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 740, "rf_id": 488, "parent": 739, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[738,329,0,163840,2,"cuda:0"],[20,8,16,64],[64,20480,1280,1],"<None>"], "input_shapes": [[8,16,20,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","None"],
      "outputs": [[741,329,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::permute", "id": 739, "rf_id": 487, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)",
      "inputs": [[738,329,0,163840,2,"cuda:0"],[2,0,1,3]], "input_shapes": [[8,16,20,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[741,329,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 745, "rf_id": 492, "parent": 744, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[746,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 744, "rf_id": 491, "parent": 743, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[741,329,0,163840,2,"cuda:0"],15,0,"cuda:0","<None>",0], "input_shapes": [[20,8,16,64],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Int"],
      "outputs": [[746,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 747, "rf_id": 493, "parent": 743, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[746,359,0,163840,2,"cuda:0"],[741,329,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[746,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::clone", "id": 743, "rf_id": 490, "parent": 742, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[741,329,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[746,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::contiguous", "id": 742, "rf_id": 489, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[741,329,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[746,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 748, "rf_id": 494, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[746,359,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[749,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 752, "rf_id": 497, "parent": 751, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[749,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 751, "rf_id": 496, "parent": 750, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[749,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[753,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 750, "rf_id": 495, "parent": 408, "fw_parent": 0, "seq_id": 428, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[749,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 756, "rf_id": 500, "parent": 755, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[753,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 755, "rf_id": 499, "parent": 754, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[753,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[757,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 754, "rf_id": 498, "parent": 408, "fw_parent": 0, "seq_id": 429, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[753,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 761, "rf_id": 504, "parent": 760, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[497,494,0,1048576,2,"cuda:0"],[1024,1024],[1,1024],"<None>"], "input_shapes": [[1024,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[762,494,0,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 760, "rf_id": 503, "parent": 759, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[497,494,0,1048576,2,"cuda:0"],0,1], "input_shapes": [[1024,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[762,494,0,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 759, "rf_id": 502, "parent": 758, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[497,494,0,1048576,2,"cuda:0"]], "input_shapes": [[1024,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[762,494,0,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 765, "rf_id": 507, "parent": 764, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[757,359,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[766,359,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 764, "rf_id": 506, "parent": 763, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[757,359,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[766,359,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 767, "rf_id": 508, "parent": 763, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[766,359,0,163840,2,"cuda:0"],[762,494,0,1048576,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[768,329,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 769, "rf_id": 509, "parent": 763, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[768,329,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[770,329,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 763, "rf_id": 505, "parent": 758, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[757,359,0,163840,2,"cuda:0"],[762,494,0,1048576,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[770,329,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 758, "rf_id": 501, "parent": 408, "fw_parent": 0, "seq_id": 430, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[757,359,0,163840,2,"cuda:0"],[497,494,0,1048576,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 773, "rf_id": 512, "parent": 772, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[770,329,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[774,329,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 772, "rf_id": 511, "parent": 771, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[770,329,0,163840,2,"cuda:0"],[770,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[774,329,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_ReduceFromModelParallelRegion", "id": 771, "rf_id": 510, "parent": 408, "fw_parent": 0, "seq_id": 431, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[770,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 777, "rf_id": 515, "parent": 776, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[774,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 776, "rf_id": 514, "parent": 775, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[774,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[778,329,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 775, "rf_id": 513, "parent": 408, "fw_parent": 0, "seq_id": 432, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[774,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 783, "rf_id": 518, "parent": 782, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[779,780,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 782, "rf_id": 517, "parent": 781, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[779,780,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[784,780,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 781, "rf_id": 516, "parent": 408, "fw_parent": 0, "seq_id": 433, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[779,780,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 787, "rf_id": 521, "parent": 786, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[778,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 786, "rf_id": 520, "parent": 785, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[778,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[788,329,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 785, "rf_id": 519, "parent": 408, "fw_parent": 0, "seq_id": 434, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[778,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 791, "rf_id": 524, "parent": 790, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[784,780,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 790, "rf_id": 523, "parent": 789, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[784,780,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[792,780,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 789, "rf_id": 522, "parent": 408, "fw_parent": 0, "seq_id": 435, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[784,780,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 795, "rf_id": 527, "parent": 794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[792,780,0,1024,2,"cuda:0"],[20,8,1024],[0,0,1],"<None>"], "input_shapes": [[1024],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[796,780,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::expand", "id": 794, "rf_id": 526, "parent": 793, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)",
      "inputs": [[792,780,0,1024,2,"cuda:0"],[20,8,1024],false], "input_shapes": [[1024],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","Bool"],
      "outputs": [[796,780,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::expand_as", "id": 793, "rf_id": 525, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[792,780,0,1024,2,"cuda:0"],[413,391,0,163840,2,"cuda:0"]], "input_shapes": [[1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[796,780,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 800, "rf_id": 531, "parent": 799, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[788,329,0,163840,2,"cuda:0"],[796,780,0,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[801,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "fallback_function", "id": 799, "rf_id": 530, "parent": 798, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[796,780,0,163840,2,"cuda:0"],[788,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "fallback_function", "id": 798, "rf_id": 529, "parent": 797, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[796,780,0,163840,2,"cuda:0"],[788,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 806, "rf_id": 536, "parent": 805, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],11,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[807,676,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 805, "rf_id": 535, "parent": 804, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[801,359,0,163840,2,"cuda:0"],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[807,676,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 809, "rf_id": 538, "parent": 808, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[810,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 808, "rf_id": 537, "parent": 804, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[801,359,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[810,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 804, "rf_id": 534, "parent": 803, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[801,359,0,163840,2,"cuda:0"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[810,578,0,163840,2,"cuda:0"],[807,676,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024],[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::dropout", "id": 803, "rf_id": 533, "parent": 802, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::dropout(Tensor input, float p, bool train) -> Tensor",
      "inputs": [[801,359,0,163840,2,"cuda:0"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[810,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 811, "rf_id": 539, "parent": 802, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[413,391,0,163840,2,"cuda:0"],[810,578,0,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[807,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "fallback_function", "id": 802, "rf_id": 532, "parent": 797, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[413,391,0,163840,2,"cuda:0"],0.100000,[801,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_dropout_add_fused_train", "id": 797, "rf_id": 528, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[788,329,0,163840,2,"cuda:0"],[796,780,0,163840,2,"cuda:0"],[413,391,0,163840,2,"cuda:0"],0.100000], "input_shapes": [[20,8,1024],[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Double"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 815, "rf_id": 542, "parent": 814, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[807,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 814, "rf_id": 541, "parent": 813, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[807,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[816,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 813, "rf_id": 540, "parent": 408, "fw_parent": 0, "seq_id": 436, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[807,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 823, "rf_id": 545, "parent": 822, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[824,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 822, "rf_id": 544, "parent": 821, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[816,812,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[824,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 825, "rf_id": 546, "parent": 821, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[160],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[826,132,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 828, "rf_id": 548, "parent": 827, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[829,436,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 827, "rf_id": 547, "parent": 821, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[826,132,0,160,4,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[160],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[829,436,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunction", "id": 821, "rf_id": 543, "parent": 408, "fw_parent": 0, "seq_id": 437, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[816,812,0,163840,2,"cuda:0"],[817,818,0,1024,2,"cuda:0"],[819,820,0,1024,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 832, "rf_id": 551, "parent": 831, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[824,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 831, "rf_id": 550, "parent": 830, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[824,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[833,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 830, "rf_id": 549, "parent": 408, "fw_parent": 0, "seq_id": 438, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[824,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 834, "rf_id": 552, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],15,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[829,835,0,1,2,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 838, "rf_id": 555, "parent": 837, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],15,0,"cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[839,840,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 841, "rf_id": 556, "parent": 837, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[839,840,0,1,2,"cuda:0"],[829,835,0,1,2,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[839,840,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_to_copy", "id": 837, "rf_id": 554, "parent": 836, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[829,835,0,1,2,"cpu"],15,"<None>","cuda:0","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","Device","None","Bool","None"],
      "outputs": [[839,840,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 836, "rf_id": 553, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[829,835,0,1,2,"cpu"],"cuda:0",15,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Device","Int","Bool","Bool","None"],
      "outputs": [[839,840,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::lift_fresh", "id": 842, "rf_id": 557, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[839,840,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[839,840,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach_", "id": 844, "rf_id": 559, "parent": 843, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[839,840,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 843, "rf_id": 558, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[839,840,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[839,840,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 845, "rf_id": 560, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],15,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[846,847,0,1,2,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 850, "rf_id": 563, "parent": 849, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],15,0,"cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[851,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 852, "rf_id": 564, "parent": 849, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[851,132,0,1,2,"cuda:0"],[846,847,0,1,2,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[851,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_to_copy", "id": 849, "rf_id": 562, "parent": 848, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[846,847,0,1,2,"cpu"],15,"<None>","cuda:0","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","Device","None","Bool","None"],
      "outputs": [[851,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 848, "rf_id": 561, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[846,847,0,1,2,"cpu"],"cuda:0",15,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Device","Int","Bool","Bool","None"],
      "outputs": [[851,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::lift_fresh", "id": 853, "rf_id": 565, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[851,132,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[851,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach_", "id": 855, "rf_id": 567, "parent": 854, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[851,132,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 854, "rf_id": 566, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[851,132,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[851,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 858, "rf_id": 570, "parent": 857, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[833,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 857, "rf_id": 569, "parent": 856, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[833,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[859,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 856, "rf_id": 568, "parent": 408, "fw_parent": 0, "seq_id": 439, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[833,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 862, "rf_id": 573, "parent": 861, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[859,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 861, "rf_id": 572, "parent": 860, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[859,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[863,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 860, "rf_id": 571, "parent": 408, "fw_parent": 0, "seq_id": 440, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[859,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 866, "rf_id": 576, "parent": 865, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[863,359,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[867,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 865, "rf_id": 575, "parent": 864, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[863,359,0,163840,2,"cuda:0"],[863,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[867,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_CopyToModelParallelRegion", "id": 864, "rf_id": 574, "parent": 408, "fw_parent": 0, "seq_id": 441, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[863,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 871, "rf_id": 580, "parent": 870, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[524,521,0,4194304,2,"cuda:0"],[1024,4096],[1,1024],"<None>"], "input_shapes": [[4096,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[872,521,0,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 870, "rf_id": 579, "parent": 869, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[524,521,0,4194304,2,"cuda:0"],0,1], "input_shapes": [[4096,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[872,521,0,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 869, "rf_id": 578, "parent": 868, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[524,521,0,4194304,2,"cuda:0"]], "input_shapes": [[4096,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[872,521,0,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 875, "rf_id": 583, "parent": 874, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[867,359,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[876,359,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 874, "rf_id": 582, "parent": 873, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[867,359,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[876,359,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 877, "rf_id": 584, "parent": 873, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[876,359,0,163840,2,"cuda:0"],[872,521,0,4194304,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[878,879,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 880, "rf_id": 585, "parent": 873, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[878,879,0,655360,2,"cuda:0"],[20,8,4096]], "input_shapes": [[160,4096],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[881,879,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 873, "rf_id": 581, "parent": 868, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[867,359,0,163840,2,"cuda:0"],[872,521,0,4194304,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[881,879,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 868, "rf_id": 577, "parent": 408, "fw_parent": 0, "seq_id": 442, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[867,359,0,163840,2,"cuda:0"],[524,521,0,4194304,2,"cuda:0"]], "input_shapes": [[20,8,1024],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 884, "rf_id": 588, "parent": 883, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[881,879,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 883, "rf_id": 587, "parent": 882, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[881,879,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[885,879,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 882, "rf_id": 586, "parent": 408, "fw_parent": 0, "seq_id": 443, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[881,879,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 890, "rf_id": 591, "parent": 889, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[886,887,0,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 889, "rf_id": 590, "parent": 888, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[886,887,0,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[891,887,0,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 888, "rf_id": 589, "parent": 408, "fw_parent": 0, "seq_id": 444, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[886,887,0,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 896, "rf_id": 596, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[891,887,0,4096,2,"cuda:0"],[885,879,0,655360,2,"cuda:0"],1], "input_shapes": [[4096],[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[897,898,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 902, "rf_id": 598, "parent": 899, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[897,898,0,655360,2,"cuda:0"],[900,901,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[903,904,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 899, "rf_id": 597, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[897,898,0,655360,2,"cuda:0"],0.500000], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[903,904,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 908, "rf_id": 600, "parent": 905, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[897,898,0,655360,2,"cuda:0"],[906,907,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[909,910,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 905, "rf_id": 599, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[897,898,0,655360,2,"cuda:0"],0.797885], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[909,910,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 914, "rf_id": 602, "parent": 911, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[897,898,0,655360,2,"cuda:0"],[912,913,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[915,916,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 911, "rf_id": 601, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[897,898,0,655360,2,"cuda:0"],0.044715], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[915,916,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 917, "rf_id": 603, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[915,916,0,655360,2,"cuda:0"],[897,898,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[918,919,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 923, "rf_id": 605, "parent": 920, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[918,919,0,655360,2,"cuda:0"],[921,922,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[924,916,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 920, "rf_id": 604, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[918,919,0,655360,2,"cuda:0"],1,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[924,916,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 925, "rf_id": 606, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[909,910,0,655360,2,"cuda:0"],[924,916,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[926,898,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::tanh", "id": 927, "rf_id": 607, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::tanh(Tensor self) -> Tensor",
      "inputs": [[926,898,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[928,910,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 932, "rf_id": 609, "parent": 929, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[928,910,0,655360,2,"cuda:0"],[930,931,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)","Int"],
      "outputs": [[933,898,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 929, "rf_id": 608, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[928,910,0,655360,2,"cuda:0"],1.000000,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Int"],
      "outputs": [[933,898,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 934, "rf_id": 610, "parent": 895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[903,904,0,655360,2,"cuda:0"],[933,898,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[935,910,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "fallback_function", "id": 895, "rf_id": 595, "parent": 894, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[885,879,0,655360,2,"cuda:0"],[891,887,0,4096,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "fallback_function", "id": 894, "rf_id": 594, "parent": 893, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[885,879,0,655360,2,"cuda:0"],[891,887,0,4096,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_gelu", "id": 893, "rf_id": 593, "parent": 892, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[891,887,0,4096,2,"cuda:0"],[885,879,0,655360,2,"cuda:0"]], "input_shapes": [[4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "GeLUFunction", "id": 892, "rf_id": 592, "parent": 408, "fw_parent": 0, "seq_id": 445, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[885,879,0,655360,2,"cuda:0"],[891,887,0,4096,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 938, "rf_id": 613, "parent": 937, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[935,910,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 937, "rf_id": 612, "parent": 936, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[935,910,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[939,910,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 936, "rf_id": 611, "parent": 408, "fw_parent": 0, "seq_id": 446, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[935,910,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 943, "rf_id": 617, "parent": 942, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[551,548,0,4194304,2,"cuda:0"],[4096,1024],[1,4096],"<None>"], "input_shapes": [[1024,4096],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[944,548,0,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 942, "rf_id": 616, "parent": 941, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[551,548,0,4194304,2,"cuda:0"],0,1], "input_shapes": [[1024,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[944,548,0,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 941, "rf_id": 615, "parent": 940, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[551,548,0,4194304,2,"cuda:0"]], "input_shapes": [[1024,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[944,548,0,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 947, "rf_id": 620, "parent": 946, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[939,910,0,655360,2,"cuda:0"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[948,910,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 946, "rf_id": 619, "parent": 945, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[939,910,0,655360,2,"cuda:0"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[948,910,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 949, "rf_id": 621, "parent": 945, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[948,910,0,655360,2,"cuda:0"],[944,548,0,4194304,2,"cuda:0"]], "input_shapes": [[160,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[950,578,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 951, "rf_id": 622, "parent": 945, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[950,578,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[952,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 945, "rf_id": 618, "parent": 940, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[939,910,0,655360,2,"cuda:0"],[944,548,0,4194304,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[952,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 940, "rf_id": 614, "parent": 408, "fw_parent": 0, "seq_id": 447, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[939,910,0,655360,2,"cuda:0"],[551,548,0,4194304,2,"cuda:0"]], "input_shapes": [[20,8,4096],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 955, "rf_id": 625, "parent": 954, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[952,578,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[956,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 954, "rf_id": 624, "parent": 953, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[952,578,0,163840,2,"cuda:0"],[952,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[956,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_ReduceFromModelParallelRegion", "id": 953, "rf_id": 623, "parent": 408, "fw_parent": 0, "seq_id": 448, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[952,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 959, "rf_id": 626, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[956,578,0,163840,2,"cuda:0"],[957,958,0,1024,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[960,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 963, "rf_id": 629, "parent": 962, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[960,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 962, "rf_id": 628, "parent": 961, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[960,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[964,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 961, "rf_id": 627, "parent": 408, "fw_parent": 0, "seq_id": 449, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[960,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 967, "rf_id": 632, "parent": 966, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[964,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 966, "rf_id": 631, "parent": 965, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[964,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[968,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 965, "rf_id": 630, "parent": 408, "fw_parent": 0, "seq_id": 450, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[964,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 974, "rf_id": 638, "parent": 973, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],11,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[975,676,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 973, "rf_id": 637, "parent": 972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[968,430,0,163840,2,"cuda:0"],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[975,676,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 977, "rf_id": 640, "parent": 976, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[978,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 976, "rf_id": 639, "parent": 972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[968,430,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[978,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 972, "rf_id": 636, "parent": 971, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[968,430,0,163840,2,"cuda:0"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[978,578,0,163840,2,"cuda:0"],[975,676,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024],[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::dropout", "id": 971, "rf_id": 635, "parent": 970, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::dropout(Tensor input, float p, bool train) -> Tensor",
      "inputs": [[968,430,0,163840,2,"cuda:0"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[978,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 979, "rf_id": 641, "parent": 970, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[807,812,0,163840,2,"cuda:0"],[978,578,0,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[975,980,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "fallback_function", "id": 970, "rf_id": 634, "parent": 969, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[807,812,0,163840,2,"cuda:0"],0.100000,[968,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_dropout_add_fused_train", "id": 969, "rf_id": 633, "parent": 408, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[968,430,0,163840,2,"cuda:0"],"<None>",[807,812,0,163840,2,"cuda:0"],0.100000], "input_shapes": [[20,8,1024],[],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","None","Tensor(c10::BFloat16)","Double"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 983, "rf_id": 644, "parent": 982, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[975,980,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 982, "rf_id": 643, "parent": 981, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[975,980,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[984,980,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 981, "rf_id": 642, "parent": 408, "fw_parent": 0, "seq_id": 451, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[975,980,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 987, "rf_id": 647, "parent": 986, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[839,840,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 986, "rf_id": 646, "parent": 985, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[839,840,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[988,840,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 985, "rf_id": 645, "parent": 408, "fw_parent": 0, "seq_id": 452, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[839,840,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "CheckpointFunction", "id": 408, "rf_id": 267, "parent": 2, "fw_parent": 0, "seq_id": 406, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[403,391,0,163840,2,"cuda:0"],[407,227,0,400,1,"cuda:0"]], "input_shapes": [[20,8,1024],[1,1,20,20]], "input_types": ["Tensor(c10::BFloat16)","Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 991, "rf_id": 650, "parent": 990, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[984,980,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 990, "rf_id": 649, "parent": 989, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[984,980,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[992,980,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 989, "rf_id": 648, "parent": 2, "fw_parent": 0, "seq_id": 453, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[984,980,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 999, "rf_id": 653, "parent": 998, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1000,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 998, "rf_id": 652, "parent": 997, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[992,980,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1000,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1001, "rf_id": 654, "parent": 997, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[160],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[1002,132,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 1004, "rf_id": 656, "parent": 1003, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[1005,436,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 1003, "rf_id": 655, "parent": 997, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1002,132,0,160,4,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[160],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[1005,436,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunction", "id": 997, "rf_id": 651, "parent": 2, "fw_parent": 0, "seq_id": 454, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[992,980,0,163840,2,"cuda:0"],[993,994,0,1024,2,"cuda:0"],[995,996,0,1024,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1008, "rf_id": 659, "parent": 1007, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1000,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1007, "rf_id": 658, "parent": 1006, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1000,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1009,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1006, "rf_id": 657, "parent": 2, "fw_parent": 0, "seq_id": 455, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1000,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1012, "rf_id": 662, "parent": 1011, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1009,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1011, "rf_id": 661, "parent": 1010, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1009,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1013,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1010, "rf_id": 660, "parent": 2, "fw_parent": 0, "seq_id": 456, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1009,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1016, "rf_id": 665, "parent": 1015, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[988,840,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1015, "rf_id": 664, "parent": 1014, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[988,840,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1017,840,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1014, "rf_id": 663, "parent": 2, "fw_parent": 0, "seq_id": 457, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[988,840,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1020, "rf_id": 668, "parent": 1019, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1013,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1019, "rf_id": 667, "parent": 1018, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1013,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1021,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1018, "rf_id": 666, "parent": 2, "fw_parent": 0, "seq_id": 458, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1013,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1024, "rf_id": 671, "parent": 1023, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1017,840,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1023, "rf_id": 670, "parent": 1022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1017,840,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1025,840,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1022, "rf_id": 669, "parent": 2, "fw_parent": 0, "seq_id": 459, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1017,840,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1028, "rf_id": 674, "parent": 1027, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1021,430,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1029,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1027, "rf_id": 673, "parent": 1026, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1021,430,0,163840,2,"cuda:0"],[1021,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1029,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_CopyToModelParallelRegion", "id": 1026, "rf_id": 672, "parent": 2, "fw_parent": 0, "seq_id": 460, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1021,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1033, "rf_id": 678, "parent": 1032, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[251,237,0,51511296,2,"cuda:0"],[1024,50304],[1,1024],"<None>"], "input_shapes": [[50304,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1034,237,0,51511296,2,"cuda:0"]], "output_shapes": [[1024,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1032, "rf_id": 677, "parent": 1031, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[251,237,0,51511296,2,"cuda:0"],0,1], "input_shapes": [[50304,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1034,237,0,51511296,2,"cuda:0"]], "output_shapes": [[1024,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1031, "rf_id": 676, "parent": 1030, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[251,237,0,51511296,2,"cuda:0"]], "input_shapes": [[50304,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1034,237,0,51511296,2,"cuda:0"]], "output_shapes": [[1024,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1037, "rf_id": 681, "parent": 1036, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1029,430,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1038,430,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1036, "rf_id": 680, "parent": 1035, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1029,430,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1038,430,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1039, "rf_id": 682, "parent": 1035, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1038,430,0,163840,2,"cuda:0"],[1034,237,0,51511296,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,50304]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1040,904,0,8048640,2,"cuda:0"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1041, "rf_id": 683, "parent": 1035, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1040,904,0,8048640,2,"cuda:0"],[20,8,50304]], "input_shapes": [[160,50304],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1042,904,0,8048640,2,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1035, "rf_id": 679, "parent": 1030, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1029,430,0,163840,2,"cuda:0"],[1034,237,0,51511296,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,50304]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1042,904,0,8048640,2,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 1030, "rf_id": 675, "parent": 2, "fw_parent": 0, "seq_id": 461, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1029,430,0,163840,2,"cuda:0"],[251,237,0,51511296,2,"cuda:0"]], "input_shapes": [[20,8,1024],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1044, "rf_id": 685, "parent": 1043, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[170,171,0,160,8,"cuda:0"],[20,8],[1,20],"<None>"], "input_shapes": [[8,20],[[],[]],[[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1045,171,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::transpose", "id": 1043, "rf_id": 684, "parent": 2, "fw_parent": 0, "seq_id": 462, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[170,171,0,160,8,"cuda:0"],0,1], "input_shapes": [[8,20],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[1045,171,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 1049, "rf_id": 689, "parent": 1048, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8],4,0,"cuda:0","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[1050,132,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_like", "id": 1048, "rf_id": 688, "parent": 1047, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1045,171,0,160,8,"cuda:0"],4,0,"cuda:0","<None>",0], "input_shapes": [[20,8],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Int"],
      "outputs": [[1050,132,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 1051, "rf_id": 690, "parent": 1047, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1050,132,0,160,8,"cuda:0"],[1045,171,0,160,8,"cuda:0"],false], "input_shapes": [[20,8],[20,8],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[1050,132,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 1047, "rf_id": 687, "parent": 1046, "fw_parent": 0, "seq_id": 462, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1045,171,0,160,8,"cuda:0"],0], "input_shapes": [[20,8],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[1050,132,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::contiguous", "id": 1046, "rf_id": 686, "parent": 2, "fw_parent": 0, "seq_id": 462, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[1045,171,0,160,8,"cuda:0"],0], "input_shapes": [[20,8],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[1050,132,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_strided", "id": 1054, "rf_id": 693, "parent": 1053, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,50304],[402432,50304,1],6,0,"cuda:0",false], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","Bool"],
      "outputs": [[1055,1056,0,8048640,4,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 1057, "rf_id": 694, "parent": 1053, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1055,1056,0,8048640,4,"cuda:0"],[1042,904,0,8048640,2,"cuda:0"],false], "input_shapes": [[20,8,50304],[20,8,50304],[]], "input_types": ["Tensor(float)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1055,1056,0,8048640,4,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 1053, "rf_id": 692, "parent": 1052, "fw_parent": 0, "seq_id": 462, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1042,904,0,8048640,2,"cuda:0"],6,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[20,8,50304],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[1055,1056,0,8048640,4,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 1052, "rf_id": 691, "parent": 2, "fw_parent": 0, "seq_id": 462, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1042,904,0,8048640,2,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[20,8,50304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[1055,1056,0,8048640,4,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1062, "rf_id": 697, "parent": 1059, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1060,1061,0,160,4,"cuda:0"],[20,8,1],[8,1,0],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1063,1061,0,160,4,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1066, "rf_id": 698, "parent": 1059, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1064,1065,0,160,8,"cuda:0"],[20,8,1],[8,1,0],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(long int)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1067,1065,0,160,8,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::max", "id": 1059, "rf_id": 696, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::max.dim(Tensor self, int dim, bool keepdim=False) -> (Tensor values, Tensor indices)",
      "inputs": [[1055,1056,0,8048640,4,"cuda:0"],-1,false], "input_shapes": [[20,8,50304],[],[]], "input_types": ["Tensor(float)","Int","Bool"],
      "outputs": [[1060,1061,0,160,4,"cuda:0"],[1064,1065,0,160,8,"cuda:0"]], "output_shapes": [[20,8],[20,8]], "output_types": ["Tensor(float)","Tensor(long int)"]
    },
    {
      "name": "nccl:all_reduce", "id": 1070, "rf_id": 701, "parent": 1069, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1060,1061,0,160,4,"cuda:0"]], "input_shapes": [[20,8]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 1069, "rf_id": 700, "parent": 1068, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[1060,1061,0,160,4,"cuda:0"]],19,93827882282480,0,"allreduce",[],[],1], "input_shapes": [[[20,8]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[1060,1061,0,160,4,"cuda:0"]]], "output_shapes": [[[20,8]]], "output_types": ["GenericList[Tensor(float)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 1068, "rf_id": 699, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[1060,1061,0,160,4,"cuda:0"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[20,8]],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Object","Object","None","Int"],
      "outputs": [[[1060,1061,0,160,4,"cuda:0"]],"<Object>"], "output_shapes": [[[20,8]],[]], "output_types": ["GenericList[Tensor(float)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 1071, "rf_id": 702, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [19,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1073, "rf_id": 704, "parent": 1072, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1060,1061,0,160,4,"cuda:0"],[20,8,1],[8,1,1],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1074,1061,0,160,4,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::unsqueeze", "id": 1072, "rf_id": 703, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[1060,1061,0,160,4,"cuda:0"],-1], "input_shapes": [[20,8],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[1074,1061,0,160,4,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sub", "id": 1075, "rf_id": 705, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1055,1056,0,8048640,4,"cuda:0"],[1074,1061,0,160,4,"cuda:0"],1], "input_shapes": [[20,8,50304],[20,8,1],[]], "input_types": ["Tensor(float)","Tensor(float)","Int"],
      "outputs": [[1076,1077,0,8048640,4,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::lt", "id": 1078, "rf_id": 706, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1050,132,0,160,8,"cuda:0"],0], "input_shapes": [[20,8],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[1079,1065,0,160,1,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::ge", "id": 1080, "rf_id": 707, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ge.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1050,132,0,160,8,"cuda:0"],50304], "input_shapes": [[20,8],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[1081,1082,0,160,1,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::bitwise_or", "id": 1084, "rf_id": 709, "parent": 1083, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::bitwise_or.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1079,1065,0,160,1,"cuda:0"],[1081,1082,0,160,1,"cuda:0"]], "input_shapes": [[20,8],[20,8]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[1085,1086,0,160,1,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::__or__", "id": 1083, "rf_id": 708, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::__or__.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1079,1065,0,160,1,"cuda:0"],[1081,1082,0,160,1,"cuda:0"]], "input_shapes": [[20,8],[20,8]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[1085,1086,0,160,1,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 1088, "rf_id": 711, "parent": 1087, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8],[8,1],4,0,"cuda:0","<None>"], "input_shapes": [[[],[]],[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[1089,1090,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 1091, "rf_id": 712, "parent": 1087, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1089,1090,0,160,8,"cuda:0"],[1050,132,0,160,8,"cuda:0"],false], "input_shapes": [[20,8],[20,8],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[1089,1090,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 1087, "rf_id": 710, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1050,132,0,160,8,"cuda:0"],"<None>"], "input_shapes": [[20,8],[]], "input_types": ["Tensor(long int)","None"],
      "outputs": [[1089,1090,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::sub", "id": 1094, "rf_id": 713, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1089,1090,0,160,8,"cuda:0"],[1092,1093,0,1,8,"cpu"],1], "input_shapes": [[20,8],[],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Int"],
      "outputs": [[1095,1096,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 1099, "rf_id": 714, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1097,1098,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [[1097,1098,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 1103, "rf_id": 718, "parent": 1102, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[1097,1098,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [0], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 1102, "rf_id": 717, "parent": 1101, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[1097,1098,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [0], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::masked_fill_", "id": 1104, "rf_id": 719, "parent": 1101, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -> Tensor(a!)",
      "inputs": [[1095,1096,0,160,8,"cuda:0"],[1085,1086,0,160,1,"cuda:0"],0], "input_shapes": [[20,8],[20,8],[]], "input_types": ["Tensor(long int)","Tensor(bool)","Int"],
      "outputs": [[1095,1096,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_index_put_impl_", "id": 1101, "rf_id": 716, "parent": 1100, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_index_put_impl_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False, bool unsafe=False) -> Tensor(a!)",
      "inputs": [[1095,1096,0,160,8,"cuda:0"],[[1085,1086,0,160,1,"cuda:0"]],[1097,1098,0,1,8,"cpu"],false,false], "input_shapes": [[20,8],[[20,8]],[],[],[]], "input_types": ["Tensor(long int)","GenericList[Tensor(bool)]","Tensor(long int)","Bool","Bool"],
      "outputs": [[1095,1096,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::index_put_", "id": 1100, "rf_id": 715, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -> Tensor(a!)",
      "inputs": [[1095,1096,0,160,8,"cuda:0"],[[1085,1086,0,160,1,"cuda:0"]],[1097,1098,0,1,8,"cpu"],false], "input_shapes": [[20,8],[[20,8]],[],[]], "input_types": ["Tensor(long int)","GenericList[Tensor(bool)]","Tensor(long int)","Bool"],
      "outputs": [[1095,1096,0,160,8,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 1105, "rf_id": 720, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1076,1077,0,8048640,4,"cuda:0"],[-1,50304]], "input_shapes": [[20,8,50304],[[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int]"],
      "outputs": [[1106,1077,0,8048640,4,"cuda:0"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 1107, "rf_id": 721, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1095,1096,0,160,8,"cuda:0"],[-1]], "input_shapes": [[20,8],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1108,1096,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 1110, "rf_id": 723, "parent": 1109, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],4,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[1111,57,0,0,8,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::resize_", "id": 1113, "rf_id": 725, "parent": 1112, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[1111,57,0,0,8,"cuda:0"],[160],"<None>"], "input_shapes": [[0],[[]],[]], "input_types": ["Tensor(long int)","GenericList[Int]","None"],
      "outputs": [[1111,1090,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 1112, "rf_id": 724, "parent": 1109, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::arange.start_out(Scalar start, Scalar end, Scalar step=1, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [0,160,1,[1111,57,0,0,8,"cuda:0"]], "input_shapes": [[],[],[],[0]], "input_types": ["Int","Int","Int","Tensor(long int)"],
      "outputs": [[1111,1090,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 1109, "rf_id": 722, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::arange.start(Scalar start, Scalar end, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [0,160,"<None>","<None>","cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Int","Int","None","None","Device","Bool"],
      "outputs": [[1111,1090,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 1115, "rf_id": 727, "parent": 1114, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1106,1077,0,8048640,4,"cuda:0"],[160],[0],"<None>"], "input_shapes": [[160,50304],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[1116,1077,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 1118, "rf_id": 729, "parent": 1117, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1111,1090,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1119,1090,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 1117, "rf_id": 728, "parent": 1114, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1111,1090,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1119,1090,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 1121, "rf_id": 731, "parent": 1120, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1108,1096,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1122,1096,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 1120, "rf_id": 730, "parent": 1114, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1108,1096,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1122,1096,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::index", "id": 1114, "rf_id": 726, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::index.Tensor(Tensor self, Tensor?[] indices) -> Tensor",
      "inputs": [[1106,1077,0,8048640,4,"cuda:0"],[[1111,1090,0,160,8,"cuda:0"],[1108,1096,0,160,8,"cuda:0"]]], "input_shapes": [[160,50304],[[160],[160]]], "input_types": ["Tensor(float)","GenericList[Tensor(long int),Tensor(long int)]"],
      "outputs": [[1123,1065,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 1125, "rf_id": 733, "parent": 1124, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[1116,676,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 1126, "rf_id": 734, "parent": 1124, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1116,676,0,160,4,"cuda:0"],[1123,1065,0,160,4,"cuda:0"],false], "input_shapes": [[160],[160],[]], "input_types": ["Tensor(float)","Tensor(float)","Bool"],
      "outputs": [[1116,676,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::clone", "id": 1124, "rf_id": 732, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1123,1065,0,160,4,"cuda:0"],"<None>"], "input_shapes": [[160],[]], "input_types": ["Tensor(float)","None"],
      "outputs": [[1116,676,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 1128, "rf_id": 736, "parent": 1127, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1116,676,0,160,4,"cuda:0"],[20,8]], "input_shapes": [[160],[[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int]"],
      "outputs": [[1119,676,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view_as", "id": 1127, "rf_id": 735, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1116,676,0,160,4,"cuda:0"],[1050,132,0,160,8,"cuda:0"]], "input_shapes": [[160],[20,8]], "input_types": ["Tensor(float)","Tensor(long int)"],
      "outputs": [[1119,676,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::lift_fresh", "id": 1130, "rf_id": 737, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1122,1129,0,1,4,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[1122,1129,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 1134, "rf_id": 741, "parent": 1133, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[1122,1129,0,1,4,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [0.000000], "output_shapes": [[]], "output_types": ["Double"]
    },
    {
      "name": "aten::item", "id": 1133, "rf_id": 740, "parent": 1132, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[1122,1129,0,1,4,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [0.000000], "output_shapes": [[]], "output_types": ["Double"]
    },
    {
      "name": "aten::masked_fill_", "id": 1135, "rf_id": 742, "parent": 1132, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -> Tensor(a!)",
      "inputs": [[1119,676,0,160,4,"cuda:0"],[1085,1086,0,160,1,"cuda:0"],0.000000], "input_shapes": [[20,8],[20,8],[]], "input_types": ["Tensor(float)","Tensor(bool)","Double"],
      "outputs": [[1119,676,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_index_put_impl_", "id": 1132, "rf_id": 739, "parent": 1131, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_index_put_impl_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False, bool unsafe=False) -> Tensor(a!)",
      "inputs": [[1119,676,0,160,4,"cuda:0"],[[1085,1086,0,160,1,"cuda:0"]],[1122,1129,0,1,4,"cpu"],false,false], "input_shapes": [[20,8],[[20,8]],[],[],[]], "input_types": ["Tensor(float)","GenericList[Tensor(bool)]","Tensor(float)","Bool","Bool"],
      "outputs": [[1119,676,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::index_put_", "id": 1131, "rf_id": 738, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -> Tensor(a!)",
      "inputs": [[1119,676,0,160,4,"cuda:0"],[[1085,1086,0,160,1,"cuda:0"]],[1122,1129,0,1,4,"cpu"],false], "input_shapes": [[20,8],[[20,8]],[],[]], "input_types": ["Tensor(float)","GenericList[Tensor(bool)]","Tensor(float)","Bool"],
      "outputs": [[1119,676,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "nccl:all_reduce", "id": 1138, "rf_id": 745, "parent": 1137, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1119,676,0,160,4,"cuda:0"]], "input_shapes": [[20,8]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 1137, "rf_id": 744, "parent": 1136, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[1119,676,0,160,4,"cuda:0"]],20,93827882282480,0,"allreduce",[],[],1], "input_shapes": [[[20,8]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[1119,676,0,160,4,"cuda:0"]]], "output_shapes": [[[20,8]]], "output_types": ["GenericList[Tensor(float)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 1136, "rf_id": 743, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[1119,676,0,160,4,"cuda:0"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[20,8]],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Object","Object","None","Int"],
      "outputs": [[[1119,676,0,160,4,"cuda:0"]],"<Object>"], "output_shapes": [[[20,8]],[]], "output_types": ["GenericList[Tensor(float)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 1139, "rf_id": 746, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [20,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::exp", "id": 1140, "rf_id": 747, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::exp.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[1076,1077,0,8048640,4,"cuda:0"],[1076,1077,0,8048640,4,"cuda:0"]], "input_shapes": [[20,8,50304],[20,8,50304]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[1076,1077,0,8048640,4,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1143, "rf_id": 749, "parent": 1141, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1142,1065,0,160,4,"cuda:0"],[20,8,1],[8,1,0],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1144,1065,0,160,4,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sum", "id": 1141, "rf_id": 748, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1076,1077,0,8048640,4,"cuda:0"],[-1],false,"<None>"], "input_shapes": [[20,8,50304],[[]],[],[]], "input_types": ["Tensor(float)","GenericList[Int]","Bool","None"],
      "outputs": [[1142,1065,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "nccl:all_reduce", "id": 1147, "rf_id": 752, "parent": 1146, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1142,1065,0,160,4,"cuda:0"]], "input_shapes": [[20,8]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 1146, "rf_id": 751, "parent": 1145, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[1142,1065,0,160,4,"cuda:0"]],21,93827882282480,0,"allreduce",[],[],1], "input_shapes": [[[20,8]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[1142,1065,0,160,4,"cuda:0"]]], "output_shapes": [[[20,8]]], "output_types": ["GenericList[Tensor(float)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 1145, "rf_id": 750, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[1142,1065,0,160,4,"cuda:0"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[20,8]],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Object","Object","None","Int"],
      "outputs": [[[1142,1065,0,160,4,"cuda:0"]],"<Object>"], "output_shapes": [[[20,8]],[]], "output_types": ["GenericList[Tensor(float)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 1148, "rf_id": 753, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [21,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::log", "id": 1149, "rf_id": 754, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::log(Tensor self) -> Tensor",
      "inputs": [[1142,1065,0,160,4,"cuda:0"]], "input_shapes": [[20,8]], "input_types": ["Tensor(float)"],
      "outputs": [[1150,1151,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sub", "id": 1152, "rf_id": 755, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1150,1151,0,160,4,"cuda:0"],[1119,676,0,160,4,"cuda:0"],1], "input_shapes": [[20,8],[20,8],[]], "input_types": ["Tensor(float)","Tensor(float)","Int"],
      "outputs": [[1153,1154,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1156, "rf_id": 757, "parent": 1155, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1142,1065,0,160,4,"cuda:0"],[20,8,1],[8,1,1],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1157,1065,0,160,4,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::unsqueeze", "id": 1155, "rf_id": 756, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[1142,1065,0,160,4,"cuda:0"],-1], "input_shapes": [[20,8],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[1157,1065,0,160,4,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::div_", "id": 1158, "rf_id": 758, "parent": 1058, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[1076,1077,0,8048640,4,"cuda:0"],[1157,1065,0,160,4,"cuda:0"]], "input_shapes": [[20,8,50304],[20,8,1]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[1076,1077,0,8048640,4,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "_VocabParallelCrossEntropy", "id": 1058, "rf_id": 695, "parent": 2, "fw_parent": 0, "seq_id": 463, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1055,1056,0,8048640,4,"cuda:0"],[1050,132,0,160,8,"cuda:0"]], "input_shapes": [[20,8,50304],[20,8]], "input_types": ["Tensor(float)","Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1160, "rf_id": 760, "parent": 1159, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1153,1154,0,160,4,"cuda:0"],[8,20],[1,8],"<None>"], "input_shapes": [[20,8],[[],[]],[[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1161,1154,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::transpose", "id": 1159, "rf_id": 759, "parent": 2, "fw_parent": 0, "seq_id": 464, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1153,1154,0,160,4,"cuda:0"],0,1], "input_shapes": [[20,8],[],[]], "input_types": ["Tensor(float)","Int","Int"],
      "outputs": [[1161,1154,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 1165, "rf_id": 764, "parent": 1164, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],6,0,"cuda:0","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[1166,1090,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 1164, "rf_id": 763, "parent": 1163, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1161,1154,0,160,4,"cuda:0"],6,0,"cuda:0","<None>",0], "input_shapes": [[8,20],[],[],[],[],[]], "input_types": ["Tensor(float)","Int","Int","Device","None","Int"],
      "outputs": [[1166,1090,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 1167, "rf_id": 765, "parent": 1163, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1166,1090,0,160,4,"cuda:0"],[1161,1154,0,160,4,"cuda:0"],false], "input_shapes": [[8,20],[8,20],[]], "input_types": ["Tensor(float)","Tensor(float)","Bool"],
      "outputs": [[1166,1090,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::clone", "id": 1163, "rf_id": 762, "parent": 1162, "fw_parent": 0, "seq_id": 465, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1161,1154,0,160,4,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[1166,1090,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::contiguous", "id": 1162, "rf_id": 761, "parent": 2, "fw_parent": 0, "seq_id": 465, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[1161,1154,0,160,4,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[1166,1090,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "detach", "id": 1170, "rf_id": 768, "parent": 1169, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1166,1090,0,160,4,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1169, "rf_id": 767, "parent": 1168, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1166,1090,0,160,4,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(float)"],
      "outputs": [[1144,1090,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1168, "rf_id": 766, "parent": 2, "fw_parent": 0, "seq_id": 466, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1166,1090,0,160,4,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1173, "rf_id": 771, "parent": 1172, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1025,840,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1172, "rf_id": 770, "parent": 1171, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1025,840,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1174,840,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1171, "rf_id": 769, "parent": 2, "fw_parent": 0, "seq_id": 467, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1025,840,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 1176, "rf_id": 772, "parent": 2, "fw_parent": 0, "seq_id": 468, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1174,840,0,1,2,"cuda:0"],[1063,1175,0,1,8,"cpu"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[1177,1178,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1181, "rf_id": 773, "parent": 2, "fw_parent": 0, "seq_id": 469, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1177,1178,0,1,2,"cuda:0"],[1179,1180,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1182,1183,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 1184, "rf_id": 774, "parent": 2, "fw_parent": 0, "seq_id": 470, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1144,1090,0,160,4,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[8,20],[],[],[],[]], "input_types": ["Tensor(float)","Int","Bool","Bool","None"],
      "outputs": [[1144,1090,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 1185, "rf_id": 775, "parent": 2, "fw_parent": 0, "seq_id": 470, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[197,198,0,160,4,"cuda:0"],[-1]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(float)","GenericList[Int]"],
      "outputs": [[1186,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 1187, "rf_id": 776, "parent": 2, "fw_parent": 0, "seq_id": 470, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1186,198,0,160,4,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[160],[],[],[],[]], "input_types": ["Tensor(float)","Int","Bool","Bool","None"],
      "outputs": [[1186,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 1188, "rf_id": 777, "parent": 2, "fw_parent": 0, "seq_id": 470, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1144,1090,0,160,4,"cuda:0"],[-1]], "input_shapes": [[8,20],[[]]], "input_types": ["Tensor(float)","GenericList[Int]"],
      "outputs": [[1189,1090,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul", "id": 1190, "rf_id": 778, "parent": 2, "fw_parent": 0, "seq_id": 471, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1189,1090,0,160,4,"cuda:0"],[1186,198,0,160,4,"cuda:0"]], "input_shapes": [[160],[160]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[1191,171,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1196, "rf_id": 781, "parent": 1193, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1194,1195,0,1,4,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[1197,1195,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sum", "id": 1193, "rf_id": 780, "parent": 1192, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1191,171,0,160,4,"cuda:0"],[],false,"<None>"], "input_shapes": [[160],[],[],[]], "input_types": ["Tensor(float)","GenericList[]","Bool","None"],
      "outputs": [[1194,1195,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sum", "id": 1192, "rf_id": 779, "parent": 2, "fw_parent": 0, "seq_id": 472, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum(Tensor self, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1191,171,0,160,4,"cuda:0"],"<None>"], "input_shapes": [[160],[]], "input_types": ["Tensor(float)","None"],
      "outputs": [[1194,1195,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1201, "rf_id": 784, "parent": 1199, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1200,1178,0,1,4,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[1202,1178,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sum", "id": 1199, "rf_id": 783, "parent": 1198, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1186,198,0,160,4,"cuda:0"],[],false,"<None>"], "input_shapes": [[160],[],[],[]], "input_types": ["Tensor(float)","GenericList[]","Bool","None"],
      "outputs": [[1200,1178,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sum", "id": 1198, "rf_id": 782, "parent": 2, "fw_parent": 0, "seq_id": 473, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum(Tensor self, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1186,198,0,160,4,"cuda:0"],"<None>"], "input_shapes": [[160],[]], "input_types": ["Tensor(float)","None"],
      "outputs": [[1200,1178,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::div", "id": 1203, "rf_id": 785, "parent": 2, "fw_parent": 0, "seq_id": 473, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1194,1195,0,1,4,"cuda:0"],[1200,1178,0,1,4,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[1202,840,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 1205, "rf_id": 787, "parent": 1204, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],6,0,"cuda:0","<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","None"],
      "outputs": [[1197,171,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 1206, "rf_id": 788, "parent": 1204, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1197,171,0,1,4,"cuda:0"],[1202,840,0,1,4,"cuda:0"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(float)","Bool"],
      "outputs": [[1197,171,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::clone", "id": 1204, "rf_id": 786, "parent": 2, "fw_parent": 0, "seq_id": 474, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1202,840,0,1,4,"cuda:0"],"<None>"], "input_shapes": [[],[]], "input_types": ["Tensor(float)","None"],
      "outputs": [[1197,171,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "detach", "id": 1208, "rf_id": 790, "parent": 1207, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1197,171,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1207, "rf_id": 789, "parent": 2, "fw_parent": 0, "seq_id": 475, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1197,171,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[1209,171,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 1210, "rf_id": 791, "parent": 2, "fw_parent": 0, "seq_id": 475, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1209,171,0,1,4,"cuda:0"],[1]], "input_shapes": [[],[[]]], "input_types": ["Tensor(float)","GenericList[Int]"],
      "outputs": [[1211,171,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1217, "rf_id": 795, "parent": 1216, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1213,1214,0,1,4,"cuda:0"],[1],[1],0], "input_shapes": [[1],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1218,1214,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::slice", "id": 1216, "rf_id": 794, "parent": 1215, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1213,1214,0,1,4,"cuda:0"],0,0,1,1], "input_shapes": [[1],[],[],[],[]], "input_types": ["Tensor(float)","Int","Int","Int","Int"],
      "outputs": [[1218,1214,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::narrow", "id": 1215, "rf_id": 793, "parent": 1212, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1213,1214,0,1,4,"cuda:0"],0,0,1], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(float)","Int","Int","Int"],
      "outputs": [[1218,1214,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::cat", "id": 1212, "rf_id": 792, "parent": 2, "fw_parent": 0, "seq_id": 475, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[1211,171,0,1,4,"cuda:0"]],0], "input_shapes": [[[1]],[]], "input_types": ["GenericList[Tensor(float)]","Int"],
      "outputs": [[1213,1214,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "nccl:all_reduce", "id": 1221, "rf_id": 798, "parent": 1220, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[1213,1214,0,1,4,"cuda:0"]], "input_shapes": [[1]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 1220, "rf_id": 797, "parent": 1219, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[1213,1214,0,1,4,"cuda:0"]],127,93827882276192,0,"allreduce",[],[],4], "input_shapes": [[[1]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[1213,1214,0,1,4,"cuda:0"]]], "output_shapes": [[[1]]], "output_types": ["GenericList[Tensor(float)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 1219, "rf_id": 796, "parent": 2, "fw_parent": 0, "seq_id": 475, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[1213,1214,0,1,4,"cuda:0"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[1]],[],[],[],[]], "input_types": ["GenericList[Tensor(float)]","Object","Object","None","Int"],
      "outputs": [[[1213,1214,0,1,4,"cuda:0"]],"<Object>"], "output_shapes": [[[1]],[]], "output_types": ["GenericList[Tensor(float)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 1222, "rf_id": 799, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [127,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::div", "id": 1225, "rf_id": 800, "parent": 2, "fw_parent": 0, "seq_id": 475, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1213,1214,0,1,4,"cuda:0"],[1223,1224,0,1,8,"cpu"]], "input_shapes": [[1],[]], "input_types": ["Tensor(float)","Tensor(long int)"],
      "outputs": [[1226,171,0,1,4,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1228, "rf_id": 802, "parent": 1227, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1226,171,0,1,4,"cuda:0"],[],[],0], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(float)","GenericList[]","GenericList[]","Int"],
      "outputs": [[1218,171,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::select", "id": 1227, "rf_id": 801, "parent": 2, "fw_parent": 0, "seq_id": 475, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[1226,171,0,1,4,"cuda:0"],0,0], "input_shapes": [[1],[],[]], "input_types": ["Tensor(float)","Int","Int"],
      "outputs": [[1218,171,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1231, "rf_id": 805, "parent": 1230, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1182,1195,0,1,4,"cuda:0"],[],[],"<None>"], "input_shapes": [[],[],[],[]], "input_types": ["Tensor(float)","GenericList[]","GenericList[]","None"],
      "outputs": [[1232,1195,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mean", "id": 1230, "rf_id": 804, "parent": 1229, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mean.dim(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1202,840,0,1,4,"cuda:0"],[],false,"<None>"], "input_shapes": [[],[],[],[]], "input_types": ["Tensor(float)","GenericList[]","Bool","None"],
      "outputs": [[1182,1195,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mean", "id": 1229, "rf_id": 803, "parent": 2, "fw_parent": 0, "seq_id": 475, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mean(Tensor self, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1202,840,0,1,4,"cuda:0"],"<None>"], "input_shapes": [[],[]], "input_types": ["Tensor(float)","None"],
      "outputs": [[1182,1195,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 1234, "rf_id": 807, "parent": 1233, "fw_parent": 0, "seq_id": 476, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[1182,1195,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [10.858075], "output_shapes": [[]], "output_types": ["Double"]
    },
    {
      "name": "aten::item", "id": 1233, "rf_id": 806, "parent": 2, "fw_parent": 0, "seq_id": 476, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[1182,1195,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [10.858075], "output_shapes": [[]], "output_types": ["Double"]
    },
    {
      "name": "aten::to", "id": 1235, "rf_id": 808, "parent": 2, "fw_parent": 0, "seq_id": 476, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1202,840,0,1,4,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(float)","Int","Bool","Bool","None"],
      "outputs": [[1202,840,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul", "id": 1237, "rf_id": 809, "parent": 2, "fw_parent": 0, "seq_id": 476, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1202,840,0,1,4,"cuda:0"],[1232,1236,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[1238,1183,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 1241, "rf_id": 812, "parent": 1240, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],6,0,"cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[1242,1214,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 1240, "rf_id": 811, "parent": 1239, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1238,1183,0,1,4,"cuda:0"],"<None>","<None>","<None>",false,1], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","Bool","Int"],
      "outputs": [[1242,1214,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::fill_", "id": 1243, "rf_id": 813, "parent": 1239, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1242,1214,0,1,4,"cuda:0"],1.000000], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Double"],
      "outputs": [[1242,1214,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::ones_like", "id": 1239, "rf_id": 810, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ones_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1238,1183,0,1,4,"cuda:0"],"<None>","<None>","<None>",false,1], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","Bool","Int"],
      "outputs": [[1242,1214,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "[pytorch|profiler|execution_trace|thread]", "id": 1244, "rf_id": 0, "parent": 1, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::mul", "id": 1247, "rf_id": 816, "parent": 1246, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1242,1214,0,1,4,"cuda:0"],[1232,1236,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[1248,1195,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "MulBackward0", "id": 1246, "rf_id": 815, "parent": 1245, "fw_parent": 2, "seq_id": 476, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1242,1214,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: MulBackward0", "id": 1245, "rf_id": 814, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::div", "id": 1251, "rf_id": 819, "parent": 1250, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::div.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1248,1195,0,1,4,"cuda:0"],[1200,1178,0,1,4,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[1252,1090,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "DivBackward0", "id": 1250, "rf_id": 818, "parent": 1249, "fw_parent": 2, "seq_id": 473, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1248,1195,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: DivBackward0", "id": 1249, "rf_id": 817, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1256, "rf_id": 823, "parent": 1255, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1252,1090,0,1,4,"cuda:0"],[160],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[1257,1090,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::expand", "id": 1255, "rf_id": 822, "parent": 1254, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)",
      "inputs": [[1252,1090,0,1,4,"cuda:0"],[160],false], "input_shapes": [[],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","Bool"],
      "outputs": [[1257,1090,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "SumBackward0", "id": 1254, "rf_id": 821, "parent": 1253, "fw_parent": 2, "seq_id": 472, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1252,1090,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SumBackward0", "id": 1253, "rf_id": 820, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::mul", "id": 1260, "rf_id": 826, "parent": 1259, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1257,1090,0,160,4,"cuda:0"],[1186,198,0,160,4,"cuda:0"]], "input_shapes": [[160],[160]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[1261,1262,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "MulBackward0", "id": 1259, "rf_id": 825, "parent": 1258, "fw_parent": 2, "seq_id": 471, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1257,1090,0,160,4,"cuda:0"]], "input_shapes": [[160]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: MulBackward0", "id": 1258, "rf_id": 824, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1266, "rf_id": 830, "parent": 1265, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1261,1262,0,160,4,"cuda:0"],[8,20]], "input_shapes": [[160],[[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int]"],
      "outputs": [[1267,1262,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::reshape", "id": 1265, "rf_id": 829, "parent": 1264, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1261,1262,0,160,4,"cuda:0"],[8,20]], "input_shapes": [[160],[[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int]"],
      "outputs": [[1267,1262,0,160,4,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "ViewBackward0", "id": 1264, "rf_id": 828, "parent": 1263, "fw_parent": 2, "seq_id": 470, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1261,1262,0,160,4,"cuda:0"]], "input_shapes": [[160]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 1263, "rf_id": 827, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 1269, "rf_id": 832, "parent": 1268, "fw_parent": 2, "seq_id": 466, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1267,1262,0,160,4,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 1268, "rf_id": 831, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "CloneBackward0", "id": 1271, "rf_id": 834, "parent": 1270, "fw_parent": 2, "seq_id": 465, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1267,1262,0,160,4,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: CloneBackward0", "id": 1270, "rf_id": 833, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1275, "rf_id": 838, "parent": 1274, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1267,1262,0,160,4,"cuda:0"],[20,8],[1,20],"<None>"], "input_shapes": [[8,20],[[],[]],[[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1276,1262,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::transpose", "id": 1274, "rf_id": 837, "parent": 1273, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1267,1262,0,160,4,"cuda:0"],0,1], "input_shapes": [[8,20],[],[]], "input_types": ["Tensor(float)","Int","Int"],
      "outputs": [[1276,1262,0,160,4,"cuda:0"]], "output_shapes": [[20,8]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "TransposeBackward0", "id": 1273, "rf_id": 836, "parent": 1272, "fw_parent": 2, "seq_id": 464, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1267,1262,0,160,4,"cuda:0"]], "input_shapes": [[8,20]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 1272, "rf_id": 835, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1279, "rf_id": 841, "parent": 1278, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1076,1077,0,8048640,4,"cuda:0"],[-1,50304]], "input_shapes": [[20,8,50304],[[],[]]], "input_types": ["Tensor(float)","GenericList[Int,Int]"],
      "outputs": [[1280,1077,0,8048640,4,"cuda:0"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 1282, "rf_id": 843, "parent": 1281, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],4,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[1283,57,0,0,8,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::resize_", "id": 1285, "rf_id": 845, "parent": 1284, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[1283,57,0,0,8,"cuda:0"],[160],"<None>"], "input_shapes": [[0],[[]],[]], "input_types": ["Tensor(long int)","GenericList[Int]","None"],
      "outputs": [[1283,132,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 1284, "rf_id": 844, "parent": 1281, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::arange.start_out(Scalar start, Scalar end, Scalar step=1, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [0,160,1,[1283,57,0,0,8,"cuda:0"]], "input_shapes": [[],[],[],[0]], "input_types": ["Int","Int","Int","Tensor(long int)"],
      "outputs": [[1283,132,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::arange", "id": 1281, "rf_id": 842, "parent": 1278, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::arange.start(Scalar start, Scalar end, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [0,160,"<None>","<None>","cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Int","Int","None","None","Device","Bool"],
      "outputs": [[1283,132,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 1286, "rf_id": 846, "parent": 1278, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1085,1086,0,160,1,"cuda:0"],[-1]], "input_shapes": [[20,8],[[]]], "input_types": ["Tensor(bool)","GenericList[Int]"],
      "outputs": [[1287,1086,0,160,1,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 1290, "rf_id": 849, "parent": 1289, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[1291,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 1292, "rf_id": 850, "parent": 1289, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1291,198,0,160,4,"cuda:0"],[1287,1086,0,160,1,"cuda:0"],false], "input_shapes": [[160],[160],[]], "input_types": ["Tensor(float)","Tensor(bool)","Bool"],
      "outputs": [[1291,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 1289, "rf_id": 848, "parent": 1288, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1287,1086,0,160,1,"cuda:0"],6,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[160],[],[],[],[],[],[]], "input_types": ["Tensor(bool)","Int","None","None","None","Bool","None"],
      "outputs": [[1291,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 1288, "rf_id": 847, "parent": 1278, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1287,1086,0,160,1,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[160],[],[],[],[]], "input_types": ["Tensor(bool)","Int","Bool","Bool","None"],
      "outputs": [[1291,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sub", "id": 1296, "rf_id": 852, "parent": 1293, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1294,1295,0,1,8,"cpu"],[1291,198,0,160,4,"cuda:0"],1], "input_shapes": [[],[160],[]], "input_types": ["Tensor(double)","Tensor(float)","Int"],
      "outputs": [[1297,1061,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::rsub", "id": 1293, "rf_id": 851, "parent": 1278, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::rsub.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[1291,198,0,160,4,"cuda:0"],1.000000,1], "input_shapes": [[160],[],[]], "input_types": ["Tensor(float)","Double","Int"],
      "outputs": [[1297,1061,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1299, "rf_id": 854, "parent": 1298, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1280,1077,0,8048640,4,"cuda:0"],[160],[0],"<None>"], "input_shapes": [[160,50304],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[1300,1077,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 1302, "rf_id": 856, "parent": 1301, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1283,132,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1303,132,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 1301, "rf_id": 855, "parent": 1298, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1283,132,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1303,132,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 1305, "rf_id": 858, "parent": 1304, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1108,1096,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1306,1096,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 1304, "rf_id": 857, "parent": 1298, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1108,1096,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1306,1096,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::index", "id": 1298, "rf_id": 853, "parent": 1278, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::index.Tensor(Tensor self, Tensor?[] indices) -> Tensor",
      "inputs": [[1280,1077,0,8048640,4,"cuda:0"],[[1283,132,0,160,8,"cuda:0"],[1108,1096,0,160,8,"cuda:0"]]], "input_shapes": [[160,50304],[[160],[160]]], "input_types": ["Tensor(float)","GenericList[Tensor(long int),Tensor(long int)]"],
      "outputs": [[1307,1065,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::sub_", "id": 1308, "rf_id": 859, "parent": 1278, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sub_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)",
      "inputs": [[1307,1065,0,160,4,"cuda:0"],[1297,1061,0,160,4,"cuda:0"],1], "input_shapes": [[160],[160],[]], "input_types": ["Tensor(float)","Tensor(float)","Int"],
      "outputs": [[1307,1065,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1311, "rf_id": 862, "parent": 1310, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1280,1077,0,8048640,4,"cuda:0"],[160],[0],"<None>"], "input_shapes": [[160,50304],[[]],[[]],[]], "input_types": ["Tensor(float)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[1300,1077,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::view", "id": 1313, "rf_id": 864, "parent": 1312, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1283,132,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1303,132,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 1312, "rf_id": 863, "parent": 1310, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1283,132,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1303,132,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::view", "id": 1315, "rf_id": 866, "parent": 1314, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1108,1096,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1306,1096,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::reshape", "id": 1314, "rf_id": 865, "parent": 1310, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1108,1096,0,160,8,"cuda:0"],[160]], "input_shapes": [[160],[[]]], "input_types": ["Tensor(long int)","GenericList[Int]"],
      "outputs": [[1306,1096,0,160,8,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_index_put_impl_", "id": 1310, "rf_id": 861, "parent": 1309, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_index_put_impl_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False, bool unsafe=False) -> Tensor(a!)",
      "inputs": [[1280,1077,0,8048640,4,"cuda:0"],[[1283,132,0,160,8,"cuda:0"],[1108,1096,0,160,8,"cuda:0"]],[1307,1065,0,160,4,"cuda:0"],false,false], "input_shapes": [[160,50304],[[160],[160]],[160],[],[]], "input_types": ["Tensor(float)","GenericList[Tensor(long int),Tensor(long int)]","Tensor(float)","Bool","Bool"],
      "outputs": [[1280,1077,0,8048640,4,"cuda:0"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::index_put_", "id": 1309, "rf_id": 860, "parent": 1278, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -> Tensor(a!)",
      "inputs": [[1280,1077,0,8048640,4,"cuda:0"],[[1283,132,0,160,8,"cuda:0"],[1108,1096,0,160,8,"cuda:0"]],[1307,1065,0,160,4,"cuda:0"],false], "input_shapes": [[160,50304],[[160],[160]],[160],[]], "input_types": ["Tensor(float)","GenericList[Tensor(long int),Tensor(long int)]","Tensor(float)","Bool"],
      "outputs": [[1280,1077,0,8048640,4,"cuda:0"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::as_strided", "id": 1317, "rf_id": 868, "parent": 1316, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1276,1262,0,160,4,"cuda:0"],[20,8,1],[1,20,1],"<None>"], "input_shapes": [[20,8],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(float)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1300,1262,0,160,4,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::unsqueeze", "id": 1316, "rf_id": 867, "parent": 1278, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[1276,1262,0,160,4,"cuda:0"],-1], "input_shapes": [[20,8],[]], "input_types": ["Tensor(float)","Int"],
      "outputs": [[1300,1262,0,160,4,"cuda:0"]], "output_shapes": [[20,8,1]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul_", "id": 1318, "rf_id": 869, "parent": 1278, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[1076,1077,0,8048640,4,"cuda:0"],[1300,1262,0,160,4,"cuda:0"]], "input_shapes": [[20,8,50304],[20,8,1]], "input_types": ["Tensor(float)","Tensor(float)"],
      "outputs": [[1076,1077,0,8048640,4,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "_VocabParallelCrossEntropyBackward", "id": 1278, "rf_id": 840, "parent": 1277, "fw_parent": 2, "seq_id": 463, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1276,1262,0,160,4,"cuda:0"]], "input_shapes": [[20,8]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _VocabParallelCrossEntropyBackward", "id": 1277, "rf_id": 839, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 1323, "rf_id": 874, "parent": 1322, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,50304],[402432,50304,1],15,0,"cuda:0",false], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","Bool"],
      "outputs": [[1306,904,0,8048640,2,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1324, "rf_id": 875, "parent": 1322, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1306,904,0,8048640,2,"cuda:0"],[1076,1077,0,8048640,4,"cuda:0"],false], "input_shapes": [[20,8,50304],[20,8,50304],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(float)","Bool"],
      "outputs": [[1306,904,0,8048640,2,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_to_copy", "id": 1322, "rf_id": 873, "parent": 1321, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1076,1077,0,8048640,4,"cuda:0"],15,0,"cuda:0","<None>",false,"<None>"], "input_shapes": [[20,8,50304],[],[],[],[],[],[]], "input_types": ["Tensor(float)","Int","Int","Device","None","Bool","None"],
      "outputs": [[1306,904,0,8048640,2,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 1321, "rf_id": 872, "parent": 1320, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1076,1077,0,8048640,4,"cuda:0"],15,0,"cuda:0","<None>",false,false,"<None>"], "input_shapes": [[20,8,50304],[],[],[],[],[],[],[]], "input_types": ["Tensor(float)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[1306,904,0,8048640,2,"cuda:0"]], "output_shapes": [[20,8,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ToCopyBackward0", "id": 1320, "rf_id": 871, "parent": 1319, "fw_parent": 2, "seq_id": 462, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1076,1077,0,8048640,4,"cuda:0"]], "input_shapes": [[20,8,50304]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ToCopyBackward0", "id": 1319, "rf_id": 870, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1329, "rf_id": 880, "parent": 1328, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1306,904,0,8048640,2,"cuda:0"],[160,50304]], "input_shapes": [[20,8,50304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1303,904,0,8048640,2,"cuda:0"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1328, "rf_id": 879, "parent": 1327, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1306,904,0,8048640,2,"cuda:0"],[160,50304]], "input_shapes": [[20,8,50304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1303,904,0,8048640,2,"cuda:0"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1330, "rf_id": 881, "parent": 1327, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1303,904,0,8048640,2,"cuda:0"],[251,237,0,51511296,2,"cuda:0"]], "input_shapes": [[160,50304],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1331,329,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1332, "rf_id": 882, "parent": 1327, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1331,329,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1333,329,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1327, "rf_id": 878, "parent": 1326, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1306,904,0,8048640,2,"cuda:0"],[251,237,0,51511296,2,"cuda:0"]], "input_shapes": [[20,8,50304],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1333,329,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1334, "rf_id": 883, "parent": 1326, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1306,904,0,8048640,2,"cuda:0"],[160,50304]], "input_shapes": [[20,8,50304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1335,904,0,8048640,2,"cuda:0"]], "output_shapes": [[160,50304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1336, "rf_id": 884, "parent": 1326, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1029,430,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1337,430,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1340, "rf_id": 887, "parent": 1339, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1335,904,0,8048640,2,"cuda:0"],[50304,160],[1,50304],"<None>"], "input_shapes": [[160,50304],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1341,904,0,8048640,2,"cuda:0"]], "output_shapes": [[50304,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1339, "rf_id": 886, "parent": 1338, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1335,904,0,8048640,2,"cuda:0"],0,1], "input_shapes": [[160,50304],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1341,904,0,8048640,2,"cuda:0"]], "output_shapes": [[50304,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1338, "rf_id": 885, "parent": 1326, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1335,904,0,8048640,2,"cuda:0"]], "input_shapes": [[160,50304]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1341,904,0,8048640,2,"cuda:0"]], "output_shapes": [[50304,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1343, "rf_id": 889, "parent": 1342, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1341,904,0,8048640,2,"cuda:0"],[1337,430,0,163840,2,"cuda:0"]], "input_shapes": [[50304,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1344,1077,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1342, "rf_id": 888, "parent": 1326, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1341,904,0,8048640,2,"cuda:0"],[1337,430,0,163840,2,"cuda:0"]], "input_shapes": [[50304,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1344,1077,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 1326, "rf_id": 877, "parent": 1325, "fw_parent": 2, "seq_id": 461, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1306,904,0,8048640,2,"cuda:0"]], "input_shapes": [[20,8,50304]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 1325, "rf_id": 876, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_CopyToModelParallelRegionBackward", "id": 1346, "rf_id": 891, "parent": 1345, "fw_parent": 2, "seq_id": 460, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1333,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _CopyToModelParallelRegionBackward", "id": 1345, "rf_id": 890, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 1348, "rf_id": 893, "parent": 1347, "fw_parent": 2, "seq_id": 458, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1333,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 1347, "rf_id": 892, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 1350, "rf_id": 895, "parent": 1349, "fw_parent": 2, "seq_id": 456, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1333,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 1349, "rf_id": 894, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 1352, "rf_id": 897, "parent": 1351, "fw_parent": 2, "seq_id": 455, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1333,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 1351, "rf_id": 896, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 1357, "rf_id": 901, "parent": 1356, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1358,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1356, "rf_id": 900, "parent": 1354, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1355,430,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1358,359,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1360, "rf_id": 903, "parent": 1359, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[1361,1061,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1359, "rf_id": 902, "parent": 1354, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[993,994,0,1024,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1361,1061,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1363, "rf_id": 905, "parent": 1362, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[1364,1086,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1362, "rf_id": 904, "parent": 1354, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[995,996,0,1024,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1364,1086,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1365, "rf_id": 906, "parent": 1354, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[16,1024],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1366,676,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 1368, "rf_id": 908, "parent": 1367, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[16,1024],[1024,1],6,0,"cuda:0","<None>"], "input_shapes": [[[],[]],[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[1369,1370,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 1367, "rf_id": 907, "parent": 1354, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1366,676,0,16384,4,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[16,1024],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[1369,1370,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunctionBackward", "id": 1354, "rf_id": 899, "parent": 1353, "fw_parent": 2, "seq_id": 454, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1333,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: FusedLayerNormAffineFunctionBackward", "id": 1353, "rf_id": 898, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1374, "rf_id": 912, "parent": 1373, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1361,1061,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1373, "rf_id": 911, "parent": 1372, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1361,1061,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1375,1061,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 1372, "rf_id": 910, "parent": 1371, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1361,1061,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1380, "rf_id": 915, "parent": 1379, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],[1024],[1],0], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1005,1377,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1379, "rf_id": 914, "parent": 1378, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,0,1024,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1005,1377,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 1378, "rf_id": 913, "parent": 1371, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,0,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1005,1377,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1382, "rf_id": 917, "parent": 1381, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1005,1377,0,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1383,1377,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1381, "rf_id": 916, "parent": 1371, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1005,1377,0,1024,2,"cuda:0"],[1375,1061,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1383,1377,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1384, "rf_id": 918, "parent": 1371, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1383,1377,0,1024,2,"cuda:0"],[1375,1061,0,1024,2,"cuda:0"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1383,1377,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 1385, "rf_id": 919, "parent": 1371, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1375,1061,0,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1386, "rf_id": 920, "parent": 1371, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[1375,1061,0,1024,2,"cuda:0"],[1383,1377,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 1371, "rf_id": 909, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1390, "rf_id": 924, "parent": 1389, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1364,1086,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1389, "rf_id": 923, "parent": 1388, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1364,1086,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1391,1086,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 1388, "rf_id": 922, "parent": 1387, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1364,1086,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1394, "rf_id": 927, "parent": 1393, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],[1024],[1],1024], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1369,1377,1024,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1393, "rf_id": 926, "parent": 1392, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,1024,2048,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1369,1377,1024,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 1392, "rf_id": 925, "parent": 1387, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,1024,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1369,1377,1024,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1396, "rf_id": 929, "parent": 1395, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1369,1377,1024,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1397,1377,1024,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1395, "rf_id": 928, "parent": 1387, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1369,1377,1024,1024,2,"cuda:0"],[1391,1086,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1397,1377,1024,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1398, "rf_id": 930, "parent": 1387, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1397,1377,1024,1024,2,"cuda:0"],[1391,1086,0,1024,2,"cuda:0"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1397,1377,1024,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 1399, "rf_id": 931, "parent": 1387, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1391,1086,0,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1400, "rf_id": 932, "parent": 1387, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[1391,1086,0,1024,2,"cuda:0"],[1397,1377,1024,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 1387, "rf_id": 921, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 1402, "rf_id": 934, "parent": 1401, "fw_parent": 2, "seq_id": 453, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1358,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 1401, "rf_id": 933, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1407, "rf_id": 938, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","None","None"],
      "outputs": [[1408,1195,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 1410, "rf_id": 940, "parent": 1409, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[1408,1195,0,1,2,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1408,1195,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 1409, "rf_id": 939, "parent": 1406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1408,1195,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1408,1195,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 1406, "rf_id": 937, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],15,0,"cuda:0","<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","None"],
      "outputs": [[1408,1195,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1412, "rf_id": 942, "parent": 1411, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[403,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1411, "rf_id": 941, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[403,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1413,391,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1415, "rf_id": 944, "parent": 1414, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[407,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1414, "rf_id": 943, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[407,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[1416,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "detach", "id": 1419, "rf_id": 947, "parent": 1418, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1413,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1418, "rf_id": 946, "parent": 1417, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1413,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1420,391,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1417, "rf_id": 945, "parent": 1405, "fw_parent": 0, "seq_id": 261, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1413,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1423, "rf_id": 950, "parent": 1422, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1416,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1422, "rf_id": 949, "parent": 1421, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1416,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[1424,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1421, "rf_id": 948, "parent": 1405, "fw_parent": 0, "seq_id": 262, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1416,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1427, "rf_id": 953, "parent": 1426, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1420,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1426, "rf_id": 952, "parent": 1425, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1420,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1428,391,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1425, "rf_id": 951, "parent": 1405, "fw_parent": 0, "seq_id": 263, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1420,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 1431, "rf_id": 956, "parent": 1430, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1432,329,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1430, "rf_id": 955, "parent": 1429, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1428,391,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1432,329,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1433, "rf_id": 957, "parent": 1429, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[160],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[1434,436,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 1436, "rf_id": 959, "parent": 1435, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[1437,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 1435, "rf_id": 958, "parent": 1429, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1434,436,0,160,4,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[160],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[1437,198,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunction", "id": 1429, "rf_id": 954, "parent": 1405, "fw_parent": 0, "seq_id": 264, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1428,391,0,163840,2,"cuda:0"],[422,423,0,1024,2,"cuda:0"],[424,425,0,1024,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1440, "rf_id": 962, "parent": 1439, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1432,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1439, "rf_id": 961, "parent": 1438, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1432,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1441,329,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1438, "rf_id": 960, "parent": 1405, "fw_parent": 0, "seq_id": 265, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1432,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1444, "rf_id": 965, "parent": 1443, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1441,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1443, "rf_id": 964, "parent": 1442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1441,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1445,329,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1442, "rf_id": 963, "parent": 1405, "fw_parent": 0, "seq_id": 266, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1441,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1448, "rf_id": 968, "parent": 1447, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1424,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1447, "rf_id": 967, "parent": 1446, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1424,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[1449,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1446, "rf_id": 966, "parent": 1405, "fw_parent": 0, "seq_id": 267, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1424,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1452, "rf_id": 971, "parent": 1451, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1445,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1451, "rf_id": 970, "parent": 1450, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1445,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1453,329,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1450, "rf_id": 969, "parent": 1405, "fw_parent": 0, "seq_id": 268, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1445,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1456, "rf_id": 974, "parent": 1455, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1453,329,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1457,329,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1455, "rf_id": 973, "parent": 1454, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1453,329,0,163840,2,"cuda:0"],[1453,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1457,329,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_CopyToModelParallelRegion", "id": 1454, "rf_id": 972, "parent": 1405, "fw_parent": 0, "seq_id": 269, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1453,329,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1461, "rf_id": 978, "parent": 1460, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[470,467,0,3145728,2,"cuda:0"],[1024,3072],[1,1024],"<None>"], "input_shapes": [[3072,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1462,467,0,3145728,2,"cuda:0"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1460, "rf_id": 977, "parent": 1459, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[470,467,0,3145728,2,"cuda:0"],0,1], "input_shapes": [[3072,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1462,467,0,3145728,2,"cuda:0"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1459, "rf_id": 976, "parent": 1458, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[470,467,0,3145728,2,"cuda:0"]], "input_shapes": [[3072,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1462,467,0,3145728,2,"cuda:0"]], "output_shapes": [[1024,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1465, "rf_id": 981, "parent": 1464, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1457,329,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1466,329,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1464, "rf_id": 980, "parent": 1463, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1457,329,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1466,329,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1467, "rf_id": 982, "parent": 1463, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1466,329,0,163840,2,"cuda:0"],[1462,467,0,3145728,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1468,578,0,491520,2,"cuda:0"]], "output_shapes": [[160,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1469, "rf_id": 983, "parent": 1463, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1468,578,0,491520,2,"cuda:0"],[20,8,3072]], "input_shapes": [[160,3072],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1470,578,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1463, "rf_id": 979, "parent": 1458, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1457,329,0,163840,2,"cuda:0"],[1462,467,0,3145728,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1470,578,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1471, "rf_id": 984, "parent": 1458, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1470,578,0,491520,2,"cuda:0"],[565,566,0,3072,2,"cuda:0"],1], "input_shapes": [[20,8,3072],[3072],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1472,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 1458, "rf_id": 975, "parent": 1405, "fw_parent": 0, "seq_id": 270, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1457,329,0,163840,2,"cuda:0"],[470,467,0,3145728,2,"cuda:0"],[565,566,0,3072,2,"cuda:0"]], "input_shapes": [[20,8,1024],[3072,1024],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1475, "rf_id": 987, "parent": 1474, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1472,583,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1474, "rf_id": 986, "parent": 1473, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1472,583,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1476,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1473, "rf_id": 985, "parent": 1405, "fw_parent": 0, "seq_id": 271, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1472,583,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1477, "rf_id": 988, "parent": 1405, "fw_parent": 0, "seq_id": 272, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1476,583,0,491520,2,"cuda:0"],[20,8,-1,3,64]], "input_shapes": [[20,8,3072],[[],[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]"],
      "outputs": [[1478,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1480, "rf_id": 990, "parent": 1479, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1478,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1481,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1479, "rf_id": 989, "parent": 1405, "fw_parent": 0, "seq_id": 273, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1478,583,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1481,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1483, "rf_id": 992, "parent": 1482, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1481,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1484,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1482, "rf_id": 991, "parent": 1405, "fw_parent": 0, "seq_id": 274, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1481,583,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1484,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1486, "rf_id": 994, "parent": 1485, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1484,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1487,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1485, "rf_id": 993, "parent": 1405, "fw_parent": 0, "seq_id": 275, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1484,583,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1487,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1489, "rf_id": 996, "parent": 1488, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1487,583,0,491520,2,"cuda:0"],[20,8,16,1,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1490,583,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1488, "rf_id": 995, "parent": 1405, "fw_parent": 0, "seq_id": 276, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1487,583,0,491520,2,"cuda:0"],3,0,-2,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1490,583,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1492, "rf_id": 998, "parent": 1491, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1490,583,0,163840,2,"cuda:0"],[20,8,16,1,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,1,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1493,583,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1491, "rf_id": 997, "parent": 1405, "fw_parent": 0, "seq_id": 277, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1490,583,0,163840,2,"cuda:0"],4,0,9223372036854775807,1], "input_shapes": [[20,8,16,1,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1493,583,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_reshape_alias", "id": 1495, "rf_id": 1000, "parent": 1494, "fw_parent": 0, "seq_id": 278, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[1493,583,0,163840,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1]], "input_shapes": [[20,8,16,1,64],[[],[],[],[]],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1496,583,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1494, "rf_id": 999, "parent": 1405, "fw_parent": 0, "seq_id": 278, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1493,583,0,163840,2,"cuda:0"],[20,8,-1,64]], "input_shapes": [[20,8,16,1,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1496,583,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1498, "rf_id": 1002, "parent": 1497, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1478,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1499,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1497, "rf_id": 1001, "parent": 1405, "fw_parent": 0, "seq_id": 279, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1478,583,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1499,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1501, "rf_id": 1004, "parent": 1500, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1499,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1502,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1500, "rf_id": 1003, "parent": 1405, "fw_parent": 0, "seq_id": 280, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1499,583,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1502,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1504, "rf_id": 1006, "parent": 1503, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1502,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1505,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1503, "rf_id": 1005, "parent": 1405, "fw_parent": 0, "seq_id": 281, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1502,583,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1505,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1507, "rf_id": 1008, "parent": 1506, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1505,583,0,491520,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],64], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[1508,583,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 1506, "rf_id": 1007, "parent": 1405, "fw_parent": 0, "seq_id": 282, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[1505,583,0,491520,2,"cuda:0"],3,-2], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1508,583,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1510, "rf_id": 1010, "parent": 1509, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1508,583,64,163840,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],64], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[1511,583,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1509, "rf_id": 1009, "parent": 1405, "fw_parent": 0, "seq_id": 283, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1508,583,64,163840,2,"cuda:0"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1511,583,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1513, "rf_id": 1012, "parent": 1512, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1478,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1514,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1512, "rf_id": 1011, "parent": 1405, "fw_parent": 0, "seq_id": 284, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1478,583,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1514,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1516, "rf_id": 1014, "parent": 1515, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1514,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1517,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1515, "rf_id": 1013, "parent": 1405, "fw_parent": 0, "seq_id": 285, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1514,583,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1517,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1519, "rf_id": 1016, "parent": 1518, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1517,583,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[1520,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1518, "rf_id": 1015, "parent": 1405, "fw_parent": 0, "seq_id": 286, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1517,583,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1520,583,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1522, "rf_id": 1018, "parent": 1521, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1520,583,0,491520,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],128], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[1523,583,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 1521, "rf_id": 1017, "parent": 1405, "fw_parent": 0, "seq_id": 287, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[1520,583,0,491520,2,"cuda:0"],3,-1], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1523,583,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1525, "rf_id": 1020, "parent": 1524, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1523,583,128,163840,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],128], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[1526,583,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1524, "rf_id": 1019, "parent": 1405, "fw_parent": 0, "seq_id": 288, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1523,583,128,163840,2,"cuda:0"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1526,583,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1529, "rf_id": 1023, "parent": 1528, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1496,583,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1528, "rf_id": 1022, "parent": 1527, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1496,583,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1530,583,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1527, "rf_id": 1021, "parent": 1405, "fw_parent": 0, "seq_id": 289, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1496,583,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1533, "rf_id": 1026, "parent": 1532, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1511,583,64,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1532, "rf_id": 1025, "parent": 1531, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1511,583,64,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1534,583,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1531, "rf_id": 1024, "parent": 1405, "fw_parent": 0, "seq_id": 290, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1511,583,64,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1537, "rf_id": 1029, "parent": 1536, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1526,583,128,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1536, "rf_id": 1028, "parent": 1535, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1526,583,128,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1538,583,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1535, "rf_id": 1027, "parent": 1405, "fw_parent": 0, "seq_id": 291, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1526,583,128,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1541, "rf_id": 1032, "parent": 1540, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1449,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1540, "rf_id": 1031, "parent": 1539, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1449,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[1542,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1539, "rf_id": 1030, "parent": 1405, "fw_parent": 0, "seq_id": 292, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1449,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1543, "rf_id": 1033, "parent": 1405, "fw_parent": 0, "seq_id": 293, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1530,583,0,163840,2,"cuda:0"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1544,583,0,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1545, "rf_id": 1034, "parent": 1405, "fw_parent": 0, "seq_id": 294, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1534,583,64,163840,2,"cuda:0"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1546,583,64,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1548, "rf_id": 1036, "parent": 1547, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[658,659,0,51200,2,"cuda:0"],[51200],[1],0], "input_shapes": [[51200],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1549,659,0,51200,2,"cuda:0"]], "output_shapes": [[51200]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1547, "rf_id": 1035, "parent": 1405, "fw_parent": 0, "seq_id": 295, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[658,659,0,51200,2,"cuda:0"],0,0,51200,1], "input_shapes": [[51200],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1549,659,0,51200,2,"cuda:0"]], "output_shapes": [[51200]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1550, "rf_id": 1037, "parent": 1405, "fw_parent": 0, "seq_id": 295, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1549,659,0,51200,2,"cuda:0"],[128,20,20]], "input_shapes": [[51200],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1551,659,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1553, "rf_id": 1039, "parent": 1552, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1544,583,0,163840,2,"cuda:0"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1554,583,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1552, "rf_id": 1038, "parent": 1405, "fw_parent": 0, "seq_id": 295, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1544,583,0,163840,2,"cuda:0"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1554,583,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1556, "rf_id": 1041, "parent": 1555, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1546,583,64,163840,2,"cuda:0"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1557,583,64,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1555, "rf_id": 1040, "parent": 1405, "fw_parent": 0, "seq_id": 296, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1546,583,64,163840,2,"cuda:0"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1557,583,64,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1559, "rf_id": 1043, "parent": 1558, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1557,583,64,163840,2,"cuda:0"],[128,64,20],[192,1,24576],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1560,583,64,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1558, "rf_id": 1042, "parent": 1405, "fw_parent": 0, "seq_id": 297, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1557,583,64,163840,2,"cuda:0"],1,2], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1560,583,64,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::baddbmm", "id": 1561, "rf_id": 1044, "parent": 1405, "fw_parent": 0, "seq_id": 298, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor",
      "inputs": [[1551,659,0,51200,2,"cuda:0"],[1554,583,0,163840,2,"cuda:0"],[1560,583,64,163840,2,"cuda:0"],0.000000,0.125000], "input_shapes": [[128,20,20],[128,20,64],[128,64,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Double","Double"],
      "outputs": [[1562,704,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1563, "rf_id": 1045, "parent": 1405, "fw_parent": 0, "seq_id": 299, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1562,704,0,51200,2,"cuda:0"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1564,704,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1567, "rf_id": 1048, "parent": 1566, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1564,704,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1566, "rf_id": 1047, "parent": 1565, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1564,704,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1568,704,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1565, "rf_id": 1046, "parent": 1405, "fw_parent": 0, "seq_id": 300, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1564,704,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1571, "rf_id": 1051, "parent": 1570, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1542,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1570, "rf_id": 1050, "parent": 1569, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1542,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [[1572,227,0,400,1,"cuda:0"]], "output_shapes": [[1,1,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1569, "rf_id": 1049, "parent": 1405, "fw_parent": 0, "seq_id": 301, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1542,227,0,400,1,"cuda:0"]], "input_shapes": [[1,1,20,20]], "input_types": ["Tensor(bool)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1573, "rf_id": 1052, "parent": 1405, "fw_parent": 0, "seq_id": 302, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1568,704,0,51200,2,"cuda:0"],[-1,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1574,704,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1576, "rf_id": 1054, "parent": 1575, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],4,0,"cpu",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","Bool","None"],
      "outputs": [[1577,1578,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::to", "id": 1579, "rf_id": 1055, "parent": 1575, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1577,1578,0,1,8,"cpu"],"cpu",4,false,false,"<None>"], "input_shapes": [[1],[],[],[],[],[]], "input_types": ["Tensor(long int)","Device","Int","Bool","Bool","None"],
      "outputs": [[1577,1578,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::lift_fresh", "id": 1580, "rf_id": 1056, "parent": 1575, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1577,1578,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [[1577,1578,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "detach_", "id": 1582, "rf_id": 1058, "parent": 1581, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1577,1578,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 1581, "rf_id": 1057, "parent": 1575, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1577,1578,0,1,8,"cpu"]], "input_shapes": [[1]], "input_types": ["Tensor(long int)"],
      "outputs": [[1577,1578,0,1,8,"cpu"]], "output_shapes": [[1]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::as_strided", "id": 1584, "rf_id": 1060, "parent": 1583, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1577,1578,0,1,8,"cpu"],[],[],0], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[1585,1578,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 1583, "rf_id": 1059, "parent": 1575, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[1577,1578,0,1,8,"cpu"],0,0], "input_shapes": [[1],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[1585,1578,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 1587, "rf_id": 1062, "parent": 1586, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[1585,1578,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 1586, "rf_id": 1061, "parent": 1575, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[1585,1578,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::empty", "id": 1588, "rf_id": 1063, "parent": 1575, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[128,20,20],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[1589,724,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ScaledUpperTriangMaskedSoftmax", "id": 1575, "rf_id": 1053, "parent": 1405, "fw_parent": 0, "seq_id": 303, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1574,704,0,51200,2,"cuda:0"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1590, "rf_id": 1064, "parent": 1405, "fw_parent": 0, "seq_id": 304, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1589,724,0,51200,2,"cuda:0"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1591,724,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1594, "rf_id": 1067, "parent": 1593, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1591,724,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1593, "rf_id": 1066, "parent": 1592, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1591,724,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1595,724,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1592, "rf_id": 1065, "parent": 1405, "fw_parent": 0, "seq_id": 305, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1591,724,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1598, "rf_id": 1070, "parent": 1597, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1595,724,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1597, "rf_id": 1069, "parent": 1596, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1595,724,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1599,724,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1596, "rf_id": 1068, "parent": 1405, "fw_parent": 0, "seq_id": 306, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1595,724,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 1603, "rf_id": 1074, "parent": 1602, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[8,16,20,20],[6400,400,20,1],11,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[]],[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1604,1605,0,51200,1,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 1602, "rf_id": 1073, "parent": 1601, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1599,724,0,51200,2,"cuda:0"],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[8,16,20,20],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[1604,1605,0,51200,1,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 1607, "rf_id": 1076, "parent": 1606, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[8,16,20,20],[6400,400,20,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[]],[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1608,430,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1606, "rf_id": 1075, "parent": 1601, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1599,724,0,51200,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[8,16,20,20],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1608,430,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 1601, "rf_id": 1072, "parent": 1600, "fw_parent": 0, "seq_id": 307, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[1599,724,0,51200,2,"cuda:0"],0.100000,true], "input_shapes": [[8,16,20,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[1608,430,0,51200,2,"cuda:0"],[1604,1605,0,51200,1,"cuda:0"]], "output_shapes": [[8,16,20,20],[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::dropout", "id": 1600, "rf_id": 1071, "parent": 1405, "fw_parent": 0, "seq_id": 307, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::dropout(Tensor input, float p, bool train) -> Tensor",
      "inputs": [[1599,724,0,51200,2,"cuda:0"],0.100000,true], "input_shapes": [[8,16,20,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[1608,430,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1611, "rf_id": 1079, "parent": 1610, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1608,430,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1610, "rf_id": 1078, "parent": 1609, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1608,430,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1612,430,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1609, "rf_id": 1077, "parent": 1405, "fw_parent": 0, "seq_id": 308, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1608,430,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1613, "rf_id": 1080, "parent": 1405, "fw_parent": 0, "seq_id": 309, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1538,583,128,163840,2,"cuda:0"],[20,128,-1]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1614,583,128,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1615, "rf_id": 1081, "parent": 1405, "fw_parent": 0, "seq_id": 310, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1612,430,0,51200,2,"cuda:0"],[128,20,-1]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1616,430,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1618, "rf_id": 1083, "parent": 1617, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1614,583,128,163840,2,"cuda:0"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[20,128,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1572,583,128,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1617, "rf_id": 1082, "parent": 1405, "fw_parent": 0, "seq_id": 311, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1614,583,128,163840,2,"cuda:0"],0,1], "input_shapes": [[20,128,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1572,583,128,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 1619, "rf_id": 1084, "parent": 1405, "fw_parent": 0, "seq_id": 312, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1616,430,0,51200,2,"cuda:0"],[1572,583,128,163840,2,"cuda:0"]], "input_shapes": [[128,20,20],[128,20,64]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1620,1621,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1622, "rf_id": 1085, "parent": 1405, "fw_parent": 0, "seq_id": 313, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1620,1621,0,163840,2,"cuda:0"],[8,16,20,64]], "input_shapes": [[128,20,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1623,1621,0,163840,2,"cuda:0"]], "output_shapes": [[8,16,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1625, "rf_id": 1087, "parent": 1624, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1623,1621,0,163840,2,"cuda:0"],[20,8,16,64],[64,20480,1280,1],"<None>"], "input_shapes": [[8,16,20,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","None"],
      "outputs": [[1626,1621,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::permute", "id": 1624, "rf_id": 1086, "parent": 1405, "fw_parent": 0, "seq_id": 314, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)",
      "inputs": [[1623,1621,0,163840,2,"cuda:0"],[2,0,1,3]], "input_shapes": [[8,16,20,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[1626,1621,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1630, "rf_id": 1091, "parent": 1629, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[1631,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1629, "rf_id": 1090, "parent": 1628, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1626,1621,0,163840,2,"cuda:0"],15,0,"cuda:0","<None>",0], "input_shapes": [[20,8,16,64],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Int"],
      "outputs": [[1631,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1632, "rf_id": 1092, "parent": 1628, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1631,578,0,163840,2,"cuda:0"],[1626,1621,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1631,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::clone", "id": 1628, "rf_id": 1089, "parent": 1627, "fw_parent": 0, "seq_id": 315, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1626,1621,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1631,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::contiguous", "id": 1627, "rf_id": 1088, "parent": 1405, "fw_parent": 0, "seq_id": 315, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[1626,1621,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[1631,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1633, "rf_id": 1093, "parent": 1405, "fw_parent": 0, "seq_id": 316, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1631,578,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,16,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1634,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1637, "rf_id": 1096, "parent": 1636, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1634,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1636, "rf_id": 1095, "parent": 1635, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1634,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1638,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1635, "rf_id": 1094, "parent": 1405, "fw_parent": 0, "seq_id": 317, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1634,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1641, "rf_id": 1099, "parent": 1640, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1638,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1640, "rf_id": 1098, "parent": 1639, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1638,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1642,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1639, "rf_id": 1097, "parent": 1405, "fw_parent": 0, "seq_id": 318, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1638,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1646, "rf_id": 1103, "parent": 1645, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[497,494,0,1048576,2,"cuda:0"],[1024,1024],[1,1024],"<None>"], "input_shapes": [[1024,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1647,494,0,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1645, "rf_id": 1102, "parent": 1644, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[497,494,0,1048576,2,"cuda:0"],0,1], "input_shapes": [[1024,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1647,494,0,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1644, "rf_id": 1101, "parent": 1643, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[497,494,0,1048576,2,"cuda:0"]], "input_shapes": [[1024,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1647,494,0,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1650, "rf_id": 1106, "parent": 1649, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1642,578,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1651,578,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1649, "rf_id": 1105, "parent": 1648, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1642,578,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1651,578,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1652, "rf_id": 1107, "parent": 1648, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1651,578,0,163840,2,"cuda:0"],[1647,494,0,1048576,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1653,1621,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1654, "rf_id": 1108, "parent": 1648, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1653,1621,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1655,1621,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1648, "rf_id": 1104, "parent": 1643, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1642,578,0,163840,2,"cuda:0"],[1647,494,0,1048576,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1655,1621,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 1643, "rf_id": 1100, "parent": 1405, "fw_parent": 0, "seq_id": 319, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1642,578,0,163840,2,"cuda:0"],[497,494,0,1048576,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1658, "rf_id": 1111, "parent": 1657, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1655,1621,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1659,1621,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1657, "rf_id": 1110, "parent": 1656, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1655,1621,0,163840,2,"cuda:0"],[1655,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1659,1621,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_ReduceFromModelParallelRegion", "id": 1656, "rf_id": 1109, "parent": 1405, "fw_parent": 0, "seq_id": 320, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1655,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1662, "rf_id": 1114, "parent": 1661, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1659,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1661, "rf_id": 1113, "parent": 1660, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1659,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1663,1621,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1660, "rf_id": 1112, "parent": 1405, "fw_parent": 0, "seq_id": 321, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1659,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1666, "rf_id": 1117, "parent": 1665, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[779,780,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1665, "rf_id": 1116, "parent": 1664, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[779,780,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1667,780,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1664, "rf_id": 1115, "parent": 1405, "fw_parent": 0, "seq_id": 322, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[779,780,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1670, "rf_id": 1120, "parent": 1669, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1663,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1669, "rf_id": 1119, "parent": 1668, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1663,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1671,1621,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1668, "rf_id": 1118, "parent": 1405, "fw_parent": 0, "seq_id": 323, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1663,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1674, "rf_id": 1123, "parent": 1673, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1667,780,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1673, "rf_id": 1122, "parent": 1672, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1667,780,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1675,780,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1672, "rf_id": 1121, "parent": 1405, "fw_parent": 0, "seq_id": 324, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1667,780,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1678, "rf_id": 1126, "parent": 1677, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1675,780,0,1024,2,"cuda:0"],[20,8,1024],[0,0,1],"<None>"], "input_shapes": [[1024],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[1679,780,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::expand", "id": 1677, "rf_id": 1125, "parent": 1676, "fw_parent": 0, "seq_id": 325, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)",
      "inputs": [[1675,780,0,1024,2,"cuda:0"],[20,8,1024],false], "input_shapes": [[1024],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","Bool"],
      "outputs": [[1679,780,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::expand_as", "id": 1676, "rf_id": 1124, "parent": 1405, "fw_parent": 0, "seq_id": 325, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1675,780,0,1024,2,"cuda:0"],[1420,391,0,163840,2,"cuda:0"]], "input_shapes": [[1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1679,780,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1683, "rf_id": 1130, "parent": 1682, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1679,780,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1682, "rf_id": 1129, "parent": 1681, "fw_parent": 0, "seq_id": 327, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1679,780,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1684,780,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1686, "rf_id": 1132, "parent": 1685, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1671,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1685, "rf_id": 1131, "parent": 1681, "fw_parent": 0, "seq_id": 327, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1671,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1687,1621,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1689, "rf_id": 1134, "parent": 1688, "fw_parent": 0, "seq_id": 327, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1687,1621,0,163840,2,"cuda:0"],[1684,780,0,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1690,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<forward op>", "id": 1688, "rf_id": 1133, "parent": 1681, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1684,780,0,163840,2,"cuda:0"],[1687,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "fallback_function", "id": 1681, "rf_id": 1128, "parent": 1680, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1679,780,0,163840,2,"cuda:0"],[1671,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1692, "rf_id": 1136, "parent": 1691, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1420,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1691, "rf_id": 1135, "parent": 1680, "fw_parent": 0, "seq_id": 328, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1420,391,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1693,391,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1695, "rf_id": 1138, "parent": 1694, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1690,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1694, "rf_id": 1137, "parent": 1680, "fw_parent": 0, "seq_id": 328, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1690,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1696,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1700, "rf_id": 1142, "parent": 1699, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],11,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1701,980,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 1699, "rf_id": 1141, "parent": 1698, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1696,812,0,163840,2,"cuda:0"],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[1701,980,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 1703, "rf_id": 1144, "parent": 1702, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1704,1705,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1702, "rf_id": 1143, "parent": 1698, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1696,812,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1704,1705,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 1698, "rf_id": 1140, "parent": 1697, "fw_parent": 0, "seq_id": 328, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[1696,812,0,163840,2,"cuda:0"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[1704,1705,0,163840,2,"cuda:0"],[1701,980,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024],[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::add", "id": 1706, "rf_id": 1145, "parent": 1697, "fw_parent": 0, "seq_id": 328, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1693,391,0,163840,2,"cuda:0"],[1704,1705,0,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1707,1708,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<forward op>", "id": 1697, "rf_id": 1139, "parent": 1680, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1693,391,0,163840,2,"cuda:0"],0.100000,[1696,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_dropout_add_fused_train", "id": 1680, "rf_id": 1127, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1671,1621,0,163840,2,"cuda:0"],[1679,780,0,163840,2,"cuda:0"],[1420,391,0,163840,2,"cuda:0"],0.100000], "input_shapes": [[20,8,1024],[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Double"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1711, "rf_id": 1148, "parent": 1710, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1707,1708,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1710, "rf_id": 1147, "parent": 1709, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1707,1708,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1712,1708,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1709, "rf_id": 1146, "parent": 1405, "fw_parent": 0, "seq_id": 328, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1707,1708,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 1715, "rf_id": 1151, "parent": 1714, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1716,1705,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1714, "rf_id": 1150, "parent": 1713, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1712,1708,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1716,1705,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1717, "rf_id": 1152, "parent": 1713, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[160],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[1718,132,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 1720, "rf_id": 1154, "parent": 1719, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[160],[1],6,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[1721,436,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 1719, "rf_id": 1153, "parent": 1713, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1718,132,0,160,4,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[160],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[1721,436,0,160,4,"cuda:0"]], "output_shapes": [[160]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunction", "id": 1713, "rf_id": 1149, "parent": 1405, "fw_parent": 0, "seq_id": 329, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1712,1708,0,163840,2,"cuda:0"],[817,818,0,1024,2,"cuda:0"],[819,820,0,1024,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1724, "rf_id": 1157, "parent": 1723, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1716,1705,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1723, "rf_id": 1156, "parent": 1722, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1716,1705,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1725,1705,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1722, "rf_id": 1155, "parent": 1405, "fw_parent": 0, "seq_id": 330, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1716,1705,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1726, "rf_id": 1158, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],15,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[1727,1728,0,1,2,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1731, "rf_id": 1161, "parent": 1730, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],15,0,"cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[1732,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1733, "rf_id": 1162, "parent": 1730, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1732,132,0,1,2,"cuda:0"],[1727,1728,0,1,2,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1732,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_to_copy", "id": 1730, "rf_id": 1160, "parent": 1729, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1727,1728,0,1,2,"cpu"],15,"<None>","cuda:0","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","Device","None","Bool","None"],
      "outputs": [[1732,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 1729, "rf_id": 1159, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1727,1728,0,1,2,"cpu"],"cuda:0",15,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Device","Int","Bool","Bool","None"],
      "outputs": [[1732,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::lift_fresh", "id": 1734, "rf_id": 1163, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1732,132,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1732,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach_", "id": 1736, "rf_id": 1165, "parent": 1735, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1732,132,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 1735, "rf_id": 1164, "parent": 1405, "fw_parent": 0, "seq_id": 331, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1732,132,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1732,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 1737, "rf_id": 1166, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],15,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[1738,1739,0,1,2,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1742, "rf_id": 1169, "parent": 1741, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],15,0,"cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[1743,1744,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1745, "rf_id": 1170, "parent": 1741, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1743,1744,0,1,2,"cuda:0"],[1738,1739,0,1,2,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1743,1744,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_to_copy", "id": 1741, "rf_id": 1168, "parent": 1740, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1738,1739,0,1,2,"cpu"],15,"<None>","cuda:0","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","Device","None","Bool","None"],
      "outputs": [[1743,1744,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 1740, "rf_id": 1167, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[1738,1739,0,1,2,"cpu"],"cuda:0",15,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Device","Int","Bool","Bool","None"],
      "outputs": [[1743,1744,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::lift_fresh", "id": 1746, "rf_id": 1171, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1743,1744,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1743,1744,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach_", "id": 1748, "rf_id": 1173, "parent": 1747, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1743,1744,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 1747, "rf_id": 1172, "parent": 1405, "fw_parent": 0, "seq_id": 331, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[1743,1744,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1743,1744,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1751, "rf_id": 1176, "parent": 1750, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1725,1705,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1750, "rf_id": 1175, "parent": 1749, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1725,1705,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1752,1705,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1749, "rf_id": 1174, "parent": 1405, "fw_parent": 0, "seq_id": 331, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1725,1705,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1755, "rf_id": 1179, "parent": 1754, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1752,1705,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1754, "rf_id": 1178, "parent": 1753, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1752,1705,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1756,1705,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1753, "rf_id": 1177, "parent": 1405, "fw_parent": 0, "seq_id": 332, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1752,1705,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1759, "rf_id": 1182, "parent": 1758, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1756,1705,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1760,1705,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1758, "rf_id": 1181, "parent": 1757, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1756,1705,0,163840,2,"cuda:0"],[1756,1705,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1760,1705,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_CopyToModelParallelRegion", "id": 1757, "rf_id": 1180, "parent": 1405, "fw_parent": 0, "seq_id": 333, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1756,1705,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1764, "rf_id": 1186, "parent": 1763, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[524,521,0,4194304,2,"cuda:0"],[1024,4096],[1,1024],"<None>"], "input_shapes": [[4096,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1765,521,0,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1763, "rf_id": 1185, "parent": 1762, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[524,521,0,4194304,2,"cuda:0"],0,1], "input_shapes": [[4096,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1765,521,0,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1762, "rf_id": 1184, "parent": 1761, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[524,521,0,4194304,2,"cuda:0"]], "input_shapes": [[4096,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1765,521,0,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1768, "rf_id": 1189, "parent": 1767, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1760,1705,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1769,1705,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1767, "rf_id": 1188, "parent": 1766, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1760,1705,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1769,1705,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1770, "rf_id": 1190, "parent": 1766, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1769,1705,0,163840,2,"cuda:0"],[1765,521,0,4194304,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1771,879,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1772, "rf_id": 1191, "parent": 1766, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1771,879,0,655360,2,"cuda:0"],[20,8,4096]], "input_shapes": [[160,4096],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1773,879,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1766, "rf_id": 1187, "parent": 1761, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1760,1705,0,163840,2,"cuda:0"],[1765,521,0,4194304,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1773,879,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 1761, "rf_id": 1183, "parent": 1405, "fw_parent": 0, "seq_id": 334, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1760,1705,0,163840,2,"cuda:0"],[524,521,0,4194304,2,"cuda:0"]], "input_shapes": [[20,8,1024],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1776, "rf_id": 1194, "parent": 1775, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1773,879,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1775, "rf_id": 1193, "parent": 1774, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1773,879,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1777,879,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1774, "rf_id": 1192, "parent": 1405, "fw_parent": 0, "seq_id": 335, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1773,879,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1780, "rf_id": 1197, "parent": 1779, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[886,887,0,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1779, "rf_id": 1196, "parent": 1778, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[886,887,0,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1781,887,0,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1778, "rf_id": 1195, "parent": 1405, "fw_parent": 0, "seq_id": 336, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[886,887,0,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1786, "rf_id": 1202, "parent": 1785, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1777,879,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1785, "rf_id": 1201, "parent": 1784, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1777,879,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1787,879,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1789, "rf_id": 1204, "parent": 1788, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1781,887,0,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1788, "rf_id": 1203, "parent": 1784, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1781,887,0,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1790,887,0,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1792, "rf_id": 1206, "parent": 1791, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1790,887,0,4096,2,"cuda:0"],[1787,879,0,655360,2,"cuda:0"],1], "input_shapes": [[4096],[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1793,898,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1797, "rf_id": 1208, "parent": 1794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1793,898,0,655360,2,"cuda:0"],[1795,1796,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1798,1799,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1794, "rf_id": 1207, "parent": 1791, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1793,898,0,655360,2,"cuda:0"],0.500000], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1798,1799,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1803, "rf_id": 1210, "parent": 1800, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1793,898,0,655360,2,"cuda:0"],[1801,1802,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1804,904,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1800, "rf_id": 1209, "parent": 1791, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1793,898,0,655360,2,"cuda:0"],0.797885], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1804,904,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1808, "rf_id": 1212, "parent": 1805, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1793,898,0,655360,2,"cuda:0"],[1806,1807,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1809,910,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1805, "rf_id": 1211, "parent": 1791, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1793,898,0,655360,2,"cuda:0"],0.044715], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1809,910,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1810, "rf_id": 1213, "parent": 1791, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1809,910,0,655360,2,"cuda:0"],[1793,898,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1811,916,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1815, "rf_id": 1215, "parent": 1812, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1811,916,0,655360,2,"cuda:0"],[1813,1814,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[1816,919,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1812, "rf_id": 1214, "parent": 1791, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[1811,916,0,655360,2,"cuda:0"],1,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1816,919,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1817, "rf_id": 1216, "parent": 1791, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1804,904,0,655360,2,"cuda:0"],[1816,919,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1818,916,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::tanh", "id": 1819, "rf_id": 1217, "parent": 1791, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::tanh(Tensor self) -> Tensor",
      "inputs": [[1818,916,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1820,1821,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1825, "rf_id": 1219, "parent": 1822, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1820,1821,0,655360,2,"cuda:0"],[1823,1824,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)","Int"],
      "outputs": [[1826,916,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1822, "rf_id": 1218, "parent": 1791, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[1820,1821,0,655360,2,"cuda:0"],1.000000,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Int"],
      "outputs": [[1826,916,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1827, "rf_id": 1220, "parent": 1791, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1798,1799,0,655360,2,"cuda:0"],[1826,916,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1828,1829,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<forward op>", "id": 1791, "rf_id": 1205, "parent": 1784, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1787,879,0,655360,2,"cuda:0"],[1790,887,0,4096,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "fallback_function", "id": 1784, "rf_id": 1200, "parent": 1783, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1777,879,0,655360,2,"cuda:0"],[1781,887,0,4096,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_gelu", "id": 1783, "rf_id": 1199, "parent": 1782, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1781,887,0,4096,2,"cuda:0"],[1777,879,0,655360,2,"cuda:0"]], "input_shapes": [[4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "GeLUFunction", "id": 1782, "rf_id": 1198, "parent": 1405, "fw_parent": 0, "seq_id": 337, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1777,879,0,655360,2,"cuda:0"],[1781,887,0,4096,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1832, "rf_id": 1223, "parent": 1831, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1828,1829,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1831, "rf_id": 1222, "parent": 1830, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1828,1829,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1833,1829,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PostBackwardFunctionModule", "id": 1830, "rf_id": 1221, "parent": 1405, "fw_parent": 0, "seq_id": 339, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1828,1829,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1837, "rf_id": 1227, "parent": 1836, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[551,548,0,4194304,2,"cuda:0"],[4096,1024],[1,4096],"<None>"], "input_shapes": [[1024,4096],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1838,548,0,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1836, "rf_id": 1226, "parent": 1835, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[551,548,0,4194304,2,"cuda:0"],0,1], "input_shapes": [[1024,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1838,548,0,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1835, "rf_id": 1225, "parent": 1834, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[551,548,0,4194304,2,"cuda:0"]], "input_shapes": [[1024,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1838,548,0,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1841, "rf_id": 1230, "parent": 1840, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1833,1829,0,655360,2,"cuda:0"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1842,1829,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1840, "rf_id": 1229, "parent": 1839, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1833,1829,0,655360,2,"cuda:0"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1842,1829,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1843, "rf_id": 1231, "parent": 1839, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1842,1829,0,655360,2,"cuda:0"],[1838,548,0,4194304,2,"cuda:0"]], "input_shapes": [[160,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1844,812,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1845, "rf_id": 1232, "parent": 1839, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1844,812,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1846,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1839, "rf_id": 1228, "parent": 1834, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1833,1829,0,655360,2,"cuda:0"],[1838,548,0,4194304,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1846,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunication", "id": 1834, "rf_id": 1224, "parent": 1405, "fw_parent": 0, "seq_id": 340, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1833,1829,0,655360,2,"cuda:0"],[551,548,0,4194304,2,"cuda:0"]], "input_shapes": [[20,8,4096],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1849, "rf_id": 1235, "parent": 1848, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1846,812,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[20,8,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1850,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1848, "rf_id": 1234, "parent": 1847, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1846,812,0,163840,2,"cuda:0"],[1846,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1850,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "_ReduceFromModelParallelRegion", "id": 1847, "rf_id": 1233, "parent": 1405, "fw_parent": 0, "seq_id": 341, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1846,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 1851, "rf_id": 1236, "parent": 1405, "fw_parent": 0, "seq_id": 342, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1850,812,0,163840,2,"cuda:0"],[957,958,0,1024,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1852,1853,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1856, "rf_id": 1239, "parent": 1855, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1852,1853,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1855, "rf_id": 1238, "parent": 1854, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1852,1853,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1857,1853,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1854, "rf_id": 1237, "parent": 1405, "fw_parent": 0, "seq_id": 343, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1852,1853,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1860, "rf_id": 1242, "parent": 1859, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1857,1853,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1859, "rf_id": 1241, "parent": 1858, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1857,1853,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1861,1853,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1858, "rf_id": 1240, "parent": 1405, "fw_parent": 0, "seq_id": 344, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1857,1853,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1864, "rf_id": 1245, "parent": 1863, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1707,1708,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1863, "rf_id": 1244, "parent": 1862, "fw_parent": 0, "seq_id": 346, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1707,1708,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1865,1708,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "detach", "id": 1867, "rf_id": 1247, "parent": 1866, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1861,1853,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1866, "rf_id": 1246, "parent": 1862, "fw_parent": 0, "seq_id": 346, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1861,1853,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1868,1853,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 1872, "rf_id": 1251, "parent": 1871, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],11,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1873,1874,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_like", "id": 1871, "rf_id": 1250, "parent": 1870, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1868,1853,0,163840,2,"cuda:0"],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","None"],
      "outputs": [[1873,1874,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty_strided", "id": 1876, "rf_id": 1253, "parent": 1875, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[1877,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1875, "rf_id": 1252, "parent": 1870, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1868,1853,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[1877,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout", "id": 1870, "rf_id": 1249, "parent": 1869, "fw_parent": 0, "seq_id": 346, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)",
      "inputs": [[1868,1853,0,163840,2,"cuda:0"],0.100000,true], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Bool"],
      "outputs": [[1877,812,0,163840,2,"cuda:0"],[1873,1874,0,163840,1,"cuda:0"]], "output_shapes": [[20,8,1024],[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)","Tensor(bool)"]
    },
    {
      "name": "aten::add", "id": 1878, "rf_id": 1254, "parent": 1869, "fw_parent": 0, "seq_id": 346, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1865,1708,0,163840,2,"cuda:0"],[1877,812,0,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1879,1880,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<forward op>", "id": 1869, "rf_id": 1248, "parent": 1862, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1865,1708,0,163840,2,"cuda:0"],0.100000,[1868,1853,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "bias_dropout_add_fused_train", "id": 1862, "rf_id": 1243, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1861,1853,0,163840,2,"cuda:0"],"<None>",[1707,1708,0,163840,2,"cuda:0"],0.100000], "input_shapes": [[20,8,1024],[],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","None","Tensor(c10::BFloat16)","Double"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1883, "rf_id": 1257, "parent": 1882, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1879,1880,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1882, "rf_id": 1256, "parent": 1881, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1879,1880,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1884,1880,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1881, "rf_id": 1255, "parent": 1405, "fw_parent": 0, "seq_id": 346, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1879,1880,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1887, "rf_id": 1260, "parent": 1886, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1732,132,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1886, "rf_id": 1259, "parent": 1885, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1732,132,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1888,132,0,1,2,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PreBackwardFunctionForModule", "id": 1885, "rf_id": 1258, "parent": 1405, "fw_parent": 0, "seq_id": 347, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1732,132,0,1,2,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::is_same_size", "id": 1889, "rf_id": 1261, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::is_same_size(Tensor self, Tensor other) -> bool",
      "inputs": [[1884,1880,0,163840,2,"cuda:0"],[1358,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024],[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 1891, "rf_id": 1263, "parent": 1890, "fw_parent": 1890, "seq_id": 346, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1358,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 1890, "rf_id": 1262, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1897, "rf_id": 1269, "parent": 1896, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,1024],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[1898,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 1896, "rf_id": 1268, "parent": 1895, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1358,359,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>",0], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","Int"],
      "outputs": [[1898,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout_backward", "id": 1895, "rf_id": 1267, "parent": 1894, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout_backward(Tensor grad_output, Tensor mask, float scale) -> Tensor",
      "inputs": [[1358,359,0,163840,2,"cuda:0"],[1873,1874,0,163840,1,"cuda:0"],1.111111], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(bool)","Double"],
      "outputs": [[1898,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<backward op>", "id": 1894, "rf_id": 1266, "parent": 1893, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1358,359,0,163840,2,"cuda:0"],1.111111,[1873,1874,0,163840,1,"cuda:0"],"<None>","<None>"], "input_shapes": [[20,8,1024],[],[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(bool)","None","None"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 1893, "rf_id": 1265, "parent": 1892, "fw_parent": 1892, "seq_id": 345, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1358,359,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 1892, "rf_id": 1264, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 1900, "rf_id": 1271, "parent": 1899, "fw_parent": 1899, "seq_id": 344, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1898,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 1899, "rf_id": 1270, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 1902, "rf_id": 1273, "parent": 1901, "fw_parent": 1901, "seq_id": 343, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1898,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 1901, "rf_id": 1272, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "AddBackward0", "id": 1904, "rf_id": 1275, "parent": 1903, "fw_parent": 1903, "seq_id": 342, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1898,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::sum", "id": 1905, "rf_id": 1276, "parent": 1903, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[1898,812,0,163840,2,"cuda:0"],[0,1],true,"<None>"], "input_shapes": [[20,8,1024],[[],[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","Bool","None"],
      "outputs": [[1906,1061,0,1024,2,"cuda:0"]], "output_shapes": [[1,1,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1907, "rf_id": 1277, "parent": 1903, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1906,1061,0,1024,2,"cuda:0"],[1024]], "input_shapes": [[1,1,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1908,1061,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: AddBackward0", "id": 1903, "rf_id": 1274, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1912, "rf_id": 1281, "parent": 1911, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1908,1061,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1911, "rf_id": 1280, "parent": 1910, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1908,1061,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1913,1061,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 1910, "rf_id": 1279, "parent": 1909, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1908,1061,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1916, "rf_id": 1284, "parent": 1915, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],[1024],[1],2048], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1917,1377,2048,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1915, "rf_id": 1283, "parent": 1914, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,2048,3072,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1917,1377,2048,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 1914, "rf_id": 1282, "parent": 1909, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,2048,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1917,1377,2048,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1919, "rf_id": 1286, "parent": 1918, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1917,1377,2048,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[1920,1377,2048,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1918, "rf_id": 1285, "parent": 1909, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1917,1377,2048,1024,2,"cuda:0"],[1913,1061,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1920,1377,2048,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1921, "rf_id": 1287, "parent": 1909, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1920,1377,2048,1024,2,"cuda:0"],[1913,1061,0,1024,2,"cuda:0"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1920,1377,2048,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 1922, "rf_id": 1288, "parent": 1909, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1913,1061,0,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1923, "rf_id": 1289, "parent": 1909, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[1913,1061,0,1024,2,"cuda:0"],[1920,1377,2048,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 1909, "rf_id": 1278, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_ReduceFromModelParallelRegionBackward", "id": 1925, "rf_id": 1291, "parent": 1924, "fw_parent": 1924, "seq_id": 341, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1898,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _ReduceFromModelParallelRegionBackward", "id": 1924, "rf_id": 1290, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 1930, "rf_id": 1296, "parent": 1929, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1898,812,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1931,812,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 1929, "rf_id": 1295, "parent": 1928, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[1898,812,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1931,812,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1932, "rf_id": 1297, "parent": 1928, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1931,812,0,163840,2,"cuda:0"],[551,548,0,4194304,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1933,898,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 1934, "rf_id": 1298, "parent": 1928, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[1933,898,0,655360,2,"cuda:0"],[20,8,4096]], "input_shapes": [[160,4096],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[1935,898,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1928, "rf_id": 1294, "parent": 1927, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1898,812,0,163840,2,"cuda:0"],[551,548,0,4194304,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1935,898,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1936, "rf_id": 1299, "parent": 1927, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1898,812,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1937,812,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1938, "rf_id": 1300, "parent": 1927, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1833,1829,0,655360,2,"cuda:0"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1939,1829,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 1942, "rf_id": 1303, "parent": 1941, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1937,812,0,163840,2,"cuda:0"],[1024,160],[1,1024],"<None>"], "input_shapes": [[160,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[1943,812,0,163840,2,"cuda:0"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 1941, "rf_id": 1302, "parent": 1940, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1937,812,0,163840,2,"cuda:0"],0,1], "input_shapes": [[160,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1943,812,0,163840,2,"cuda:0"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 1940, "rf_id": 1301, "parent": 1927, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1937,812,0,163840,2,"cuda:0"]], "input_shapes": [[160,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1943,812,0,163840,2,"cuda:0"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 1945, "rf_id": 1305, "parent": 1944, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[1943,812,0,163840,2,"cuda:0"],[1939,1829,0,655360,2,"cuda:0"]], "input_shapes": [[1024,160],[160,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1946,1947,0,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 1944, "rf_id": 1304, "parent": 1927, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1943,812,0,163840,2,"cuda:0"],[1939,1829,0,655360,2,"cuda:0"]], "input_shapes": [[1024,160],[160,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1946,1947,0,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 1927, "rf_id": 1293, "parent": 1926, "fw_parent": 1926, "seq_id": 340, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1898,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 1926, "rf_id": 1292, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 1951, "rf_id": 1309, "parent": 1950, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1946,1947,0,4194304,2,"cuda:0"]], "input_shapes": [[1024,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 1950, "rf_id": 1308, "parent": 1949, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1946,1947,0,4194304,2,"cuda:0"]], "input_shapes": [[1024,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1952,1947,0,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 1949, "rf_id": 1307, "parent": 1948, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1946,1947,0,4194304,2,"cuda:0"]], "input_shapes": [[1024,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 1955, "rf_id": 1312, "parent": 1954, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],[4194304],[1],3072], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1956,1377,3072,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 1954, "rf_id": 1311, "parent": 1953, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,3072,4197376,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1956,1377,3072,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 1953, "rf_id": 1310, "parent": 1948, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,3072,4194304], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1956,1377,3072,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 1958, "rf_id": 1314, "parent": 1957, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1956,1377,3072,4194304,2,"cuda:0"],[1024,4096]], "input_shapes": [[4194304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[1959,1377,3072,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 1957, "rf_id": 1313, "parent": 1948, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1956,1377,3072,4194304,2,"cuda:0"],[1952,1947,0,4194304,2,"cuda:0"]], "input_shapes": [[4194304],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1959,1377,3072,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 1960, "rf_id": 1315, "parent": 1948, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[1959,1377,3072,4194304,2,"cuda:0"],[1952,1947,0,4194304,2,"cuda:0"],true], "input_shapes": [[1024,4096],[1024,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[1959,1377,3072,4194304,2,"cuda:0"]], "output_shapes": [[1024,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 1961, "rf_id": 1316, "parent": 1948, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1952,1947,0,4194304,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1962, "rf_id": 1317, "parent": 1948, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[1952,1947,0,4194304,2,"cuda:0"],[1959,1377,3072,4194304,2,"cuda:0"]], "input_shapes": [[1024,4096],[1024,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 1948, "rf_id": 1306, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 1966, "rf_id": 1320, "parent": 1964, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1965,548,0,4194304,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 1967, "rf_id": 1321, "parent": 1964, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[1968,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 1969, "rf_id": 1322, "parent": 1964, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[551,548,0,4194304,2,"cuda:0"],[1968,57,0,0,2,"cuda:0"]], "input_shapes": [[1024,4096],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 1964, "rf_id": 1319, "parent": 1963, "fw_parent": 1963, "seq_id": 339, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1935,898,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 1963, "rf_id": 1318, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 1973, "rf_id": 1326, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1781,887,0,4096,2,"cuda:0"],[1777,879,0,655360,2,"cuda:0"],1], "input_shapes": [[4096],[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1974,1799,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1978, "rf_id": 1328, "parent": 1975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1974,1799,0,655360,2,"cuda:0"],[1976,1977,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1979,904,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1975, "rf_id": 1327, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1974,1799,0,655360,2,"cuda:0"],0.797885], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1979,904,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1983, "rf_id": 1330, "parent": 1980, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1974,1799,0,655360,2,"cuda:0"],[1981,1982,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[1984,910,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1980, "rf_id": 1329, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1974,1799,0,655360,2,"cuda:0"],0.044715], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[1984,910,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1985, "rf_id": 1331, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1984,910,0,655360,2,"cuda:0"],[1974,1799,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1986,916,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1990, "rf_id": 1333, "parent": 1987, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1986,916,0,655360,2,"cuda:0"],[1988,1989,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[1991,910,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 1987, "rf_id": 1332, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[1986,916,0,655360,2,"cuda:0"],1,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[1991,910,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1992, "rf_id": 1334, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1979,904,0,655360,2,"cuda:0"],[1991,910,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[1993,916,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::tanh", "id": 1994, "rf_id": 1335, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::tanh(Tensor self) -> Tensor",
      "inputs": [[1993,916,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[1995,904,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1999, "rf_id": 1337, "parent": 1996, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1974,1799,0,655360,2,"cuda:0"],[1997,1998,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[2000,910,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 1996, "rf_id": 1336, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1974,1799,0,655360,2,"cuda:0"],0.500000], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[2000,910,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2001, "rf_id": 1338, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1995,904,0,655360,2,"cuda:0"],[1995,904,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2002,916,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::neg", "id": 2003, "rf_id": 1339, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::neg(Tensor self) -> Tensor",
      "inputs": [[2002,916,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2004,919,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 2008, "rf_id": 1341, "parent": 2005, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[2004,919,0,655360,2,"cuda:0"],[2006,2007,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[2009,916,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 2005, "rf_id": 1340, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[2004,919,0,655360,2,"cuda:0"],1,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2009,916,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2013, "rf_id": 1343, "parent": 2010, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[1974,1799,0,655360,2,"cuda:0"],[2011,2012,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[2014,919,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2010, "rf_id": 1342, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[1974,1799,0,655360,2,"cuda:0"],0.107032], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[2014,919,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2015, "rf_id": 1344, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2014,919,0,655360,2,"cuda:0"],[1974,1799,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2016,1821,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 2020, "rf_id": 1346, "parent": 2017, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[2016,1821,0,655360,2,"cuda:0"],[2018,2019,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)","Int"],
      "outputs": [[2021,919,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 2017, "rf_id": 1345, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[2016,1821,0,655360,2,"cuda:0"],0.797885,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Int"],
      "outputs": [[2021,919,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2022, "rf_id": 1347, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2009,916,0,655360,2,"cuda:0"],[2021,919,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2023,1799,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2024, "rf_id": 1348, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2000,910,0,655360,2,"cuda:0"],[2023,1799,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2025,916,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 2029, "rf_id": 1350, "parent": 2026, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1995,904,0,655360,2,"cuda:0"],[2027,2028,0,1,8,"cpu"],1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int"],
      "outputs": [[2030,910,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 2026, "rf_id": 1349, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -> Tensor",
      "inputs": [[1995,904,0,655360,2,"cuda:0"],1,1], "input_shapes": [[20,8,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2030,910,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2034, "rf_id": 1352, "parent": 2031, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2030,910,0,655360,2,"cuda:0"],[2032,2033,0,1,8,"cpu"]], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[2035,904,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2031, "rf_id": 1351, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[2030,910,0,655360,2,"cuda:0"],0.500000], "input_shapes": [[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[2035,904,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::add", "id": 2036, "rf_id": 1353, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[2025,916,0,655360,2,"cuda:0"],[2035,904,0,655360,2,"cuda:0"],1], "input_shapes": [[20,8,4096],[20,8,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[2037,910,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2038, "rf_id": 1354, "parent": 1972, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2037,910,0,655360,2,"cuda:0"],[1935,898,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2039,904,0,655360,2,"cuda:0"]], "output_shapes": [[20,8,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "bias_gelu_back", "id": 1972, "rf_id": 1325, "parent": 1971, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1935,898,0,655360,2,"cuda:0"],[1781,887,0,4096,2,"cuda:0"],[1777,879,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096],[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "GeLUFunctionBackward", "id": 1971, "rf_id": 1324, "parent": 1970, "fw_parent": 1970, "seq_id": 337, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[1935,898,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::sum", "id": 2040, "rf_id": 1355, "parent": 1970, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[2039,904,0,655360,2,"cuda:0"],[0,1],true,"<None>"], "input_shapes": [[20,8,4096],[[],[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","Bool","None"],
      "outputs": [[2041,2042,0,4096,2,"cuda:0"]], "output_shapes": [[1,1,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2043, "rf_id": 1356, "parent": 1970, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2041,2042,0,4096,2,"cuda:0"],[4096]], "input_shapes": [[1,1,4096],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2044,2042,0,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: GeLUFunctionBackward", "id": 1970, "rf_id": 1323, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2046, "rf_id": 1358, "parent": 2045, "fw_parent": 2045, "seq_id": 336, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2044,2042,0,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2045, "rf_id": 1357, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2050, "rf_id": 1362, "parent": 2049, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2044,2042,0,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2049, "rf_id": 1361, "parent": 2048, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2044,2042,0,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2051,2042,0,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2048, "rf_id": 1360, "parent": 2047, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2044,2042,0,4096,2,"cuda:0"]], "input_shapes": [[4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2054, "rf_id": 1365, "parent": 2053, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],[4096],[1],4197376], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2055,1377,4197376,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2053, "rf_id": 1364, "parent": 2052, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,4197376,4201472,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2055,1377,4197376,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2052, "rf_id": 1363, "parent": 2047, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,4197376,4096], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2055,1377,4197376,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2057, "rf_id": 1367, "parent": 2056, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2055,1377,4197376,4096,2,"cuda:0"],[4096]], "input_shapes": [[4096],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2058,1377,4197376,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2056, "rf_id": 1366, "parent": 2047, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2055,1377,4197376,4096,2,"cuda:0"],[2051,2042,0,4096,2,"cuda:0"]], "input_shapes": [[4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2058,1377,4197376,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2059, "rf_id": 1368, "parent": 2047, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2058,1377,4197376,4096,2,"cuda:0"],[2051,2042,0,4096,2,"cuda:0"],true], "input_shapes": [[4096],[4096],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2058,1377,4197376,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2060, "rf_id": 1369, "parent": 2047, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2051,2042,0,4096,2,"cuda:0"],"<Stream>"], "input_shapes": [[4096],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2061, "rf_id": 1370, "parent": 2047, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2051,2042,0,4096,2,"cuda:0"],[2058,1377,4197376,4096,2,"cuda:0"]], "input_shapes": [[4096],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2047, "rf_id": 1359, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2063, "rf_id": 1372, "parent": 2062, "fw_parent": 2062, "seq_id": 335, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2039,904,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2062, "rf_id": 1371, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2068, "rf_id": 1377, "parent": 2067, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2039,904,0,655360,2,"cuda:0"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2069,904,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2067, "rf_id": 1376, "parent": 2066, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2039,904,0,655360,2,"cuda:0"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2069,904,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 2070, "rf_id": 1378, "parent": 2066, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2069,904,0,655360,2,"cuda:0"],[524,521,0,4194304,2,"cuda:0"]], "input_shapes": [[160,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2071,812,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 2072, "rf_id": 1379, "parent": 2066, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[2071,812,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2073,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 2066, "rf_id": 1375, "parent": 2065, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2039,904,0,655360,2,"cuda:0"],[524,521,0,4194304,2,"cuda:0"]], "input_shapes": [[20,8,4096],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2073,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2074, "rf_id": 1380, "parent": 2065, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2039,904,0,655360,2,"cuda:0"],[160,4096]], "input_shapes": [[20,8,4096],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2075,904,0,655360,2,"cuda:0"]], "output_shapes": [[160,4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2076, "rf_id": 1381, "parent": 2065, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1760,1705,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2077,1705,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2080, "rf_id": 1384, "parent": 2079, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2075,904,0,655360,2,"cuda:0"],[4096,160],[1,4096],"<None>"], "input_shapes": [[160,4096],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[2081,904,0,655360,2,"cuda:0"]], "output_shapes": [[4096,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2079, "rf_id": 1383, "parent": 2078, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[2075,904,0,655360,2,"cuda:0"],0,1], "input_shapes": [[160,4096],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2081,904,0,655360,2,"cuda:0"]], "output_shapes": [[4096,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 2078, "rf_id": 1382, "parent": 2065, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2075,904,0,655360,2,"cuda:0"]], "input_shapes": [[160,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2081,904,0,655360,2,"cuda:0"]], "output_shapes": [[4096,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 2083, "rf_id": 1386, "parent": 2082, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2081,904,0,655360,2,"cuda:0"],[2077,1705,0,163840,2,"cuda:0"]], "input_shapes": [[4096,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2084,910,0,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 2082, "rf_id": 1385, "parent": 2065, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2081,904,0,655360,2,"cuda:0"],[2077,1705,0,163840,2,"cuda:0"]], "input_shapes": [[4096,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2084,910,0,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 2065, "rf_id": 1374, "parent": 2064, "fw_parent": 2064, "seq_id": 334, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2039,904,0,655360,2,"cuda:0"]], "input_shapes": [[20,8,4096]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 2064, "rf_id": 1373, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2088, "rf_id": 1390, "parent": 2087, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2084,910,0,4194304,2,"cuda:0"]], "input_shapes": [[4096,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2087, "rf_id": 1389, "parent": 2086, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2084,910,0,4194304,2,"cuda:0"]], "input_shapes": [[4096,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2089,910,0,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2086, "rf_id": 1388, "parent": 2085, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2084,910,0,4194304,2,"cuda:0"]], "input_shapes": [[4096,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2092, "rf_id": 1393, "parent": 2091, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],[4194304],[1],4201472], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2093,1377,4201472,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2091, "rf_id": 1392, "parent": 2090, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,4201472,8395776,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2093,1377,4201472,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2090, "rf_id": 1391, "parent": 2085, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,4201472,4194304], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2093,1377,4201472,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2095, "rf_id": 1395, "parent": 2094, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2093,1377,4201472,4194304,2,"cuda:0"],[4096,1024]], "input_shapes": [[4194304],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2096,1377,4201472,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2094, "rf_id": 1394, "parent": 2085, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2093,1377,4201472,4194304,2,"cuda:0"],[2089,910,0,4194304,2,"cuda:0"]], "input_shapes": [[4194304],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2096,1377,4201472,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2097, "rf_id": 1396, "parent": 2085, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2096,1377,4201472,4194304,2,"cuda:0"],[2089,910,0,4194304,2,"cuda:0"],true], "input_shapes": [[4096,1024],[4096,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2096,1377,4201472,4194304,2,"cuda:0"]], "output_shapes": [[4096,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2098, "rf_id": 1397, "parent": 2085, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2089,910,0,4194304,2,"cuda:0"],"<Stream>"], "input_shapes": [[4096,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2099, "rf_id": 1398, "parent": 2085, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2089,910,0,4194304,2,"cuda:0"],[2096,1377,4201472,4194304,2,"cuda:0"]], "input_shapes": [[4096,1024],[4096,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2085, "rf_id": 1387, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_CopyToModelParallelRegionBackward", "id": 2101, "rf_id": 1400, "parent": 2100, "fw_parent": 2100, "seq_id": 333, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2073,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _CopyToModelParallelRegionBackward", "id": 2100, "rf_id": 1399, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 2105, "rf_id": 1403, "parent": 2103, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2104,521,0,4194304,2,"cuda:0"],"<Stream>"], "input_shapes": [[4096,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2106, "rf_id": 1404, "parent": 2103, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[2107,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2108, "rf_id": 1405, "parent": 2103, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[524,521,0,4194304,2,"cuda:0"],[2107,57,0,0,2,"cuda:0"]], "input_shapes": [[4096,1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2103, "rf_id": 1402, "parent": 2102, "fw_parent": 2102, "seq_id": 332, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2073,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2102, "rf_id": 1401, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2110, "rf_id": 1407, "parent": 2109, "fw_parent": 2109, "seq_id": 331, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2073,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2109, "rf_id": 1406, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2112, "rf_id": 1409, "parent": 2111, "fw_parent": 2111, "seq_id": 330, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2073,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2111, "rf_id": 1408, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 2117, "rf_id": 1413, "parent": 2116, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2118,1621,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2116, "rf_id": 1412, "parent": 2114, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2115,1705,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[2118,1621,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 2120, "rf_id": 1415, "parent": 2119, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[2121,1061,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2119, "rf_id": 1414, "parent": 2114, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[817,818,0,1024,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[2121,1061,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 2123, "rf_id": 1417, "parent": 2122, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[2124,1086,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2122, "rf_id": 1416, "parent": 2114, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[819,820,0,1024,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[2124,1086,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 2125, "rf_id": 1418, "parent": 2114, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[16,1024],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2126,2042,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 2128, "rf_id": 1420, "parent": 2127, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[16,1024],[1024,1],6,0,"cuda:0","<None>"], "input_shapes": [[[],[]],[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[2129,704,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 2127, "rf_id": 1419, "parent": 2114, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2126,2042,0,16384,4,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[16,1024],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[2129,704,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunctionBackward", "id": 2114, "rf_id": 1411, "parent": 2113, "fw_parent": 2113, "seq_id": 329, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2073,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: FusedLayerNormAffineFunctionBackward", "id": 2113, "rf_id": 1410, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2133, "rf_id": 1424, "parent": 2132, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2121,1061,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2132, "rf_id": 1423, "parent": 2131, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2121,1061,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2134,1061,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2131, "rf_id": 1422, "parent": 2130, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2121,1061,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2137, "rf_id": 1427, "parent": 2136, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],[1024],[1],8395776], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1721,1377,8395776,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2136, "rf_id": 1426, "parent": 2135, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,8395776,8396800,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1721,1377,8395776,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2135, "rf_id": 1425, "parent": 2130, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,8395776,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1721,1377,8395776,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2139, "rf_id": 1429, "parent": 2138, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1721,1377,8395776,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2140,1377,8395776,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2138, "rf_id": 1428, "parent": 2130, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1721,1377,8395776,1024,2,"cuda:0"],[2134,1061,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2140,1377,8395776,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2141, "rf_id": 1430, "parent": 2130, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2140,1377,8395776,1024,2,"cuda:0"],[2134,1061,0,1024,2,"cuda:0"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2140,1377,8395776,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2142, "rf_id": 1431, "parent": 2130, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2134,1061,0,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2143, "rf_id": 1432, "parent": 2130, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2134,1061,0,1024,2,"cuda:0"],[2140,1377,8395776,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2130, "rf_id": 1421, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2147, "rf_id": 1436, "parent": 2146, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2124,1086,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2146, "rf_id": 1435, "parent": 2145, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2124,1086,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2148,1086,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2145, "rf_id": 1434, "parent": 2144, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2124,1086,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2151, "rf_id": 1439, "parent": 2150, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],[1024],[1],8396800], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2129,1377,8396800,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2150, "rf_id": 1438, "parent": 2149, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,8396800,8397824,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2129,1377,8396800,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2149, "rf_id": 1437, "parent": 2144, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,8396800,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2129,1377,8396800,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2153, "rf_id": 1441, "parent": 2152, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2129,1377,8396800,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2154,1377,8396800,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2152, "rf_id": 1440, "parent": 2144, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2129,1377,8396800,1024,2,"cuda:0"],[2148,1086,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2154,1377,8396800,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2155, "rf_id": 1442, "parent": 2144, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2154,1377,8396800,1024,2,"cuda:0"],[2148,1086,0,1024,2,"cuda:0"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2154,1377,8396800,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2156, "rf_id": 1443, "parent": 2144, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2148,1086,0,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2157, "rf_id": 1444, "parent": 2144, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2148,1086,0,1024,2,"cuda:0"],[2154,1377,8396800,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2144, "rf_id": 1433, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2159, "rf_id": 1446, "parent": 2158, "fw_parent": 2158, "seq_id": 328, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2118,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add", "id": 2160, "rf_id": 1447, "parent": 2158, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1358,359,0,163840,2,"cuda:0"],[2118,1621,0,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[2161,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2158, "rf_id": 1445, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2167, "rf_id": 1453, "parent": 2166, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,1024],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[2168,1621,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2166, "rf_id": 1452, "parent": 2165, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2161,812,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>",0], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","Int"],
      "outputs": [[2168,1621,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout_backward", "id": 2165, "rf_id": 1451, "parent": 2164, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout_backward(Tensor grad_output, Tensor mask, float scale) -> Tensor",
      "inputs": [[2161,812,0,163840,2,"cuda:0"],[1701,980,0,163840,1,"cuda:0"],1.111111], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(bool)","Double"],
      "outputs": [[2168,1621,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<backward op>", "id": 2164, "rf_id": 1450, "parent": 2163, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2161,812,0,163840,2,"cuda:0"],1.111111,[1701,980,0,163840,1,"cuda:0"],"<None>","<None>"], "input_shapes": [[20,8,1024],[],[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Double","Tensor(bool)","None","None"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 2163, "rf_id": 1449, "parent": 2162, "fw_parent": 2162, "seq_id": 327, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2161,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 2162, "rf_id": 1448, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::mul", "id": 2175, "rf_id": 1458, "parent": 2172, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2168,1621,0,163840,2,"cuda:0"],[2173,2174,0,1,8,"cpu"]], "input_shapes": [[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)"],
      "outputs": [[2176,980,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2172, "rf_id": 1457, "parent": 2171, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[2168,1621,0,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2176,980,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "<backward op>", "id": 2171, "rf_id": 1456, "parent": 2170, "fw_parent": 0, "seq_id": -1, "scope": 2, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2168,1621,0,163840,2,"cuda:0"],"<None>","<None>"], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 2170, "rf_id": 1455, "parent": 2169, "fw_parent": 2169, "seq_id": 326, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2168,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward", "id": 2169, "rf_id": 1454, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::sum", "id": 2179, "rf_id": 1461, "parent": 2178, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[2176,980,0,163840,2,"cuda:0"],[0,1],true,"<None>"], "input_shapes": [[20,8,1024],[[],[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","Bool","None"],
      "outputs": [[2180,436,0,1024,2,"cuda:0"]], "output_shapes": [[1,1,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2181, "rf_id": 1462, "parent": 2178, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2180,436,0,1024,2,"cuda:0"],[1024]], "input_shapes": [[1,1,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2182,436,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ExpandBackward0", "id": 2178, "rf_id": 1460, "parent": 2177, "fw_parent": 2177, "seq_id": 325, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2176,980,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ExpandBackward0", "id": 2177, "rf_id": 1459, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2184, "rf_id": 1464, "parent": 2183, "fw_parent": 2183, "seq_id": 324, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2182,436,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2183, "rf_id": 1463, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2186, "rf_id": 1466, "parent": 2185, "fw_parent": 2185, "seq_id": 323, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2168,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2185, "rf_id": 1465, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2188, "rf_id": 1468, "parent": 2187, "fw_parent": 2187, "seq_id": 322, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2182,436,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2187, "rf_id": 1467, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2192, "rf_id": 1472, "parent": 2191, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2182,436,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2191, "rf_id": 1471, "parent": 2190, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2182,436,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2193,436,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2190, "rf_id": 1470, "parent": 2189, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2182,436,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2196, "rf_id": 1475, "parent": 2195, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],[1024],[1],8397824], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2197,1377,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2195, "rf_id": 1474, "parent": 2194, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,8397824,8398848,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2197,1377,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2194, "rf_id": 1473, "parent": 2189, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,8397824,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2197,1377,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2199, "rf_id": 1477, "parent": 2198, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2197,1377,8397824,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2200,1377,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2198, "rf_id": 1476, "parent": 2189, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2197,1377,8397824,1024,2,"cuda:0"],[2193,436,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2200,1377,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2201, "rf_id": 1478, "parent": 2189, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2200,1377,8397824,1024,2,"cuda:0"],[2193,436,0,1024,2,"cuda:0"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2200,1377,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2202, "rf_id": 1479, "parent": 2189, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2193,436,0,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2203, "rf_id": 1480, "parent": 2189, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2193,436,0,1024,2,"cuda:0"],[2200,1377,8397824,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2189, "rf_id": 1469, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2205, "rf_id": 1482, "parent": 2204, "fw_parent": 2204, "seq_id": 321, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2168,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2204, "rf_id": 1481, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_ReduceFromModelParallelRegionBackward", "id": 2207, "rf_id": 1484, "parent": 2206, "fw_parent": 2206, "seq_id": 320, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2168,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _ReduceFromModelParallelRegionBackward", "id": 2206, "rf_id": 1483, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2212, "rf_id": 1489, "parent": 2211, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2168,1621,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2213,1621,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2211, "rf_id": 1488, "parent": 2210, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2168,1621,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2213,1621,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 2214, "rf_id": 1490, "parent": 2210, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2213,1621,0,163840,2,"cuda:0"],[497,494,0,1048576,2,"cuda:0"]], "input_shapes": [[160,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2215,980,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 2216, "rf_id": 1491, "parent": 2210, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[2215,980,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2217,980,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 2210, "rf_id": 1487, "parent": 2209, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2168,1621,0,163840,2,"cuda:0"],[497,494,0,1048576,2,"cuda:0"]], "input_shapes": [[20,8,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2217,980,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2218, "rf_id": 1492, "parent": 2209, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2168,1621,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2219,1621,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2220, "rf_id": 1493, "parent": 2209, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1642,578,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2221,578,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2224, "rf_id": 1496, "parent": 2223, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2219,1621,0,163840,2,"cuda:0"],[1024,160],[1,1024],"<None>"], "input_shapes": [[160,1024],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[2225,1621,0,163840,2,"cuda:0"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2223, "rf_id": 1495, "parent": 2222, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[2219,1621,0,163840,2,"cuda:0"],0,1], "input_shapes": [[160,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2225,1621,0,163840,2,"cuda:0"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 2222, "rf_id": 1494, "parent": 2209, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2219,1621,0,163840,2,"cuda:0"]], "input_shapes": [[160,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2225,1621,0,163840,2,"cuda:0"]], "output_shapes": [[1024,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 2227, "rf_id": 1498, "parent": 2226, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2225,1621,0,163840,2,"cuda:0"],[2221,578,0,163840,2,"cuda:0"]], "input_shapes": [[1024,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2228,904,0,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 2226, "rf_id": 1497, "parent": 2209, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2225,1621,0,163840,2,"cuda:0"],[2221,578,0,163840,2,"cuda:0"]], "input_shapes": [[1024,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2228,904,0,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 2209, "rf_id": 1486, "parent": 2208, "fw_parent": 2208, "seq_id": 319, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2168,1621,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 2208, "rf_id": 1485, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2232, "rf_id": 1502, "parent": 2231, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2228,904,0,1048576,2,"cuda:0"]], "input_shapes": [[1024,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2231, "rf_id": 1501, "parent": 2230, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2228,904,0,1048576,2,"cuda:0"]], "input_shapes": [[1024,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2233,904,0,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2230, "rf_id": 1500, "parent": 2229, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2228,904,0,1048576,2,"cuda:0"]], "input_shapes": [[1024,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2236, "rf_id": 1505, "parent": 2235, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],[1048576],[1],8398848], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2237,1377,8398848,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2235, "rf_id": 1504, "parent": 2234, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,8398848,9447424,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2237,1377,8398848,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2234, "rf_id": 1503, "parent": 2229, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,8398848,1048576], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2237,1377,8398848,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2239, "rf_id": 1507, "parent": 2238, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2237,1377,8398848,1048576,2,"cuda:0"],[1024,1024]], "input_shapes": [[1048576],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2240,1377,8398848,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2238, "rf_id": 1506, "parent": 2229, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2237,1377,8398848,1048576,2,"cuda:0"],[2233,904,0,1048576,2,"cuda:0"]], "input_shapes": [[1048576],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2240,1377,8398848,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2241, "rf_id": 1508, "parent": 2229, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2240,1377,8398848,1048576,2,"cuda:0"],[2233,904,0,1048576,2,"cuda:0"],true], "input_shapes": [[1024,1024],[1024,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2240,1377,8398848,1048576,2,"cuda:0"]], "output_shapes": [[1024,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2242, "rf_id": 1509, "parent": 2229, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2233,904,0,1048576,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2243, "rf_id": 1510, "parent": 2229, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2233,904,0,1048576,2,"cuda:0"],[2240,1377,8398848,1048576,2,"cuda:0"]], "input_shapes": [[1024,1024],[1024,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2229, "rf_id": 1499, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 2247, "rf_id": 1513, "parent": 2245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2246,494,0,1048576,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2248, "rf_id": 1514, "parent": 2245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[2249,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2250, "rf_id": 1515, "parent": 2245, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[497,494,0,1048576,2,"cuda:0"],[2249,57,0,0,2,"cuda:0"]], "input_shapes": [[1024,1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2245, "rf_id": 1512, "parent": 2244, "fw_parent": 2244, "seq_id": 318, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2217,980,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2244, "rf_id": 1511, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2252, "rf_id": 1517, "parent": 2251, "fw_parent": 2251, "seq_id": 317, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2217,980,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2251, "rf_id": 1516, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2256, "rf_id": 1521, "parent": 2255, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2217,980,0,163840,2,"cuda:0"],[20,8,16,64]], "input_shapes": [[20,8,1024],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2257,980,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2255, "rf_id": 1520, "parent": 2254, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2217,980,0,163840,2,"cuda:0"],[20,8,16,64]], "input_shapes": [[20,8,1024],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2257,980,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2254, "rf_id": 1519, "parent": 2253, "fw_parent": 2253, "seq_id": 316, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2217,980,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2253, "rf_id": 1518, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "CloneBackward0", "id": 2259, "rf_id": 1523, "parent": 2258, "fw_parent": 2258, "seq_id": 315, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2257,980,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: CloneBackward0", "id": 2258, "rf_id": 1522, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2263, "rf_id": 1527, "parent": 2262, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2257,980,0,163840,2,"cuda:0"],[8,16,20,64],[1024,64,8192,1],"<None>"], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","None"],
      "outputs": [[2264,980,0,163840,2,"cuda:0"]], "output_shapes": [[8,16,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::permute", "id": 2262, "rf_id": 1526, "parent": 2261, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)",
      "inputs": [[2257,980,0,163840,2,"cuda:0"],[1,2,0,3]], "input_shapes": [[20,8,16,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2264,980,0,163840,2,"cuda:0"]], "output_shapes": [[8,16,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "PermuteBackward0", "id": 2261, "rf_id": 1525, "parent": 2260, "fw_parent": 2260, "seq_id": 314, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2257,980,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PermuteBackward0", "id": 2260, "rf_id": 1524, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_reshape_alias", "id": 2268, "rf_id": 1531, "parent": 2267, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[2264,980,0,163840,2,"cuda:0"],[128,20,64],[64,8192,1]], "input_shapes": [[8,16,20,64],[[],[],[]],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]"],
      "outputs": [[2269,980,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2267, "rf_id": 1530, "parent": 2266, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2264,980,0,163840,2,"cuda:0"],[128,20,64]], "input_shapes": [[8,16,20,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2269,980,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2266, "rf_id": 1529, "parent": 2265, "fw_parent": 2265, "seq_id": 313, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2264,980,0,163840,2,"cuda:0"]], "input_shapes": [[8,16,20,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2265, "rf_id": 1528, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2273, "rf_id": 1535, "parent": 2272, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1616,430,0,51200,2,"cuda:0"],[128,20,20],[400,1,20],"<None>"], "input_shapes": [[128,20,20],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2274,430,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2272, "rf_id": 1534, "parent": 2271, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1616,430,0,51200,2,"cuda:0"],1,2], "input_shapes": [[128,20,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2274,430,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 2275, "rf_id": 1536, "parent": 2271, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2274,430,0,51200,2,"cuda:0"],[2269,980,0,163840,2,"cuda:0"]], "input_shapes": [[128,20,20],[128,20,64]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2276,578,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2278, "rf_id": 1538, "parent": 2277, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1572,583,128,163840,2,"cuda:0"],[128,64,20],[192,1,24576],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2279,583,128,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2277, "rf_id": 1537, "parent": 2271, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1572,583,128,163840,2,"cuda:0"],1,2], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2279,583,128,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 2280, "rf_id": 1539, "parent": 2271, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2269,980,0,163840,2,"cuda:0"],[2279,583,128,163840,2,"cuda:0"]], "input_shapes": [[128,20,64],[128,64,20]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2281,704,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "BmmBackward0", "id": 2271, "rf_id": 1533, "parent": 2270, "fw_parent": 2270, "seq_id": 312, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2269,980,0,163840,2,"cuda:0"]], "input_shapes": [[128,20,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: BmmBackward0", "id": 2270, "rf_id": 1532, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2285, "rf_id": 1543, "parent": 2284, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2276,578,0,163840,2,"cuda:0"],[20,128,64],[64,1280,1],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2286,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2284, "rf_id": 1542, "parent": 2283, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[2276,578,0,163840,2,"cuda:0"],0,1], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2286,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "TransposeBackward0", "id": 2283, "rf_id": 1541, "parent": 2282, "fw_parent": 2282, "seq_id": 311, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2276,578,0,163840,2,"cuda:0"]], "input_shapes": [[128,20,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 2282, "rf_id": 1540, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2290, "rf_id": 1547, "parent": 2289, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2281,704,0,51200,2,"cuda:0"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2291,704,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2289, "rf_id": 1546, "parent": 2288, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2281,704,0,51200,2,"cuda:0"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2291,704,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2288, "rf_id": 1545, "parent": 2287, "fw_parent": 2287, "seq_id": 310, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2281,704,0,51200,2,"cuda:0"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2287, "rf_id": 1544, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_reshape_alias", "id": 2295, "rf_id": 1551, "parent": 2294, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[2286,578,0,163840,2,"cuda:0"],[20,8,16,64],[64,20480,1280,1]], "input_shapes": [[20,128,64],[[],[],[],[]],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2296,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2294, "rf_id": 1550, "parent": 2293, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2286,578,0,163840,2,"cuda:0"],[20,8,16,64]], "input_shapes": [[20,128,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2296,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2293, "rf_id": 1549, "parent": 2292, "fw_parent": 2292, "seq_id": 309, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2286,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,128,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2292, "rf_id": 1548, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2298, "rf_id": 1553, "parent": 2297, "fw_parent": 2297, "seq_id": 308, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2291,704,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2297, "rf_id": 1552, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2303, "rf_id": 1558, "parent": 2302, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,16,20,20],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[2304,980,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2302, "rf_id": 1557, "parent": 2301, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2291,704,0,51200,2,"cuda:0"],"<None>","<None>","<None>","<None>",0], "input_shapes": [[8,16,20,20],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","Int"],
      "outputs": [[2304,980,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout_backward", "id": 2301, "rf_id": 1556, "parent": 2300, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout_backward(Tensor grad_output, Tensor mask, float scale) -> Tensor",
      "inputs": [[2291,704,0,51200,2,"cuda:0"],[1604,1605,0,51200,1,"cuda:0"],1.111111], "input_shapes": [[8,16,20,20],[8,16,20,20],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(bool)","Double"],
      "outputs": [[2304,980,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "NativeDropoutBackward0", "id": 2300, "rf_id": 1555, "parent": 2299, "fw_parent": 2299, "seq_id": 307, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2291,704,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: NativeDropoutBackward0", "id": 2299, "rf_id": 1554, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2306, "rf_id": 1560, "parent": 2305, "fw_parent": 2305, "seq_id": 306, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2304,980,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2305, "rf_id": 1559, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2308, "rf_id": 1562, "parent": 2307, "fw_parent": 2307, "seq_id": 305, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2304,980,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2307, "rf_id": 1561, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2312, "rf_id": 1566, "parent": 2311, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2304,980,0,51200,2,"cuda:0"],[128,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2313,980,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2311, "rf_id": 1565, "parent": 2310, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2304,980,0,51200,2,"cuda:0"],[128,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2313,980,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2310, "rf_id": 1564, "parent": 2309, "fw_parent": 2309, "seq_id": 304, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2304,980,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2309, "rf_id": 1563, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2317, "rf_id": 1570, "parent": 2316, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1577,1578,0,1,8,"cpu"],[],[],0], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(long int)","GenericList[]","GenericList[]","Int"],
      "outputs": [[2318,1578,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::select", "id": 2316, "rf_id": 1569, "parent": 2315, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[1577,1578,0,1,8,"cpu"],0,0], "input_shapes": [[1],[],[]], "input_types": ["Tensor(long int)","Int","Int"],
      "outputs": [[2318,1578,0,1,8,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 2320, "rf_id": 1572, "parent": 2319, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[2318,1578,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::item", "id": 2319, "rf_id": 1571, "parent": 2315, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[2318,1578,0,1,8,"cpu"]], "input_shapes": [[]], "input_types": ["Tensor(long int)"],
      "outputs": [1], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "ScaledUpperTriangMaskedSoftmaxBackward", "id": 2315, "rf_id": 1568, "parent": 2314, "fw_parent": 2314, "seq_id": 303, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2313,980,0,51200,2,"cuda:0"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ScaledUpperTriangMaskedSoftmaxBackward", "id": 2314, "rf_id": 1567, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2324, "rf_id": 1576, "parent": 2323, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2313,980,0,51200,2,"cuda:0"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2325,980,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2323, "rf_id": 1575, "parent": 2322, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2313,980,0,51200,2,"cuda:0"],[8,16,20,20]], "input_shapes": [[128,20,20],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2325,980,0,51200,2,"cuda:0"]], "output_shapes": [[8,16,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2322, "rf_id": 1574, "parent": 2321, "fw_parent": 2321, "seq_id": 302, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2313,980,0,51200,2,"cuda:0"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2321, "rf_id": 1573, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2327, "rf_id": 1578, "parent": 2326, "fw_parent": 2326, "seq_id": 300, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2325,980,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2326, "rf_id": 1577, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2331, "rf_id": 1582, "parent": 2330, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2325,980,0,51200,2,"cuda:0"],[128,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2332,980,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2330, "rf_id": 1581, "parent": 2329, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2325,980,0,51200,2,"cuda:0"],[128,20,20]], "input_shapes": [[8,16,20,20],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2332,980,0,51200,2,"cuda:0"]], "output_shapes": [[128,20,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2329, "rf_id": 1580, "parent": 2328, "fw_parent": 2328, "seq_id": 299, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2325,980,0,51200,2,"cuda:0"]], "input_shapes": [[8,16,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2328, "rf_id": 1579, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2336, "rf_id": 1586, "parent": 2335, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1560,583,64,163840,2,"cuda:0"],[128,20,64],[192,24576,1],"<None>"], "input_shapes": [[128,64,20],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2337,583,64,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2335, "rf_id": 1585, "parent": 2334, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1560,583,64,163840,2,"cuda:0"],1,2], "input_shapes": [[128,64,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2337,583,64,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 2338, "rf_id": 1587, "parent": 2334, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2332,980,0,51200,2,"cuda:0"],[2337,583,64,163840,2,"cuda:0"]], "input_shapes": [[128,20,20],[128,20,64]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2339,430,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2343, "rf_id": 1589, "parent": 2340, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2339,430,0,163840,2,"cuda:0"],[2341,2342,0,1,8,"cpu"]], "input_shapes": [[128,20,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[2344,2345,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2340, "rf_id": 1588, "parent": 2334, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[2339,430,0,163840,2,"cuda:0"],0.125000], "input_shapes": [[128,20,64],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[2344,2345,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2347, "rf_id": 1591, "parent": 2346, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1554,583,0,163840,2,"cuda:0"],[128,64,20],[192,1,24576],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2348,583,0,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2346, "rf_id": 1590, "parent": 2334, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1554,583,0,163840,2,"cuda:0"],1,2], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2348,583,0,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::bmm", "id": 2349, "rf_id": 1592, "parent": 2334, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::bmm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2348,583,0,163840,2,"cuda:0"],[2332,980,0,51200,2,"cuda:0"]], "input_shapes": [[128,64,20],[128,20,20]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2350,2351,0,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2355, "rf_id": 1594, "parent": 2352, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2350,2351,0,163840,2,"cuda:0"],[2353,2354,0,1,8,"cpu"]], "input_shapes": [[128,64,20],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(double)"],
      "outputs": [[2356,430,0,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mul", "id": 2352, "rf_id": 1593, "parent": 2334, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mul.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[2350,2351,0,163840,2,"cuda:0"],0.125000], "input_shapes": [[128,64,20],[]], "input_types": ["Tensor(c10::BFloat16)","Double"],
      "outputs": [[2356,430,0,163840,2,"cuda:0"]], "output_shapes": [[128,64,20]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "BaddbmmBackward0", "id": 2334, "rf_id": 1584, "parent": 2333, "fw_parent": 2333, "seq_id": 298, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2332,980,0,51200,2,"cuda:0"]], "input_shapes": [[128,20,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: BaddbmmBackward0", "id": 2333, "rf_id": 1583, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2360, "rf_id": 1598, "parent": 2359, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2356,430,0,163840,2,"cuda:0"],[128,20,64],[1280,1,20],"<None>"], "input_shapes": [[128,64,20],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2361,430,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2359, "rf_id": 1597, "parent": 2358, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[2356,430,0,163840,2,"cuda:0"],1,2], "input_shapes": [[128,64,20],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2361,430,0,163840,2,"cuda:0"]], "output_shapes": [[128,20,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "TransposeBackward0", "id": 2358, "rf_id": 1596, "parent": 2357, "fw_parent": 2357, "seq_id": 297, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2356,430,0,163840,2,"cuda:0"]], "input_shapes": [[128,64,20]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 2357, "rf_id": 1595, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2365, "rf_id": 1602, "parent": 2364, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2361,430,0,163840,2,"cuda:0"],[20,128,64],[1,1280,20],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2366,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2364, "rf_id": 1601, "parent": 2363, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[2361,430,0,163840,2,"cuda:0"],0,1], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2366,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "TransposeBackward0", "id": 2363, "rf_id": 1600, "parent": 2362, "fw_parent": 2362, "seq_id": 296, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2361,430,0,163840,2,"cuda:0"]], "input_shapes": [[128,20,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 2362, "rf_id": 1599, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2370, "rf_id": 1606, "parent": 2369, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2344,2345,0,163840,2,"cuda:0"],[20,128,64],[64,1280,1],"<None>"], "input_shapes": [[128,20,64],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2371,2345,0,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2369, "rf_id": 1605, "parent": 2368, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[2344,2345,0,163840,2,"cuda:0"],0,1], "input_shapes": [[128,20,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2371,2345,0,163840,2,"cuda:0"]], "output_shapes": [[20,128,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "TransposeBackward0", "id": 2368, "rf_id": 1604, "parent": 2367, "fw_parent": 2367, "seq_id": 295, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2344,2345,0,163840,2,"cuda:0"]], "input_shapes": [[128,20,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 2367, "rf_id": 1603, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_reshape_alias", "id": 2375, "rf_id": 1610, "parent": 2374, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[2366,430,0,163840,2,"cuda:0"],[20,8,16,64],[1,20480,1280,20]], "input_shapes": [[20,128,64],[[],[],[],[]],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2376,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2374, "rf_id": 1609, "parent": 2373, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2366,430,0,163840,2,"cuda:0"],[20,8,16,64]], "input_shapes": [[20,128,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2376,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2373, "rf_id": 1608, "parent": 2372, "fw_parent": 2372, "seq_id": 294, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2366,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,128,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2372, "rf_id": 1607, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_reshape_alias", "id": 2380, "rf_id": 1614, "parent": 2379, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[2371,2345,0,163840,2,"cuda:0"],[20,8,16,64],[64,20480,1280,1]], "input_shapes": [[20,128,64],[[],[],[],[]],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2381,2345,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2379, "rf_id": 1613, "parent": 2378, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2371,2345,0,163840,2,"cuda:0"],[20,8,16,64]], "input_shapes": [[20,128,64],[[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]"],
      "outputs": [[2381,2345,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2378, "rf_id": 1612, "parent": 2377, "fw_parent": 2377, "seq_id": 293, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2371,2345,0,163840,2,"cuda:0"]], "input_shapes": [[20,128,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2377, "rf_id": 1611, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2383, "rf_id": 1616, "parent": 2382, "fw_parent": 2382, "seq_id": 291, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2296,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2382, "rf_id": 1615, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2385, "rf_id": 1618, "parent": 2384, "fw_parent": 2384, "seq_id": 290, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2376,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2384, "rf_id": 1617, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2387, "rf_id": 1620, "parent": 2386, "fw_parent": 2386, "seq_id": 289, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2381,2345,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2386, "rf_id": 1619, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2392, "rf_id": 1625, "parent": 2391, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2393,2351,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2395, "rf_id": 1627, "parent": 2394, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2393,2351,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2393,2351,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2394, "rf_id": 1626, "parent": 2391, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2393,2351,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2393,2351,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2391, "rf_id": 1624, "parent": 2390, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2393,2351,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2397, "rf_id": 1629, "parent": 2396, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2393,2351,0,163840,2,"cuda:0"],[20,8,16,64],[8192,1024,64,1],0], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[2398,2351,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2396, "rf_id": 1628, "parent": 2390, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2393,2351,0,163840,2,"cuda:0"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2398,2351,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2399, "rf_id": 1630, "parent": 2390, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2398,2351,0,163840,2,"cuda:0"],[2296,578,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2398,2351,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2390, "rf_id": 1623, "parent": 2389, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2296,578,0,163840,2,"cuda:0"],[20,8,16,64],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2393,2351,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2389, "rf_id": 1622, "parent": 2388, "fw_parent": 2388, "seq_id": 288, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2296,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2388, "rf_id": 1621, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2404, "rf_id": 1635, "parent": 2403, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2405,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2407, "rf_id": 1637, "parent": 2406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2405,1705,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2405,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2406, "rf_id": 1636, "parent": 2403, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2405,1705,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2405,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2403, "rf_id": 1634, "parent": 2402, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2405,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2409, "rf_id": 1639, "parent": 2408, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2405,1705,0,491520,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],128], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[2410,1705,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 2408, "rf_id": 1638, "parent": 2402, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[2405,1705,0,491520,2,"cuda:0"],3,-1], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2410,1705,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2411, "rf_id": 1640, "parent": 2402, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2410,1705,128,163840,2,"cuda:0"],[2393,2351,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2410,1705,128,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select_backward", "id": 2402, "rf_id": 1633, "parent": 2401, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt index) -> Tensor",
      "inputs": [[2393,2351,0,163840,2,"cuda:0"],[20,8,16,3,64],3,-1], "input_shapes": [[20,8,16,64],[[],[],[],[],[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int"],
      "outputs": [[2405,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SelectBackward0", "id": 2401, "rf_id": 1632, "parent": 2400, "fw_parent": 2400, "seq_id": 287, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2393,2351,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SelectBackward0", "id": 2400, "rf_id": 1631, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2416, "rf_id": 1645, "parent": 2415, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2417,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2419, "rf_id": 1647, "parent": 2418, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2417,980,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2417,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2418, "rf_id": 1646, "parent": 2415, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2417,980,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2417,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2415, "rf_id": 1644, "parent": 2414, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2417,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2421, "rf_id": 1649, "parent": 2420, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2417,980,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2422,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2420, "rf_id": 1648, "parent": 2414, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2417,980,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2422,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2423, "rf_id": 1650, "parent": 2414, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2422,980,0,491520,2,"cuda:0"],[2405,1705,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2422,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2414, "rf_id": 1643, "parent": 2413, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2405,1705,0,491520,2,"cuda:0"],[20,8,16,3,64],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2417,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2413, "rf_id": 1642, "parent": 2412, "fw_parent": 2412, "seq_id": 286, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2405,1705,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2412, "rf_id": 1641, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2428, "rf_id": 1655, "parent": 2427, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2429,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2431, "rf_id": 1657, "parent": 2430, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2429,1705,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2429,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2430, "rf_id": 1656, "parent": 2427, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2429,1705,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2429,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2427, "rf_id": 1654, "parent": 2426, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2429,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2433, "rf_id": 1659, "parent": 2432, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2429,1705,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2434,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2432, "rf_id": 1658, "parent": 2426, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2429,1705,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2434,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2435, "rf_id": 1660, "parent": 2426, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2434,1705,0,491520,2,"cuda:0"],[2417,980,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2434,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2426, "rf_id": 1653, "parent": 2425, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2417,980,0,491520,2,"cuda:0"],[20,8,16,3,64],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2429,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2425, "rf_id": 1652, "parent": 2424, "fw_parent": 2424, "seq_id": 285, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2417,980,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2424, "rf_id": 1651, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2440, "rf_id": 1665, "parent": 2439, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2441,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2443, "rf_id": 1667, "parent": 2442, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2441,980,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2441,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2442, "rf_id": 1666, "parent": 2439, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2441,980,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2441,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2439, "rf_id": 1664, "parent": 2438, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2441,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2445, "rf_id": 1669, "parent": 2444, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2441,980,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2446,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2444, "rf_id": 1668, "parent": 2438, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2441,980,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2446,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2447, "rf_id": 1670, "parent": 2438, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2446,980,0,491520,2,"cuda:0"],[2429,1705,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2446,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2438, "rf_id": 1663, "parent": 2437, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2429,1705,0,491520,2,"cuda:0"],[20,8,16,3,64],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2441,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2437, "rf_id": 1662, "parent": 2436, "fw_parent": 2436, "seq_id": 284, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2429,1705,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2436, "rf_id": 1661, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2452, "rf_id": 1675, "parent": 2451, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2453,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2455, "rf_id": 1677, "parent": 2454, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2453,578,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2453,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2454, "rf_id": 1676, "parent": 2451, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2453,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2453,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2451, "rf_id": 1674, "parent": 2450, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2453,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2457, "rf_id": 1679, "parent": 2456, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2453,578,0,163840,2,"cuda:0"],[20,8,16,64],[8192,1024,64,1],0], "input_shapes": [[20,8,16,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[2458,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2456, "rf_id": 1678, "parent": 2450, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2453,578,0,163840,2,"cuda:0"],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2458,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2459, "rf_id": 1680, "parent": 2450, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2458,578,0,163840,2,"cuda:0"],[2376,430,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2458,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2450, "rf_id": 1673, "parent": 2449, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2376,430,0,163840,2,"cuda:0"],[20,8,16,64],3,0,9223372036854775807,1], "input_shapes": [[20,8,16,64],[[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2453,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2449, "rf_id": 1672, "parent": 2448, "fw_parent": 2448, "seq_id": 283, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2376,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2448, "rf_id": 1671, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2464, "rf_id": 1685, "parent": 2463, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2465,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2467, "rf_id": 1687, "parent": 2466, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2465,1705,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2465,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2466, "rf_id": 1686, "parent": 2463, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2465,1705,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2465,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2463, "rf_id": 1684, "parent": 2462, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2465,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2469, "rf_id": 1689, "parent": 2468, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2465,1705,0,491520,2,"cuda:0"],[20,8,16,64],[24576,3072,192,1],64], "input_shapes": [[20,8,16,3,64],[[],[],[],[]],[[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int]","GenericList[Int,Int,Int,Int]","Int"],
      "outputs": [[2470,1705,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select", "id": 2468, "rf_id": 1688, "parent": 2462, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)",
      "inputs": [[2465,1705,0,491520,2,"cuda:0"],3,-2], "input_shapes": [[20,8,16,3,64],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2470,1705,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2471, "rf_id": 1690, "parent": 2462, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2470,1705,64,163840,2,"cuda:0"],[2453,578,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,16,64],[20,8,16,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2470,1705,64,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::select_backward", "id": 2462, "rf_id": 1683, "parent": 2461, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::select_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt index) -> Tensor",
      "inputs": [[2453,578,0,163840,2,"cuda:0"],[20,8,16,3,64],3,-2], "input_shapes": [[20,8,16,64],[[],[],[],[],[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int"],
      "outputs": [[2465,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SelectBackward0", "id": 2461, "rf_id": 1682, "parent": 2460, "fw_parent": 2460, "seq_id": 282, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2453,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SelectBackward0", "id": 2460, "rf_id": 1681, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2476, "rf_id": 1695, "parent": 2475, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2477,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2480, "rf_id": 1697, "parent": 2479, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2477,2478,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2477,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2479, "rf_id": 1696, "parent": 2475, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2477,2478,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2477,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2475, "rf_id": 1694, "parent": 2474, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2477,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2482, "rf_id": 1699, "parent": 2481, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2477,2478,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2483,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2481, "rf_id": 1698, "parent": 2474, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2477,2478,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2483,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2484, "rf_id": 1700, "parent": 2474, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2483,2478,0,491520,2,"cuda:0"],[2465,1705,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2483,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2474, "rf_id": 1693, "parent": 2473, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2465,1705,0,491520,2,"cuda:0"],[20,8,16,3,64],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2477,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2473, "rf_id": 1692, "parent": 2472, "fw_parent": 2472, "seq_id": 281, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2465,1705,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2472, "rf_id": 1691, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2489, "rf_id": 1705, "parent": 2488, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2490,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2492, "rf_id": 1707, "parent": 2491, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2490,1705,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2490,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2491, "rf_id": 1706, "parent": 2488, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2490,1705,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2490,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2488, "rf_id": 1704, "parent": 2487, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2490,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2494, "rf_id": 1709, "parent": 2493, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2490,1705,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2495,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2493, "rf_id": 1708, "parent": 2487, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2490,1705,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2495,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2496, "rf_id": 1710, "parent": 2487, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2495,1705,0,491520,2,"cuda:0"],[2477,2478,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2495,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2487, "rf_id": 1703, "parent": 2486, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2477,2478,0,491520,2,"cuda:0"],[20,8,16,3,64],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2490,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2486, "rf_id": 1702, "parent": 2485, "fw_parent": 2485, "seq_id": 280, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2477,2478,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2485, "rf_id": 1701, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2501, "rf_id": 1715, "parent": 2500, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2502,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2504, "rf_id": 1717, "parent": 2503, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2502,2478,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2502,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2503, "rf_id": 1716, "parent": 2500, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2502,2478,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2502,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2500, "rf_id": 1714, "parent": 2499, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2502,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2506, "rf_id": 1719, "parent": 2505, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2502,2478,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2507,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2505, "rf_id": 1718, "parent": 2499, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2502,2478,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2507,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2508, "rf_id": 1720, "parent": 2499, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2507,2478,0,491520,2,"cuda:0"],[2490,1705,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2507,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2499, "rf_id": 1713, "parent": 2498, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2490,1705,0,491520,2,"cuda:0"],[20,8,16,3,64],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2502,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2498, "rf_id": 1712, "parent": 2497, "fw_parent": 2497, "seq_id": 279, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2490,1705,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add_", "id": 2509, "rf_id": 1721, "parent": 2497, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)",
      "inputs": [[2441,980,0,491520,2,"cuda:0"],[2502,2478,0,491520,2,"cuda:0"],1], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[2441,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2497, "rf_id": 1711, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_reshape_alias", "id": 2513, "rf_id": 1725, "parent": 2512, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)",
      "inputs": [[2381,2345,0,163840,2,"cuda:0"],[20,8,16,1,64],[64,20480,1280,64,1]], "input_shapes": [[20,8,16,64],[[],[],[],[],[]],[[],[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]"],
      "outputs": [[2514,2345,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2512, "rf_id": 1724, "parent": 2511, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2381,2345,0,163840,2,"cuda:0"],[20,8,16,1,64]], "input_shapes": [[20,8,16,64],[[],[],[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]"],
      "outputs": [[2514,2345,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ReshapeAliasBackward0", "id": 2511, "rf_id": 1723, "parent": 2510, "fw_parent": 2510, "seq_id": 278, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2381,2345,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ReshapeAliasBackward0", "id": 2510, "rf_id": 1722, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2519, "rf_id": 1730, "parent": 2518, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,1,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2520,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2522, "rf_id": 1732, "parent": 2521, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2520,578,0,163840,2,"cuda:0"],0], "input_shapes": [[20,8,16,1,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2520,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2521, "rf_id": 1731, "parent": 2518, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2520,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,1,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2520,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2518, "rf_id": 1729, "parent": 2517, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,1,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2520,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2524, "rf_id": 1734, "parent": 2523, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2520,578,0,163840,2,"cuda:0"],[20,8,16,1,64],[8192,1024,64,64,1],0], "input_shapes": [[20,8,16,1,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2525,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2523, "rf_id": 1733, "parent": 2517, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2520,578,0,163840,2,"cuda:0"],4,0,9223372036854775807,1], "input_shapes": [[20,8,16,1,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2525,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2526, "rf_id": 1735, "parent": 2517, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2525,578,0,163840,2,"cuda:0"],[2514,2345,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,16,1,64],[20,8,16,1,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2525,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2517, "rf_id": 1728, "parent": 2516, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2514,2345,0,163840,2,"cuda:0"],[20,8,16,1,64],4,0,9223372036854775807,1], "input_shapes": [[20,8,16,1,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2520,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2516, "rf_id": 1727, "parent": 2515, "fw_parent": 2515, "seq_id": 277, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2514,2345,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,1,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2515, "rf_id": 1726, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2531, "rf_id": 1740, "parent": 2530, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2532,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2534, "rf_id": 1742, "parent": 2533, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2532,1705,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2532,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2533, "rf_id": 1741, "parent": 2530, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2532,1705,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2532,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2530, "rf_id": 1739, "parent": 2529, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2532,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2536, "rf_id": 1744, "parent": 2535, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2532,1705,0,491520,2,"cuda:0"],[20,8,16,1,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2537,1705,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2535, "rf_id": 1743, "parent": 2529, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2532,1705,0,491520,2,"cuda:0"],3,0,-2,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2537,1705,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2538, "rf_id": 1745, "parent": 2529, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2537,1705,0,163840,2,"cuda:0"],[2520,578,0,163840,2,"cuda:0"],false], "input_shapes": [[20,8,16,1,64],[20,8,16,1,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2537,1705,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,16,1,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2529, "rf_id": 1738, "parent": 2528, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2520,578,0,163840,2,"cuda:0"],[20,8,16,3,64],3,0,-2,1], "input_shapes": [[20,8,16,1,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2532,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2528, "rf_id": 1737, "parent": 2527, "fw_parent": 2527, "seq_id": 276, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2520,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,16,1,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2527, "rf_id": 1736, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2543, "rf_id": 1750, "parent": 2542, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2544,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2546, "rf_id": 1752, "parent": 2545, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2544,2478,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2544,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2545, "rf_id": 1751, "parent": 2542, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2544,2478,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2544,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2542, "rf_id": 1749, "parent": 2541, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2544,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2548, "rf_id": 1754, "parent": 2547, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2544,2478,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2549,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2547, "rf_id": 1753, "parent": 2541, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2544,2478,0,491520,2,"cuda:0"],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2549,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2550, "rf_id": 1755, "parent": 2541, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2549,2478,0,491520,2,"cuda:0"],[2532,1705,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2549,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2541, "rf_id": 1748, "parent": 2540, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2532,1705,0,491520,2,"cuda:0"],[20,8,16,3,64],2,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2544,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2540, "rf_id": 1747, "parent": 2539, "fw_parent": 2539, "seq_id": 275, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2532,1705,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2539, "rf_id": 1746, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2555, "rf_id": 1760, "parent": 2554, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2556,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2558, "rf_id": 1762, "parent": 2557, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2556,1705,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2556,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2557, "rf_id": 1761, "parent": 2554, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2556,1705,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2556,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2554, "rf_id": 1759, "parent": 2553, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2556,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2560, "rf_id": 1764, "parent": 2559, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2556,1705,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2561,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2559, "rf_id": 1763, "parent": 2553, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2556,1705,0,491520,2,"cuda:0"],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2561,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2562, "rf_id": 1765, "parent": 2553, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2561,1705,0,491520,2,"cuda:0"],[2544,2478,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2561,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2553, "rf_id": 1758, "parent": 2552, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2544,2478,0,491520,2,"cuda:0"],[20,8,16,3,64],1,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2556,1705,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2552, "rf_id": 1757, "parent": 2551, "fw_parent": 2551, "seq_id": 274, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2544,2478,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2551, "rf_id": 1756, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2567, "rf_id": 1770, "parent": 2566, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2568,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2570, "rf_id": 1772, "parent": 2569, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2568,2478,0,491520,2,"cuda:0"],0], "input_shapes": [[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2568,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2569, "rf_id": 1771, "parent": 2566, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2568,2478,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2568,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2566, "rf_id": 1769, "parent": 2565, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,16,3,64],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2568,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2572, "rf_id": 1774, "parent": 2571, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2568,2478,0,491520,2,"cuda:0"],[20,8,16,3,64],[24576,3072,192,64,1],0], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[[],[],[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","GenericList[Int,Int,Int,Int,Int]","Int"],
      "outputs": [[2573,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2571, "rf_id": 1773, "parent": 2565, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2568,2478,0,491520,2,"cuda:0"],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2573,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2574, "rf_id": 1775, "parent": 2565, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2573,2478,0,491520,2,"cuda:0"],[2556,1705,0,491520,2,"cuda:0"],false], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2573,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice_backward", "id": 2565, "rf_id": 1768, "parent": 2564, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice_backward(Tensor grad_output, SymInt[] input_sizes, int dim, SymInt start, SymInt end, SymInt step) -> Tensor",
      "inputs": [[2556,1705,0,491520,2,"cuda:0"],[20,8,16,3,64],0,0,9223372036854775807,1], "input_shapes": [[20,8,16,3,64],[[],[],[],[],[]],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int,Int,Int]","Int","Int","Int","Int"],
      "outputs": [[2568,2478,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "SliceBackward0", "id": 2564, "rf_id": 1767, "parent": 2563, "fw_parent": 2563, "seq_id": 273, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2556,1705,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add_", "id": 2575, "rf_id": 1776, "parent": 2563, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)",
      "inputs": [[2441,980,0,491520,2,"cuda:0"],[2568,2478,0,491520,2,"cuda:0"],1], "input_shapes": [[20,8,16,3,64],[20,8,16,3,64],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[2441,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,16,3,64]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: SliceBackward0", "id": 2563, "rf_id": 1766, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2579, "rf_id": 1780, "parent": 2578, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2441,980,0,491520,2,"cuda:0"],[20,8,3072]], "input_shapes": [[20,8,16,3,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2580,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2578, "rf_id": 1779, "parent": 2577, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2441,980,0,491520,2,"cuda:0"],[20,8,3072]], "input_shapes": [[20,8,16,3,64],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2580,980,0,491520,2,"cuda:0"]], "output_shapes": [[20,8,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "ViewBackward0", "id": 2577, "rf_id": 1778, "parent": 2576, "fw_parent": 2576, "seq_id": 272, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2441,980,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,16,3,64]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: ViewBackward0", "id": 2576, "rf_id": 1777, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2582, "rf_id": 1782, "parent": 2581, "fw_parent": 2581, "seq_id": 271, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2580,980,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2581, "rf_id": 1781, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2587, "rf_id": 1787, "parent": 2586, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2580,980,0,491520,2,"cuda:0"],[160,3072]], "input_shapes": [[20,8,3072],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2588,980,0,491520,2,"cuda:0"]], "output_shapes": [[160,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::reshape", "id": 2586, "rf_id": 1786, "parent": 2585, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)",
      "inputs": [[2580,980,0,491520,2,"cuda:0"],[160,3072]], "input_shapes": [[20,8,3072],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2588,980,0,491520,2,"cuda:0"]], "output_shapes": [[160,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 2589, "rf_id": 1788, "parent": 2585, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2588,980,0,491520,2,"cuda:0"],[470,467,0,3145728,2,"cuda:0"]], "input_shapes": [[160,3072],[3072,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2590,578,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_unsafe_view", "id": 2591, "rf_id": 1789, "parent": 2585, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor",
      "inputs": [[2590,578,0,163840,2,"cuda:0"],[20,8,1024]], "input_shapes": [[160,1024],[[],[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]"],
      "outputs": [[2592,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 2585, "rf_id": 1785, "parent": 2584, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2580,980,0,491520,2,"cuda:0"],[470,467,0,3145728,2,"cuda:0"]], "input_shapes": [[20,8,3072],[3072,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2592,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2593, "rf_id": 1790, "parent": 2584, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2580,980,0,491520,2,"cuda:0"],[160,3072]], "input_shapes": [[20,8,3072],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2594,980,0,491520,2,"cuda:0"]], "output_shapes": [[160,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2595, "rf_id": 1791, "parent": 2584, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1457,329,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[20,8,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2596,329,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2599, "rf_id": 1794, "parent": 2598, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2594,980,0,491520,2,"cuda:0"],[3072,160],[1,3072],"<None>"], "input_shapes": [[160,3072],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[2600,980,0,491520,2,"cuda:0"]], "output_shapes": [[3072,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2598, "rf_id": 1793, "parent": 2597, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[2594,980,0,491520,2,"cuda:0"],0,1], "input_shapes": [[160,3072],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2600,980,0,491520,2,"cuda:0"]], "output_shapes": [[3072,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::t", "id": 2597, "rf_id": 1792, "parent": 2584, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::t(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2594,980,0,491520,2,"cuda:0"]], "input_shapes": [[160,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2600,980,0,491520,2,"cuda:0"]], "output_shapes": [[3072,160]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::mm", "id": 2602, "rf_id": 1796, "parent": 2601, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::mm(Tensor self, Tensor mat2) -> Tensor",
      "inputs": [[2600,980,0,491520,2,"cuda:0"],[2596,329,0,163840,2,"cuda:0"]], "input_shapes": [[3072,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2603,904,0,3145728,2,"cuda:0"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::matmul", "id": 2601, "rf_id": 1795, "parent": 2584, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::matmul(Tensor self, Tensor other) -> Tensor",
      "inputs": [[2600,980,0,491520,2,"cuda:0"],[2596,329,0,163840,2,"cuda:0"]], "input_shapes": [[3072,160],[160,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2603,904,0,3145728,2,"cuda:0"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2606, "rf_id": 1798, "parent": 2604, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2605,436,0,3072,2,"cuda:0"],[1,3072],[0,1],"<None>"], "input_shapes": [[3072],[[],[]],[[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]","GenericList[Int,Int]","None"],
      "outputs": [[2607,436,0,3072,2,"cuda:0"]], "output_shapes": [[1,3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::sum", "id": 2604, "rf_id": 1797, "parent": 2584, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[2594,980,0,491520,2,"cuda:0"],[0],false,"<None>"], "input_shapes": [[160,3072],[[]],[],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","Bool","None"],
      "outputs": [[2605,436,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 2584, "rf_id": 1784, "parent": 2583, "fw_parent": 2583, "seq_id": 270, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2580,980,0,491520,2,"cuda:0"]], "input_shapes": [[20,8,3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: LinearWithGradAccumulationAndAsyncCommunicationBackward", "id": 2583, "rf_id": 1783, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2611, "rf_id": 1802, "parent": 2610, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2603,904,0,3145728,2,"cuda:0"]], "input_shapes": [[3072,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2610, "rf_id": 1801, "parent": 2609, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2603,904,0,3145728,2,"cuda:0"]], "input_shapes": [[3072,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2607,904,0,3145728,2,"cuda:0"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2609, "rf_id": 1800, "parent": 2608, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2603,904,0,3145728,2,"cuda:0"]], "input_shapes": [[3072,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2614, "rf_id": 1805, "parent": 2613, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],[3145728],[1],9447424], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2615,1377,9447424,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2613, "rf_id": 1804, "parent": 2612, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,9447424,12593152,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2615,1377,9447424,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2612, "rf_id": 1803, "parent": 2608, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,9447424,3145728], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2615,1377,9447424,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2617, "rf_id": 1807, "parent": 2616, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2615,1377,9447424,3145728,2,"cuda:0"],[3072,1024]], "input_shapes": [[3145728],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2618,1377,9447424,3145728,2,"cuda:0"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2616, "rf_id": 1806, "parent": 2608, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2615,1377,9447424,3145728,2,"cuda:0"],[2607,904,0,3145728,2,"cuda:0"]], "input_shapes": [[3145728],[3072,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2618,1377,9447424,3145728,2,"cuda:0"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2619, "rf_id": 1808, "parent": 2608, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2618,1377,9447424,3145728,2,"cuda:0"],[2607,904,0,3145728,2,"cuda:0"],true], "input_shapes": [[3072,1024],[3072,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2618,1377,9447424,3145728,2,"cuda:0"]], "output_shapes": [[3072,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2620, "rf_id": 1809, "parent": 2608, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2607,904,0,3145728,2,"cuda:0"],"<Stream>"], "input_shapes": [[3072,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2621, "rf_id": 1810, "parent": 2608, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2607,904,0,3145728,2,"cuda:0"],[2618,1377,9447424,3145728,2,"cuda:0"]], "input_shapes": [[3072,1024],[3072,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2608, "rf_id": 1799, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2625, "rf_id": 1814, "parent": 2624, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2605,436,0,3072,2,"cuda:0"]], "input_shapes": [[3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2624, "rf_id": 1813, "parent": 2623, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2605,436,0,3072,2,"cuda:0"]], "input_shapes": [[3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2626,436,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2623, "rf_id": 1812, "parent": 2622, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2605,436,0,3072,2,"cuda:0"]], "input_shapes": [[3072]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2629, "rf_id": 1817, "parent": 2628, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],[3072],[1],12593152], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2630,1377,12593152,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2628, "rf_id": 1816, "parent": 2627, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,12593152,12596224,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2630,1377,12593152,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2627, "rf_id": 1815, "parent": 2622, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,12593152,3072], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2630,1377,12593152,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2632, "rf_id": 1819, "parent": 2631, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2630,1377,12593152,3072,2,"cuda:0"],[3072]], "input_shapes": [[3072],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2633,1377,12593152,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2631, "rf_id": 1818, "parent": 2622, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2630,1377,12593152,3072,2,"cuda:0"],[2626,436,0,3072,2,"cuda:0"]], "input_shapes": [[3072],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2633,1377,12593152,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2634, "rf_id": 1820, "parent": 2622, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2633,1377,12593152,3072,2,"cuda:0"],[2626,436,0,3072,2,"cuda:0"],true], "input_shapes": [[3072],[3072],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2633,1377,12593152,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2635, "rf_id": 1821, "parent": 2622, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2626,436,0,3072,2,"cuda:0"],"<Stream>"], "input_shapes": [[3072],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2636, "rf_id": 1822, "parent": 2622, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2626,436,0,3072,2,"cuda:0"],[2633,1377,12593152,3072,2,"cuda:0"]], "input_shapes": [[3072],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2622, "rf_id": 1811, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_CopyToModelParallelRegionBackward", "id": 2638, "rf_id": 1824, "parent": 2637, "fw_parent": 2637, "seq_id": 269, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2592,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _CopyToModelParallelRegionBackward", "id": 2637, "rf_id": 1823, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 2642, "rf_id": 1827, "parent": 2640, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2641,467,0,3145728,2,"cuda:0"],"<Stream>"], "input_shapes": [[3072,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2643, "rf_id": 1828, "parent": 2640, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[2644,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2645, "rf_id": 1829, "parent": 2640, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[470,467,0,3145728,2,"cuda:0"],[2644,57,0,0,2,"cuda:0"]], "input_shapes": [[3072,1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2640, "rf_id": 1826, "parent": 2639, "fw_parent": 2639, "seq_id": 268, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2592,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2639, "rf_id": 1825, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2647, "rf_id": 1831, "parent": 2646, "fw_parent": 2646, "seq_id": 266, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2592,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2646, "rf_id": 1830, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2649, "rf_id": 1833, "parent": 2648, "fw_parent": 2648, "seq_id": 265, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2592,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2648, "rf_id": 1832, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty_strided", "id": 2654, "rf_id": 1837, "parent": 2653, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,8,1024],[8192,1024,1],15,0,"cuda:0","<None>"], "input_shapes": [[[],[],[]],[[],[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","Int","Int","Device","None"],
      "outputs": [[2655,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2653, "rf_id": 1836, "parent": 2651, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2652,329,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[2655,430,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 2657, "rf_id": 1839, "parent": 2656, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[2658,436,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2656, "rf_id": 1838, "parent": 2651, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[422,423,0,1024,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[2658,436,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 2660, "rf_id": 1841, "parent": 2659, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],15,0,"cuda:0","<None>"], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","None"],
      "outputs": [[2661,1065,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2659, "rf_id": 1840, "parent": 2651, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[424,425,0,1024,2,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","None"],
      "outputs": [[2661,1065,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 2662, "rf_id": 1842, "parent": 2651, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[16,1024],6,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2663,676,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 2665, "rf_id": 1844, "parent": 2664, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[16,1024],[1024,1],6,0,"cuda:0","<None>"], "input_shapes": [[[],[]],[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[2666,1370,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_like", "id": 2664, "rf_id": 1843, "parent": 2651, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2663,676,0,16384,4,"cuda:0"],"<None>","<None>","<None>","<None>","<None>"], "input_shapes": [[16,1024],[],[],[],[],[]], "input_types": ["Tensor(float)","None","None","None","None","None"],
      "outputs": [[2666,1370,0,16384,4,"cuda:0"]], "output_shapes": [[16,1024]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "FusedLayerNormAffineFunctionBackward", "id": 2651, "rf_id": 1835, "parent": 2650, "fw_parent": 2650, "seq_id": 264, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2592,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: FusedLayerNormAffineFunctionBackward", "id": 2650, "rf_id": 1834, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2670, "rf_id": 1848, "parent": 2669, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2658,436,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2669, "rf_id": 1847, "parent": 2668, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2658,436,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2671,436,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2668, "rf_id": 1846, "parent": 2667, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2658,436,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2674, "rf_id": 1851, "parent": 2673, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],[1024],[1],12596224], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[1437,1377,12596224,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2673, "rf_id": 1850, "parent": 2672, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,12596224,12597248,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[1437,1377,12596224,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2672, "rf_id": 1849, "parent": 2667, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,12596224,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[1437,1377,12596224,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2676, "rf_id": 1853, "parent": 2675, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1437,1377,12596224,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2677,1377,12596224,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2675, "rf_id": 1852, "parent": 2667, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[1437,1377,12596224,1024,2,"cuda:0"],[2671,436,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2677,1377,12596224,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2678, "rf_id": 1854, "parent": 2667, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2677,1377,12596224,1024,2,"cuda:0"],[2671,436,0,1024,2,"cuda:0"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2677,1377,12596224,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2679, "rf_id": 1855, "parent": 2667, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2671,436,0,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2680, "rf_id": 1856, "parent": 2667, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2671,436,0,1024,2,"cuda:0"],[2677,1377,12596224,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2667, "rf_id": 1845, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2684, "rf_id": 1860, "parent": 2683, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2661,1065,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2683, "rf_id": 1859, "parent": 2682, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2661,1065,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2685,1065,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2682, "rf_id": 1858, "parent": 2681, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2661,1065,0,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2688, "rf_id": 1863, "parent": 2687, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],[1024],[1],12597248], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2666,1377,12597248,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2687, "rf_id": 1862, "parent": 2686, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,12597248,12598272,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2666,1377,12597248,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2686, "rf_id": 1861, "parent": 2681, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,12597248,1024], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2666,1377,12597248,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2690, "rf_id": 1865, "parent": 2689, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2666,1377,12597248,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2691,1377,12597248,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2689, "rf_id": 1864, "parent": 2681, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2666,1377,12597248,1024,2,"cuda:0"],[2685,1065,0,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2691,1377,12597248,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2692, "rf_id": 1866, "parent": 2681, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2691,1377,12597248,1024,2,"cuda:0"],[2685,1065,0,1024,2,"cuda:0"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2691,1377,12597248,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2693, "rf_id": 1867, "parent": 2681, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2685,1065,0,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2694, "rf_id": 1868, "parent": 2681, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2685,1065,0,1024,2,"cuda:0"],[2691,1377,12597248,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2681, "rf_id": 1857, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2696, "rf_id": 1870, "parent": 2695, "fw_parent": 2695, "seq_id": 263, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2655,430,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add_", "id": 2697, "rf_id": 1871, "parent": 2695, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)",
      "inputs": [[2161,812,0,163840,2,"cuda:0"],[2655,430,0,163840,2,"cuda:0"],1], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[2161,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2695, "rf_id": 1869, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2699, "rf_id": 1873, "parent": 2698, "fw_parent": 2698, "seq_id": 261, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2161,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2698, "rf_id": 1872, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2703, "rf_id": 1877, "parent": 2702, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2161,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2702, "rf_id": 1876, "parent": 2701, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2161,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2704,812,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2701, "rf_id": 1875, "parent": 2700, "fw_parent": 2700, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 2, "op_schema": "",
      "inputs": [[2161,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2700, "rf_id": 1874, "parent": 1405, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "CheckpointFunctionBackward", "id": 1405, "rf_id": 936, "parent": 1403, "fw_parent": 2, "seq_id": 406, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1358,359,0,163840,2,"cuda:0"],[1404,0,0,0,0,""]], "input_shapes": [[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(nullptr (uninitialized))"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: CheckpointFunctionBackward", "id": 1403, "rf_id": 935, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2706, "rf_id": 1879, "parent": 2705, "fw_parent": 2, "seq_id": 404, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2704,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2705, "rf_id": 1878, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2708, "rf_id": 1881, "parent": 2707, "fw_parent": 2, "seq_id": 403, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2704,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2707, "rf_id": 1880, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2710, "rf_id": 1883, "parent": 2709, "fw_parent": 2, "seq_id": 402, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2704,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2709, "rf_id": 1882, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2715, "rf_id": 1888, "parent": 2714, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,8,1024],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[1888,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2714, "rf_id": 1887, "parent": 2713, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2704,812,0,163840,2,"cuda:0"],"<None>","<None>","<None>","<None>",0], "input_shapes": [[20,8,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","None","None","None","None","Int"],
      "outputs": [[1888,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::native_dropout_backward", "id": 2713, "rf_id": 1886, "parent": 2712, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::native_dropout_backward(Tensor grad_output, Tensor mask, float scale) -> Tensor",
      "inputs": [[2704,812,0,163840,2,"cuda:0"],[387,368,0,163840,1,"cuda:0"],1.111111], "input_shapes": [[20,8,1024],[20,8,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(bool)","Double"],
      "outputs": [[1888,578,0,163840,2,"cuda:0"]], "output_shapes": [[20,8,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "NativeDropoutBackward0", "id": 2712, "rf_id": 1885, "parent": 2711, "fw_parent": 2, "seq_id": 401, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2704,812,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: NativeDropoutBackward0", "id": 2711, "rf_id": 1884, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PostBackwardFunctionModuleBackward", "id": 2717, "rf_id": 1890, "parent": 2716, "fw_parent": 2, "seq_id": 400, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1888,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward", "id": 2716, "rf_id": 1889, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "CloneBackward0", "id": 2719, "rf_id": 1892, "parent": 2718, "fw_parent": 2, "seq_id": 399, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1888,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: CloneBackward0", "id": 2718, "rf_id": 1891, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2723, "rf_id": 1896, "parent": 2722, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1888,578,0,163840,2,"cuda:0"],[8,20,1024],[1024,8192,1],"<None>"], "input_shapes": [[20,8,1024],[[],[],[]],[[],[],[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int,Int]","GenericList[Int,Int,Int]","None"],
      "outputs": [[2724,578,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::transpose", "id": 2722, "rf_id": 1895, "parent": 2721, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)",
      "inputs": [[1888,578,0,163840,2,"cuda:0"],0,1], "input_shapes": [[20,8,1024],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[2724,578,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "TransposeBackward0", "id": 2721, "rf_id": 1894, "parent": 2720, "fw_parent": 2, "seq_id": 398, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1888,578,0,163840,2,"cuda:0"]], "input_shapes": [[20,8,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: TransposeBackward0", "id": 2720, "rf_id": 1893, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "AddBackward0", "id": 2726, "rf_id": 1898, "parent": 2725, "fw_parent": 2, "seq_id": 397, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2724,578,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: AddBackward0", "id": 2725, "rf_id": 1897, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2728, "rf_id": 1900, "parent": 2727, "fw_parent": 2, "seq_id": 396, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2724,578,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2727, "rf_id": 1899, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2736, "rf_id": 1908, "parent": 2735, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20],4,0,"cuda:0","<None>",0], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[2737,132,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty_like", "id": 2735, "rf_id": 1907, "parent": 2734, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[343,10,0,160,8,"cuda:0"],4,0,"cuda:0","<None>",0], "input_shapes": [[8,20],[],[],[],[],[]], "input_types": ["Tensor(long int)","Int","Int","Device","None","Int"],
      "outputs": [[2737,132,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::copy_", "id": 2738, "rf_id": 1909, "parent": 2734, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2737,132,0,160,8,"cuda:0"],[343,10,0,160,8,"cuda:0"],false], "input_shapes": [[8,20],[8,20],[]], "input_types": ["Tensor(long int)","Tensor(long int)","Bool"],
      "outputs": [[2737,132,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::clone", "id": 2734, "rf_id": 1906, "parent": 2733, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[343,10,0,160,8,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[2737,132,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::contiguous", "id": 2733, "rf_id": 1905, "parent": 2732, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[343,10,0,160,8,"cuda:0"],0], "input_shapes": [[8,20],[]], "input_types": ["Tensor(long int)","Int"],
      "outputs": [[2737,132,0,160,8,"cuda:0"]], "output_shapes": [[8,20]], "output_types": ["Tensor(long int)"]
    },
    {
      "name": "aten::empty", "id": 2742, "rf_id": 1913, "parent": 2741, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20,1024],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[2743,812,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2741, "rf_id": 1912, "parent": 2740, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2724,578,0,163840,2,"cuda:0"],15,0,"cuda:0","<None>",0], "input_shapes": [[8,20,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Int"],
      "outputs": [[2743,812,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2744, "rf_id": 1914, "parent": 2740, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2743,812,0,163840,2,"cuda:0"],[2724,578,0,163840,2,"cuda:0"],false], "input_shapes": [[8,20,1024],[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2743,812,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::clone", "id": 2740, "rf_id": 1911, "parent": 2739, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2724,578,0,163840,2,"cuda:0"],0], "input_shapes": [[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2743,812,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::contiguous", "id": 2739, "rf_id": 1910, "parent": 2732, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[2724,578,0,163840,2,"cuda:0"],0], "input_shapes": [[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2743,812,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2745, "rf_id": 1915, "parent": 2732, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2743,812,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[8,20,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2746,812,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 2748, "rf_id": 1917, "parent": 2747, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20,1024],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2749,980,0,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2751, "rf_id": 1919, "parent": 2750, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2749,980,0,20480,2,"cuda:0"],0], "input_shapes": [[20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2749,980,0,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2750, "rf_id": 1918, "parent": 2747, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2749,980,0,20480,2,"cuda:0"]], "input_shapes": [[20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2749,980,0,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2747, "rf_id": 1916, "parent": 2732, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[20,1024],15,0,"cuda:0","<None>"], "input_shapes": [[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[2749,980,0,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding_dense_backward", "id": 2732, "rf_id": 1904, "parent": 2731, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::embedding_dense_backward(Tensor grad_output, Tensor indices, SymInt num_weights, SymInt padding_idx, bool scale_grad_by_freq) -> Tensor",
      "inputs": [[2724,578,0,163840,2,"cuda:0"],[343,10,0,160,8,"cuda:0"],20,-1,false], "input_shapes": [[8,20,1024],[8,20],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Int","Bool"],
      "outputs": [[2749,980,0,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding_backward", "id": 2731, "rf_id": 1903, "parent": 2730, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::embedding_backward(Tensor grad, Tensor indices, SymInt num_weights, SymInt padding_idx, bool scale_grad_by_freq, bool sparse) -> Tensor",
      "inputs": [[2724,578,0,163840,2,"cuda:0"],[343,10,0,160,8,"cuda:0"],20,-1,false,false], "input_shapes": [[8,20,1024],[8,20],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Int","Bool","Bool"],
      "outputs": [[2749,980,0,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "EmbeddingBackward0", "id": 2730, "rf_id": 1902, "parent": 2729, "fw_parent": 2, "seq_id": 395, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2724,578,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: EmbeddingBackward0", "id": 2729, "rf_id": 1901, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2755, "rf_id": 1923, "parent": 2754, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[2749,980,0,20480,2,"cuda:0"]], "input_shapes": [[20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2754, "rf_id": 1922, "parent": 2753, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[2749,980,0,20480,2,"cuda:0"]], "input_shapes": [[20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2756,980,0,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2753, "rf_id": 1921, "parent": 2752, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2749,980,0,20480,2,"cuda:0"]], "input_shapes": [[20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2759, "rf_id": 1926, "parent": 2758, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],[20480],[1],12598272], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2746,1377,12598272,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2758, "rf_id": 1925, "parent": 2757, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,12598272,12618752,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2746,1377,12598272,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2757, "rf_id": 1924, "parent": 2752, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,12598272,20480], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2746,1377,12598272,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2761, "rf_id": 1928, "parent": 2760, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2746,1377,12598272,20480,2,"cuda:0"],[20,1024]], "input_shapes": [[20480],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2762,1377,12598272,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2760, "rf_id": 1927, "parent": 2752, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2746,1377,12598272,20480,2,"cuda:0"],[2756,980,0,20480,2,"cuda:0"]], "input_shapes": [[20480],[20,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2762,1377,12598272,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2763, "rf_id": 1929, "parent": 2752, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2762,1377,12598272,20480,2,"cuda:0"],[2756,980,0,20480,2,"cuda:0"],true], "input_shapes": [[20,1024],[20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2762,1377,12598272,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2764, "rf_id": 1930, "parent": 2752, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2756,980,0,20480,2,"cuda:0"],"<Stream>"], "input_shapes": [[20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2765, "rf_id": 1931, "parent": 2752, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2756,980,0,20480,2,"cuda:0"],[2762,1377,12598272,20480,2,"cuda:0"]], "input_shapes": [[20,1024],[20,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2752, "rf_id": 1920, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "PreBackwardFunctionForModuleBackward", "id": 2767, "rf_id": 1933, "parent": 2766, "fw_parent": 2, "seq_id": 393, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2724,578,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward", "id": 2766, "rf_id": 1932, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "_ReduceFromModelParallelRegionBackward", "id": 2769, "rf_id": 1935, "parent": 2768, "fw_parent": 2, "seq_id": 392, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2724,578,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "autograd::engine::evaluate_function: _ReduceFromModelParallelRegionBackward", "id": 2768, "rf_id": 1934, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 2777, "rf_id": 1943, "parent": 2776, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[8,20,1024],15,0,"cuda:0","<None>",0], "input_shapes": [[[],[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int,Int]","Int","Int","Device","None","Int"],
      "outputs": [[2778,812,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_like", "id": 2776, "rf_id": 1942, "parent": 2775, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2724,578,0,163840,2,"cuda:0"],15,0,"cuda:0","<None>",0], "input_shapes": [[8,20,1024],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Int"],
      "outputs": [[2778,812,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2779, "rf_id": 1944, "parent": 2775, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2778,812,0,163840,2,"cuda:0"],[2724,578,0,163840,2,"cuda:0"],false], "input_shapes": [[8,20,1024],[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2778,812,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::clone", "id": 2775, "rf_id": 1941, "parent": 2774, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[2724,578,0,163840,2,"cuda:0"],0], "input_shapes": [[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2778,812,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::contiguous", "id": 2774, "rf_id": 1940, "parent": 2773, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)",
      "inputs": [[2724,578,0,163840,2,"cuda:0"],0], "input_shapes": [[8,20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2778,812,0,163840,2,"cuda:0"]], "output_shapes": [[8,20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2780, "rf_id": 1945, "parent": 2773, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2778,812,0,163840,2,"cuda:0"],[160,1024]], "input_shapes": [[8,20,1024],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2781,812,0,163840,2,"cuda:0"]], "output_shapes": [[160,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 2783, "rf_id": 1947, "parent": 2782, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[50304,1024],15,0,"cuda:0","<None>","<None>"], "input_shapes": [[[],[]],[],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None","None"],
      "outputs": [[2784,2785,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::fill_", "id": 2787, "rf_id": 1949, "parent": 2786, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)",
      "inputs": [[2784,2785,0,51511296,2,"cuda:0"],0], "input_shapes": [[50304,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Int"],
      "outputs": [[2784,2785,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zero_", "id": 2786, "rf_id": 1948, "parent": 2782, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zero_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[2784,2785,0,51511296,2,"cuda:0"]], "input_shapes": [[50304,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2784,2785,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::zeros", "id": 2782, "rf_id": 1946, "parent": 2773, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::zeros(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[50304,1024],15,0,"cuda:0","<None>"], "input_shapes": [[[],[]],[],[],[],[]], "input_types": ["GenericList[Int,Int]","Int","Int","Device","None"],
      "outputs": [[2784,2785,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding_dense_backward", "id": 2773, "rf_id": 1939, "parent": 2772, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::embedding_dense_backward(Tensor grad_output, Tensor indices, SymInt num_weights, SymInt padding_idx, bool scale_grad_by_freq) -> Tensor",
      "inputs": [[2724,578,0,163840,2,"cuda:0"],[320,184,0,160,8,"cuda:0"],50304,-1,false], "input_shapes": [[8,20,1024],[8,20],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Int","Bool"],
      "outputs": [[2784,2785,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::embedding_backward", "id": 2772, "rf_id": 1938, "parent": 2771, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::embedding_backward(Tensor grad, Tensor indices, SymInt num_weights, SymInt padding_idx, bool scale_grad_by_freq, bool sparse) -> Tensor",
      "inputs": [[2724,578,0,163840,2,"cuda:0"],[320,184,0,160,8,"cuda:0"],50304,-1,false,false], "input_shapes": [[8,20,1024],[8,20],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)","Int","Int","Bool","Bool"],
      "outputs": [[2784,2785,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "EmbeddingBackward0", "id": 2771, "rf_id": 1937, "parent": 2770, "fw_parent": 2, "seq_id": 391, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[2724,578,0,163840,2,"cuda:0"]], "input_shapes": [[8,20,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::add_", "id": 2788, "rf_id": 1950, "parent": 2770, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)",
      "inputs": [[1344,1077,0,51511296,2,"cuda:0"],[2784,2785,0,51511296,2,"cuda:0"],1], "input_shapes": [[50304,1024],[50304,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Int"],
      "outputs": [[1344,1077,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "autograd::engine::evaluate_function: EmbeddingBackward0", "id": 2770, "rf_id": 1936, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "detach", "id": 2792, "rf_id": 1954, "parent": 2791, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [[1344,1077,0,51511296,2,"cuda:0"]], "input_shapes": [[50304,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach", "id": 2791, "rf_id": 1953, "parent": 2790, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::detach(Tensor(a) self) -> Tensor(a)",
      "inputs": [[1344,1077,0,51511296,2,"cuda:0"]], "input_shapes": [[50304,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [[2793,1077,0,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "torch::autograd::AccumulateGrad", "id": 2790, "rf_id": 1952, "parent": 2789, "fw_parent": 2, "seq_id": -1, "scope": 1, "tid": 2, "fw_tid": 1, "op_schema": "",
      "inputs": [[1344,1077,0,51511296,2,"cuda:0"]], "input_shapes": [[50304,1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 2796, "rf_id": 1957, "parent": 2795, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],[51511296],[1],12618752], "input_shapes": [[500000000],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2797,1377,12618752,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2795, "rf_id": 1956, "parent": 2794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,12618752,64130048,1], "input_shapes": [[500000000],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2797,1377,12618752,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 2794, "rf_id": 1955, "parent": 2789, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[1376,1377,0,500000000,2,"cuda:0"],0,12618752,51511296], "input_shapes": [[500000000],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[2797,1377,12618752,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2799, "rf_id": 1959, "parent": 2798, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2797,1377,12618752,51511296,2,"cuda:0"],[50304,1024]], "input_shapes": [[51511296],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[2800,1377,12618752,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view_as", "id": 2798, "rf_id": 1958, "parent": 2789, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)",
      "inputs": [[2797,1377,12618752,51511296,2,"cuda:0"],[2793,1077,0,51511296,2,"cuda:0"]], "input_shapes": [[51511296],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [[2800,1377,12618752,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 2801, "rf_id": 1960, "parent": 2789, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[2800,1377,12618752,51511296,2,"cuda:0"],[2793,1077,0,51511296,2,"cuda:0"],true], "input_shapes": [[50304,1024],[50304,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[2800,1377,12618752,51511296,2,"cuda:0"]], "output_shapes": [[50304,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 2802, "rf_id": 1961, "parent": 2789, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2793,1077,0,51511296,2,"cuda:0"],"<Stream>"], "input_shapes": [[50304,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 2803, "rf_id": 1962, "parent": 2789, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[2793,1077,0,51511296,2,"cuda:0"],[2800,1377,12618752,51511296,2,"cuda:0"]], "input_shapes": [[50304,1024],[50304,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad", "id": 2789, "rf_id": 1951, "parent": 1244, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 2, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::view", "id": 2804, "rf_id": 1963, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2793,1377,12618752,51511296,2,"cuda:0"],[-1]], "input_shapes": [[50304,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2805,1377,12618752,51511296,2,"cuda:0"]], "output_shapes": [[51511296]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2807, "rf_id": 1965, "parent": 2806, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2805,1377,12618752,51511296,2,"cuda:0"],[12877824],[1],12618752], "input_shapes": [[51511296],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2808,1377,12618752,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2806, "rf_id": 1964, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2805,1377,12618752,51511296,2,"cuda:0"],0,0,12877824,1], "input_shapes": [[51511296],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2808,1377,12618752,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2810, "rf_id": 1967, "parent": 2809, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2805,1377,12618752,51511296,2,"cuda:0"],[12877824],[1],25496576], "input_shapes": [[51511296],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2811,1377,25496576,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2809, "rf_id": 1966, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2805,1377,12618752,51511296,2,"cuda:0"],0,12877824,25755648,1], "input_shapes": [[51511296],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2811,1377,25496576,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2813, "rf_id": 1969, "parent": 2812, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2805,1377,12618752,51511296,2,"cuda:0"],[12877824],[1],38374400], "input_shapes": [[51511296],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2814,1377,38374400,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2812, "rf_id": 1968, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2805,1377,12618752,51511296,2,"cuda:0"],0,25755648,38633472,1], "input_shapes": [[51511296],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2814,1377,38374400,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2816, "rf_id": 1971, "parent": 2815, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2805,1377,12618752,51511296,2,"cuda:0"],[12877824],[1],51252224], "input_shapes": [[51511296],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2817,1377,51252224,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2815, "rf_id": 1970, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2805,1377,12618752,51511296,2,"cuda:0"],0,38633472,51511296,1], "input_shapes": [[51511296],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2817,1377,51252224,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2818, "rf_id": 1972, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2756,1377,12598272,20480,2,"cuda:0"],[-1]], "input_shapes": [[20,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2819,1377,12598272,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2821, "rf_id": 1974, "parent": 2820, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2819,1377,12598272,20480,2,"cuda:0"],[5120],[1],12598272], "input_shapes": [[20480],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2822,1377,12598272,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2820, "rf_id": 1973, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2819,1377,12598272,20480,2,"cuda:0"],0,0,5120,1], "input_shapes": [[20480],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2822,1377,12598272,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2824, "rf_id": 1976, "parent": 2823, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2819,1377,12598272,20480,2,"cuda:0"],[5120],[1],12603392], "input_shapes": [[20480],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2825,1377,12603392,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2823, "rf_id": 1975, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2819,1377,12598272,20480,2,"cuda:0"],0,5120,10240,1], "input_shapes": [[20480],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2825,1377,12603392,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2827, "rf_id": 1978, "parent": 2826, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2819,1377,12598272,20480,2,"cuda:0"],[5120],[1],12608512], "input_shapes": [[20480],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2828,1377,12608512,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2826, "rf_id": 1977, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2819,1377,12598272,20480,2,"cuda:0"],0,10240,15360,1], "input_shapes": [[20480],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2828,1377,12608512,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2830, "rf_id": 1980, "parent": 2829, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2819,1377,12598272,20480,2,"cuda:0"],[5120],[1],12613632], "input_shapes": [[20480],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2831,1377,12613632,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2829, "rf_id": 1979, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2819,1377,12598272,20480,2,"cuda:0"],0,15360,20480,1], "input_shapes": [[20480],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2831,1377,12613632,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2832, "rf_id": 1981, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2671,1377,12596224,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2833,1377,12596224,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2835, "rf_id": 1983, "parent": 2834, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2833,1377,12596224,1024,2,"cuda:0"],[256],[1],12596224], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2836,1377,12596224,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2834, "rf_id": 1982, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2833,1377,12596224,1024,2,"cuda:0"],0,0,256,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2836,1377,12596224,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2838, "rf_id": 1985, "parent": 2837, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2833,1377,12596224,1024,2,"cuda:0"],[256],[1],12596480], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2839,1377,12596480,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2837, "rf_id": 1984, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2833,1377,12596224,1024,2,"cuda:0"],0,256,512,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2839,1377,12596480,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2841, "rf_id": 1987, "parent": 2840, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2833,1377,12596224,1024,2,"cuda:0"],[256],[1],12596736], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2842,1377,12596736,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2840, "rf_id": 1986, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2833,1377,12596224,1024,2,"cuda:0"],0,512,768,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2842,1377,12596736,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2844, "rf_id": 1989, "parent": 2843, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2833,1377,12596224,1024,2,"cuda:0"],[256],[1],12596992], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2845,1377,12596992,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2843, "rf_id": 1988, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2833,1377,12596224,1024,2,"cuda:0"],0,768,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2845,1377,12596992,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2846, "rf_id": 1990, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2685,1377,12597248,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2847,1377,12597248,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2849, "rf_id": 1992, "parent": 2848, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2847,1377,12597248,1024,2,"cuda:0"],[256],[1],12597248], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2850,1377,12597248,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2848, "rf_id": 1991, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2847,1377,12597248,1024,2,"cuda:0"],0,0,256,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2850,1377,12597248,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2852, "rf_id": 1994, "parent": 2851, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2847,1377,12597248,1024,2,"cuda:0"],[256],[1],12597504], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2853,1377,12597504,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2851, "rf_id": 1993, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2847,1377,12597248,1024,2,"cuda:0"],0,256,512,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2853,1377,12597504,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2855, "rf_id": 1996, "parent": 2854, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2847,1377,12597248,1024,2,"cuda:0"],[256],[1],12597760], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2856,1377,12597760,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2854, "rf_id": 1995, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2847,1377,12597248,1024,2,"cuda:0"],0,512,768,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2856,1377,12597760,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2858, "rf_id": 1998, "parent": 2857, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2847,1377,12597248,1024,2,"cuda:0"],[256],[1],12598016], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2859,1377,12598016,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2857, "rf_id": 1997, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2847,1377,12597248,1024,2,"cuda:0"],0,768,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2859,1377,12598016,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2860, "rf_id": 1999, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2607,1377,9447424,3145728,2,"cuda:0"],[-1]], "input_shapes": [[3072,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2861,1377,9447424,3145728,2,"cuda:0"]], "output_shapes": [[3145728]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2863, "rf_id": 2001, "parent": 2862, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2861,1377,9447424,3145728,2,"cuda:0"],[786432],[1],9447424], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2864,1377,9447424,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2862, "rf_id": 2000, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2861,1377,9447424,3145728,2,"cuda:0"],0,0,786432,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2864,1377,9447424,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2866, "rf_id": 2003, "parent": 2865, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2861,1377,9447424,3145728,2,"cuda:0"],[786432],[1],10233856], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2867,1377,10233856,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2865, "rf_id": 2002, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2861,1377,9447424,3145728,2,"cuda:0"],0,786432,1572864,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2867,1377,10233856,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2869, "rf_id": 2005, "parent": 2868, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2861,1377,9447424,3145728,2,"cuda:0"],[786432],[1],11020288], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2870,1377,11020288,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2868, "rf_id": 2004, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2861,1377,9447424,3145728,2,"cuda:0"],0,1572864,2359296,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2870,1377,11020288,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2872, "rf_id": 2007, "parent": 2871, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2861,1377,9447424,3145728,2,"cuda:0"],[786432],[1],11806720], "input_shapes": [[3145728],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2873,1377,11806720,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2871, "rf_id": 2006, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2861,1377,9447424,3145728,2,"cuda:0"],0,2359296,3145728,1], "input_shapes": [[3145728],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2873,1377,11806720,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2874, "rf_id": 2008, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2626,1377,12593152,3072,2,"cuda:0"],[-1]], "input_shapes": [[3072],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2875,1377,12593152,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2877, "rf_id": 2010, "parent": 2876, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2875,1377,12593152,3072,2,"cuda:0"],[768],[1],12593152], "input_shapes": [[3072],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2878,1377,12593152,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2876, "rf_id": 2009, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2875,1377,12593152,3072,2,"cuda:0"],0,0,768,1], "input_shapes": [[3072],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2878,1377,12593152,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2880, "rf_id": 2012, "parent": 2879, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2875,1377,12593152,3072,2,"cuda:0"],[768],[1],12593920], "input_shapes": [[3072],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2881,1377,12593920,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2879, "rf_id": 2011, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2875,1377,12593152,3072,2,"cuda:0"],0,768,1536,1], "input_shapes": [[3072],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2881,1377,12593920,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2883, "rf_id": 2014, "parent": 2882, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2875,1377,12593152,3072,2,"cuda:0"],[768],[1],12594688], "input_shapes": [[3072],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2884,1377,12594688,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2882, "rf_id": 2013, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2875,1377,12593152,3072,2,"cuda:0"],0,1536,2304,1], "input_shapes": [[3072],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2884,1377,12594688,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2886, "rf_id": 2016, "parent": 2885, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2875,1377,12593152,3072,2,"cuda:0"],[768],[1],12595456], "input_shapes": [[3072],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2887,1377,12595456,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2885, "rf_id": 2015, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2875,1377,12593152,3072,2,"cuda:0"],0,2304,3072,1], "input_shapes": [[3072],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2887,1377,12595456,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2888, "rf_id": 2017, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2233,1377,8398848,1048576,2,"cuda:0"],[-1]], "input_shapes": [[1024,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2889,1377,8398848,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2891, "rf_id": 2019, "parent": 2890, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2889,1377,8398848,1048576,2,"cuda:0"],[262144],[1],8398848], "input_shapes": [[1048576],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2892,1377,8398848,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2890, "rf_id": 2018, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2889,1377,8398848,1048576,2,"cuda:0"],0,0,262144,1], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2892,1377,8398848,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2894, "rf_id": 2021, "parent": 2893, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2889,1377,8398848,1048576,2,"cuda:0"],[262144],[1],8660992], "input_shapes": [[1048576],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2895,1377,8660992,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2893, "rf_id": 2020, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2889,1377,8398848,1048576,2,"cuda:0"],0,262144,524288,1], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2895,1377,8660992,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2897, "rf_id": 2023, "parent": 2896, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2889,1377,8398848,1048576,2,"cuda:0"],[262144],[1],8923136], "input_shapes": [[1048576],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2898,1377,8923136,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2896, "rf_id": 2022, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2889,1377,8398848,1048576,2,"cuda:0"],0,524288,786432,1], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2898,1377,8923136,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2900, "rf_id": 2025, "parent": 2899, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2889,1377,8398848,1048576,2,"cuda:0"],[262144],[1],9185280], "input_shapes": [[1048576],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2901,1377,9185280,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2899, "rf_id": 2024, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2889,1377,8398848,1048576,2,"cuda:0"],0,786432,1048576,1], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2901,1377,9185280,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2902, "rf_id": 2026, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2193,1377,8397824,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2903,1377,8397824,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2905, "rf_id": 2028, "parent": 2904, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2903,1377,8397824,1024,2,"cuda:0"],[256],[1],8397824], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2906,1377,8397824,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2904, "rf_id": 2027, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2903,1377,8397824,1024,2,"cuda:0"],0,0,256,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2906,1377,8397824,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2908, "rf_id": 2030, "parent": 2907, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2903,1377,8397824,1024,2,"cuda:0"],[256],[1],8398080], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2909,1377,8398080,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2907, "rf_id": 2029, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2903,1377,8397824,1024,2,"cuda:0"],0,256,512,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2909,1377,8398080,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2911, "rf_id": 2032, "parent": 2910, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2903,1377,8397824,1024,2,"cuda:0"],[256],[1],8398336], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2912,1377,8398336,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2910, "rf_id": 2031, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2903,1377,8397824,1024,2,"cuda:0"],0,512,768,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2912,1377,8398336,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2914, "rf_id": 2034, "parent": 2913, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2903,1377,8397824,1024,2,"cuda:0"],[256],[1],8398592], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2915,1377,8398592,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2913, "rf_id": 2033, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2903,1377,8397824,1024,2,"cuda:0"],0,768,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2915,1377,8398592,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2916, "rf_id": 2035, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2134,1377,8395776,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2917,1377,8395776,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2919, "rf_id": 2037, "parent": 2918, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2917,1377,8395776,1024,2,"cuda:0"],[256],[1],8395776], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2920,1377,8395776,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2918, "rf_id": 2036, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2917,1377,8395776,1024,2,"cuda:0"],0,0,256,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2920,1377,8395776,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2922, "rf_id": 2039, "parent": 2921, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2917,1377,8395776,1024,2,"cuda:0"],[256],[1],8396032], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2923,1377,8396032,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2921, "rf_id": 2038, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2917,1377,8395776,1024,2,"cuda:0"],0,256,512,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2923,1377,8396032,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2925, "rf_id": 2041, "parent": 2924, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2917,1377,8395776,1024,2,"cuda:0"],[256],[1],8396288], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2926,1377,8396288,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2924, "rf_id": 2040, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2917,1377,8395776,1024,2,"cuda:0"],0,512,768,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2926,1377,8396288,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2928, "rf_id": 2043, "parent": 2927, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2917,1377,8395776,1024,2,"cuda:0"],[256],[1],8396544], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2929,1377,8396544,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2927, "rf_id": 2042, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2917,1377,8395776,1024,2,"cuda:0"],0,768,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2929,1377,8396544,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2930, "rf_id": 2044, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2148,1377,8396800,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2931,1377,8396800,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2933, "rf_id": 2046, "parent": 2932, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2931,1377,8396800,1024,2,"cuda:0"],[256],[1],8396800], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2934,1377,8396800,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2932, "rf_id": 2045, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2931,1377,8396800,1024,2,"cuda:0"],0,0,256,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2934,1377,8396800,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2936, "rf_id": 2048, "parent": 2935, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2931,1377,8396800,1024,2,"cuda:0"],[256],[1],8397056], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2937,1377,8397056,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2935, "rf_id": 2047, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2931,1377,8396800,1024,2,"cuda:0"],0,256,512,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2937,1377,8397056,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2939, "rf_id": 2050, "parent": 2938, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2931,1377,8396800,1024,2,"cuda:0"],[256],[1],8397312], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2940,1377,8397312,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2938, "rf_id": 2049, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2931,1377,8396800,1024,2,"cuda:0"],0,512,768,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2940,1377,8397312,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2942, "rf_id": 2052, "parent": 2941, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2931,1377,8396800,1024,2,"cuda:0"],[256],[1],8397568], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2943,1377,8397568,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2941, "rf_id": 2051, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2931,1377,8396800,1024,2,"cuda:0"],0,768,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2943,1377,8397568,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2944, "rf_id": 2053, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2089,1377,4201472,4194304,2,"cuda:0"],[-1]], "input_shapes": [[4096,1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2945,1377,4201472,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2947, "rf_id": 2055, "parent": 2946, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2945,1377,4201472,4194304,2,"cuda:0"],[1048576],[1],4201472], "input_shapes": [[4194304],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2948,1377,4201472,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2946, "rf_id": 2054, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2945,1377,4201472,4194304,2,"cuda:0"],0,0,1048576,1], "input_shapes": [[4194304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2948,1377,4201472,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2950, "rf_id": 2057, "parent": 2949, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2945,1377,4201472,4194304,2,"cuda:0"],[1048576],[1],5250048], "input_shapes": [[4194304],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2951,1377,5250048,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2949, "rf_id": 2056, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2945,1377,4201472,4194304,2,"cuda:0"],0,1048576,2097152,1], "input_shapes": [[4194304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2951,1377,5250048,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2953, "rf_id": 2059, "parent": 2952, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2945,1377,4201472,4194304,2,"cuda:0"],[1048576],[1],6298624], "input_shapes": [[4194304],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2954,1377,6298624,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2952, "rf_id": 2058, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2945,1377,4201472,4194304,2,"cuda:0"],0,2097152,3145728,1], "input_shapes": [[4194304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2954,1377,6298624,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2956, "rf_id": 2061, "parent": 2955, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2945,1377,4201472,4194304,2,"cuda:0"],[1048576],[1],7347200], "input_shapes": [[4194304],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2957,1377,7347200,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2955, "rf_id": 2060, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2945,1377,4201472,4194304,2,"cuda:0"],0,3145728,4194304,1], "input_shapes": [[4194304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2957,1377,7347200,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2958, "rf_id": 2062, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[2051,1377,4197376,4096,2,"cuda:0"],[-1]], "input_shapes": [[4096],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2959,1377,4197376,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2961, "rf_id": 2064, "parent": 2960, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2959,1377,4197376,4096,2,"cuda:0"],[1024],[1],4197376], "input_shapes": [[4096],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2962,1377,4197376,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2960, "rf_id": 2063, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2959,1377,4197376,4096,2,"cuda:0"],0,0,1024,1], "input_shapes": [[4096],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2962,1377,4197376,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2964, "rf_id": 2066, "parent": 2963, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2959,1377,4197376,4096,2,"cuda:0"],[1024],[1],4198400], "input_shapes": [[4096],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2965,1377,4198400,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2963, "rf_id": 2065, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2959,1377,4197376,4096,2,"cuda:0"],0,1024,2048,1], "input_shapes": [[4096],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2965,1377,4198400,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2967, "rf_id": 2068, "parent": 2966, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2959,1377,4197376,4096,2,"cuda:0"],[1024],[1],4199424], "input_shapes": [[4096],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2968,1377,4199424,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2966, "rf_id": 2067, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2959,1377,4197376,4096,2,"cuda:0"],0,2048,3072,1], "input_shapes": [[4096],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2968,1377,4199424,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2970, "rf_id": 2070, "parent": 2969, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2959,1377,4197376,4096,2,"cuda:0"],[1024],[1],4200448], "input_shapes": [[4096],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2971,1377,4200448,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2969, "rf_id": 2069, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2959,1377,4197376,4096,2,"cuda:0"],0,3072,4096,1], "input_shapes": [[4096],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2971,1377,4200448,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2972, "rf_id": 2071, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1952,1377,3072,4194304,2,"cuda:0"],[-1]], "input_shapes": [[1024,4096],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2973,1377,3072,4194304,2,"cuda:0"]], "output_shapes": [[4194304]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2975, "rf_id": 2073, "parent": 2974, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2973,1377,3072,4194304,2,"cuda:0"],[1048576],[1],3072], "input_shapes": [[4194304],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2976,1377,3072,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2974, "rf_id": 2072, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2973,1377,3072,4194304,2,"cuda:0"],0,0,1048576,1], "input_shapes": [[4194304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2976,1377,3072,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2978, "rf_id": 2075, "parent": 2977, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2973,1377,3072,4194304,2,"cuda:0"],[1048576],[1],1051648], "input_shapes": [[4194304],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2979,1377,1051648,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2977, "rf_id": 2074, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2973,1377,3072,4194304,2,"cuda:0"],0,1048576,2097152,1], "input_shapes": [[4194304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2979,1377,1051648,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2981, "rf_id": 2077, "parent": 2980, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2973,1377,3072,4194304,2,"cuda:0"],[1048576],[1],2100224], "input_shapes": [[4194304],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2982,1377,2100224,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2980, "rf_id": 2076, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2973,1377,3072,4194304,2,"cuda:0"],0,2097152,3145728,1], "input_shapes": [[4194304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2982,1377,2100224,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2984, "rf_id": 2079, "parent": 2983, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2973,1377,3072,4194304,2,"cuda:0"],[1048576],[1],3148800], "input_shapes": [[4194304],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2985,1377,3148800,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2983, "rf_id": 2078, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2973,1377,3072,4194304,2,"cuda:0"],0,3145728,4194304,1], "input_shapes": [[4194304],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2985,1377,3148800,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 2986, "rf_id": 2080, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1913,1377,2048,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[2987,1377,2048,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2989, "rf_id": 2082, "parent": 2988, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2987,1377,2048,1024,2,"cuda:0"],[256],[1],2048], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2990,1377,2048,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2988, "rf_id": 2081, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2987,1377,2048,1024,2,"cuda:0"],0,0,256,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2990,1377,2048,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2992, "rf_id": 2084, "parent": 2991, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2987,1377,2048,1024,2,"cuda:0"],[256],[1],2304], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2993,1377,2304,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2991, "rf_id": 2083, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2987,1377,2048,1024,2,"cuda:0"],0,256,512,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2993,1377,2304,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2995, "rf_id": 2086, "parent": 2994, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2987,1377,2048,1024,2,"cuda:0"],[256],[1],2560], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2996,1377,2560,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2994, "rf_id": 2085, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2987,1377,2048,1024,2,"cuda:0"],0,512,768,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2996,1377,2560,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 2998, "rf_id": 2088, "parent": 2997, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[2987,1377,2048,1024,2,"cuda:0"],[256],[1],2816], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[2999,1377,2816,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 2997, "rf_id": 2087, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[2987,1377,2048,1024,2,"cuda:0"],0,768,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[2999,1377,2816,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3000, "rf_id": 2089, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1375,1377,0,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3001,1377,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3003, "rf_id": 2091, "parent": 3002, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3001,1377,0,1024,2,"cuda:0"],[256],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3004,1377,0,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3002, "rf_id": 2090, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3001,1377,0,1024,2,"cuda:0"],0,0,256,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3004,1377,0,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3006, "rf_id": 2093, "parent": 3005, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3001,1377,0,1024,2,"cuda:0"],[256],[1],256], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3007,1377,256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3005, "rf_id": 2092, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3001,1377,0,1024,2,"cuda:0"],0,256,512,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3007,1377,256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3009, "rf_id": 2095, "parent": 3008, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3001,1377,0,1024,2,"cuda:0"],[256],[1],512], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3010,1377,512,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3008, "rf_id": 2094, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3001,1377,0,1024,2,"cuda:0"],0,512,768,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3010,1377,512,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3012, "rf_id": 2097, "parent": 3011, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3001,1377,0,1024,2,"cuda:0"],[256],[1],768], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3013,1377,768,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3011, "rf_id": 2096, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3001,1377,0,1024,2,"cuda:0"],0,768,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3013,1377,768,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3014, "rf_id": 2098, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[1391,1377,1024,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3015,1377,1024,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3017, "rf_id": 2100, "parent": 3016, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3015,1377,1024,1024,2,"cuda:0"],[256],[1],1024], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3018,1377,1024,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3016, "rf_id": 2099, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3015,1377,1024,1024,2,"cuda:0"],0,0,256,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3018,1377,1024,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3020, "rf_id": 2102, "parent": 3019, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3015,1377,1024,1024,2,"cuda:0"],[256],[1],1280], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3021,1377,1280,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3019, "rf_id": 2101, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3015,1377,1024,1024,2,"cuda:0"],0,256,512,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3021,1377,1280,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3023, "rf_id": 2104, "parent": 3022, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3015,1377,1024,1024,2,"cuda:0"],[256],[1],1536], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3024,1377,1536,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3022, "rf_id": 2103, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3015,1377,1024,1024,2,"cuda:0"],0,512,768,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3024,1377,1536,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3026, "rf_id": 2106, "parent": 3025, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3015,1377,1024,1024,2,"cuda:0"],[256],[1],1792], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3027,1377,1792,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3025, "rf_id": 2105, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3015,1377,1024,1024,2,"cuda:0"],0,768,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3027,1377,1792,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 3028, "rf_id": 2107, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[2808,1377,12618752,12877824,2,"cuda:0"],[2822,1377,12598272,5120,2,"cuda:0"],[2836,1377,12596224,256,2,"cuda:0"],[2850,1377,12597248,256,2,"cuda:0"],[2864,1377,9447424,786432,2,"cuda:0"],[2878,1377,12593152,768,2,"cuda:0"],[2892,1377,8398848,262144,2,"cuda:0"],[2906,1377,8397824,256,2,"cuda:0"],[2920,1377,8395776,256,2,"cuda:0"],[2934,1377,8396800,256,2,"cuda:0"],[2948,1377,4201472,1048576,2,"cuda:0"],[2962,1377,4197376,1024,2,"cuda:0"],[2976,1377,3072,1048576,2,"cuda:0"],[2990,1377,2048,256,2,"cuda:0"],[3004,1377,0,256,2,"cuda:0"],[3018,1377,1024,256,2,"cuda:0"],[2811,1377,25496576,12877824,2,"cuda:0"],[2825,1377,12603392,5120,2,"cuda:0"],[2839,1377,12596480,256,2,"cuda:0"],[2853,1377,12597504,256,2,"cuda:0"],[2867,1377,10233856,786432,2,"cuda:0"],[2881,1377,12593920,768,2,"cuda:0"],[2895,1377,8660992,262144,2,"cuda:0"],[2909,1377,8398080,256,2,"cuda:0"],[2923,1377,8396032,256,2,"cuda:0"],[2937,1377,8397056,256,2,"cuda:0"],[2951,1377,5250048,1048576,2,"cuda:0"],[2965,1377,4198400,1024,2,"cuda:0"],[2979,1377,1051648,1048576,2,"cuda:0"],[2993,1377,2304,256,2,"cuda:0"],[3007,1377,256,256,2,"cuda:0"],[3021,1377,1280,256,2,"cuda:0"],[2814,1377,38374400,12877824,2,"cuda:0"],[2828,1377,12608512,5120,2,"cuda:0"],[2842,1377,12596736,256,2,"cuda:0"],[2856,1377,12597760,256,2,"cuda:0"],[2870,1377,11020288,786432,2,"cuda:0"],[2884,1377,12594688,768,2,"cuda:0"],[2898,1377,8923136,262144,2,"cuda:0"],[2912,1377,8398336,256,2,"cuda:0"],[2926,1377,8396288,256,2,"cuda:0"],[2940,1377,8397312,256,2,"cuda:0"],[2954,1377,6298624,1048576,2,"cuda:0"],[2968,1377,4199424,1024,2,"cuda:0"],[2982,1377,2100224,1048576,2,"cuda:0"],[2996,1377,2560,256,2,"cuda:0"],[3010,1377,512,256,2,"cuda:0"],[3024,1377,1536,256,2,"cuda:0"],[2817,1377,51252224,12877824,2,"cuda:0"],[2831,1377,12613632,5120,2,"cuda:0"],[2845,1377,12596992,256,2,"cuda:0"],[2859,1377,12598016,256,2,"cuda:0"],[2873,1377,11806720,786432,2,"cuda:0"],[2887,1377,12595456,768,2,"cuda:0"],[2901,1377,9185280,262144,2,"cuda:0"],[2915,1377,8398592,256,2,"cuda:0"],[2929,1377,8396544,256,2,"cuda:0"],[2943,1377,8397568,256,2,"cuda:0"],[2957,1377,7347200,1048576,2,"cuda:0"],[2971,1377,4200448,1024,2,"cuda:0"],[2985,1377,3148800,1048576,2,"cuda:0"],[2999,1377,2816,256,2,"cuda:0"],[3013,1377,768,256,2,"cuda:0"],[3027,1377,1792,256,2,"cuda:0"]],0], "input_shapes": [[[12877824],[5120],[256],[256],[786432],[768],[262144],[256],[256],[256],[1048576],[1024],[1048576],[256],[256],[256],[12877824],[5120],[256],[256],[786432],[768],[262144],[256],[256],[256],[1048576],[1024],[1048576],[256],[256],[256],[12877824],[5120],[256],[256],[786432],[768],[262144],[256],[256],[256],[1048576],[1024],[1048576],[256],[256],[256],[12877824],[5120],[256],[256],[786432],[768],[262144],[256],[256],[256],[1048576],[1024],[1048576],[256],[256],[256]],[]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int"],
      "outputs": [[3029,3030,0,64130048,2,"cuda:0"]], "output_shapes": [[64130048]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::div_", "id": 3033, "rf_id": 2108, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[3029,3030,0,64130048,2,"cuda:0"],[3031,3032,0,1,8,"cpu"]], "input_shapes": [[64130048],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(long int)"],
      "outputs": [[3029,3030,0,64130048,2,"cuda:0"]], "output_shapes": [[64130048]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3038, "rf_id": 2113, "parent": 3037, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3029,3030,0,64130048,2,"cuda:0"],[16032512],[1],0], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3039,3030,0,16032512,2,"cuda:0"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3037, "rf_id": 2112, "parent": 3036, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3029,3030,0,64130048,2,"cuda:0"],0,0,16032512,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3039,3030,0,16032512,2,"cuda:0"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3036, "rf_id": 2111, "parent": 3035, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3029,3030,0,64130048,2,"cuda:0"],0,0,16032512], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3039,3030,0,16032512,2,"cuda:0"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3042, "rf_id": 2116, "parent": 3041, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3029,3030,0,64130048,2,"cuda:0"],[16032512],[1],16032512], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3043,3030,16032512,16032512,2,"cuda:0"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3041, "rf_id": 2115, "parent": 3040, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3029,3030,0,64130048,2,"cuda:0"],0,16032512,32065024,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3043,3030,16032512,16032512,2,"cuda:0"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3040, "rf_id": 2114, "parent": 3035, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3029,3030,0,64130048,2,"cuda:0"],0,16032512,16032512], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3043,3030,16032512,16032512,2,"cuda:0"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3046, "rf_id": 2119, "parent": 3045, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3029,3030,0,64130048,2,"cuda:0"],[16032512],[1],32065024], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3047,3030,32065024,16032512,2,"cuda:0"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3045, "rf_id": 2118, "parent": 3044, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3029,3030,0,64130048,2,"cuda:0"],0,32065024,48097536,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3047,3030,32065024,16032512,2,"cuda:0"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3044, "rf_id": 2117, "parent": 3035, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3029,3030,0,64130048,2,"cuda:0"],0,32065024,16032512], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3047,3030,32065024,16032512,2,"cuda:0"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3050, "rf_id": 2122, "parent": 3049, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3029,3030,0,64130048,2,"cuda:0"],[16032512],[1],48097536], "input_shapes": [[64130048],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3051,3030,48097536,16032512,2,"cuda:0"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3049, "rf_id": 2121, "parent": 3048, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3029,3030,0,64130048,2,"cuda:0"],0,48097536,64130048,1], "input_shapes": [[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3051,3030,48097536,16032512,2,"cuda:0"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3048, "rf_id": 2120, "parent": 3035, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3029,3030,0,64130048,2,"cuda:0"],0,48097536,16032512], "input_shapes": [[64130048],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3051,3030,48097536,16032512,2,"cuda:0"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::split", "id": 3035, "rf_id": 2110, "parent": 3034, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::split.Tensor(Tensor(a -> *) self, SymInt split_size, int dim=0) -> Tensor(a)[]",
      "inputs": [[3029,3030,0,64130048,2,"cuda:0"],16032512,0], "input_shapes": [[64130048],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[[3039,3030,0,16032512,2,"cuda:0"],[3043,3030,16032512,16032512,2,"cuda:0"],[3047,3030,32065024,16032512,2,"cuda:0"],[3051,3030,48097536,16032512,2,"cuda:0"]]], "output_shapes": [[[16032512],[16032512],[16032512],[16032512]]], "output_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"]
    },
    {
      "name": "aten::chunk", "id": 3034, "rf_id": 2109, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::chunk(Tensor(a -> *) self, int chunks, int dim=0) -> Tensor(a)[]",
      "inputs": [[3029,3030,0,64130048,2,"cuda:0"],4,0], "input_shapes": [[64130048],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int"],
      "outputs": [[[3039,3030,0,16032512,2,"cuda:0"],[3043,3030,16032512,16032512,2,"cuda:0"],[3047,3030,32065024,16032512,2,"cuda:0"],[3051,3030,48097536,16032512,2,"cuda:0"]]], "output_shapes": [[[16032512],[16032512],[16032512],[16032512]]], "output_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"]
    },
    {
      "name": "nccl:_reduce_scatter_base", "id": 3054, "rf_id": 2125, "parent": 3053, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3029,3030,0,64130048,2,"cuda:0"]], "input_shapes": [[64130048]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3053, "rf_id": 2124, "parent": 3052, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3029,3030,0,64130048,2,"cuda:0"],128,93827882276192,0,"_reduce_scatter_base",[],[],4], "input_shapes": [[64130048],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3039,3030,0,16032512,2,"cuda:0"]], "output_shapes": [[16032512]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_reduce_scatter_base_", "id": 3052, "rf_id": 2123, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_reduce_scatter_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],[3029,3030,0,64130048,2,"cuda:0"],"<Object>","<Object>",false,-1], "input_shapes": [[16032512],[64130048],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Object","Bool","Int"],
      "outputs": [[3039,3030,0,16032512,2,"cuda:0"],"<Object>"], "output_shapes": [[16032512],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "record_param_comms", "id": 3055, "rf_id": 2126, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [128,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3058, "rf_id": 2129, "parent": 3057, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],[12877824],[1],0], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3059,3030,0,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3057, "rf_id": 2128, "parent": 3056, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,0,12877824,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3059,3030,0,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3056, "rf_id": 2127, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,0,12877824], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3059,3030,0,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3062, "rf_id": 2132, "parent": 3061, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],[5120],[1],12877824], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3063,3030,12877824,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3061, "rf_id": 2131, "parent": 3060, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,12877824,12882944,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3063,3030,12877824,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3060, "rf_id": 2130, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,12877824,5120], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3063,3030,12877824,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3066, "rf_id": 2135, "parent": 3065, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],[256],[1],12882944], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3067,3030,12882944,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3065, "rf_id": 2134, "parent": 3064, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,12882944,12883200,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3067,3030,12882944,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3064, "rf_id": 2133, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,12882944,256], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3067,3030,12882944,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3070, "rf_id": 2138, "parent": 3069, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],[256],[1],12883200], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3071,3030,12883200,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3069, "rf_id": 2137, "parent": 3068, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,12883200,12883456,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3071,3030,12883200,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3068, "rf_id": 2136, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,12883200,256], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3071,3030,12883200,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3074, "rf_id": 2141, "parent": 3073, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],[786432],[1],12883456], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3075,3030,12883456,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3073, "rf_id": 2140, "parent": 3072, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,12883456,13669888,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3075,3030,12883456,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3072, "rf_id": 2139, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,12883456,786432], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3075,3030,12883456,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3078, "rf_id": 2144, "parent": 3077, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],[768],[1],13669888], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3079,3030,13669888,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3077, "rf_id": 2143, "parent": 3076, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,13669888,13670656,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3079,3030,13669888,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3076, "rf_id": 2142, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,13669888,768], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3079,3030,13669888,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3082, "rf_id": 2147, "parent": 3081, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],[262144],[1],13670656], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3083,3030,13670656,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3081, "rf_id": 2146, "parent": 3080, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,13670656,13932800,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3083,3030,13670656,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3080, "rf_id": 2145, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,13670656,262144], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3083,3030,13670656,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3086, "rf_id": 2150, "parent": 3085, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],[256],[1],13932800], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3087,3030,13932800,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3085, "rf_id": 2149, "parent": 3084, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,13932800,13933056,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3087,3030,13932800,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3084, "rf_id": 2148, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,13932800,256], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3087,3030,13932800,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3090, "rf_id": 2153, "parent": 3089, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],[256],[1],13933056], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3091,3030,13933056,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3089, "rf_id": 2152, "parent": 3088, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,13933056,13933312,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3091,3030,13933056,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3088, "rf_id": 2151, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,13933056,256], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3091,3030,13933056,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3094, "rf_id": 2156, "parent": 3093, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],[256],[1],13933312], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3095,3030,13933312,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3093, "rf_id": 2155, "parent": 3092, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,13933312,13933568,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3095,3030,13933312,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3092, "rf_id": 2154, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,13933312,256], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3095,3030,13933312,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3098, "rf_id": 2159, "parent": 3097, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],[1048576],[1],13933568], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3099,3030,13933568,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3097, "rf_id": 2158, "parent": 3096, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,13933568,14982144,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3099,3030,13933568,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3096, "rf_id": 2157, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,13933568,1048576], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3099,3030,13933568,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3102, "rf_id": 2162, "parent": 3101, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],[1024],[1],14982144], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3103,3030,14982144,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3101, "rf_id": 2161, "parent": 3100, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,14982144,14983168,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3103,3030,14982144,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3100, "rf_id": 2160, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,14982144,1024], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3103,3030,14982144,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3106, "rf_id": 2165, "parent": 3105, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],[1048576],[1],14983168], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3107,3030,14983168,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3105, "rf_id": 2164, "parent": 3104, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,14983168,16031744,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3107,3030,14983168,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3104, "rf_id": 2163, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,14983168,1048576], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3107,3030,14983168,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3110, "rf_id": 2168, "parent": 3109, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],[256],[1],16031744], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3111,3030,16031744,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3109, "rf_id": 2167, "parent": 3108, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,16031744,16032000,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3111,3030,16031744,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3108, "rf_id": 2166, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,16031744,256], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3111,3030,16031744,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3114, "rf_id": 2171, "parent": 3113, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],[256],[1],16032000], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3115,3030,16032000,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3113, "rf_id": 2170, "parent": 3112, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,16032000,16032256,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3115,3030,16032000,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3112, "rf_id": 2169, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,16032000,256], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3115,3030,16032000,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3118, "rf_id": 2174, "parent": 3117, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],[256],[1],16032256], "input_shapes": [[16032512],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3119,3030,16032256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3117, "rf_id": 2173, "parent": 3116, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,16032256,16032512,1], "input_shapes": [[16032512],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3119,3030,16032256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3116, "rf_id": 2172, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3039,3030,0,16032512,2,"cuda:0"],0,16032256,256], "input_shapes": [[16032512],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3119,3030,16032256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3124, "rf_id": 2177, "parent": 3123, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3120,3121,0,12877824,2,"cuda:0"],[12877824],[1],0], "input_shapes": [[12877824],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3043,3121,0,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3123, "rf_id": 2176, "parent": 3122, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3120,3121,0,12877824,2,"cuda:0"],0,0,12877824,1], "input_shapes": [[12877824],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3043,3121,0,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3122, "rf_id": 2175, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3120,3121,0,12877824,2,"cuda:0"],0,0,12877824], "input_shapes": [[12877824],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3043,3121,0,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3125, "rf_id": 2178, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3043,3121,0,12877824,2,"cuda:0"],[3059,3030,0,12877824,2,"cuda:0"],true], "input_shapes": [[12877824],[12877824],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3043,3121,0,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3126, "rf_id": 2179, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3043,3121,0,12877824,2,"cuda:0"],15,0,"cuda:0","<None>",true,false,"<None>"], "input_shapes": [[12877824],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3043,3121,0,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3127, "rf_id": 2180, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2793,1377,12618752,51511296,2,"cuda:0"],"<Stream>"], "input_shapes": [[50304,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3131, "rf_id": 2183, "parent": 3130, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3128,3121,12877824,5120,2,"cuda:0"],[5120],[1],12877824], "input_shapes": [[5120],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3047,3121,12877824,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3130, "rf_id": 2182, "parent": 3129, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3128,3121,12877824,5120,2,"cuda:0"],0,0,5120,1], "input_shapes": [[5120],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3047,3121,12877824,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3129, "rf_id": 2181, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3128,3121,12877824,5120,2,"cuda:0"],0,0,5120], "input_shapes": [[5120],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3047,3121,12877824,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3132, "rf_id": 2184, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3047,3121,12877824,5120,2,"cuda:0"],[3063,3030,12877824,5120,2,"cuda:0"],true], "input_shapes": [[5120],[5120],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3047,3121,12877824,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3133, "rf_id": 2185, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3047,3121,12877824,5120,2,"cuda:0"],15,0,"cuda:0","<None>",true,false,"<None>"], "input_shapes": [[5120],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3047,3121,12877824,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3134, "rf_id": 2186, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2756,1377,12598272,20480,2,"cuda:0"],"<Stream>"], "input_shapes": [[20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3138, "rf_id": 2189, "parent": 3137, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3135,3121,16028672,256,2,"cuda:0"],[256],[1],16028672], "input_shapes": [[256],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3051,3121,16028672,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3137, "rf_id": 2188, "parent": 3136, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3135,3121,16028672,256,2,"cuda:0"],0,0,256,1], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3051,3121,16028672,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3136, "rf_id": 2187, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3135,3121,16028672,256,2,"cuda:0"],0,0,256], "input_shapes": [[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3051,3121,16028672,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3139, "rf_id": 2190, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3051,3121,16028672,256,2,"cuda:0"],[3067,3030,12882944,256,2,"cuda:0"],true], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3051,3121,16028672,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3140, "rf_id": 2191, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3051,3121,16028672,256,2,"cuda:0"],15,0,"cuda:0","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3051,3121,16028672,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3141, "rf_id": 2192, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2671,1377,12596224,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3145, "rf_id": 2195, "parent": 3144, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3142,3121,16028928,256,2,"cuda:0"],[256],[1],16028928], "input_shapes": [[256],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3146,3121,16028928,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3144, "rf_id": 2194, "parent": 3143, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3142,3121,16028928,256,2,"cuda:0"],0,0,256,1], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3146,3121,16028928,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3143, "rf_id": 2193, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3142,3121,16028928,256,2,"cuda:0"],0,0,256], "input_shapes": [[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3146,3121,16028928,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3147, "rf_id": 2196, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3146,3121,16028928,256,2,"cuda:0"],[3071,3030,12883200,256,2,"cuda:0"],true], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3146,3121,16028928,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3148, "rf_id": 2197, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3146,3121,16028928,256,2,"cuda:0"],15,0,"cuda:0","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3146,3121,16028928,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3149, "rf_id": 2198, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2685,1377,12597248,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3153, "rf_id": 2201, "parent": 3152, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3150,3121,12882944,786432,2,"cuda:0"],[786432],[1],12882944], "input_shapes": [[786432],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3154,3121,12882944,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3152, "rf_id": 2200, "parent": 3151, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3150,3121,12882944,786432,2,"cuda:0"],0,0,786432,1], "input_shapes": [[786432],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3154,3121,12882944,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3151, "rf_id": 2199, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3150,3121,12882944,786432,2,"cuda:0"],0,0,786432], "input_shapes": [[786432],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3154,3121,12882944,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3155, "rf_id": 2202, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3154,3121,12882944,786432,2,"cuda:0"],[3075,3030,12883456,786432,2,"cuda:0"],true], "input_shapes": [[786432],[786432],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3154,3121,12882944,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3156, "rf_id": 2203, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3154,3121,12882944,786432,2,"cuda:0"],15,0,"cuda:0","<None>",true,false,"<None>"], "input_shapes": [[786432],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3154,3121,12882944,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3157, "rf_id": 2204, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2607,1377,9447424,3145728,2,"cuda:0"],"<Stream>"], "input_shapes": [[3072,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3161, "rf_id": 2207, "parent": 3160, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3158,3121,16029184,768,2,"cuda:0"],[768],[1],16029184], "input_shapes": [[768],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3162,3121,16029184,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3160, "rf_id": 2206, "parent": 3159, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3158,3121,16029184,768,2,"cuda:0"],0,0,768,1], "input_shapes": [[768],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3162,3121,16029184,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3159, "rf_id": 2205, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3158,3121,16029184,768,2,"cuda:0"],0,0,768], "input_shapes": [[768],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3162,3121,16029184,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3163, "rf_id": 2208, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3162,3121,16029184,768,2,"cuda:0"],[3079,3030,13669888,768,2,"cuda:0"],true], "input_shapes": [[768],[768],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3162,3121,16029184,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3164, "rf_id": 2209, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3162,3121,16029184,768,2,"cuda:0"],15,0,"cuda:0","<None>",true,false,"<None>"], "input_shapes": [[768],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3162,3121,16029184,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3165, "rf_id": 2210, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2626,1377,12593152,3072,2,"cuda:0"],"<Stream>"], "input_shapes": [[3072],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3169, "rf_id": 2213, "parent": 3168, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3166,3121,13669376,262144,2,"cuda:0"],[262144],[1],13669376], "input_shapes": [[262144],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3170,3121,13669376,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3168, "rf_id": 2212, "parent": 3167, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3166,3121,13669376,262144,2,"cuda:0"],0,0,262144,1], "input_shapes": [[262144],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3170,3121,13669376,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3167, "rf_id": 2211, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3166,3121,13669376,262144,2,"cuda:0"],0,0,262144], "input_shapes": [[262144],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3170,3121,13669376,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3171, "rf_id": 2214, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3170,3121,13669376,262144,2,"cuda:0"],[3083,3030,13670656,262144,2,"cuda:0"],true], "input_shapes": [[262144],[262144],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3170,3121,13669376,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3172, "rf_id": 2215, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3170,3121,13669376,262144,2,"cuda:0"],15,0,"cuda:0","<None>",true,false,"<None>"], "input_shapes": [[262144],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3170,3121,13669376,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3173, "rf_id": 2216, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2233,1377,8398848,1048576,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3177, "rf_id": 2219, "parent": 3176, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3174,3121,16029952,256,2,"cuda:0"],[256],[1],16029952], "input_shapes": [[256],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3178,3121,16029952,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3176, "rf_id": 2218, "parent": 3175, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3174,3121,16029952,256,2,"cuda:0"],0,0,256,1], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3178,3121,16029952,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3175, "rf_id": 2217, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3174,3121,16029952,256,2,"cuda:0"],0,0,256], "input_shapes": [[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3178,3121,16029952,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3179, "rf_id": 2220, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3178,3121,16029952,256,2,"cuda:0"],[3087,3030,13932800,256,2,"cuda:0"],true], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3178,3121,16029952,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3180, "rf_id": 2221, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3178,3121,16029952,256,2,"cuda:0"],15,0,"cuda:0","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3178,3121,16029952,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3181, "rf_id": 2222, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2193,1377,8397824,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3185, "rf_id": 2225, "parent": 3184, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3182,3121,16030208,256,2,"cuda:0"],[256],[1],16030208], "input_shapes": [[256],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3186,3121,16030208,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3184, "rf_id": 2224, "parent": 3183, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3182,3121,16030208,256,2,"cuda:0"],0,0,256,1], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3186,3121,16030208,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3183, "rf_id": 2223, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3182,3121,16030208,256,2,"cuda:0"],0,0,256], "input_shapes": [[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3186,3121,16030208,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3187, "rf_id": 2226, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3186,3121,16030208,256,2,"cuda:0"],[3091,3030,13933056,256,2,"cuda:0"],true], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3186,3121,16030208,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3188, "rf_id": 2227, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3186,3121,16030208,256,2,"cuda:0"],15,0,"cuda:0","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3186,3121,16030208,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3189, "rf_id": 2228, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2134,1377,8395776,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3193, "rf_id": 2231, "parent": 3192, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3190,3121,16030464,256,2,"cuda:0"],[256],[1],16030464], "input_shapes": [[256],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3194,3121,16030464,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3192, "rf_id": 2230, "parent": 3191, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3190,3121,16030464,256,2,"cuda:0"],0,0,256,1], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3194,3121,16030464,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3191, "rf_id": 2229, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3190,3121,16030464,256,2,"cuda:0"],0,0,256], "input_shapes": [[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3194,3121,16030464,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3195, "rf_id": 2232, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3194,3121,16030464,256,2,"cuda:0"],[3095,3030,13933312,256,2,"cuda:0"],true], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3194,3121,16030464,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3196, "rf_id": 2233, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3194,3121,16030464,256,2,"cuda:0"],15,0,"cuda:0","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3194,3121,16030464,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3197, "rf_id": 2234, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2148,1377,8396800,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3201, "rf_id": 2237, "parent": 3200, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3198,3121,13931520,1048576,2,"cuda:0"],[1048576],[1],13931520], "input_shapes": [[1048576],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3202,3121,13931520,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3200, "rf_id": 2236, "parent": 3199, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3198,3121,13931520,1048576,2,"cuda:0"],0,0,1048576,1], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3202,3121,13931520,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3199, "rf_id": 2235, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3198,3121,13931520,1048576,2,"cuda:0"],0,0,1048576], "input_shapes": [[1048576],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3202,3121,13931520,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3203, "rf_id": 2238, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3202,3121,13931520,1048576,2,"cuda:0"],[3099,3030,13933568,1048576,2,"cuda:0"],true], "input_shapes": [[1048576],[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3202,3121,13931520,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3204, "rf_id": 2239, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3202,3121,13931520,1048576,2,"cuda:0"],15,0,"cuda:0","<None>",true,false,"<None>"], "input_shapes": [[1048576],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3202,3121,13931520,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3205, "rf_id": 2240, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2089,1377,4201472,4194304,2,"cuda:0"],"<Stream>"], "input_shapes": [[4096,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3209, "rf_id": 2243, "parent": 3208, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3206,3121,16030720,1024,2,"cuda:0"],[1024],[1],16030720], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3210,3121,16030720,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3208, "rf_id": 2242, "parent": 3207, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3206,3121,16030720,1024,2,"cuda:0"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3210,3121,16030720,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3207, "rf_id": 2241, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3206,3121,16030720,1024,2,"cuda:0"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3210,3121,16030720,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3211, "rf_id": 2244, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3210,3121,16030720,1024,2,"cuda:0"],[3103,3030,14982144,1024,2,"cuda:0"],true], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3210,3121,16030720,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3212, "rf_id": 2245, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3210,3121,16030720,1024,2,"cuda:0"],15,0,"cuda:0","<None>",true,false,"<None>"], "input_shapes": [[1024],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3210,3121,16030720,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3213, "rf_id": 2246, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[2051,1377,4197376,4096,2,"cuda:0"],"<Stream>"], "input_shapes": [[4096],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3217, "rf_id": 2249, "parent": 3216, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3214,3121,14980096,1048576,2,"cuda:0"],[1048576],[1],14980096], "input_shapes": [[1048576],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3218,3121,14980096,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3216, "rf_id": 2248, "parent": 3215, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3214,3121,14980096,1048576,2,"cuda:0"],0,0,1048576,1], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3218,3121,14980096,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3215, "rf_id": 2247, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3214,3121,14980096,1048576,2,"cuda:0"],0,0,1048576], "input_shapes": [[1048576],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3218,3121,14980096,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3219, "rf_id": 2250, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3218,3121,14980096,1048576,2,"cuda:0"],[3107,3030,14983168,1048576,2,"cuda:0"],true], "input_shapes": [[1048576],[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3218,3121,14980096,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3220, "rf_id": 2251, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3218,3121,14980096,1048576,2,"cuda:0"],15,0,"cuda:0","<None>",true,false,"<None>"], "input_shapes": [[1048576],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3218,3121,14980096,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3221, "rf_id": 2252, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1952,1377,3072,4194304,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024,4096],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3225, "rf_id": 2255, "parent": 3224, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3222,3121,16031744,256,2,"cuda:0"],[256],[1],16031744], "input_shapes": [[256],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3226,3121,16031744,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3224, "rf_id": 2254, "parent": 3223, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3222,3121,16031744,256,2,"cuda:0"],0,0,256,1], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3226,3121,16031744,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3223, "rf_id": 2253, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3222,3121,16031744,256,2,"cuda:0"],0,0,256], "input_shapes": [[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3226,3121,16031744,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3227, "rf_id": 2256, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3226,3121,16031744,256,2,"cuda:0"],[3111,3030,16031744,256,2,"cuda:0"],true], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3226,3121,16031744,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3228, "rf_id": 2257, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3226,3121,16031744,256,2,"cuda:0"],15,0,"cuda:0","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3226,3121,16031744,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3229, "rf_id": 2258, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1913,1377,2048,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3233, "rf_id": 2261, "parent": 3232, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3230,3121,16032000,256,2,"cuda:0"],[256],[1],16032000], "input_shapes": [[256],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3234,3121,16032000,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3232, "rf_id": 2260, "parent": 3231, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3230,3121,16032000,256,2,"cuda:0"],0,0,256,1], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3234,3121,16032000,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3231, "rf_id": 2259, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3230,3121,16032000,256,2,"cuda:0"],0,0,256], "input_shapes": [[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3234,3121,16032000,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3235, "rf_id": 2262, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3234,3121,16032000,256,2,"cuda:0"],[3115,3030,16032000,256,2,"cuda:0"],true], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3234,3121,16032000,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3236, "rf_id": 2263, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3234,3121,16032000,256,2,"cuda:0"],15,0,"cuda:0","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3234,3121,16032000,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3237, "rf_id": 2264, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1375,1377,0,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3241, "rf_id": 2267, "parent": 3240, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3238,3121,16032256,256,2,"cuda:0"],[256],[1],16032256], "input_shapes": [[256],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3242,3121,16032256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3240, "rf_id": 2266, "parent": 3239, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3238,3121,16032256,256,2,"cuda:0"],0,0,256,1], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3242,3121,16032256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3239, "rf_id": 2265, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3238,3121,16032256,256,2,"cuda:0"],0,0,256], "input_shapes": [[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3242,3121,16032256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::copy_", "id": 3243, "rf_id": 2268, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3242,3121,16032256,256,2,"cuda:0"],[3119,3030,16032256,256,2,"cuda:0"],true], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3242,3121,16032256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3244, "rf_id": 2269, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3242,3121,16032256,256,2,"cuda:0"],15,0,"cuda:0","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3242,3121,16032256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::record_stream", "id": 3245, "rf_id": 2270, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[1391,1377,1024,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3246, "rf_id": 2271, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],0,"<None>","cuda","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","None","None"],
      "outputs": [[3247,10,0,1,1,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(unsigned char)"]
    },
    {
      "name": "aten::empty", "id": 3250, "rf_id": 2274, "parent": 3249, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1],0,"<None>","cuda","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","None","None"],
      "outputs": [[3251,5,0,1,1,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(unsigned char)"]
    },
    {
      "name": "nccl:all_reduce", "id": 3253, "rf_id": 2276, "parent": 3252, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3251,5,0,1,1,"cuda:0"]], "input_shapes": [[1]], "input_types": ["Tensor(unsigned char)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3252, "rf_id": 2275, "parent": 3249, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[3251,5,0,1,1,"cuda:0"]],41,93827882298608,0,"allreduce",[],[],4], "input_shapes": [[[1]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(unsigned char)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[3251,5,0,1,1,"cuda:0"]]], "output_shapes": [[[1]]], "output_types": ["GenericList[Tensor(unsigned char)]"]
    },
    {
      "name": "record_param_comms", "id": 3249, "rf_id": 2273, "parent": 3248, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [41,93827882298608,0,"barrier",[],[],4], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "c10d::barrier", "id": 3248, "rf_id": 2272, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::barrier(Tensor tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, int[] device_ids, int timeout) -> __torch__.torch.classes.c10d.Work",
      "inputs": [[3247,10,0,1,1,"cuda:0"],"<Object>",[],-1], "input_shapes": [[1],[],[],[]], "input_types": ["Tensor(unsigned char)","Object","GenericList[]","Int"],
      "outputs": ["<Object>"], "output_shapes": [[]], "output_types": ["Object"]
    },
    {
      "name": "record_param_comms", "id": 3254, "rf_id": 2277, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [41,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3256, "rf_id": 2278, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3255,237,0,51511296,2,"cuda:0"],"<Stream>"], "input_shapes": [[50304,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3257, "rf_id": 2279, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3258,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3259, "rf_id": 2280, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[251,237,0,51511296,2,"cuda:0"],[3258,57,0,0,2,"cuda:0"]], "input_shapes": [[50304,1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3261, "rf_id": 2281, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3260,345,0,20480,2,"cuda:0"],"<Stream>"], "input_shapes": [[20,1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3262, "rf_id": 2282, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3263,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3264, "rf_id": 2283, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[344,345,0,20480,2,"cuda:0"],[3263,57,0,0,2,"cuda:0"]], "input_shapes": [[20,1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3266, "rf_id": 2284, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3265,423,0,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3267, "rf_id": 2285, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3268,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3269, "rf_id": 2286, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[422,423,0,1024,2,"cuda:0"],[3268,57,0,0,2,"cuda:0"]], "input_shapes": [[1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3271, "rf_id": 2287, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3270,425,0,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3272, "rf_id": 2288, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3273,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3274, "rf_id": 2289, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[424,425,0,1024,2,"cuda:0"],[3273,57,0,0,2,"cuda:0"]], "input_shapes": [[1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3276, "rf_id": 2290, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3275,566,0,3072,2,"cuda:0"],"<Stream>"], "input_shapes": [[3072],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3277, "rf_id": 2291, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3278,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3279, "rf_id": 2292, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[565,566,0,3072,2,"cuda:0"],[3278,57,0,0,2,"cuda:0"]], "input_shapes": [[3072],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3281, "rf_id": 2293, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3280,780,0,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3282, "rf_id": 2294, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3283,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3284, "rf_id": 2295, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[779,780,0,1024,2,"cuda:0"],[3283,57,0,0,2,"cuda:0"]], "input_shapes": [[1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3286, "rf_id": 2296, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3285,818,0,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3287, "rf_id": 2297, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3288,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3289, "rf_id": 2298, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[817,818,0,1024,2,"cuda:0"],[3288,57,0,0,2,"cuda:0"]], "input_shapes": [[1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3291, "rf_id": 2299, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3290,820,0,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3292, "rf_id": 2300, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3293,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3294, "rf_id": 2301, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[819,820,0,1024,2,"cuda:0"],[3293,57,0,0,2,"cuda:0"]], "input_shapes": [[1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3296, "rf_id": 2302, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3295,887,0,4096,2,"cuda:0"],"<Stream>"], "input_shapes": [[4096],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3297, "rf_id": 2303, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3298,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3299, "rf_id": 2304, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[886,887,0,4096,2,"cuda:0"],[3298,57,0,0,2,"cuda:0"]], "input_shapes": [[4096],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3301, "rf_id": 2305, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3300,958,0,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3302, "rf_id": 2306, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3303,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3304, "rf_id": 2307, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[957,958,0,1024,2,"cuda:0"],[3303,57,0,0,2,"cuda:0"]], "input_shapes": [[1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3306, "rf_id": 2308, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3305,994,0,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3307, "rf_id": 2309, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3308,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3309, "rf_id": 2310, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[993,994,0,1024,2,"cuda:0"],[3308,57,0,0,2,"cuda:0"]], "input_shapes": [[1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::record_stream", "id": 3311, "rf_id": 2311, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3310,996,0,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::empty", "id": 3312, "rf_id": 2312, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3313,57,0,0,2,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3314, "rf_id": 2313, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[995,996,0,1024,2,"cuda:0"],[3313,57,0,0,2,"cuda:0"]], "input_shapes": [[1024],[0]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::to", "id": 3315, "rf_id": 2314, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3120,3121,0,12877824,2,"cuda:0"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[12877824],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3120,3121,0,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3318, "rf_id": 2317, "parent": 3317, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[12877824],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3319,1077,0,12877824,8,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3320, "rf_id": 2318, "parent": 3317, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3319,1077,0,12877824,8,"cuda:0"],[3120,3121,0,12877824,2,"cuda:0"],false], "input_shapes": [[12877824],[12877824],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3319,1077,0,12877824,8,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3317, "rf_id": 2316, "parent": 3316, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3120,3121,0,12877824,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[12877824],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3319,1077,0,12877824,8,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3316, "rf_id": 2315, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3120,3121,0,12877824,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[12877824],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3319,1077,0,12877824,8,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3323, "rf_id": 2320, "parent": 3321, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3322,5,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3324,5,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3321, "rf_id": 2319, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3319,1077,0,12877824,8,"cuda:0"],2,"<None>",false,"<None>"], "input_shapes": [[12877824],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3322,5,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3325, "rf_id": 2321, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3128,3121,12877824,5120,2,"cuda:0"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[5120],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3128,3121,12877824,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3328, "rf_id": 2324, "parent": 3327, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[5120],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3324,345,0,5120,8,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3329, "rf_id": 2325, "parent": 3327, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3324,345,0,5120,8,"cuda:0"],[3128,3121,12877824,5120,2,"cuda:0"],false], "input_shapes": [[5120],[5120],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3324,345,0,5120,8,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3327, "rf_id": 2323, "parent": 3326, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3128,3121,12877824,5120,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[5120],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3324,345,0,5120,8,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3326, "rf_id": 2322, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3128,3121,12877824,5120,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[5120],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3324,345,0,5120,8,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3332, "rf_id": 2327, "parent": 3330, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3331,198,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3333,198,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3330, "rf_id": 2326, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3324,345,0,5120,8,"cuda:0"],2,"<None>",false,"<None>"], "input_shapes": [[5120],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3331,198,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3334, "rf_id": 2328, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3150,3121,12882944,786432,2,"cuda:0"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[786432],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3150,3121,12882944,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3337, "rf_id": 2331, "parent": 3336, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[786432],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3333,904,0,786432,8,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3338, "rf_id": 2332, "parent": 3336, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3333,904,0,786432,8,"cuda:0"],[3150,3121,12882944,786432,2,"cuda:0"],false], "input_shapes": [[786432],[786432],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3333,904,0,786432,8,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3336, "rf_id": 2330, "parent": 3335, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3150,3121,12882944,786432,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[786432],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3333,904,0,786432,8,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3335, "rf_id": 2329, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3150,3121,12882944,786432,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[786432],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3333,904,0,786432,8,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3342, "rf_id": 2334, "parent": 3339, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3340,3341,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3343,3341,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3339, "rf_id": 2333, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3333,904,0,786432,8,"cuda:0"],2,"<None>",false,"<None>"], "input_shapes": [[786432],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3340,3341,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3344, "rf_id": 2335, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3166,3121,13669376,262144,2,"cuda:0"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[262144],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3166,3121,13669376,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3347, "rf_id": 2338, "parent": 3346, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[262144],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3343,904,0,262144,8,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3348, "rf_id": 2339, "parent": 3346, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3343,904,0,262144,8,"cuda:0"],[3166,3121,13669376,262144,2,"cuda:0"],false], "input_shapes": [[262144],[262144],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3343,904,0,262144,8,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3346, "rf_id": 2337, "parent": 3345, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3166,3121,13669376,262144,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[262144],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3343,904,0,262144,8,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3345, "rf_id": 2336, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3166,3121,13669376,262144,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[262144],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3343,904,0,262144,8,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3351, "rf_id": 2341, "parent": 3349, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3350,1214,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3352,1214,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3349, "rf_id": 2340, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3343,904,0,262144,8,"cuda:0"],2,"<None>",false,"<None>"], "input_shapes": [[262144],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3350,1214,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3353, "rf_id": 2342, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3198,3121,13931520,1048576,2,"cuda:0"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[1048576],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3198,3121,13931520,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3356, "rf_id": 2345, "parent": 3355, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1048576],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3352,904,0,1048576,8,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3357, "rf_id": 2346, "parent": 3355, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3352,904,0,1048576,8,"cuda:0"],[3198,3121,13931520,1048576,2,"cuda:0"],false], "input_shapes": [[1048576],[1048576],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3352,904,0,1048576,8,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3355, "rf_id": 2344, "parent": 3354, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3198,3121,13931520,1048576,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[1048576],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3352,904,0,1048576,8,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3354, "rf_id": 2343, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3198,3121,13931520,1048576,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3352,904,0,1048576,8,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3360, "rf_id": 2348, "parent": 3358, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3359,1195,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3361,1195,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3358, "rf_id": 2347, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3352,904,0,1048576,8,"cuda:0"],2,"<None>",false,"<None>"], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3359,1195,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3362, "rf_id": 2349, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3214,3121,14980096,1048576,2,"cuda:0"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[1048576],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3214,3121,14980096,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3365, "rf_id": 2352, "parent": 3364, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1048576],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3361,904,0,1048576,8,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3366, "rf_id": 2353, "parent": 3364, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3361,904,0,1048576,8,"cuda:0"],[3214,3121,14980096,1048576,2,"cuda:0"],false], "input_shapes": [[1048576],[1048576],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3361,904,0,1048576,8,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3364, "rf_id": 2351, "parent": 3363, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3214,3121,14980096,1048576,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[1048576],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3361,904,0,1048576,8,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3363, "rf_id": 2350, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3214,3121,14980096,1048576,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3361,904,0,1048576,8,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3369, "rf_id": 2355, "parent": 3367, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3368,184,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3370,184,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3367, "rf_id": 2354, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3361,904,0,1048576,8,"cuda:0"],2,"<None>",false,"<None>"], "input_shapes": [[1048576],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3368,184,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3373, "rf_id": 2358, "parent": 3372, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3322,5,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3370,5,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3372, "rf_id": 2357, "parent": 3371, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3322,5,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3370,5,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3375, "rf_id": 2360, "parent": 3374, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3331,198,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3376,198,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3374, "rf_id": 2359, "parent": 3371, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3331,198,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3376,198,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3378, "rf_id": 2362, "parent": 3377, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3340,3341,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3379,3341,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3377, "rf_id": 2361, "parent": 3371, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3340,3341,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3379,3341,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3381, "rf_id": 2364, "parent": 3380, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3350,1214,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3382,1214,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3380, "rf_id": 2363, "parent": 3371, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3350,1214,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3382,1214,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3384, "rf_id": 2366, "parent": 3383, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3359,1195,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3385,1195,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3383, "rf_id": 2365, "parent": 3371, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3359,1195,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3385,1195,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3387, "rf_id": 2368, "parent": 3386, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3368,184,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3388,184,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3386, "rf_id": 2367, "parent": 3371, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3368,184,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3388,184,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::cat", "id": 3389, "rf_id": 2369, "parent": 3371, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[3370,5,0,1,8,"cuda:0"],[3376,198,0,1,8,"cuda:0"],[3379,3341,0,1,8,"cuda:0"],[3382,1214,0,1,8,"cuda:0"],[3385,1195,0,1,8,"cuda:0"],[3388,184,0,1,8,"cuda:0"]],0], "input_shapes": [[[1],[1],[1],[1],[1],[1]],[]], "input_types": ["GenericList[Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double)]","Int"],
      "outputs": [[3390,3391,0,6,8,"cuda:0"]], "output_shapes": [[6]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::stack", "id": 3371, "rf_id": 2356, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::stack(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[3322,5,0,1,8,"cuda:0"],[3331,198,0,1,8,"cuda:0"],[3340,3341,0,1,8,"cuda:0"],[3350,1214,0,1,8,"cuda:0"],[3359,1195,0,1,8,"cuda:0"],[3368,184,0,1,8,"cuda:0"]],0], "input_shapes": [[[],[],[],[],[],[]],[]], "input_types": ["GenericList[Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double)]","Int"],
      "outputs": [[3390,3391,0,6,8,"cuda:0"]], "output_shapes": [[6]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::result_type", "id": 3393, "rf_id": 2371, "parent": 3392, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::result_type.Scalar(Tensor tensor, Scalar other) -> ScalarType",
      "inputs": [[3390,3391,0,6,8,"cuda:0"],2], "input_shapes": [[6],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [7], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::to", "id": 3394, "rf_id": 2372, "parent": 3392, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3390,3391,0,6,8,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[6],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[3390,3391,0,6,8,"cuda:0"]], "output_shapes": [[6]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::pow", "id": 3392, "rf_id": 2370, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -> Tensor",
      "inputs": [[3390,3391,0,6,8,"cuda:0"],2], "input_shapes": [[6],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3395,3396,0,6,8,"cuda:0"]], "output_shapes": [[6]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3400, "rf_id": 2375, "parent": 3398, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3399,3391,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3401,3391,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::sum", "id": 3398, "rf_id": 2374, "parent": 3397, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3395,3396,0,6,8,"cuda:0"],[],false,"<None>"], "input_shapes": [[6],[],[],[]], "input_types": ["Tensor(double)","GenericList[]","Bool","None"],
      "outputs": [[3399,3391,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::sum", "id": 3397, "rf_id": 2373, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum(Tensor self, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3395,3396,0,6,8,"cuda:0"],"<None>"], "input_shapes": [[6],[]], "input_types": ["Tensor(double)","None"],
      "outputs": [[3399,3391,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "nccl:all_reduce", "id": 3404, "rf_id": 2378, "parent": 3403, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3399,3391,0,1,8,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3403, "rf_id": 2377, "parent": 3402, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[3399,3391,0,1,8,"cuda:0"]],129,93827882276192,0,"allreduce",[],[],4], "input_shapes": [[[]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(double)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[3399,3391,0,1,8,"cuda:0"]]], "output_shapes": [[[]]], "output_types": ["GenericList[Tensor(double)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 3402, "rf_id": 2376, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[3399,3391,0,1,8,"cuda:0"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[]],[],[],[],[]], "input_types": ["GenericList[Tensor(double)]","Object","Object","None","Int"],
      "outputs": [[[3399,3391,0,1,8,"cuda:0"]],"<Object>"], "output_shapes": [[[]],[]], "output_types": ["GenericList[Tensor(double)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 3405, "rf_id": 2379, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [129,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "nccl:all_reduce", "id": 3408, "rf_id": 2382, "parent": 3407, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3399,3391,0,1,8,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3407, "rf_id": 2381, "parent": 3406, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[3399,3391,0,1,8,"cuda:0"]],7,93827882280384,0,"allreduce",[],[],1], "input_shapes": [[[]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(double)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[3399,3391,0,1,8,"cuda:0"]]], "output_shapes": [[[]]], "output_types": ["GenericList[Tensor(double)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 3406, "rf_id": 2380, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[3399,3391,0,1,8,"cuda:0"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[]],[],[],[],[]], "input_types": ["GenericList[Tensor(double)]","Object","Object","None","Int"],
      "outputs": [[[3399,3391,0,1,8,"cuda:0"]],"<Object>"], "output_shapes": [[[]],[]], "output_types": ["GenericList[Tensor(double)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 3409, "rf_id": 2383, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [7,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::result_type", "id": 3411, "rf_id": 2385, "parent": 3410, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::result_type.Scalar(Tensor tensor, Scalar other) -> ScalarType",
      "inputs": [[3399,3391,0,1,8,"cuda:0"],0.500000], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [7], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::to", "id": 3412, "rf_id": 2386, "parent": 3410, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3399,3391,0,1,8,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[3399,3391,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::pow", "id": 3410, "rf_id": 2384, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -> Tensor",
      "inputs": [[3399,3391,0,1,8,"cuda:0"],0.500000], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [[3413,3396,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::empty", "id": 3416, "rf_id": 2389, "parent": 3415, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],7,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[3417,57,0,0,8,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::resize_", "id": 3419, "rf_id": 2391, "parent": 3418, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[3417,57,0,0,8,"cuda:0"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(double)","GenericList[]","None"],
      "outputs": [[3417,436,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::abs", "id": 3418, "rf_id": 2390, "parent": 3415, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::abs.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[3413,3396,0,1,8,"cuda:0"],[3417,57,0,0,8,"cuda:0"]], "input_shapes": [[],[0]], "input_types": ["Tensor(double)","Tensor(double)"],
      "outputs": [[3417,436,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::abs", "id": 3415, "rf_id": 2388, "parent": 3414, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::abs(Tensor self) -> Tensor",
      "inputs": [[3413,3396,0,1,8,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [[3417,436,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::eq", "id": 3420, "rf_id": 2392, "parent": 3414, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::eq.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[3417,436,0,1,8,"cuda:0"],"inf"], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [[3421,3422,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::isinf", "id": 3414, "rf_id": 2387, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::isinf(Tensor self) -> Tensor",
      "inputs": [[3413,3396,0,1,8,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [[3421,3422,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::ne", "id": 3424, "rf_id": 2394, "parent": 3423, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ne.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[3413,3396,0,1,8,"cuda:0"],[3413,3396,0,1,8,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Tensor(double)"],
      "outputs": [[3425,436,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::isnan", "id": 3423, "rf_id": 2393, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::isnan(Tensor self) -> Tensor",
      "inputs": [[3413,3396,0,1,8,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [[3425,436,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty", "id": 3427, "rf_id": 2396, "parent": 3426, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[3428,57,0,0,1,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::resize_", "id": 3430, "rf_id": 2398, "parent": 3429, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[3428,57,0,0,1,"cuda:0"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(bool)","GenericList[]","None"],
      "outputs": [[3428,1061,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_or", "id": 3429, "rf_id": 2397, "parent": 3426, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_or.out(Tensor self, Tensor other, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[3425,436,0,1,1,"cuda:0"],[3421,3422,0,1,1,"cuda:0"],[3428,57,0,0,1,"cuda:0"]], "input_shapes": [[],[],[0]], "input_types": ["Tensor(bool)","Tensor(bool)","Tensor(bool)"],
      "outputs": [[3428,1061,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_or", "id": 3426, "rf_id": 2395, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_or(Tensor self, Tensor other) -> Tensor",
      "inputs": [[3425,436,0,1,1,"cuda:0"],[3421,3422,0,1,1,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[3428,1061,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty", "id": 3431, "rf_id": 2399, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],6,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[3432,3433,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 3436, "rf_id": 2402, "parent": 3435, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],6,0,"cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[3437,3438,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 3439, "rf_id": 2403, "parent": 3435, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3437,3438,0,1,4,"cuda:0"],[3432,3433,0,1,4,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(float)","Bool"],
      "outputs": [[3437,3438,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 3435, "rf_id": 2401, "parent": 3434, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3432,3433,0,1,4,"cpu"],6,"<None>","cuda:0","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(float)","Int","None","Device","None","Bool","None"],
      "outputs": [[3437,3438,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 3434, "rf_id": 2400, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3432,3433,0,1,4,"cpu"],"cuda:0",6,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(float)","Device","Int","Bool","Bool","None"],
      "outputs": [[3437,3438,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::lift_fresh", "id": 3440, "rf_id": 2404, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[3437,3438,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[3437,3438,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "detach_", "id": 3442, "rf_id": 2406, "parent": 3441, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3437,3438,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 3441, "rf_id": 2405, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[3437,3438,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[3437,3438,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul", "id": 3443, "rf_id": 2407, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[3428,1061,0,1,1,"cuda:0"],[3437,3438,0,1,4,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(float)"],
      "outputs": [[3444,1065,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 3446, "rf_id": 2409, "parent": 3445, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[3447,57,0,0,1,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::resize_", "id": 3449, "rf_id": 2411, "parent": 3448, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[3447,57,0,0,1,"cuda:0"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(bool)","GenericList[]","None"],
      "outputs": [[3447,1082,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_not", "id": 3448, "rf_id": 2410, "parent": 3445, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_not.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[3428,1061,0,1,1,"cuda:0"],[3447,57,0,0,1,"cuda:0"]], "input_shapes": [[],[0]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[3447,1082,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_not", "id": 3445, "rf_id": 2408, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_not(Tensor self) -> Tensor",
      "inputs": [[3428,1061,0,1,1,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [[3447,1082,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::mul", "id": 3450, "rf_id": 2412, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[3447,1082,0,1,1,"cuda:0"],[3413,3396,0,1,8,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(double)"],
      "outputs": [[3451,1086,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::add", "id": 3452, "rf_id": 2413, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[3444,1065,0,1,4,"cuda:0"],[3451,1086,0,1,8,"cuda:0"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(double)","Int"],
      "outputs": [[3453,1082,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3454, "rf_id": 2414, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3135,3121,16028672,256,2,"cuda:0"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3135,3121,16028672,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3457, "rf_id": 2417, "parent": 3456, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[256],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3458,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3459, "rf_id": 2418, "parent": 3456, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3458,1214,0,256,8,"cuda:0"],[3135,3121,16028672,256,2,"cuda:0"],false], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3458,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3456, "rf_id": 2416, "parent": 3455, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3135,3121,16028672,256,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3458,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3455, "rf_id": 2415, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3135,3121,16028672,256,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3458,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3462, "rf_id": 2420, "parent": 3460, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3461,5,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3401,5,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3460, "rf_id": 2419, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3458,1214,0,256,8,"cuda:0"],2,"<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3461,5,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3463, "rf_id": 2421, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3142,3121,16028928,256,2,"cuda:0"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3142,3121,16028928,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3466, "rf_id": 2424, "parent": 3465, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[256],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3401,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3467, "rf_id": 2425, "parent": 3465, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3401,1214,0,256,8,"cuda:0"],[3142,3121,16028928,256,2,"cuda:0"],false], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3401,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3465, "rf_id": 2423, "parent": 3464, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3142,3121,16028928,256,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3401,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3464, "rf_id": 2422, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3142,3121,16028928,256,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3401,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3470, "rf_id": 2427, "parent": 3468, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3469,198,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3471,198,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3468, "rf_id": 2426, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3401,1214,0,256,8,"cuda:0"],2,"<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3469,198,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3472, "rf_id": 2428, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3158,3121,16029184,768,2,"cuda:0"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[768],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3158,3121,16029184,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3475, "rf_id": 2431, "parent": 3474, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[768],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3471,1086,0,768,8,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3476, "rf_id": 2432, "parent": 3474, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3471,1086,0,768,8,"cuda:0"],[3158,3121,16029184,768,2,"cuda:0"],false], "input_shapes": [[768],[768],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3471,1086,0,768,8,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3474, "rf_id": 2430, "parent": 3473, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3158,3121,16029184,768,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[768],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3471,1086,0,768,8,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3473, "rf_id": 2429, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3158,3121,16029184,768,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[768],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3471,1086,0,768,8,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3479, "rf_id": 2434, "parent": 3477, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3478,3341,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3480,3341,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3477, "rf_id": 2433, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3471,1086,0,768,8,"cuda:0"],2,"<None>",false,"<None>"], "input_shapes": [[768],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3478,3341,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3481, "rf_id": 2435, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3174,3121,16029952,256,2,"cuda:0"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3174,3121,16029952,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3484, "rf_id": 2438, "parent": 3483, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[256],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3480,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3485, "rf_id": 2439, "parent": 3483, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3480,1214,0,256,8,"cuda:0"],[3174,3121,16029952,256,2,"cuda:0"],false], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3480,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3483, "rf_id": 2437, "parent": 3482, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3174,3121,16029952,256,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3480,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3482, "rf_id": 2436, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3174,3121,16029952,256,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3480,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3488, "rf_id": 2441, "parent": 3486, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3487,3396,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3489,3396,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3486, "rf_id": 2440, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3480,1214,0,256,8,"cuda:0"],2,"<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3487,3396,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3490, "rf_id": 2442, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3182,3121,16030208,256,2,"cuda:0"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3182,3121,16030208,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3493, "rf_id": 2445, "parent": 3492, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[256],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3489,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3494, "rf_id": 2446, "parent": 3492, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3489,1214,0,256,8,"cuda:0"],[3182,3121,16030208,256,2,"cuda:0"],false], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3489,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3492, "rf_id": 2444, "parent": 3491, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3182,3121,16030208,256,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3489,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3491, "rf_id": 2443, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3182,3121,16030208,256,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3489,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3497, "rf_id": 2448, "parent": 3495, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3496,436,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3498,436,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3495, "rf_id": 2447, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3489,1214,0,256,8,"cuda:0"],2,"<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3496,436,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3499, "rf_id": 2449, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3190,3121,16030464,256,2,"cuda:0"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3190,3121,16030464,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3502, "rf_id": 2452, "parent": 3501, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[256],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3498,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3503, "rf_id": 2453, "parent": 3501, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3498,1214,0,256,8,"cuda:0"],[3190,3121,16030464,256,2,"cuda:0"],false], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3498,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3501, "rf_id": 2451, "parent": 3500, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3190,3121,16030464,256,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3498,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3500, "rf_id": 2450, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3190,3121,16030464,256,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3498,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3506, "rf_id": 2455, "parent": 3504, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3505,3422,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3507,3422,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3504, "rf_id": 2454, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3498,1214,0,256,8,"cuda:0"],2,"<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3505,3422,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3508, "rf_id": 2456, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3206,3121,16030720,1024,2,"cuda:0"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[1024],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3206,3121,16030720,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3511, "rf_id": 2459, "parent": 3510, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[1024],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3507,425,0,1024,8,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3512, "rf_id": 2460, "parent": 3510, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3507,425,0,1024,8,"cuda:0"],[3206,3121,16030720,1024,2,"cuda:0"],false], "input_shapes": [[1024],[1024],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3507,425,0,1024,8,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3510, "rf_id": 2458, "parent": 3509, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3206,3121,16030720,1024,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[1024],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3507,425,0,1024,8,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3509, "rf_id": 2457, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3206,3121,16030720,1024,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3507,425,0,1024,8,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3515, "rf_id": 2462, "parent": 3513, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3514,1061,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3516,1061,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3513, "rf_id": 2461, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3507,425,0,1024,8,"cuda:0"],2,"<None>",false,"<None>"], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3514,1061,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3517, "rf_id": 2463, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3222,3121,16031744,256,2,"cuda:0"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3222,3121,16031744,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3520, "rf_id": 2466, "parent": 3519, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[256],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3516,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3521, "rf_id": 2467, "parent": 3519, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3516,1214,0,256,8,"cuda:0"],[3222,3121,16031744,256,2,"cuda:0"],false], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3516,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3519, "rf_id": 2465, "parent": 3518, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3222,3121,16031744,256,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3516,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3518, "rf_id": 2464, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3222,3121,16031744,256,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3516,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3524, "rf_id": 2469, "parent": 3522, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3523,3438,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3525,3438,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3522, "rf_id": 2468, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3516,1214,0,256,8,"cuda:0"],2,"<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3523,3438,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3526, "rf_id": 2470, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3230,3121,16032000,256,2,"cuda:0"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3230,3121,16032000,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3529, "rf_id": 2473, "parent": 3528, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[256],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3525,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3530, "rf_id": 2474, "parent": 3528, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3525,1214,0,256,8,"cuda:0"],[3230,3121,16032000,256,2,"cuda:0"],false], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3525,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3528, "rf_id": 2472, "parent": 3527, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3230,3121,16032000,256,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3525,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3527, "rf_id": 2471, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3230,3121,16032000,256,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3525,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3533, "rf_id": 2476, "parent": 3531, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3532,1065,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3534,1065,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3531, "rf_id": 2475, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3525,1214,0,256,8,"cuda:0"],2,"<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3532,1065,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3535, "rf_id": 2477, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3238,3121,16032256,256,2,"cuda:0"],15,0,"cuda","<None>",true,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3238,3121,16032256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3538, "rf_id": 2480, "parent": 3537, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[256],[1],7,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3534,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::copy_", "id": 3539, "rf_id": 2481, "parent": 3537, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3534,1214,0,256,8,"cuda:0"],[3238,3121,16032256,256,2,"cuda:0"],false], "input_shapes": [[256],[256],[]], "input_types": ["Tensor(double)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3534,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_to_copy", "id": 3537, "rf_id": 2479, "parent": 3536, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3238,3121,16032256,256,2,"cuda:0"],7,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3534,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::to", "id": 3536, "rf_id": 2478, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3238,3121,16032256,256,2,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3534,1214,0,256,8,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3542, "rf_id": 2483, "parent": 3540, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3541,1086,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3543,1086,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::linalg_vector_norm", "id": 3540, "rf_id": 2482, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3534,1214,0,256,8,"cuda:0"],2,"<None>",false,"<None>"], "input_shapes": [[256],[],[],[],[]], "input_types": ["Tensor(double)","Int","None","Bool","None"],
      "outputs": [[3541,1086,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3546, "rf_id": 2486, "parent": 3545, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3461,5,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3543,5,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3545, "rf_id": 2485, "parent": 3544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3461,5,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3543,5,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3548, "rf_id": 2488, "parent": 3547, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3469,198,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3549,198,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3547, "rf_id": 2487, "parent": 3544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3469,198,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3549,198,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3551, "rf_id": 2490, "parent": 3550, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3478,3341,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3552,3341,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3550, "rf_id": 2489, "parent": 3544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3478,3341,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3552,3341,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3554, "rf_id": 2492, "parent": 3553, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3487,3396,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3555,3396,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3553, "rf_id": 2491, "parent": 3544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3487,3396,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3555,3396,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3557, "rf_id": 2494, "parent": 3556, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3496,436,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3558,436,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3556, "rf_id": 2493, "parent": 3544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3496,436,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3558,436,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3560, "rf_id": 2496, "parent": 3559, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3505,3422,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3561,3422,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3559, "rf_id": 2495, "parent": 3544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3505,3422,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3561,3422,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3563, "rf_id": 2498, "parent": 3562, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3514,1061,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3564,1061,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3562, "rf_id": 2497, "parent": 3544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3514,1061,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3564,1061,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3566, "rf_id": 2500, "parent": 3565, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3523,3438,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3567,3438,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3565, "rf_id": 2499, "parent": 3544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3523,3438,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3567,3438,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3569, "rf_id": 2502, "parent": 3568, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3532,1065,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3570,1065,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3568, "rf_id": 2501, "parent": 3544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3532,1065,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3570,1065,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3572, "rf_id": 2504, "parent": 3571, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3541,1086,0,1,8,"cuda:0"],[1],[1],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3573,1086,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::unsqueeze", "id": 3571, "rf_id": 2503, "parent": 3544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)",
      "inputs": [[3541,1086,0,1,8,"cuda:0"],0], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3573,1086,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::cat", "id": 3574, "rf_id": 2505, "parent": 3544, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[3543,5,0,1,8,"cuda:0"],[3549,198,0,1,8,"cuda:0"],[3552,3341,0,1,8,"cuda:0"],[3555,3396,0,1,8,"cuda:0"],[3558,436,0,1,8,"cuda:0"],[3561,3422,0,1,8,"cuda:0"],[3564,1061,0,1,8,"cuda:0"],[3567,3438,0,1,8,"cuda:0"],[3570,1065,0,1,8,"cuda:0"],[3573,1086,0,1,8,"cuda:0"]],0], "input_shapes": [[[1],[1],[1],[1],[1],[1],[1],[1],[1],[1]],[]], "input_types": ["GenericList[Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double)]","Int"],
      "outputs": [[3575,1214,0,10,8,"cuda:0"]], "output_shapes": [[10]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::stack", "id": 3544, "rf_id": 2484, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::stack(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[3461,5,0,1,8,"cuda:0"],[3469,198,0,1,8,"cuda:0"],[3478,3341,0,1,8,"cuda:0"],[3487,3396,0,1,8,"cuda:0"],[3496,436,0,1,8,"cuda:0"],[3505,3422,0,1,8,"cuda:0"],[3514,1061,0,1,8,"cuda:0"],[3523,3438,0,1,8,"cuda:0"],[3532,1065,0,1,8,"cuda:0"],[3541,1086,0,1,8,"cuda:0"]],0], "input_shapes": [[[],[],[],[],[],[],[],[],[],[]],[]], "input_types": ["GenericList[Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double),Tensor(double)]","Int"],
      "outputs": [[3575,1214,0,10,8,"cuda:0"]], "output_shapes": [[10]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::result_type", "id": 3577, "rf_id": 2507, "parent": 3576, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::result_type.Scalar(Tensor tensor, Scalar other) -> ScalarType",
      "inputs": [[3575,1214,0,10,8,"cuda:0"],2], "input_shapes": [[10],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [7], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::to", "id": 3578, "rf_id": 2508, "parent": 3576, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3575,1214,0,10,8,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[10],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[3575,1214,0,10,8,"cuda:0"]], "output_shapes": [[10]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::pow", "id": 3576, "rf_id": 2506, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -> Tensor",
      "inputs": [[3575,1214,0,10,8,"cuda:0"],2], "input_shapes": [[10],[]], "input_types": ["Tensor(double)","Int"],
      "outputs": [[3579,1195,0,10,8,"cuda:0"]], "output_shapes": [[10]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::as_strided", "id": 3583, "rf_id": 2511, "parent": 3581, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3582,1214,0,1,8,"cuda:0"],[1],[0],"<None>"], "input_shapes": [[],[[]],[[]],[]], "input_types": ["Tensor(double)","GenericList[Int]","GenericList[Int]","None"],
      "outputs": [[3584,1214,0,1,8,"cuda:0"]], "output_shapes": [[1]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::sum", "id": 3581, "rf_id": 2510, "parent": 3580, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3579,1195,0,10,8,"cuda:0"],[],false,"<None>"], "input_shapes": [[10],[],[],[]], "input_types": ["Tensor(double)","GenericList[]","Bool","None"],
      "outputs": [[3582,1214,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::sum", "id": 3580, "rf_id": 2509, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::sum(Tensor self, *, ScalarType? dtype=None) -> Tensor",
      "inputs": [[3579,1195,0,10,8,"cuda:0"],"<None>"], "input_shapes": [[10],[]], "input_types": ["Tensor(double)","None"],
      "outputs": [[3582,1214,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "nccl:all_reduce", "id": 3587, "rf_id": 2514, "parent": 3586, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3582,1214,0,1,8,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3586, "rf_id": 2513, "parent": 3585, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[3582,1214,0,1,8,"cuda:0"]],130,93827882276192,0,"allreduce",[],[],4], "input_shapes": [[[]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(double)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[3582,1214,0,1,8,"cuda:0"]]], "output_shapes": [[[]]], "output_types": ["GenericList[Tensor(double)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 3585, "rf_id": 2512, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[3582,1214,0,1,8,"cuda:0"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[]],[],[],[],[]], "input_types": ["GenericList[Tensor(double)]","Object","Object","None","Int"],
      "outputs": [[[3582,1214,0,1,8,"cuda:0"]],"<Object>"], "output_shapes": [[[]],[]], "output_types": ["GenericList[Tensor(double)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 3588, "rf_id": 2515, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [130,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "nccl:all_reduce", "id": 3591, "rf_id": 2518, "parent": 3590, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3582,1214,0,1,8,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3590, "rf_id": 2517, "parent": 3589, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[[3582,1214,0,1,8,"cuda:0"]],8,93827882280384,0,"allreduce",[],[],1], "input_shapes": [[[]],[],[],[],[],[],[],[]], "input_types": ["GenericList[Tensor(double)]","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[[3582,1214,0,1,8,"cuda:0"]]], "output_shapes": [[[]]], "output_types": ["GenericList[Tensor(double)]"]
    },
    {
      "name": "c10d::allreduce_", "id": 3589, "rf_id": 2516, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)",
      "inputs": [[[3582,1214,0,1,8,"cuda:0"]],"<Object>","<Object>","<None>",-1], "input_shapes": [[[]],[],[],[],[]], "input_types": ["GenericList[Tensor(double)]","Object","Object","None","Int"],
      "outputs": [[[3582,1214,0,1,8,"cuda:0"]],"<Object>"], "output_shapes": [[[]],[]], "output_types": ["GenericList[Tensor(double)]","Object"]
    },
    {
      "name": "record_param_comms", "id": 3592, "rf_id": 2519, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [8,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::result_type", "id": 3594, "rf_id": 2521, "parent": 3593, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::result_type.Scalar(Tensor tensor, Scalar other) -> ScalarType",
      "inputs": [[3582,1214,0,1,8,"cuda:0"],0.500000], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [7], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::to", "id": 3595, "rf_id": 2522, "parent": 3593, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3582,1214,0,1,8,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[3582,1214,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::pow", "id": 3593, "rf_id": 2520, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -> Tensor",
      "inputs": [[3582,1214,0,1,8,"cuda:0"],0.500000], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [[3596,1195,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::empty", "id": 3599, "rf_id": 2525, "parent": 3598, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],7,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[3600,57,0,0,8,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::resize_", "id": 3602, "rf_id": 2527, "parent": 3601, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[3600,57,0,0,8,"cuda:0"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(double)","GenericList[]","None"],
      "outputs": [[3600,184,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::abs", "id": 3601, "rf_id": 2526, "parent": 3598, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::abs.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[3596,1195,0,1,8,"cuda:0"],[3600,57,0,0,8,"cuda:0"]], "input_shapes": [[],[0]], "input_types": ["Tensor(double)","Tensor(double)"],
      "outputs": [[3600,184,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::abs", "id": 3598, "rf_id": 2524, "parent": 3597, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::abs(Tensor self) -> Tensor",
      "inputs": [[3596,1195,0,1,8,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [[3600,184,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::eq", "id": 3603, "rf_id": 2528, "parent": 3597, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::eq.Scalar(Tensor self, Scalar other) -> Tensor",
      "inputs": [[3600,184,0,1,8,"cuda:0"],"inf"], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [[3604,3391,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::isinf", "id": 3597, "rf_id": 2523, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::isinf(Tensor self) -> Tensor",
      "inputs": [[3596,1195,0,1,8,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [[3604,3391,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::ne", "id": 3606, "rf_id": 2530, "parent": 3605, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::ne.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[3596,1195,0,1,8,"cuda:0"],[3596,1195,0,1,8,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Tensor(double)"],
      "outputs": [[3607,184,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::isnan", "id": 3605, "rf_id": 2529, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::isnan(Tensor self) -> Tensor",
      "inputs": [[3596,1195,0,1,8,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [[3607,184,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty", "id": 3609, "rf_id": 2532, "parent": 3608, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[3610,57,0,0,1,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::resize_", "id": 3612, "rf_id": 2534, "parent": 3611, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[3610,57,0,0,1,"cuda:0"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(bool)","GenericList[]","None"],
      "outputs": [[3610,1090,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_or", "id": 3611, "rf_id": 2533, "parent": 3608, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_or.out(Tensor self, Tensor other, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[3607,184,0,1,1,"cuda:0"],[3604,3391,0,1,1,"cuda:0"],[3610,57,0,0,1,"cuda:0"]], "input_shapes": [[],[],[0]], "input_types": ["Tensor(bool)","Tensor(bool)","Tensor(bool)"],
      "outputs": [[3610,1090,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_or", "id": 3608, "rf_id": 2531, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_or(Tensor self, Tensor other) -> Tensor",
      "inputs": [[3607,184,0,1,1,"cuda:0"],[3604,3391,0,1,1,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[3610,1090,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::empty", "id": 3613, "rf_id": 2535, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[],6,0,"cpu",false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","Int","Int","Device","Bool","None"],
      "outputs": [[3614,3615,0,1,4,"cpu"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty_strided", "id": 3618, "rf_id": 2538, "parent": 3617, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[],[],6,0,"cuda:0",false], "input_shapes": [[],[],[],[],[],[]], "input_types": ["GenericList[]","GenericList[]","Int","Int","Device","Bool"],
      "outputs": [[3619,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 3620, "rf_id": 2539, "parent": 3617, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3619,1262,0,1,4,"cuda:0"],[3614,3615,0,1,4,"cpu"],false], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(float)","Bool"],
      "outputs": [[3619,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 3617, "rf_id": 2537, "parent": 3616, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3614,3615,0,1,4,"cpu"],6,"<None>","cuda:0","<None>",false,"<None>"], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Tensor(float)","Int","None","Device","None","Bool","None"],
      "outputs": [[3619,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 3616, "rf_id": 2536, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3614,3615,0,1,4,"cpu"],"cuda:0",6,false,false,"<None>"], "input_shapes": [[],[],[],[],[],[]], "input_types": ["Tensor(float)","Device","Int","Bool","Bool","None"],
      "outputs": [[3619,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::lift_fresh", "id": 3621, "rf_id": 2540, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::lift_fresh(Tensor(a) self) -> Tensor(a)",
      "inputs": [[3619,1262,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[3619,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "detach_", "id": 3623, "rf_id": 2542, "parent": 3622, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3619,1262,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::detach_", "id": 3622, "rf_id": 2541, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::detach_(Tensor(a!) self) -> Tensor(a!)",
      "inputs": [[3619,1262,0,1,4,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(float)"],
      "outputs": [[3619,1262,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::mul", "id": 3624, "rf_id": 2543, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[3610,1090,0,1,1,"cuda:0"],[3619,1262,0,1,4,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(float)"],
      "outputs": [[3625,1178,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::empty", "id": 3627, "rf_id": 2545, "parent": 3626, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[0],11,0,"cuda:0","<None>","<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","Int","Device","None","None"],
      "outputs": [[3628,57,0,0,1,"cuda:0"]], "output_shapes": [[0]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::resize_", "id": 3630, "rf_id": 2547, "parent": 3629, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)",
      "inputs": [[3628,57,0,0,1,"cuda:0"],[],"<None>"], "input_shapes": [[0],[],[]], "input_types": ["Tensor(bool)","GenericList[]","None"],
      "outputs": [[3628,1096,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_not", "id": 3629, "rf_id": 2546, "parent": 3626, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_not.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)",
      "inputs": [[3610,1090,0,1,1,"cuda:0"],[3628,57,0,0,1,"cuda:0"]], "input_shapes": [[],[0]], "input_types": ["Tensor(bool)","Tensor(bool)"],
      "outputs": [[3628,1096,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::logical_not", "id": 3626, "rf_id": 2544, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::logical_not(Tensor self) -> Tensor",
      "inputs": [[3610,1090,0,1,1,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(bool)"],
      "outputs": [[3628,1096,0,1,1,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(bool)"]
    },
    {
      "name": "aten::mul", "id": 3631, "rf_id": 2548, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[3628,1096,0,1,1,"cuda:0"],[3596,1195,0,1,8,"cuda:0"]], "input_shapes": [[],[]], "input_types": ["Tensor(bool)","Tensor(double)"],
      "outputs": [[3632,3633,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::add", "id": 3634, "rf_id": 2549, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[3625,1178,0,1,4,"cuda:0"],[3632,3633,0,1,8,"cuda:0"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(double)","Int"],
      "outputs": [[3635,1096,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::result_type", "id": 3637, "rf_id": 2551, "parent": 3636, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::result_type.Scalar(Tensor tensor, Scalar other) -> ScalarType",
      "inputs": [[3453,1082,0,1,8,"cuda:0"],2.000000], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [7], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::to", "id": 3638, "rf_id": 2552, "parent": 3636, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3453,1082,0,1,8,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[3453,1082,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::pow", "id": 3636, "rf_id": 2550, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -> Tensor",
      "inputs": [[3453,1082,0,1,8,"cuda:0"],2.000000], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [[3639,5,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::add", "id": 3641, "rf_id": 2553, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[3639,5,0,1,8,"cuda:0"],[3584,3640,0,1,8,"cpu"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(double)","Tensor(double)","Int"],
      "outputs": [[3642,198,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::result_type", "id": 3644, "rf_id": 2555, "parent": 3643, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::result_type.Scalar(Tensor tensor, Scalar other) -> ScalarType",
      "inputs": [[3635,1096,0,1,8,"cuda:0"],2.000000], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [7], "output_shapes": [[]], "output_types": ["Int"]
    },
    {
      "name": "aten::to", "id": 3645, "rf_id": 2556, "parent": 3643, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3635,1096,0,1,8,"cuda:0"],7,false,false,"<None>"], "input_shapes": [[],[],[],[],[]], "input_types": ["Tensor(double)","Int","Bool","Bool","None"],
      "outputs": [[3635,1096,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::pow", "id": 3643, "rf_id": 2554, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -> Tensor",
      "inputs": [[3635,1096,0,1,8,"cuda:0"],2.000000], "input_shapes": [[],[]], "input_types": ["Tensor(double)","Double"],
      "outputs": [[3646,5,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::add_", "id": 3647, "rf_id": 2557, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)",
      "inputs": [[3642,198,0,1,8,"cuda:0"],[3646,5,0,1,8,"cuda:0"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(double)","Tensor(double)","Int"],
      "outputs": [[3642,198,0,1,8,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(double)"]
    },
    {
      "name": "aten::_local_scalar_dense", "id": 3649, "rf_id": 2559, "parent": 3648, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_local_scalar_dense(Tensor self) -> Scalar",
      "inputs": [[3642,198,0,1,8,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [22.060853], "output_shapes": [[]], "output_types": ["Double"]
    },
    {
      "name": "aten::item", "id": 3648, "rf_id": 2558, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::item(Tensor self) -> Scalar",
      "inputs": [[3642,198,0,1,8,"cuda:0"]], "input_shapes": [[]], "input_types": ["Tensor(double)"],
      "outputs": [22.060853], "output_shapes": [[]], "output_types": ["Double"]
    },
    {
      "name": "aten::view", "id": 3651, "rf_id": 2561, "parent": 3650, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3120,3121,0,12877824,2,"cuda:0"],[-1]], "input_shapes": [[12877824],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3652,3121,0,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3653, "rf_id": 2562, "parent": 3650, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3128,3121,12877824,5120,2,"cuda:0"],[-1]], "input_shapes": [[5120],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3654,3121,12877824,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3655, "rf_id": 2563, "parent": 3650, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3150,3121,12882944,786432,2,"cuda:0"],[-1]], "input_shapes": [[786432],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3656,3121,12882944,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3657, "rf_id": 2564, "parent": 3650, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3166,3121,13669376,262144,2,"cuda:0"],[-1]], "input_shapes": [[262144],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3658,3121,13669376,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3659, "rf_id": 2565, "parent": 3650, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3198,3121,13931520,1048576,2,"cuda:0"],[-1]], "input_shapes": [[1048576],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3660,3121,13931520,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3661, "rf_id": 2566, "parent": 3650, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3214,3121,14980096,1048576,2,"cuda:0"],[-1]], "input_shapes": [[1048576],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3662,3121,14980096,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 3663, "rf_id": 2567, "parent": 3650, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[3652,3121,0,12877824,2,"cuda:0"],[3654,3121,12877824,5120,2,"cuda:0"],[3656,3121,12882944,786432,2,"cuda:0"],[3658,3121,13669376,262144,2,"cuda:0"],[3660,3121,13931520,1048576,2,"cuda:0"],[3662,3121,14980096,1048576,2,"cuda:0"]],0], "input_shapes": [[[12877824],[5120],[786432],[262144],[1048576],[1048576]],[]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int"],
      "outputs": [[3664,1056,0,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::flatten_dense_tensors", "id": 3650, "rf_id": 2560, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::flatten_dense_tensors(Tensor[] tensors) -> Tensor",
      "inputs": [[[3120,3121,0,12877824,2,"cuda:0"],[3128,3121,12877824,5120,2,"cuda:0"],[3150,3121,12882944,786432,2,"cuda:0"],[3166,3121,13669376,262144,2,"cuda:0"],[3198,3121,13931520,1048576,2,"cuda:0"],[3214,3121,14980096,1048576,2,"cuda:0"]]], "input_shapes": [[[12877824],[5120],[786432],[262144],[1048576],[1048576]]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"],
      "outputs": [[3664,1056,0,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3667, "rf_id": 2570, "parent": 3666, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[16028672],[1],6,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3668,1077,0,16028672,4,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 3669, "rf_id": 2571, "parent": 3666, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3668,1077,0,16028672,4,"cuda:0"],[3664,1056,0,16028672,2,"cuda:0"],false], "input_shapes": [[16028672],[16028672],[]], "input_types": ["Tensor(float)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3668,1077,0,16028672,4,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 3666, "rf_id": 2569, "parent": 3665, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3664,1056,0,16028672,2,"cuda:0"],6,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[16028672],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3668,1077,0,16028672,4,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 3665, "rf_id": 2568, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3664,1056,0,16028672,2,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[16028672],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3668,1077,0,16028672,4,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::record_stream", "id": 3670, "rf_id": 2572, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3120,3121,0,12877824,2,"cuda:0"],"<Stream>"], "input_shapes": [[12877824],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3671, "rf_id": 2573, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3128,3121,12877824,5120,2,"cuda:0"],"<Stream>"], "input_shapes": [[5120],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3672, "rf_id": 2574, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3150,3121,12882944,786432,2,"cuda:0"],"<Stream>"], "input_shapes": [[786432],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3673, "rf_id": 2575, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3166,3121,13669376,262144,2,"cuda:0"],"<Stream>"], "input_shapes": [[262144],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3674, "rf_id": 2576, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3198,3121,13931520,1048576,2,"cuda:0"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3675, "rf_id": 2577, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3214,3121,14980096,1048576,2,"cuda:0"],"<Stream>"], "input_shapes": [[1048576],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::mul_", "id": 3678, "rf_id": 2578, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[3668,1077,0,16028672,4,"cuda:0"],[3676,3677,0,1,8,"cpu"]], "input_shapes": [[16028672],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[3668,1077,0,16028672,4,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "Optimizer.step#FusedAdam.step", "id": 3679, "rf_id": 2579, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::copy_", "id": 3683, "rf_id": 2580, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3680,239,0,16028672,2,"cuda:0"],[3681,3682,0,16028672,4,"cuda:0"],false], "input_shapes": [[16028672],[16028672],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(float)","Bool"],
      "outputs": [[3680,239,0,16028672,2,"cuda:0"]], "output_shapes": [[16028672]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3689, "rf_id": 2584, "parent": 3688, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],[12877824],[1],0], "input_shapes": [[16028672],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3690,239,0,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3688, "rf_id": 2583, "parent": 3687, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],0,0,12877824,1], "input_shapes": [[16028672],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3690,239,0,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3687, "rf_id": 2582, "parent": 3686, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],0,0,12877824], "input_shapes": [[16028672],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3690,239,0,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3691, "rf_id": 2585, "parent": 3686, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3690,239,0,12877824,2,"cuda:0"],[12877824]], "input_shapes": [[12877824],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3692,239,0,12877824,2,"cuda:0"]], "output_shapes": [[12877824]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3695, "rf_id": 2588, "parent": 3694, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],[5120],[1],12877824], "input_shapes": [[16028672],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3696,239,12877824,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3694, "rf_id": 2587, "parent": 3693, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],0,12877824,12882944,1], "input_shapes": [[16028672],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3696,239,12877824,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3693, "rf_id": 2586, "parent": 3686, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],0,12877824,5120], "input_shapes": [[16028672],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3696,239,12877824,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3697, "rf_id": 2589, "parent": 3686, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3696,239,12877824,5120,2,"cuda:0"],[5120]], "input_shapes": [[5120],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3698,239,12877824,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3701, "rf_id": 2592, "parent": 3700, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],[786432],[1],12882944], "input_shapes": [[16028672],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3702,239,12882944,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3700, "rf_id": 2591, "parent": 3699, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],0,12882944,13669376,1], "input_shapes": [[16028672],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3702,239,12882944,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3699, "rf_id": 2590, "parent": 3686, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],0,12882944,786432], "input_shapes": [[16028672],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3702,239,12882944,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3703, "rf_id": 2593, "parent": 3686, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3702,239,12882944,786432,2,"cuda:0"],[786432]], "input_shapes": [[786432],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3704,239,12882944,786432,2,"cuda:0"]], "output_shapes": [[786432]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3707, "rf_id": 2596, "parent": 3706, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],[262144],[1],13669376], "input_shapes": [[16028672],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3708,239,13669376,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3706, "rf_id": 2595, "parent": 3705, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],0,13669376,13931520,1], "input_shapes": [[16028672],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3708,239,13669376,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3705, "rf_id": 2594, "parent": 3686, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],0,13669376,262144], "input_shapes": [[16028672],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3708,239,13669376,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3709, "rf_id": 2597, "parent": 3686, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3708,239,13669376,262144,2,"cuda:0"],[262144]], "input_shapes": [[262144],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3710,239,13669376,262144,2,"cuda:0"]], "output_shapes": [[262144]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3713, "rf_id": 2600, "parent": 3712, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],[1048576],[1],13931520], "input_shapes": [[16028672],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3714,239,13931520,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3712, "rf_id": 2599, "parent": 3711, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],0,13931520,14980096,1], "input_shapes": [[16028672],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3714,239,13931520,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3711, "rf_id": 2598, "parent": 3686, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],0,13931520,1048576], "input_shapes": [[16028672],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3714,239,13931520,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3715, "rf_id": 2601, "parent": 3686, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3714,239,13931520,1048576,2,"cuda:0"],[1048576]], "input_shapes": [[1048576],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3716,239,13931520,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3719, "rf_id": 2604, "parent": 3718, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],[1048576],[1],14980096], "input_shapes": [[16028672],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3720,239,14980096,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3718, "rf_id": 2603, "parent": 3717, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],0,14980096,16028672,1], "input_shapes": [[16028672],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3720,239,14980096,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3717, "rf_id": 2602, "parent": 3686, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],0,14980096,1048576], "input_shapes": [[16028672],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3720,239,14980096,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3721, "rf_id": 2605, "parent": 3686, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3720,239,14980096,1048576,2,"cuda:0"],[1048576]], "input_shapes": [[1048576],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3722,239,14980096,1048576,2,"cuda:0"]], "output_shapes": [[1048576]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::unflatten_dense_tensors", "id": 3686, "rf_id": 2581, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unflatten_dense_tensors(Tensor flat, Tensor[] tensors) -> Tensor[]",
      "inputs": [[3684,239,0,16028672,2,"cuda:0"],[[238,239,0,12877824,2,"cuda:0"],[3685,239,12877824,5120,2,"cuda:0"],[273,239,12882944,786432,2,"cuda:0"],[275,239,13669376,262144,2,"cuda:0"],[277,239,13931520,1048576,2,"cuda:0"],[279,239,14980096,1048576,2,"cuda:0"]]], "input_shapes": [[16028672],[[12877824],[5120],[786432],[262144],[1048576],[1048576]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"],
      "outputs": [[[3692,239,0,12877824,2,"cuda:0"],[3698,239,12877824,5120,2,"cuda:0"],[3704,239,12882944,786432,2,"cuda:0"],[3710,239,13669376,262144,2,"cuda:0"],[3716,239,13931520,1048576,2,"cuda:0"],[3722,239,14980096,1048576,2,"cuda:0"]]], "output_shapes": [[[12877824],[5120],[786432],[262144],[1048576],[1048576]]], "output_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3724, "rf_id": 2606, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[238,239,0,12877824,2,"cuda:0"],[3723,239,0,12877824,2,"cuda:0"]], "input_shapes": [[12877824],[12877824]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3726, "rf_id": 2607, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3685,239,12877824,5120,2,"cuda:0"],[3725,239,12877824,5120,2,"cuda:0"]], "input_shapes": [[5120],[5120]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3728, "rf_id": 2608, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[273,239,12882944,786432,2,"cuda:0"],[3727,239,12882944,786432,2,"cuda:0"]], "input_shapes": [[786432],[786432]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3730, "rf_id": 2609, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[275,239,13669376,262144,2,"cuda:0"],[3729,239,13669376,262144,2,"cuda:0"]], "input_shapes": [[262144],[262144]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3732, "rf_id": 2610, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[277,239,13931520,1048576,2,"cuda:0"],[3731,239,13931520,1048576,2,"cuda:0"]], "input_shapes": [[1048576],[1048576]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3734, "rf_id": 2611, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[279,239,14980096,1048576,2,"cuda:0"],[3733,239,14980096,1048576,2,"cuda:0"]], "input_shapes": [[1048576],[1048576]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::view", "id": 3736, "rf_id": 2613, "parent": 3735, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3135,3121,16028672,256,2,"cuda:0"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3722,3121,16028672,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3737, "rf_id": 2614, "parent": 3735, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3142,3121,16028928,256,2,"cuda:0"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3692,3121,16028928,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3738, "rf_id": 2615, "parent": 3735, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3158,3121,16029184,768,2,"cuda:0"],[-1]], "input_shapes": [[768],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3698,3121,16029184,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3739, "rf_id": 2616, "parent": 3735, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3174,3121,16029952,256,2,"cuda:0"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3704,3121,16029952,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3740, "rf_id": 2617, "parent": 3735, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3182,3121,16030208,256,2,"cuda:0"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3710,3121,16030208,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3741, "rf_id": 2618, "parent": 3735, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3190,3121,16030464,256,2,"cuda:0"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3716,3121,16030464,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3742, "rf_id": 2619, "parent": 3735, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3206,3121,16030720,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3743,3121,16030720,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3744, "rf_id": 2620, "parent": 3735, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3222,3121,16031744,256,2,"cuda:0"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3745,3121,16031744,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3746, "rf_id": 2621, "parent": 3735, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3230,3121,16032000,256,2,"cuda:0"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3747,3121,16032000,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3748, "rf_id": 2622, "parent": 3735, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3238,3121,16032256,256,2,"cuda:0"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3749,3121,16032256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::cat", "id": 3750, "rf_id": 2623, "parent": 3735, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::cat(Tensor[] tensors, int dim=0) -> Tensor",
      "inputs": [[[3722,3121,16028672,256,2,"cuda:0"],[3692,3121,16028928,256,2,"cuda:0"],[3698,3121,16029184,768,2,"cuda:0"],[3704,3121,16029952,256,2,"cuda:0"],[3710,3121,16030208,256,2,"cuda:0"],[3716,3121,16030464,256,2,"cuda:0"],[3743,3121,16030720,1024,2,"cuda:0"],[3745,3121,16031744,256,2,"cuda:0"],[3747,3121,16032000,256,2,"cuda:0"],[3749,3121,16032256,256,2,"cuda:0"]],0], "input_shapes": [[[256],[256],[768],[256],[256],[256],[1024],[256],[256],[256]],[]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]","Int"],
      "outputs": [[3751,425,0,3840,2,"cuda:0"]], "output_shapes": [[3840]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::flatten_dense_tensors", "id": 3735, "rf_id": 2612, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::flatten_dense_tensors(Tensor[] tensors) -> Tensor",
      "inputs": [[[3135,3121,16028672,256,2,"cuda:0"],[3142,3121,16028928,256,2,"cuda:0"],[3158,3121,16029184,768,2,"cuda:0"],[3174,3121,16029952,256,2,"cuda:0"],[3182,3121,16030208,256,2,"cuda:0"],[3190,3121,16030464,256,2,"cuda:0"],[3206,3121,16030720,1024,2,"cuda:0"],[3222,3121,16031744,256,2,"cuda:0"],[3230,3121,16032000,256,2,"cuda:0"],[3238,3121,16032256,256,2,"cuda:0"]]], "input_shapes": [[[256],[256],[768],[256],[256],[256],[1024],[256],[256],[256]]], "input_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"],
      "outputs": [[3751,425,0,3840,2,"cuda:0"]], "output_shapes": [[3840]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty_strided", "id": 3754, "rf_id": 2626, "parent": 3753, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor",
      "inputs": [[3840],[1],6,0,"cuda:0",false], "input_shapes": [[[]],[[]],[],[],[],[]], "input_types": ["GenericList[Int]","GenericList[Int]","Int","Int","Device","Bool"],
      "outputs": [[3755,820,0,3840,4,"cuda:0"]], "output_shapes": [[3840]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::copy_", "id": 3756, "rf_id": 2627, "parent": 3753, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3755,820,0,3840,4,"cuda:0"],[3751,425,0,3840,2,"cuda:0"],false], "input_shapes": [[3840],[3840],[]], "input_types": ["Tensor(float)","Tensor(c10::BFloat16)","Bool"],
      "outputs": [[3755,820,0,3840,4,"cuda:0"]], "output_shapes": [[3840]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::_to_copy", "id": 3753, "rf_id": 2625, "parent": 3752, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3751,425,0,3840,2,"cuda:0"],6,"<None>","<None>","<None>",false,"<None>"], "input_shapes": [[3840],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","None","None","None","Bool","None"],
      "outputs": [[3755,820,0,3840,4,"cuda:0"]], "output_shapes": [[3840]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::to", "id": 3752, "rf_id": 2624, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3751,425,0,3840,2,"cuda:0"],6,false,false,"<None>"], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Bool","Bool","None"],
      "outputs": [[3755,820,0,3840,4,"cuda:0"]], "output_shapes": [[3840]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::record_stream", "id": 3757, "rf_id": 2628, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3135,3121,16028672,256,2,"cuda:0"],"<Stream>"], "input_shapes": [[256],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3758, "rf_id": 2629, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3142,3121,16028928,256,2,"cuda:0"],"<Stream>"], "input_shapes": [[256],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3759, "rf_id": 2630, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3158,3121,16029184,768,2,"cuda:0"],"<Stream>"], "input_shapes": [[768],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3760, "rf_id": 2631, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3174,3121,16029952,256,2,"cuda:0"],"<Stream>"], "input_shapes": [[256],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3761, "rf_id": 2632, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3182,3121,16030208,256,2,"cuda:0"],"<Stream>"], "input_shapes": [[256],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3762, "rf_id": 2633, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3190,3121,16030464,256,2,"cuda:0"],"<Stream>"], "input_shapes": [[256],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3763, "rf_id": 2634, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3206,3121,16030720,1024,2,"cuda:0"],"<Stream>"], "input_shapes": [[1024],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3764, "rf_id": 2635, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3222,3121,16031744,256,2,"cuda:0"],"<Stream>"], "input_shapes": [[256],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3765, "rf_id": 2636, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3230,3121,16032000,256,2,"cuda:0"],"<Stream>"], "input_shapes": [[256],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::record_stream", "id": 3766, "rf_id": 2637, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::record_stream(Tensor(a!) self, Stream s) -> ()",
      "inputs": [[3238,3121,16032256,256,2,"cuda:0"],"<Stream>"], "input_shapes": [[256],[]], "input_types": ["Tensor(c10::BFloat16)","Stream"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::mul_", "id": 3769, "rf_id": 2638, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::mul_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)",
      "inputs": [[3755,820,0,3840,4,"cuda:0"],[3767,3768,0,1,8,"cpu"]], "input_shapes": [[3840],[]], "input_types": ["Tensor(float)","Tensor(double)"],
      "outputs": [[3755,820,0,3840,4,"cuda:0"]], "output_shapes": [[3840]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "Optimizer.step#FusedAdam.step", "id": 3770, "rf_id": 2639, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::copy_", "id": 3774, "rf_id": 2640, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)",
      "inputs": [[3771,239,16028672,3840,2,"cuda:0"],[3772,3773,0,3840,4,"cuda:0"],false], "input_shapes": [[3840],[3840],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(float)","Bool"],
      "outputs": [[3771,239,16028672,3840,2,"cuda:0"]], "output_shapes": [[3840]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3789, "rf_id": 2644, "parent": 3788, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],[256],[1],16028672], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3790,239,16028672,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3788, "rf_id": 2643, "parent": 3787, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,0,256,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3790,239,16028672,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3787, "rf_id": 2642, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,0,256], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3790,239,16028672,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3791, "rf_id": 2645, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3790,239,16028672,256,2,"cuda:0"],[256]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3792,239,16028672,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3795, "rf_id": 2648, "parent": 3794, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],[256],[1],16028928], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3796,239,16028928,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3794, "rf_id": 2647, "parent": 3793, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,256,512,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3796,239,16028928,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3793, "rf_id": 2646, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,256,256], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3796,239,16028928,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3797, "rf_id": 2649, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3796,239,16028928,256,2,"cuda:0"],[256]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3798,239,16028928,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3801, "rf_id": 2652, "parent": 3800, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],[768],[1],16029184], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3802,239,16029184,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3800, "rf_id": 2651, "parent": 3799, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,512,1280,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3802,239,16029184,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3799, "rf_id": 2650, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,512,768], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3802,239,16029184,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3803, "rf_id": 2653, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3802,239,16029184,768,2,"cuda:0"],[768]], "input_shapes": [[768],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3804,239,16029184,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3807, "rf_id": 2656, "parent": 3806, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],[256],[1],16029952], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3808,239,16029952,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3806, "rf_id": 2655, "parent": 3805, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,1280,1536,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3808,239,16029952,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3805, "rf_id": 2654, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,1280,256], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3808,239,16029952,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3809, "rf_id": 2657, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3808,239,16029952,256,2,"cuda:0"],[256]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3810,239,16029952,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3813, "rf_id": 2660, "parent": 3812, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],[256],[1],16030208], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3814,239,16030208,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3812, "rf_id": 2659, "parent": 3811, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,1536,1792,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3814,239,16030208,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3811, "rf_id": 2658, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,1536,256], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3814,239,16030208,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3815, "rf_id": 2661, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3814,239,16030208,256,2,"cuda:0"],[256]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3816,239,16030208,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3819, "rf_id": 2664, "parent": 3818, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],[256],[1],16030464], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3820,239,16030464,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3818, "rf_id": 2663, "parent": 3817, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,1792,2048,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3820,239,16030464,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3817, "rf_id": 2662, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,1792,256], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3820,239,16030464,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3821, "rf_id": 2665, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3820,239,16030464,256,2,"cuda:0"],[256]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3822,239,16030464,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3825, "rf_id": 2668, "parent": 3824, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],[1024],[1],16030720], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3826,239,16030720,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3824, "rf_id": 2667, "parent": 3823, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,2048,3072,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3826,239,16030720,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3823, "rf_id": 2666, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,2048,1024], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3826,239,16030720,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3827, "rf_id": 2669, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3826,239,16030720,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3828,239,16030720,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3831, "rf_id": 2672, "parent": 3830, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],[256],[1],16031744], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3832,239,16031744,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3830, "rf_id": 2671, "parent": 3829, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,3072,3328,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3832,239,16031744,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3829, "rf_id": 2670, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,3072,256], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3832,239,16031744,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3833, "rf_id": 2673, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3832,239,16031744,256,2,"cuda:0"],[256]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3834,239,16031744,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3837, "rf_id": 2676, "parent": 3836, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],[256],[1],16032000], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3838,239,16032000,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3836, "rf_id": 2675, "parent": 3835, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,3328,3584,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3838,239,16032000,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3835, "rf_id": 2674, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,3328,256], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3838,239,16032000,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3839, "rf_id": 2677, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3838,239,16032000,256,2,"cuda:0"],[256]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3840,239,16032000,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::as_strided", "id": 3843, "rf_id": 2680, "parent": 3842, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],[256],[1],16032256], "input_shapes": [[3840],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3844,239,16032256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3842, "rf_id": 2679, "parent": 3841, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,3584,3840,1], "input_shapes": [[3840],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3844,239,16032256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3841, "rf_id": 2678, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],0,3584,256], "input_shapes": [[3840],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3844,239,16032256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3845, "rf_id": 2681, "parent": 3786, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3844,239,16032256,256,2,"cuda:0"],[256]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3846,239,16032256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::unflatten_dense_tensors", "id": 3786, "rf_id": 2641, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::unflatten_dense_tensors(Tensor flat, Tensor[] tensors) -> Tensor[]",
      "inputs": [[3775,239,16028672,3840,2,"cuda:0"],[[3776,239,16028672,256,2,"cuda:0"],[3777,239,16028928,256,2,"cuda:0"],[3778,239,16029184,768,2,"cuda:0"],[3779,239,16029952,256,2,"cuda:0"],[3780,239,16030208,256,2,"cuda:0"],[3781,239,16030464,256,2,"cuda:0"],[3782,239,16030720,1024,2,"cuda:0"],[3783,239,16031744,256,2,"cuda:0"],[3784,239,16032000,256,2,"cuda:0"],[3785,239,16032256,256,2,"cuda:0"]]], "input_shapes": [[3840],[[256],[256],[768],[256],[256],[256],[1024],[256],[256],[256]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"],
      "outputs": [[[3792,239,16028672,256,2,"cuda:0"],[3798,239,16028928,256,2,"cuda:0"],[3804,239,16029184,768,2,"cuda:0"],[3810,239,16029952,256,2,"cuda:0"],[3816,239,16030208,256,2,"cuda:0"],[3822,239,16030464,256,2,"cuda:0"],[3828,239,16030720,1024,2,"cuda:0"],[3834,239,16031744,256,2,"cuda:0"],[3840,239,16032000,256,2,"cuda:0"],[3846,239,16032256,256,2,"cuda:0"]]], "output_shapes": [[[256],[256],[768],[256],[256],[256],[1024],[256],[256],[256]]], "output_types": ["GenericList[Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16),Tensor(c10::BFloat16)]"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3848, "rf_id": 2682, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3776,239,16028672,256,2,"cuda:0"],[3847,239,16028672,256,2,"cuda:0"]], "input_shapes": [[256],[256]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3850, "rf_id": 2683, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3777,239,16028928,256,2,"cuda:0"],[3849,239,16028928,256,2,"cuda:0"]], "input_shapes": [[256],[256]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3852, "rf_id": 2684, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3778,239,16029184,768,2,"cuda:0"],[3851,239,16029184,768,2,"cuda:0"]], "input_shapes": [[768],[768]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3854, "rf_id": 2685, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3779,239,16029952,256,2,"cuda:0"],[3853,239,16029952,256,2,"cuda:0"]], "input_shapes": [[256],[256]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3856, "rf_id": 2686, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3780,239,16030208,256,2,"cuda:0"],[3855,239,16030208,256,2,"cuda:0"]], "input_shapes": [[256],[256]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3858, "rf_id": 2687, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3781,239,16030464,256,2,"cuda:0"],[3857,239,16030464,256,2,"cuda:0"]], "input_shapes": [[256],[256]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3860, "rf_id": 2688, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3782,239,16030720,1024,2,"cuda:0"],[3859,239,16030720,1024,2,"cuda:0"]], "input_shapes": [[1024],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3862, "rf_id": 2689, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3783,239,16031744,256,2,"cuda:0"],[3861,239,16031744,256,2,"cuda:0"]], "input_shapes": [[256],[256]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3864, "rf_id": 2690, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3784,239,16032000,256,2,"cuda:0"],[3863,239,16032000,256,2,"cuda:0"]], "input_shapes": [[256],[256]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3866, "rf_id": 2691, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[3785,239,16032256,256,2,"cuda:0"],[3865,239,16032256,256,2,"cuda:0"]], "input_shapes": [[256],[256]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::to", "id": 3867, "rf_id": 2692, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3685,239,12877824,5120,2,"cuda:0"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[5120],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3685,239,12877824,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3868, "rf_id": 2693, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3776,239,16028672,256,2,"cuda:0"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3776,239,16028672,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3869, "rf_id": 2694, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3777,239,16028928,256,2,"cuda:0"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3777,239,16028928,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3870, "rf_id": 2695, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3778,239,16029184,768,2,"cuda:0"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[768],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3778,239,16029184,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3871, "rf_id": 2696, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3779,239,16029952,256,2,"cuda:0"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3779,239,16029952,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3872, "rf_id": 2697, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3780,239,16030208,256,2,"cuda:0"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3780,239,16030208,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3873, "rf_id": 2698, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3781,239,16030464,256,2,"cuda:0"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3781,239,16030464,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3874, "rf_id": 2699, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3782,239,16030720,1024,2,"cuda:0"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[1024],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3782,239,16030720,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3875, "rf_id": 2700, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3783,239,16031744,256,2,"cuda:0"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3783,239,16031744,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3876, "rf_id": 2701, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3784,239,16032000,256,2,"cuda:0"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3784,239,16032000,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::to", "id": 3877, "rf_id": 2702, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)",
      "inputs": [[3785,239,16032256,256,2,"cuda:0"],15,0,"cuda","<None>",false,false,"<None>"], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Device","None","Bool","Bool","None"],
      "outputs": [[3785,239,16032256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3878, "rf_id": 2703, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[20480],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3804,345,0,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3879, "rf_id": 2704, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3804,345,0,20480,2,"cuda:0"],[-1]], "input_shapes": [[20480],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3810,345,0,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3880, "rf_id": 2705, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1024],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3816,1086,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3881, "rf_id": 2706, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3816,1086,0,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3822,1086,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3882, "rf_id": 2707, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1024],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3828,3633,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3883, "rf_id": 2708, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3828,3633,0,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3834,3633,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3884, "rf_id": 2709, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[3072],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3840,425,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3885, "rf_id": 2710, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3840,425,0,3072,2,"cuda:0"],[-1]], "input_shapes": [[3072],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3886,425,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3887, "rf_id": 2711, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1024],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3888,1214,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3889, "rf_id": 2712, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3888,1214,0,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3846,1214,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3890, "rf_id": 2713, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1024],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3891,3396,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3892, "rf_id": 2714, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3891,3396,0,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3893,3396,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3894, "rf_id": 2715, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1024],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3895,3896,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3897, "rf_id": 2716, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3895,3896,0,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3898,3896,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3899, "rf_id": 2717, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[4096],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3900,820,0,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3901, "rf_id": 2718, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3900,820,0,4096,2,"cuda:0"],[-1]], "input_shapes": [[4096],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3902,820,0,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3903, "rf_id": 2719, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1024],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3904,3905,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3906, "rf_id": 2720, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3904,3905,0,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3907,3905,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3908, "rf_id": 2721, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1024],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3909,3910,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3911, "rf_id": 2722, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3909,3910,0,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3912,3910,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::empty", "id": 3913, "rf_id": 2723, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",
      "inputs": [[1024],15,"<None>","cuda:0",false,"<None>"], "input_shapes": [[[]],[],[],[],[],[]], "input_types": ["GenericList[Int]","Int","None","Device","Bool","None"],
      "outputs": [[3914,3915,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3916, "rf_id": 2724, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3914,3915,0,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3917,3915,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3918, "rf_id": 2725, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3685,239,12877824,5120,2,"cuda:0"],[-1]], "input_shapes": [[5120],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3919,239,12877824,5120,2,"cuda:0"]], "output_shapes": [[5120]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3922, "rf_id": 2728, "parent": 3921, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3919,239,12877824,5120,2,"cuda:0"]], "input_shapes": [[5120]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3921, "rf_id": 2727, "parent": 3920, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3919,239,12877824,5120,2,"cuda:0"],131,93827882276192,0,"_allgather_base",[],[],4], "input_shapes": [[5120],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3810,345,0,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3920, "rf_id": 2726, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3810,345,0,20480,2,"cuda:0"],[3919,239,12877824,5120,2,"cuda:0"],"<Object>",true,-1], "input_shapes": [[20480],[5120],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3810,345,0,20480,2,"cuda:0"],"<Object>"], "output_shapes": [[20480],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3923, "rf_id": 2729, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3776,239,16028672,256,2,"cuda:0"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3924,239,16028672,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3927, "rf_id": 2732, "parent": 3926, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3924,239,16028672,256,2,"cuda:0"]], "input_shapes": [[256]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3926, "rf_id": 2731, "parent": 3925, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3924,239,16028672,256,2,"cuda:0"],132,93827882276192,0,"_allgather_base",[],[],4], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3822,1086,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3925, "rf_id": 2730, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3822,1086,0,1024,2,"cuda:0"],[3924,239,16028672,256,2,"cuda:0"],"<Object>",true,-1], "input_shapes": [[1024],[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3822,1086,0,1024,2,"cuda:0"],"<Object>"], "output_shapes": [[1024],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3928, "rf_id": 2733, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3777,239,16028928,256,2,"cuda:0"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3929,239,16028928,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3932, "rf_id": 2736, "parent": 3931, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3929,239,16028928,256,2,"cuda:0"]], "input_shapes": [[256]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3931, "rf_id": 2735, "parent": 3930, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3929,239,16028928,256,2,"cuda:0"],133,93827882276192,0,"_allgather_base",[],[],4], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3834,3633,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3930, "rf_id": 2734, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3834,3633,0,1024,2,"cuda:0"],[3929,239,16028928,256,2,"cuda:0"],"<Object>",true,-1], "input_shapes": [[1024],[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3834,3633,0,1024,2,"cuda:0"],"<Object>"], "output_shapes": [[1024],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3933, "rf_id": 2737, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3778,239,16029184,768,2,"cuda:0"],[-1]], "input_shapes": [[768],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3934,239,16029184,768,2,"cuda:0"]], "output_shapes": [[768]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3937, "rf_id": 2740, "parent": 3936, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3934,239,16029184,768,2,"cuda:0"]], "input_shapes": [[768]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3936, "rf_id": 2739, "parent": 3935, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3934,239,16029184,768,2,"cuda:0"],134,93827882276192,0,"_allgather_base",[],[],4], "input_shapes": [[768],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3886,425,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3935, "rf_id": 2738, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3886,425,0,3072,2,"cuda:0"],[3934,239,16029184,768,2,"cuda:0"],"<Object>",true,-1], "input_shapes": [[3072],[768],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3886,425,0,3072,2,"cuda:0"],"<Object>"], "output_shapes": [[3072],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3938, "rf_id": 2741, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3779,239,16029952,256,2,"cuda:0"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3939,239,16029952,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3942, "rf_id": 2744, "parent": 3941, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3939,239,16029952,256,2,"cuda:0"]], "input_shapes": [[256]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3941, "rf_id": 2743, "parent": 3940, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3939,239,16029952,256,2,"cuda:0"],135,93827882276192,0,"_allgather_base",[],[],4], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3846,1214,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3940, "rf_id": 2742, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3846,1214,0,1024,2,"cuda:0"],[3939,239,16029952,256,2,"cuda:0"],"<Object>",true,-1], "input_shapes": [[1024],[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3846,1214,0,1024,2,"cuda:0"],"<Object>"], "output_shapes": [[1024],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3943, "rf_id": 2745, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3780,239,16030208,256,2,"cuda:0"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3944,239,16030208,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3947, "rf_id": 2748, "parent": 3946, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3944,239,16030208,256,2,"cuda:0"]], "input_shapes": [[256]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3946, "rf_id": 2747, "parent": 3945, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3944,239,16030208,256,2,"cuda:0"],136,93827882276192,0,"_allgather_base",[],[],4], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3893,3396,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3945, "rf_id": 2746, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3893,3396,0,1024,2,"cuda:0"],[3944,239,16030208,256,2,"cuda:0"],"<Object>",true,-1], "input_shapes": [[1024],[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3893,3396,0,1024,2,"cuda:0"],"<Object>"], "output_shapes": [[1024],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3948, "rf_id": 2749, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3781,239,16030464,256,2,"cuda:0"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3949,239,16030464,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3952, "rf_id": 2752, "parent": 3951, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3949,239,16030464,256,2,"cuda:0"]], "input_shapes": [[256]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3951, "rf_id": 2751, "parent": 3950, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3949,239,16030464,256,2,"cuda:0"],137,93827882276192,0,"_allgather_base",[],[],4], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3898,3896,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3950, "rf_id": 2750, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3898,3896,0,1024,2,"cuda:0"],[3949,239,16030464,256,2,"cuda:0"],"<Object>",true,-1], "input_shapes": [[1024],[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3898,3896,0,1024,2,"cuda:0"],"<Object>"], "output_shapes": [[1024],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3953, "rf_id": 2753, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3782,239,16030720,1024,2,"cuda:0"],[-1]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3954,239,16030720,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3957, "rf_id": 2756, "parent": 3956, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3954,239,16030720,1024,2,"cuda:0"]], "input_shapes": [[1024]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3956, "rf_id": 2755, "parent": 3955, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3954,239,16030720,1024,2,"cuda:0"],138,93827882276192,0,"_allgather_base",[],[],4], "input_shapes": [[1024],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3902,820,0,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3955, "rf_id": 2754, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3902,820,0,4096,2,"cuda:0"],[3954,239,16030720,1024,2,"cuda:0"],"<Object>",true,-1], "input_shapes": [[4096],[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3902,820,0,4096,2,"cuda:0"],"<Object>"], "output_shapes": [[4096],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3958, "rf_id": 2757, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3783,239,16031744,256,2,"cuda:0"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3959,239,16031744,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3962, "rf_id": 2760, "parent": 3961, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3959,239,16031744,256,2,"cuda:0"]], "input_shapes": [[256]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3961, "rf_id": 2759, "parent": 3960, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3959,239,16031744,256,2,"cuda:0"],139,93827882276192,0,"_allgather_base",[],[],4], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3907,3905,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3960, "rf_id": 2758, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3907,3905,0,1024,2,"cuda:0"],[3959,239,16031744,256,2,"cuda:0"],"<Object>",true,-1], "input_shapes": [[1024],[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3907,3905,0,1024,2,"cuda:0"],"<Object>"], "output_shapes": [[1024],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3963, "rf_id": 2761, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3784,239,16032000,256,2,"cuda:0"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3964,239,16032000,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3967, "rf_id": 2764, "parent": 3966, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3964,239,16032000,256,2,"cuda:0"]], "input_shapes": [[256]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3966, "rf_id": 2763, "parent": 3965, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3964,239,16032000,256,2,"cuda:0"],140,93827882276192,0,"_allgather_base",[],[],4], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3912,3910,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3965, "rf_id": 2762, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3912,3910,0,1024,2,"cuda:0"],[3964,239,16032000,256,2,"cuda:0"],"<Object>",true,-1], "input_shapes": [[1024],[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3912,3910,0,1024,2,"cuda:0"],"<Object>"], "output_shapes": [[1024],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "aten::view", "id": 3968, "rf_id": 2765, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3785,239,16032256,256,2,"cuda:0"],[-1]], "input_shapes": [[256],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3969,239,16032256,256,2,"cuda:0"]], "output_shapes": [[256]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "nccl:_all_gather_base", "id": 3972, "rf_id": 2768, "parent": 3971, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3969,239,16032256,256,2,"cuda:0"]], "input_shapes": [[256]], "input_types": ["Tensor(c10::BFloat16)"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "record_param_comms", "id": 3971, "rf_id": 2767, "parent": 3970, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [[3969,239,16032256,256,2,"cuda:0"],141,93827882276192,0,"_allgather_base",[],[],4], "input_shapes": [[256],[],[],[],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [[3917,3915,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "c10d::_allgather_base_", "id": 3970, "rf_id": 2766, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "c10d::_allgather_base_(Tensor output_tensor, Tensor input_tensor, __torch__.torch.classes.c10d.ProcessGroup process_group, bool asyncOp, int timeout) -> (Tensor, __torch__.torch.classes.c10d.Work)",
      "inputs": [[3917,3915,0,1024,2,"cuda:0"],[3969,239,16032256,256,2,"cuda:0"],"<Object>",true,-1], "input_shapes": [[1024],[256],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)","Object","Bool","Int"],
      "outputs": [[3917,3915,0,1024,2,"cuda:0"],"<Object>"], "output_shapes": [[1024],[]], "output_types": ["Tensor(c10::BFloat16)","Object"]
    },
    {
      "name": "record_param_comms", "id": 3973, "rf_id": 2769, "parent": 2, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "",
      "inputs": [141,0,0,"wait",[],[],1], "input_shapes": [[],[],[],[],[],[],[]], "input_types": ["Int","Int","Int","String","GenericList[]","GenericList[]","Int"],
      "outputs": [], "output_shapes": [], "output_types": []
    },
    {
      "name": "aten::as_strided", "id": 3976, "rf_id": 2772, "parent": 3975, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3810,345,0,20480,2,"cuda:0"],[20480],[1],0], "input_shapes": [[20480],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3977,345,0,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3975, "rf_id": 2771, "parent": 3974, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3810,345,0,20480,2,"cuda:0"],0,0,20480,1], "input_shapes": [[20480],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3977,345,0,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3974, "rf_id": 2770, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3810,345,0,20480,2,"cuda:0"],0,0,20480], "input_shapes": [[20480],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3977,345,0,20480,2,"cuda:0"]], "output_shapes": [[20480]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3978, "rf_id": 2773, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3977,345,0,20480,2,"cuda:0"],[20,1024]], "input_shapes": [[20480],[[],[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int,Int]"],
      "outputs": [[3979,345,0,20480,2,"cuda:0"]], "output_shapes": [[20,1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3981, "rf_id": 2774, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[344,57,0,0,2,"cuda:0"],[3980,345,0,20480,2,"cuda:0"]], "input_shapes": [[0],[20,1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 3984, "rf_id": 2777, "parent": 3983, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3822,1086,0,1024,2,"cuda:0"],[1024],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3979,1086,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3983, "rf_id": 2776, "parent": 3982, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3822,1086,0,1024,2,"cuda:0"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3979,1086,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3982, "rf_id": 2775, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3822,1086,0,1024,2,"cuda:0"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3979,1086,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3985, "rf_id": 2778, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3979,1086,0,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3986,1086,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3988, "rf_id": 2779, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[422,57,0,0,2,"cuda:0"],[3987,1086,0,1024,2,"cuda:0"]], "input_shapes": [[0],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 3991, "rf_id": 2782, "parent": 3990, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3834,3633,0,1024,2,"cuda:0"],[1024],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3986,3633,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3990, "rf_id": 2781, "parent": 3989, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3834,3633,0,1024,2,"cuda:0"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3986,3633,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3989, "rf_id": 2780, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3834,3633,0,1024,2,"cuda:0"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3986,3633,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3992, "rf_id": 2783, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3986,3633,0,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[3993,3633,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 3995, "rf_id": 2784, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[424,57,0,0,2,"cuda:0"],[3994,3633,0,1024,2,"cuda:0"]], "input_shapes": [[0],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 3998, "rf_id": 2787, "parent": 3997, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3886,425,0,3072,2,"cuda:0"],[3072],[1],0], "input_shapes": [[3072],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[3993,425,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 3997, "rf_id": 2786, "parent": 3996, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3886,425,0,3072,2,"cuda:0"],0,0,3072,1], "input_shapes": [[3072],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[3993,425,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 3996, "rf_id": 2785, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3886,425,0,3072,2,"cuda:0"],0,0,3072], "input_shapes": [[3072],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[3993,425,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 3999, "rf_id": 2788, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[3993,425,0,3072,2,"cuda:0"],[3072]], "input_shapes": [[3072],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[4000,425,0,3072,2,"cuda:0"]], "output_shapes": [[3072]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 4002, "rf_id": 2789, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[565,57,0,0,2,"cuda:0"],[4001,425,0,3072,2,"cuda:0"]], "input_shapes": [[0],[3072]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 4005, "rf_id": 2792, "parent": 4004, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3846,1214,0,1024,2,"cuda:0"],[1024],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[4000,1214,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 4004, "rf_id": 2791, "parent": 4003, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3846,1214,0,1024,2,"cuda:0"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[4000,1214,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 4003, "rf_id": 2790, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3846,1214,0,1024,2,"cuda:0"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[4000,1214,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 4006, "rf_id": 2793, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[4000,1214,0,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[4007,1214,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 4009, "rf_id": 2794, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[779,57,0,0,2,"cuda:0"],[4008,1214,0,1024,2,"cuda:0"]], "input_shapes": [[0],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 4012, "rf_id": 2797, "parent": 4011, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3893,3396,0,1024,2,"cuda:0"],[1024],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[4007,3396,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 4011, "rf_id": 2796, "parent": 4010, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3893,3396,0,1024,2,"cuda:0"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[4007,3396,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 4010, "rf_id": 2795, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3893,3396,0,1024,2,"cuda:0"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[4007,3396,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 4013, "rf_id": 2798, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[4007,3396,0,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[4014,3396,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 4016, "rf_id": 2799, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[817,57,0,0,2,"cuda:0"],[4015,3396,0,1024,2,"cuda:0"]], "input_shapes": [[0],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 4019, "rf_id": 2802, "parent": 4018, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3898,3896,0,1024,2,"cuda:0"],[1024],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[4014,3896,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 4018, "rf_id": 2801, "parent": 4017, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3898,3896,0,1024,2,"cuda:0"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[4014,3896,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 4017, "rf_id": 2800, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3898,3896,0,1024,2,"cuda:0"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[4014,3896,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 4020, "rf_id": 2803, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[4014,3896,0,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[4021,3896,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 4023, "rf_id": 2804, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[819,57,0,0,2,"cuda:0"],[4022,3896,0,1024,2,"cuda:0"]], "input_shapes": [[0],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 4026, "rf_id": 2807, "parent": 4025, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3902,820,0,4096,2,"cuda:0"],[4096],[1],0], "input_shapes": [[4096],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[4021,820,0,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 4025, "rf_id": 2806, "parent": 4024, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3902,820,0,4096,2,"cuda:0"],0,0,4096,1], "input_shapes": [[4096],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[4021,820,0,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 4024, "rf_id": 2805, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3902,820,0,4096,2,"cuda:0"],0,0,4096], "input_shapes": [[4096],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[4021,820,0,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 4027, "rf_id": 2808, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[4021,820,0,4096,2,"cuda:0"],[4096]], "input_shapes": [[4096],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[4028,820,0,4096,2,"cuda:0"]], "output_shapes": [[4096]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 4030, "rf_id": 2809, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[886,57,0,0,2,"cuda:0"],[4029,820,0,4096,2,"cuda:0"]], "input_shapes": [[0],[4096]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 4033, "rf_id": 2812, "parent": 4032, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3907,3905,0,1024,2,"cuda:0"],[1024],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[4028,3905,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 4032, "rf_id": 2811, "parent": 4031, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3907,3905,0,1024,2,"cuda:0"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[4028,3905,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 4031, "rf_id": 2810, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3907,3905,0,1024,2,"cuda:0"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[4028,3905,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 4034, "rf_id": 2813, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[4028,3905,0,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[4035,3905,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 4037, "rf_id": 2814, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[957,57,0,0,2,"cuda:0"],[4036,3905,0,1024,2,"cuda:0"]], "input_shapes": [[0],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 4040, "rf_id": 2817, "parent": 4039, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3912,3910,0,1024,2,"cuda:0"],[1024],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[4035,3910,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 4039, "rf_id": 2816, "parent": 4038, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3912,3910,0,1024,2,"cuda:0"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[4035,3910,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 4038, "rf_id": 2815, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3912,3910,0,1024,2,"cuda:0"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[4035,3910,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 4041, "rf_id": 2818, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[4035,3910,0,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[4042,3910,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 4044, "rf_id": 2819, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[993,57,0,0,2,"cuda:0"],[4043,3910,0,1024,2,"cuda:0"]], "input_shapes": [[0],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::as_strided", "id": 4047, "rf_id": 2822, "parent": 4046, "fw_parent": 0, "seq_id": -1, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)",
      "inputs": [[3917,3915,0,1024,2,"cuda:0"],[1024],[1],0], "input_shapes": [[1024],[[]],[[]],[]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]","GenericList[Int]","Int"],
      "outputs": [[4042,3915,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::slice", "id": 4046, "rf_id": 2821, "parent": 4045, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)",
      "inputs": [[3917,3915,0,1024,2,"cuda:0"],0,0,1024,1], "input_shapes": [[1024],[],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int","Int"],
      "outputs": [[4042,3915,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::narrow", "id": 4045, "rf_id": 2820, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -> Tensor(a)",
      "inputs": [[3917,3915,0,1024,2,"cuda:0"],0,0,1024], "input_shapes": [[1024],[],[],[]], "input_types": ["Tensor(c10::BFloat16)","Int","Int","Int"],
      "outputs": [[4042,3915,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::view", "id": 4048, "rf_id": 2823, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)",
      "inputs": [[4042,3915,0,1024,2,"cuda:0"],[1024]], "input_shapes": [[1024],[[]]], "input_types": ["Tensor(c10::BFloat16)","GenericList[Int]"],
      "outputs": [[4049,3915,0,1024,2,"cuda:0"]], "output_shapes": [[1024]], "output_types": ["Tensor(c10::BFloat16)"]
    },
    {
      "name": "aten::_has_compatible_shallow_copy_type", "id": 4051, "rf_id": 2824, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool",
      "inputs": [[995,57,0,0,2,"cuda:0"],[4050,3915,0,1024,2,"cuda:0"]], "input_shapes": [[0],[1024]], "input_types": ["Tensor(c10::BFloat16)","Tensor(c10::BFloat16)"],
      "outputs": [true], "output_shapes": [[]], "output_types": ["Bool"]
    },
    {
      "name": "aten::add", "id": 4054, "rf_id": 2825, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor",
      "inputs": [[1218,171,0,1,4,"cuda:0"],[4052,4053,0,1,8,"cpu"],1], "input_shapes": [[],[],[]], "input_types": ["Tensor(float)","Tensor(long int)","Int"],
      "outputs": [[4055,1096,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "aten::div", "id": 4058, "rf_id": 2826, "parent": 2, "fw_parent": 0, "seq_id": 477, "scope": 0, "tid": 1, "fw_tid": 0, "op_schema": "aten::div.Tensor(Tensor self, Tensor other) -> Tensor",
      "inputs": [[4055,1096,0,1,4,"cuda:0"],[4056,4057,0,1,8,"cpu"]], "input_shapes": [[],[]], "input_types": ["Tensor(float)","Tensor(long int)"],
      "outputs": [[4059,4060,0,1,4,"cuda:0"]], "output_shapes": [[]], "output_types": ["Tensor(float)"]
    },
    {
      "name": "[pytorch|profiler|execution_trace|process]", "id": 1, "rf_id": 0, "parent": 1, "fw_parent": 0, "seq_id": -1, "scope": 7, "tid": 0, "fw_tid": 0, "op_schema": "",
      "inputs": [], "input_shapes": [], "input_types": [],
      "outputs": [], "output_shapes": [], "output_types": []
    }
  ],
  "finish_ts": 11020159
}